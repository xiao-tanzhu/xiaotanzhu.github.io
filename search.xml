<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>利用telnet进行SMTP的验证</title>
    <url>/%E5%85%B6%E4%BB%96/2016-06-15-login-smtp-with-telnet.html</url>
    <content><![CDATA[<p>先计算BASE64编码的用户名密码，认证登录需要用到：</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">**fify<span class="variable">@fify</span>-<span class="title class_">Vostro</span><span class="number">-3902</span><span class="symbol">:~</span><span class="variable">$ </span>perl -<span class="title class_">MMIME</span>::<span class="title class_">Base64</span> -e <span class="string">&#x27;print encode_base64(&quot;wangjingfei&quot;);&#x27;</span>**</span><br><span class="line">d2FuZ2ppbmdmZWk=</span><br><span class="line">**fify<span class="variable">@fify</span>-<span class="title class_">Vostro</span><span class="number">-3902</span><span class="symbol">:~</span><span class="variable">$ </span>perl -<span class="title class_">MMIME</span>::<span class="title class_">Base64</span> -e <span class="string">&#x27;print encode_base64(&quot;fakepassword&quot;);&#x27;</span>**</span><br><span class="line"><span class="title class_">ZmFrZXBhc3N3b3Jk</span></span><br></pre></td></tr></table></figure>

<p>开始登录并使用SMTP发送邮件：</p>
<blockquote>
<p><strong>fify@fify-Vostro-3902:~$ telnet smtp.163.com 25</strong><br>Trying 123.125.50.133…<br>Connected to smtp.163.com.<br>Escape character is ‘^]’.<br>220 163.com Anti-spam GT for Coremail System (163com[20141201])<br><strong>EHLO smtp.163.com</strong> # 开始连接前握手<br>250-mail<br>250-PIPELINING<br>250-AUTH LOGIN PLAIN<br>250-AUTH=LOGIN PLAIN<br>250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8FY2U3Uj8Cz28x1UUUUU7Ic2I0Y2UFCvVepUCa0xDrUUUUj<br>250-STARTTLS<br>250 8BITMIME<br><strong>AUTH LOGIN</strong> # 开始登录，使用LOGIN方式<br>334 dXNlcm5hbWU6<br><strong>d2FuZ2ppbmdmZWk=</strong> # 用户名的Base64<br>334 UGFzc3dvcmQ6<br><strong>ZmFrZXBhc3N3b3Jk</strong> # 密码的Base64<br>235 Authentication successful<br><strong>MAIL FROM: &lt;<a href="mailto:&#x77;&#97;&#x6e;&#x67;&#106;&#x69;&#110;&#103;&#x66;&#x65;&#105;&#x40;&#x31;&#54;&#51;&#x2e;&#99;&#x6f;&#109;">&#x77;&#97;&#x6e;&#x67;&#106;&#x69;&#110;&#103;&#x66;&#x65;&#105;&#x40;&#x31;&#54;&#51;&#x2e;&#99;&#x6f;&#109;</a>&gt;</strong> # 发件箱地址<br>250 Mail OK<br><strong>RCPT TO: &lt;<a href="mailto:&#119;&#97;&#x6e;&#103;&#x6a;&#x69;&#110;&#103;&#x66;&#x65;&#x69;&#x40;&#50;&#x36;&#51;&#x2e;&#99;&#x6f;&#109;">&#119;&#97;&#x6e;&#103;&#x6a;&#x69;&#110;&#103;&#x66;&#x65;&#x69;&#x40;&#50;&#x36;&#51;&#x2e;&#99;&#x6f;&#109;</a>&gt;</strong> # 收件箱地址<br>250 Mail OK<br><strong>DATA</strong> # 开始编写邮件正文<br>354 End data with &lt;CR&gt;&lt;LF&gt;.&lt;CR&gt;&lt;LF&gt;<br><strong>TO: <a href="mailto:&#x6f;&#98;&#97;&#109;&#97;&#x40;&#x77;&#x68;&#105;&#116;&#x65;&#x68;&#x6f;&#x75;&#x73;&#x65;&#46;&#x63;&#111;&#109;">&#x6f;&#98;&#97;&#109;&#97;&#x40;&#x77;&#x68;&#105;&#116;&#x65;&#x68;&#x6f;&#x75;&#x73;&#x65;&#46;&#x63;&#111;&#109;</a></strong> # 这里的数据可以随便写<br><strong>FROM: <a href="mailto:&#x78;&#x69;&#106;&#x69;&#110;&#112;&#x69;&#110;&#103;&#x40;&#x7a;&#104;&#111;&#x6e;&#x67;&#110;&#97;&#110;&#104;&#x61;&#105;&#46;&#99;&#111;&#109;">&#x78;&#x69;&#106;&#x69;&#110;&#112;&#x69;&#110;&#103;&#x40;&#x7a;&#104;&#111;&#x6e;&#x67;&#110;&#97;&#110;&#104;&#x61;&#105;&#46;&#99;&#111;&#109;</a></strong> # 这里也是<br><strong>SUBJECT: A very important conference.</strong></p>
<p><strong>Please note that!</strong></p>
<p><strong>.</strong></p>
<p>250 Mail OK queued as smtp10,wKjADQ2ApxRnnqBE0CWaEw==.38326S3 # 返回250 表示发送成功。<br><strong>NOOP</strong> # 空语句，不执行任何操作，一般用来保持和服务器连接，不要掉线<br>250 OK<br><strong>QUIT</strong> # 退出<br>221 Closing connection. Good bye.<br>Connection closed by foreign host.</p>
</blockquote>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%85%B6%E4%BB%96/2016-06-15-login-smtp-with-telnet.html" target="_blank">利用telnet进行SMTP的验证</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%85%B6%E4%BB%96/2016-06-15-login-smtp-with-telnet.html]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>SMTP</tag>
        <tag>Telnet</tag>
        <tag>Email</tag>
      </tags>
  </entry>
  <entry>
    <title>批量删除Redis数据库中的Key</title>
    <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-06-16-delete-keys-in-batch-redis.html</url>
    <content><![CDATA[<blockquote>
<p>转载自：<a href="http://img.snail8.com/?p=502">http://img.snail8.com/?p=502</a></p>
</blockquote>
<p>Redis中有删除单个Key的指令<code>DEL</code>，但好像没有批量删除Key的指令，不过我们可以借助Linux的<code>xargs</code>指令来完成这个动作。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">redis-cli keys <span class="string">&quot;*&quot;</span> | xargs redis-cli del</span><br><span class="line"><span class="comment"># 如果redis-cli没有设置成系统变量，需要指定redis-cli的完整路径</span></span><br><span class="line"><span class="comment"># 如：/opt/redis/redis-cli keys &quot;*&quot; | xargs /opt/redis/redis-cli del</span></span><br></pre></td></tr></table></figure>

<p>如果要指定 Redis 数据库访问密码，使用下面的命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">redis-cli -a password keys <span class="string">&quot;*&quot;</span> | xargs redis-cli -a password del</span><br></pre></td></tr></table></figure>

<p>如果要访问 Redis 中特定的数据库，使用下面的命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下面的命令指定数据序号为0，即默认数据库</span></span><br><span class="line">redis-cli -n 0 keys <span class="string">&quot;*&quot;</span> | xargs redis-cli -n 0 del</span><br></pre></td></tr></table></figure>

<p>删除所有Key，可以使用Redis的flushdb和flushall命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除当前数据库中的所有Key</span></span><br><span class="line">flushdb</span><br><span class="line"><span class="comment"># 删除所有数据库中的key</span></span><br><span class="line">flushall</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-06-16-delete-keys-in-batch-redis.html" target="_blank">批量删除Redis数据库中的Key</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-06-16-delete-keys-in-batch-redis.html]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Zabbix监控MySQL服务器</title>
    <url>/%E8%BF%90%E7%BB%B4/2016-06-27-monitor-mysql-with-zabbix.html</url>
    <content><![CDATA[<p>从Zabbix 2.2开始，Zabbix官方已经支持了MySQL监控，但是MySQL监控默认是不可用的，需要经过额外的设置才可以使用。</p>
<h2 id="创建MySQL监控帐号"><a href="#创建MySQL监控帐号" class="headerlink" title="创建MySQL监控帐号"></a>创建MySQL监控帐号</h2><p>首先要建立一个MySQL帐户用于Zabbix Agent登录获取MySQL状态，这个帐户不需要任何权限，因此实质上可以使用debian-sys-maint也是可以的，另外如果在被监控的机子上本身就安装有Zabbix Server，那么可以直接使用zabbix帐户（密码可以在/etc/zabbix/zabbix_server.conf中找到）。当然可以登录被监控端的MySQL新建一个帐户：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;zabbix&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;zabbix&#x27;</span>;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>

<h2 id="脚本收集MySQL数据"><a href="#脚本收集MySQL数据" class="headerlink" title="脚本收集MySQL数据"></a>脚本收集MySQL数据</h2><p>创建收集MySQL数据的脚本（/etc/zabbix/scripts/mysql-status.sh）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#use zabbix to monitor mysql status</span></span><br><span class="line"><span class="comment">#carl 20150316 1st</span></span><br><span class="line"></span><br><span class="line">mysql=/usr/bin/mysql</span><br><span class="line">var=<span class="variable">$1</span></span><br><span class="line">MYSQL_USER=<span class="variable">$2</span></span><br><span class="line">MYSQL_PASSWORD=<span class="variable">$3</span></span><br><span class="line">MYSQL_Host=<span class="variable">$4</span></span><br><span class="line">[ <span class="string">&quot;<span class="variable">$&#123;MYSQL_USER&#125;</span>&quot;</span>     = <span class="string">&#x27;&#x27;</span> ] &amp;&amp;  MYSQL_USER=zabbix   <span class="comment">#mysql的zabbix用户</span></span><br><span class="line">[ <span class="string">&quot;<span class="variable">$&#123;MYSQL_PASSWORD&#125;</span>&quot;</span> = <span class="string">&#x27;&#x27;</span> ] &amp;&amp;  MYSQL_PASSWORD=zabbix  <span class="comment">#mysql的zabbix密码</span></span><br><span class="line">[ <span class="string">&quot;<span class="variable">$&#123;MYSQL_Host&#125;</span>&quot;</span>     = <span class="string">&#x27;&#x27;</span> ] &amp;&amp;  MYSQL_Host=192.168.1.3</span><br><span class="line">[ <span class="string">&quot;<span class="variable">$&#123;var&#125;</span>&quot;</span> = <span class="string">&#x27;&#x27;</span> ] &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;&quot;</span>||<span class="variable">$&#123;mysql&#125;</span> -h<span class="variable">$&#123;MYSQL_Host&#125;</span> -u<span class="variable">$&#123;MYSQL_USER&#125;</span> -p<span class="variable">$&#123;MYSQL_PASSWORD&#125;</span> -e <span class="string">&#x27;show global status&#x27;</span> 2&gt;/dev/null |grep -v Variable_name|grep <span class="string">&quot;\b<span class="variable">$&#123;var&#125;</span>\b&quot;</span>|awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="配置Zabbix-Agent"><a href="#配置Zabbix-Agent" class="headerlink" title="配置Zabbix Agent"></a>配置Zabbix Agent</h2><p>添加配置文件：/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">UserParameter</span>=mysql.status[*],/etc/zabbix/scripts/mysql-status.sh <span class="variable">$1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Flexible parameter to determine database or table size. On the frontend side, use keys like mysql.size[zabbix,history,data].</span></span><br><span class="line"><span class="comment"># Key syntax is mysql.size[&lt;database&gt;,&lt;table&gt;,&lt;type&gt;].</span></span><br><span class="line"><span class="comment"># Database may be a database name or &quot;all&quot;. Default is &quot;all&quot;.</span></span><br><span class="line"><span class="comment"># Table may be a table name or &quot;all&quot;. Default is &quot;all&quot;.</span></span><br><span class="line"><span class="comment"># Type may be &quot;data&quot;, &quot;index&quot;, &quot;free&quot; or &quot;both&quot;. Both is a sum of data and index. Default is &quot;both&quot;.</span></span><br><span class="line"><span class="comment"># Database is mandatory if a table is specified. Type may be specified always.</span></span><br><span class="line"><span class="comment"># Returns value in bytes.</span></span><br><span class="line"><span class="comment"># &#x27;sum&#x27; on data_length or index_length alone needed when we are getting this information for whole database instead of a single table</span></span><br><span class="line"><span class="attr">UserParameter</span>=mysql.size[*],bash -c <span class="string">&#x27;echo &quot;select sum($(case &quot;$3&quot; in both|&quot;&quot;) echo &quot;data_length+index_length&quot;;; data|index) echo &quot;$3_length&quot;;; free) echo &quot;data_free&quot;;; esac)) from information_schema.tables$([[ &quot;$1&quot; = &quot;all&quot; || ! &quot;$1&quot; ]] || echo &quot; where table_schema=\&quot;$1\&quot;&quot;)$([[ &quot;$2&quot; = &quot;all&quot; || ! &quot;$2&quot; ]] || echo &quot;and table_name=\&quot;$2\&quot;&quot;);&quot; | HOME=/var/lib/zabbix mysql -N&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">UserParameter</span>=mysql.ping,/usr/bin/mysqladmin ping -h192.<span class="number">168.1</span>.<span class="number">3</span> -uzabbix -pzabbix|grep alive|wc -l</span><br><span class="line"><span class="attr">UserParameter</span>=mysql.version,/usr/bin/mysql -h192.<span class="number">168.1</span>.<span class="number">3</span> -uzabbix -pzabbix -e <span class="string">&quot;select version();&quot;</span>|awk <span class="string">&#x27;END &#123;print&#125;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>其中192.168.1.3为MySQL服务器IP。</p>
<p>如果不想在脚本中使用用户名密码，可以使用<code>.my.cnf</code>配置文件，然后使用类似<code>HOME=/var/lib/zabbix mysql -N</code>命令访问MySQL，其中HOME为存放<code>.my.cnf</code>文件的路径。</p>
<h2 id="增加配置模板"><a href="#增加配置模板" class="headerlink" title="增加配置模板"></a>增加配置模板</h2><p>在Zabbix的Hosts中增加<code>Template App MySQL</code>这个模板，如图所示：</p>
<p><img src="/upload/images/12.png"></p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-06-27-monitor-mysql-with-zabbix.html" target="_blank">使用Zabbix监控MySQL服务器</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-06-27-monitor-mysql-with-zabbix.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
        <tag>监控</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Mongo常用命令</title>
    <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-07-19-mongo-queries.html</url>
    <content><![CDATA[<p>###根据日期查找</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;webExceptionRecord&#x27;</span>).<span class="title function_">find</span>(&#123;<span class="attr">createdDate</span>: &#123;<span class="string">&quot;$gte&quot;</span>:<span class="title class_">ISODate</span>(<span class="string">&quot;2016-03-31T12:48:25.040+08:00&quot;</span>)&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>###根据日期倒序排序</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;webExceptionRecord&#x27;</span>).<span class="title function_">find</span>(&#123;&#125;).<span class="title function_">sort</span>(&#123;<span class="attr">createdDate</span>:-<span class="number">1</span>&#125;)</span><br></pre></td></tr></table></figure>

<p>###查询“不等于”</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;webExceptionRecord&#x27;</span>).<span class="title function_">find</span>(&#123;<span class="attr">version</span>: &#123;<span class="attr">$not</span>:<span class="regexp">/v5\.0\.5/</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p><code>$not</code>后边必须跟正则表达式或文档（regex or document）</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;webExceptionRecord&#x27;</span>).<span class="title function_">find</span>(&#123;<span class="attr">version</span>:&#123;<span class="attr">$nin</span>:[<span class="string">&#x27;v5.0.5&#x27;</span>]&#125;&#125;)</span><br></pre></td></tr></table></figure>
<p><code>$nin</code>: not in</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;appStatisticsActiveUser&#x27;</span>).<span class="title function_">find</span>(&#123;<span class="attr">count</span>:&#123;<span class="attr">$not</span>: &#123;<span class="attr">$lt</span>:<span class="number">100</span>&#125;&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>###查询“包含”</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;webExceptionRecord&#x27;</span>).<span class="title function_">find</span>(&#123;<span class="attr">version</span>: &#123;<span class="attr">$regex</span>:<span class="regexp">/.*5\.0\.5.*/</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>

<p>###查询“不包含”</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">getCollection</span>(<span class="string">&#x27;webExceptionRecord&#x27;</span>).<span class="title function_">find</span>(&#123;<span class="attr">version</span>: &#123;<span class="attr">$not</span>:<span class="regexp">/.*v5\.0\.5.*/</span>&#125;&#125;)</span><br></pre></td></tr></table></figure>
<span id="more"></span>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-07-19-mongo-queries.html" target="_blank">Mongo常用命令</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-07-19-mongo-queries.html]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Mongo</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim常用命令</title>
    <url>/linux/2016-07-19-vim-commands.html</url>
    <content><![CDATA[<ul>
<li>Vim是Emacs的反物质，两者本身没有问题，只是他们的使用者如果在一起会打起来，造成最后的湮灭。这里不讨论湮灭的问题。</li>
<li>本文只用作我平时用到命令的记录，并不是所有常见的Vim命令。</li>
</ul>
<p>##查找替换</p>
<p>###在所有手机号码前后增加引号</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="symbol">:%s/</span>\(\d\&#123;<span class="number">11</span>&#125;\)/<span class="string">&#x27;\1&#x27;</span>/g</span><br></pre></td></tr></table></figure>
<p>###在所有行最前面增加“-”</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="symbol">:%s/^/-/g</span></span><br></pre></td></tr></table></figure>

<p>###在所有行的最后增加“-”</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line"><span class="symbol">:%s/</span><span class="variable">$/</span>-/g</span><br></pre></td></tr></table></figure>

<span id="more"></span>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-07-19-vim-commands.html" target="_blank">Vim常用命令</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-07-19-vim-commands.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Generate SSH key in none-interactive way</title>
    <url>/linux/2016-07-20-generate-sshkey-in-noneinteractive-way.html</url>
    <content><![CDATA[<p>We use ssh-keygen to generate ssh keys. Sometime we need to generate keys without any interaction during runtime. We have the following ways to do this.</p>
<p>###1. Use the full commands<br>Provide all parameters needed when running ssh-keygen, as</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -N <span class="string">&quot;&quot;</span> -f my.key</span><br></pre></td></tr></table></figure>
<p>in which</p>
<ul>
<li><strong><code>-N &quot;&quot;</code></strong> tells it to use an empty passphrase (the same as two of the enters in an interactive script)</li>
<li><strong><code>-f my.key</code></strong> tells it to store the key into my.key (change as you see fit).</li>
</ul>
<p>###2. Provide “ENTER”s before running ssh-keygen</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\n\n\n&quot;</span> | ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<p>By using pipe, we actually enters 3 “ENTER”s while executing ssh-keygen, which uses the default values.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-07-20-generate-sshkey-in-noneinteractive-way.html" target="_blank">Generate SSH key in none-interactive way</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-07-20-generate-sshkey-in-noneinteractive-way.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis被bgsave和bgrewriteaof阻塞的解决方法</title>
    <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-07-20-redis-blocked-by-disk-ops.html</url>
    <content><![CDATA[<p>我们的系统由于业务特点在每天早上上班的时候，会出现访问高峰。最近发现在访问高峰的时候，系统响应会变慢。无理是APP的后端还是Web服务的后端，平时响应时间都在100ms以内的接口，响应时间居然超过了一秒，甚至有一些能够达到10秒。</p>
<p>查看后台的监控数据，无论是服务器硬件资源利用率还是数据库访问频次都在正常的范围内。那么问题非常可能出现在Redis上，因为在我们的系统中，Redis担任了所有Web端和APP端Session的管理，权限的校验以及数据库的缓存等等任务。</p>
<p>查看Redis的日志，果然发现了异常：后台不停的打出bgsave相关的日志。</p>
<p>###bgsave频率的问题<br>查看<code>/etc/redis/redis.conf</code>配置，发现了下面这一段：</p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">################################ SNAPSHOTTING  ################################</span><br><span class="line">#</span><br><span class="line"># Save the DB on disk:</span><br><span class="line">#</span><br><span class="line">#   save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line">#</span><br><span class="line">#   Will save the DB <span class="keyword">if</span> both the given number <span class="keyword">of</span> seconds and the given</span><br><span class="line">#   number <span class="keyword">of</span> write operations against the DB occurred.</span><br><span class="line">#</span><br><span class="line">#   In the example below the behaviour will be to save:</span><br><span class="line">#   after <span class="number">900</span> sec (<span class="number">15</span> min) <span class="keyword">if</span> at least <span class="number">1</span> key changed</span><br><span class="line">#   after <span class="number">300</span> sec (<span class="number">5</span> min) <span class="keyword">if</span> at least <span class="number">10</span> keys changed</span><br><span class="line">#   after <span class="number">60</span> sec <span class="keyword">if</span> at least <span class="number">10000</span> keys changed</span><br><span class="line">#</span><br><span class="line">#   Note: you can disable saving at all commenting all the <span class="string">&quot;save&quot;</span> lines.</span><br><span class="line">#</span><br><span class="line">#   It is also possible to remove all the previously configured save</span><br><span class="line">#   points by adding a save directive <span class="keyword">with</span> a single empty string argument</span><br><span class="line">#   like <span class="keyword">in</span> the following example:</span><br><span class="line">#</span><br><span class="line">#   save <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">save <span class="number">900</span> <span class="number">1</span></span><br><span class="line">save <span class="number">300</span> <span class="number">10</span></span><br><span class="line">save <span class="number">60</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure>
<p>这三行的意思是：如果Redis在60秒之内有超过10000次修改，那么触发一次磁盘快照；或者在300秒内如果有10次修改，则触发一次快照；或者在900秒内有一次修改，则触发磁盘快照。</p>
<p>在我们的系统中，早晨访问高峰时，60秒内Redis的访问次数一定会超过10000次，所以系统就在不停的进行磁盘快照，于是就有了bgsave相关的日志。</p>
<p>###bgsave影响系统性能？<br>问题又来了。按字面理解，<code>bgrewriteaof</code>是在后台进行操作，不应该影响Redis的正常服务。原理也确实是这样的，Redis首先fork一个子进程，并在该子进程里进行归并和写持久化存储设备（如硬盘）的。按照正常逻辑，在一台多核的机器上，即使子进程占满CPU和硬盘,也不应该导致Redis服务阻塞啊！</p>
<p>Google了一下，发现问题就出在硬盘上。</p>
<p>Redis服务设置了<code>appendfsync everysec</code>，主进程每秒钟便会调用<code>fsync()</code>，要求内核将数据”确实”写到存储硬件里。但由于子进程同时也在写硬盘，从而导致主进程<code>fsync()/write()</code>操作被阻塞，最终导致Redis主进程阻塞了。</p>
<p>###解决方法<br>解决方法便是设置</p>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="literal">no</span>-appendfsync-<span class="literal">on</span>-rewrite <span class="literal">yes</span></span><br></pre></td></tr></table></figure>
<p>在子进程处理和写硬盘时，主进程不调用 fsync() 操作。需要注意的是，即使进程不调用<code>fsync()</code>，系统内核也会根据自己的算法在适当的时机将数据写到硬盘（Linux默认最长不超过30秒）。</p>
<p>###进一步提速：降低磁盘快照频率<br>由于目前我们的系统中，Redis真的是做为缓存，并且只作为缓存，不处理任何持久性数据，所以不需要快照的如此频繁。于是修改了快照的频率，把以下内容</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">save</span> <span class="number">900</span> <span class="number">1</span></span><br><span class="line"><span class="attribute">save</span> <span class="number">300</span> <span class="number">10</span></span><br><span class="line"><span class="attribute">save</span> <span class="number">60</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure>
<p>修改为：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">save</span> <span class="number">900</span> <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>即，900秒内，如果有一次修改，则进行一次快照。于是乎，问题搞定！</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-07-20-redis-blocked-by-disk-ops.html" target="_blank">Redis被bgsave和bgrewriteaof阻塞的解决方法</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-07-20-redis-blocked-by-disk-ops.html]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Performance</tag>
      </tags>
  </entry>
  <entry>
    <title>删除Docker中没有被挂载的卷（dangling volumes）</title>
    <url>/%E8%99%9A%E6%8B%9F%E5%8C%96/2016-07-20-remove-dangling-docker-volumes.html</url>
    <content><![CDATA[<p>最近在帮合作上制作Docker镜像。由于系统中有需要持久化的数据，数据卷几乎成了一个必选项。但是在N多次创建镜像、删除实例、新建实例的过程中，发现我的硬盘居然不够用了！查看<code>/var/lib/docker</code>的空间，居然有几十个G之多。于是想到了数据卷。</p>
<p>###重建实例时数据卷是否会被保留<br>基于同一个镜像时，多次创建实例会共享他们创建出的数据卷，这也是数据卷的最常用用法。但当镜像被修改时，即使名字和tags都相同，只要镜像ID不同，那么基于“相同名字”的这个镜像创建出的实例就不会共享之前的数据卷。</p>
<p>原因就在于我的系统中保留了很多过时的未被挂载的数据卷。</p>
<p>###删除未被挂载的数据卷<br>Docker并没有提供直接删除所有无用卷的功能（实际上出于安全考虑也不应该提供）。但是通过命令组合可以达到这个目的。</p>
<p>以下命令可以现实所有的未挂载数据卷：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker volume <span class="built_in">ls</span> -f dangling=<span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>组合使用以下命令可以删除所有未挂载卷：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker volume <span class="built_in">rm</span> $(docker volume <span class="built_in">ls</span> -qf dangling=<span class="literal">true</span>)</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%99%9A%E6%8B%9F%E5%8C%96/2016-07-20-remove-dangling-docker-volumes.html" target="_blank">删除Docker中没有被挂载的卷（dangling volumes）</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%99%9A%E6%8B%9F%E5%8C%96/2016-07-20-remove-dangling-docker-volumes.html]]></content>
      <categories>
        <category>虚拟化</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Volumes</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring中使用JUnit+mockito+powermock进行单元测试</title>
    <url>/spring/2016-07-25-spring-unit-test-with-junit-mockito-powermock.html</url>
    <content><![CDATA[<p>Spring中执行单元测试，最麻烦的就是解决Bean的定义以及注入的问题。最开始使用Spring的上下文初始化进行测试，开头是这样的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RunWith(SpringJUnit4ClassRunner.class)</span> </span><br><span class="line"><span class="meta">@ContextConfiguration(&quot;/config/Spring-db1.xml&quot;)</span> </span><br></pre></td></tr></table></figure>
<p>于是，为了能让这个单元测试正常运行起来，我又Mock了一堆其他的如：MySQL，MongoDB，Redis等等无数的组件。最终测试终于可以运行起来，但是运行的时候又需要对整个Spring的上下文进行初始化，跑一个单元测试需要0.1秒，跑初始化流程就需要1分钟。不过当时单元测试并不是团队高优先级的任务，后来也就没有再研究。   </p>
<p>最近回归Bug频频出现，单元测试又开始提上日程。花了大半天时间研究了JUnit+mockito+powermock进行可行的单元测试。</p>
<h2 id="三个软件的定位"><a href="#三个软件的定位" class="headerlink" title="三个软件的定位"></a>三个软件的定位</h2><ul>
<li><strong>JUnit</strong> 作为优秀的测试框架，在Spring单元测试占有相当大的市场份额</li>
<li><strong>Mockito</strong> 管理Spring的Mock对象管理，以及依赖注入等</li>
<li><strong>PowerMock</strong> Mockito不能对构造函数、静态函数以及私有函数进行Stunning，PowerMock是Mockito基础上的增强，填补了后者这方面的空白</li>
</ul>
<h2 id="从一个例子开始：签到"><a href="#从一个例子开始：签到" class="headerlink" title="从一个例子开始：签到"></a>从一个例子开始：签到</h2><p>凡事从简单的开始，我选择了系统中最复杂模块之一————“签到”的最简单部分进行单元测试。以下是需要进行测试的代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="keyword">public</span> SigninResult <span class="title function_">signV3</span><span class="params">(String staffId, SigninType signType, String wifiName, String wifiMac, Double longitude,</span></span><br><span class="line"><span class="params">                           Double latitude, Double radius, String locationName, String mobileId, Date signDate, String companyId, <span class="type">boolean</span> isSigninOnlyOnce)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.checkOutSign(signType, companyId, staffId, signDate);<span class="comment">//校验是否有相同类型的外出签到在申请中或已经审批通过了</span></span><br><span class="line">    <span class="keyword">return</span> actualSignV3(staffId, signType, wifiName, wifiMac, longitude, latitude, radius, locationName, mobileId, signDate, companyId, <span class="keyword">new</span> <span class="title class_">Date</span>(), isSigninOnlyOnce, <span class="literal">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>大家可以忽略乱七八糟的参数，只关注函数的两步：</p>
<ol>
<li>校验和外出签到关联的条件：checkOutSign</li>
<li>实际执行签到的逻辑：actualSignV3<br>另外需要注意的是：</li>
<li>checkOutSign是私有函数，如果其中不符合签到条件的话会抛出异常</li>
<li>actualSignV3是共有函数，在某些版本的接口中可以被其他模块直接调用<br>由于我们要演示对私有函数的测试，所以<code>checkOutSign</code>内的大致流程为：</li>
<li>获取一个外出签到记录，<code>signinOutRecordDao.findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn(xxx, xxx)</code>。（JPA实现，函数名比较长，勿喷）</li>
<li>校验外出签到，如果有异常的时候，抛出<code>IrenshiException</code></li>
</ol>
<h2 id="单元测试代码"><a href="#单元测试代码" class="headerlink" title="单元测试代码"></a>单元测试代码</h2><p>先从代码开始，然后一步步讲解</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.irenshi.biz.attendance.service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cn.irenshi.biz.attendance.dao.mysql.SigninOutRecordDao;</span><br><span class="line"><span class="keyword">import</span> cn.irenshi.biz.attendance.service.impl.SignServiceImpl;</span><br><span class="line"><span class="keyword">import</span> cn.irenshi.meta.dto.attendance.mysql.SigninOutRecord;</span><br><span class="line"><span class="keyword">import</span> cn.irenshi.meta.entity.attendance.SigninResult;</span><br><span class="line"><span class="keyword">import</span> cn.irenshi.meta.exception.IrenshiException;</span><br><span class="line"><span class="keyword">import</span> cn.irenshi.meta.type.ApplicationStatus;</span><br><span class="line"><span class="keyword">import</span> cn.irenshi.meta.type.SigninType;</span><br><span class="line"><span class="keyword">import</span> com.google.common.collect.Lists;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"><span class="keyword">import</span> org.junit.runner.RunWith;</span><br><span class="line"><span class="keyword">import</span> org.mockito.InjectMocks;</span><br><span class="line"><span class="keyword">import</span> org.mockito.Mock;</span><br><span class="line"><span class="keyword">import</span> org.powermock.core.classloader.annotations.PrepareOnlyThisForTest;</span><br><span class="line"><span class="keyword">import</span> org.powermock.modules.junit4.PowerMockRunner;</span><br><span class="line"><span class="keyword">import</span> org.powermock.reflect.Whitebox;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Date;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.junit.Assert.assertTrue;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mockito.Matchers.any;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mockito.Matchers.eq;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mockito.Mockito.doReturn;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.mockito.Mockito.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.powermock.api.mockito.PowerMockito.doNothing;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.powermock.api.mockito.PowerMockito.spy;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> org.powermock.api.mockito.PowerMockito.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 使用名称为PowerMockRunner的JUnit模块执行单元测试</span></span><br><span class="line"><span class="meta">@RunWith(PowerMockRunner.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SignServiceTest</span> &#123;</span><br><span class="line">    <span class="comment">// 2. 使用Mockito的@InjectMocks注解将待测试的实现类注入</span></span><br><span class="line">    <span class="meta">@InjectMocks</span></span><br><span class="line">    <span class="keyword">private</span> SignServiceImpl signService;</span><br><span class="line">    <span class="comment">// 3. 将生成MockDao，并注入到@InjectMocks指定的类中</span></span><br><span class="line">    <span class="meta">@Mock</span></span><br><span class="line">    <span class="keyword">private</span> SigninOutRecordDao signinOutRecordDao;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="comment">// 4. 对于final类，有private函数及static函数的类等，必须使用此注解，之后才能着Stubbing</span></span><br><span class="line">    <span class="meta">@PrepareOnlyThisForTest(SignServiceImpl.class)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSignV3</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">staffId</span> <span class="operator">=</span> <span class="string">&quot;mockStaffId&quot;</span>;</span><br><span class="line">        <span class="type">SigninType</span> <span class="variable">signType</span> <span class="operator">=</span> SigninType.SIGNIN_AFTERNOON;</span><br><span class="line">        <span class="type">String</span> <span class="variable">wifiName</span> <span class="operator">=</span> <span class="string">&quot;mockWifiName&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">wifiMac</span> <span class="operator">=</span> <span class="string">&quot;mockWifiMac&quot;</span>;</span><br><span class="line">        <span class="type">Double</span> <span class="variable">longitude</span> <span class="operator">=</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="type">Double</span> <span class="variable">latitude</span> <span class="operator">=</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="type">Double</span> <span class="variable">radius</span> <span class="operator">=</span> <span class="number">0.0</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">locationName</span> <span class="operator">=</span> <span class="string">&quot;mockLocationName&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">mobileId</span> <span class="operator">=</span> <span class="string">&quot;mockMobileId&quot;</span>;</span><br><span class="line">        <span class="type">Date</span> <span class="variable">signDate</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line">        <span class="type">String</span> <span class="variable">companyId</span> <span class="operator">=</span> <span class="string">&quot;mockCompanyId&quot;</span>;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">isSigninOnlyOnce</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5. 对实体类进行Stubbing，从spy()开始</span></span><br><span class="line">        <span class="type">SignServiceImpl</span> <span class="variable">spy</span> <span class="operator">=</span> spy(signService);</span><br><span class="line"></span><br><span class="line">        <span class="type">SigninResult</span> <span class="variable">signinResult</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninResult</span>();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6. 对私有函数进行Stubbing</span></span><br><span class="line">        doNothing().when(spy, <span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br><span class="line">        <span class="comment">// 7. 对共有和函数进行Stubbing</span></span><br><span class="line">        <span class="comment">// 8. 因为actualSignV3含有不确定的变量，所以必须使用Matchers进行参数处理</span></span><br><span class="line">        doReturn(signinResult).when(spy).actualSignV3(eq(staffId), eq(signType), eq(wifiName), eq(wifiMac),</span><br><span class="line">                eq(longitude), eq(latitude), eq(radius), eq(locationName), eq(mobileId), eq(signDate), eq(companyId),</span><br><span class="line">                any(), eq(isSigninOnlyOnce), eq(<span class="literal">false</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 9. 执行即将进行测试的代码</span></span><br><span class="line">        <span class="type">SigninResult</span> <span class="variable">result</span> <span class="operator">=</span> spy.signV3(staffId, signType, wifiName, wifiMac, longitude, latitude, radius, locationName, mobileId,</span><br><span class="line">                signDate, companyId, isSigninOnlyOnce);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 10. 检查该私有函数是否以给定的参数被调用了1次</span></span><br><span class="line">        verifyPrivate(spy, times(<span class="number">1</span>)).invoke(<span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br><span class="line">        <span class="comment">// 11. 检查该共有函数是否以给定的参数被调用了1次</span></span><br><span class="line">        <span class="comment">// 12. 同样由于含有不确定变量，校验的时候也需要使用Matchers对参数进行处理</span></span><br><span class="line">        verify(spy, times(<span class="number">1</span>)).actualSignV3(eq(staffId), eq(signType), eq(wifiName), eq(wifiMac),</span><br><span class="line">                eq(longitude), eq(latitude), eq(radius), eq(locationName), eq(mobileId), eq(signDate), eq(companyId),</span><br><span class="line">                any(), eq(isSigninOnlyOnce), eq(<span class="literal">false</span>));</span><br><span class="line">        <span class="comment">// 13. 校验函数的返回值是否正确</span></span><br><span class="line">        assertTrue(signinResult == result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCheckOutSign1</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">staffId</span> <span class="operator">=</span> <span class="string">&quot;mockStaffId&quot;</span>;</span><br><span class="line">        <span class="type">SigninType</span> <span class="variable">signType</span> <span class="operator">=</span> SigninType.SIGNIN_AFTERNOON;</span><br><span class="line">        <span class="type">Date</span> <span class="variable">signDate</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line">        <span class="type">String</span> <span class="variable">companyId</span> <span class="operator">=</span> <span class="string">&quot;mockCompanyId&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">SigninOutRecord</span> <span class="variable">record1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninOutRecord</span>();</span><br><span class="line">        <span class="type">SigninOutRecord</span> <span class="variable">record2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninOutRecord</span>();</span><br><span class="line">        <span class="type">SigninOutRecord</span> <span class="variable">record3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninOutRecord</span>();</span><br><span class="line">        <span class="type">SigninOutRecord</span> <span class="variable">record4</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninOutRecord</span>();</span><br><span class="line">        <span class="type">SigninOutRecord</span> <span class="variable">record5</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninOutRecord</span>();</span><br><span class="line">        record1.setApplicationStatus(ApplicationStatus.CANCEL_APPROVED);</span><br><span class="line">        record2.setApplicationStatus(ApplicationStatus.CANCEL_PROCESSING);</span><br><span class="line">        record3.setApplicationStatus(ApplicationStatus.DELETE);</span><br><span class="line">        record4.setApplicationStatus(ApplicationStatus.DENIED);</span><br><span class="line">        record5.setApplicationStatus(ApplicationStatus.PROCESSING);</span><br><span class="line">        <span class="comment">// 14. 对Mock的接口进行处理，定义接口的返回值</span></span><br><span class="line">        doReturn(Lists.newArrayList(record1, record2, record3, record4)).when(signinOutRecordDao)</span><br><span class="line">                .findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn(companyId, staffId,</span><br><span class="line">                        signType, signDate, Lists.newArrayList(ApplicationStatus.APPROVED,</span><br><span class="line">                                ApplicationStatus.WAITING_HR_APPROVAL, ApplicationStatus.PROCESSING));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 15. 执行私有函数进行测试</span></span><br><span class="line">        Whitebox.invokeMethod(signService, <span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 16. 校验Mock的对象的函数是否被调用了1次</span></span><br><span class="line">        verify(signinOutRecordDao, times(<span class="number">1</span>)).findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn(companyId, staffId,</span><br><span class="line">                signType, signDate, Lists.newArrayList(ApplicationStatus.APPROVED,</span><br><span class="line">                        ApplicationStatus.WAITING_HR_APPROVAL, ApplicationStatus.PROCESSING));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 17. 该函数预计会产生Exception</span></span><br><span class="line">    <span class="meta">@Test(expected = IrenshiException.class)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testCheckOutSign2</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">staffId</span> <span class="operator">=</span> <span class="string">&quot;mockStaffId&quot;</span>;</span><br><span class="line">        <span class="type">SigninType</span> <span class="variable">signType</span> <span class="operator">=</span> SigninType.SIGNIN_AFTERNOON;</span><br><span class="line">        <span class="type">Date</span> <span class="variable">signDate</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Date</span>();</span><br><span class="line">        <span class="type">String</span> <span class="variable">companyId</span> <span class="operator">=</span> <span class="string">&quot;mockCompanyId&quot;</span>;</span><br><span class="line"></span><br><span class="line">        <span class="type">SigninOutRecord</span> <span class="variable">record</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SigninOutRecord</span>();</span><br><span class="line">        record.setApplicationStatus(ApplicationStatus.APPROVED);</span><br><span class="line">        doReturn(Lists.newArrayList(record)).when(signinOutRecordDao)</span><br><span class="line">                .findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn(companyId, staffId,</span><br><span class="line">                        signType, signDate, Lists.newArrayList(ApplicationStatus.APPROVED,</span><br><span class="line">                                ApplicationStatus.WAITING_HR_APPROVAL, ApplicationStatus.PROCESSING));</span><br><span class="line"></span><br><span class="line">        Whitebox.invokeMethod(signService, <span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br><span class="line"></span><br><span class="line">        verify(signinOutRecordDao, times(<span class="number">1</span>)).findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn(companyId, staffId,</span><br><span class="line">                signType, signDate, Lists.newArrayList(ApplicationStatus.APPROVED,</span><br><span class="line">                        ApplicationStatus.WAITING_HR_APPROVAL, ApplicationStatus.PROCESSING));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="代码详细分析"><a href="#代码详细分析" class="headerlink" title="代码详细分析"></a>代码详细分析</h2><h3 id="使用JUnit测试框架启动"><a href="#使用JUnit测试框架启动" class="headerlink" title="使用JUnit测试框架启动"></a>使用JUnit测试框架启动</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RunWith(PowerMockRunner.class)</span></span><br></pre></td></tr></table></figure>
<p><code>@RunWith</code>是JUnit的注解，可以指定测试用的Runner。如：使用Spring上下文做测试的代码为<code>@RunWith(SpringJUnit4ClassRunner.class) </code>，使用纯Mockito的代码为<code>@RunWith(MockitoJUnitRunner.class)</code></p>
<h3 id="注入待测试的类"><a href="#注入待测试的类" class="headerlink" title="注入待测试的类"></a>注入待测试的类</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@InjectMocks</span></span><br><span class="line"><span class="keyword">private</span> SignServiceImpl signService;</span><br></pre></td></tr></table></figure>
<p><code>@InjectMocks</code>是原生Mockito的注解，负责将待测试的类注入到单元测试中。这里需要注意：</p>
<ol>
<li>此处的对象（SignServiceImpl）必须是实体对象，不能是接口或者抽象类。因为<code>InjectMocks</code>需要实例化该对象</li>
<li>对象中所有的依赖注入都会以一个简单粗暴的方式解决，默认将所有的<code>@Autowired</code>对象注入成<code>null</code><br>所以，只要增加这个注解就可以快速生成一个对象，比Spring的Bean管理简单很多。</li>
</ol>
<h3 id="Mock一个Bean"><a href="#Mock一个Bean" class="headerlink" title="Mock一个Bean"></a>Mock一个Bean</h3><p>大部分情况下，我们还是要Mock一些Bean，来辅助完成单元测试的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Mock</span></span><br><span class="line"><span class="keyword">private</span> SigninOutRecordDao signinOutRecordDao;</span><br></pre></td></tr></table></figure>
<p><code>@Mock</code>也是原生Mockito的注解，增加该Mock之后，<code>SignServiceImpl</code>所有依赖<code>SigninOutRecordDao</code>的地方，都会被注入成该对象。我们可以对Mock的对象进行各种操作，修改函数调用行为（称作Stub，有人叫“打桩”）等。</p>
<h3 id="测试类包含私有函数的调用时"><a href="#测试类包含私有函数的调用时" class="headerlink" title="测试类包含私有函数的调用时"></a>测试类包含私有函数的调用时</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@PrepareOnlyThisForTest(SignServiceImpl.class)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">testSignV3</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span><br></pre></td></tr></table></figure>
<p><code>@Test</code>注解不用说，就是生成一个测试用例。<code>@PrepareOnlyThisForTest</code>需要特别注意。因为我们在测试<code>SignServiceImpl</code>的过程中，需要对<code>SignServiceImpl</code>的私有函数<code>checkOutSign</code>进行Stubbing，修改其行为，所以必须使用<code>@PrepareOnlyThisForTest(SignServiceImpl.class)</code>为Stubbing做好准备。</p>
<h3 id="为测试实体Stubbing"><a href="#为测试实体Stubbing" class="headerlink" title="为测试实体Stubbing"></a>为测试实体Stubbing</h3><p>测试的时候，我们需要用到实体类，但又不想使用实体类的所有实现函数。所以我们需要针对特定的某些函数进行Stubbing。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SignServiceImpl</span> <span class="variable">spy</span> <span class="operator">=</span> spy(signService);</span><br></pre></td></tr></table></figure>
<p>对Mock的接口（如：SigninOutRecordDao signinOutRecordDao）来说，直接对其中的函数进行Stub即可。但如果要对测试实体进行Stubbing，则需要先对其进行<code>spy</code>。然后即可开展后边的Stubbing操作。</p>
<h3 id="对函数进行Stubbing"><a href="#对函数进行Stubbing" class="headerlink" title="对函数进行Stubbing"></a>对函数进行Stubbing</h3><p>先从对Mock对象进行的Stubbing开始。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">doReturn(Lists.newArrayList(record1, record2, record3, record4)).when(signinOutRecordDao)</span><br><span class="line">                .findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn(companyId, staffId,</span><br><span class="line">                        signType, signDate, Lists.newArrayList(ApplicationStatus.APPROVED,</span><br><span class="line">                                ApplicationStatus.WAITING_HR_APPROVAL, ApplicationStatus.PROCESSING));</span><br></pre></td></tr></table></figure>
<p>这个函数对<code>signinOutRecordDao</code>进行Stubbing。根据字面意思可以理解：</p>
<pre><code>This function will be stubbed as: **return** the given **List** when **signinOutRecordDao**
is called by **findByCompanyIdAndStaffIdAndSignTypeAndSignDateAndApplicationStatusIn**
with these **parameters**
</code></pre>
<p>都比较容易理解。</p>
<h3 id="对私有函数进行Stubbing"><a href="#对私有函数进行Stubbing" class="headerlink" title="对私有函数进行Stubbing"></a>对私有函数进行Stubbing</h3><p>对私有函数进行Stubbing和公共函数类似：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">doNothing().when(spy, <span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br></pre></td></tr></table></figure>
<p>在这里，Stubbing对象是实体<code>spy</code>的<code>checkOutSign</code>函数，参数为<code>signType, companyId, staffId, signDate</code>。</p>
<h3 id="当被Stub的函数不是确定输入参数时"><a href="#当被Stub的函数不是确定输入参数时" class="headerlink" title="当被Stub的函数不是确定输入参数时"></a>当被Stub的函数不是确定输入参数时</h3><p><code>actualSignV3</code>这个函数在调用的时候，用了一个很Anti-Pattern的一个设计，<code>signTime</code>这个参数用的是<code>new Date()</code>。暂且先不讨论代码的质量，先看看下边的Stub代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">doReturn(signinResult).when(spy).actualSignV3(eq(staffId), eq(signType), eq(wifiName), eq(wifiMac),</span><br><span class="line">                eq(longitude), eq(latitude), eq(radius), eq(locationName), eq(mobileId), eq(signDate), eq(companyId),</span><br><span class="line">                any(), eq(isSigninOnlyOnce), eq(<span class="literal">false</span>));</span><br></pre></td></tr></table></figure>
<p><code>any()</code>函数意思是，当<code>actualSignV3</code>函数调用的时候，无论<code>signTime</code>这个参数是什么值，这个Stubbing均生效。需要注意的是，一旦函数参数里边有任何一个<code>any</code>或类似的<code>Matcher</code>函数（如<code>anyInt</code>，<code>anyString</code>等）时，其他所有参数也必须以同样的形式出现。<br>上边代码中可以看到所有参数都使用了<code>eq()</code>进行封装。</p>
<h3 id="另一种Stubbing方法（不推荐）"><a href="#另一种Stubbing方法（不推荐）" class="headerlink" title="另一种Stubbing方法（不推荐）"></a>另一种Stubbing方法（不推荐）</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">when(spy.actualSignV3(eq(staffId), eq(signType), eq(wifiName), eq(wifiMac),</span><br><span class="line">        eq(longitude), eq(latitude), eq(radius), eq(locationName), eq(mobileId), eq(signDate), eq(companyId),</span><br><span class="line">        any(), eq(isSigninOnlyOnce), eq(<span class="literal">false</span>))).thenReturn(signinResult);</span><br></pre></td></tr></table></figure>
<p>这种Stubbing比较符合汉语的语法：当xxx的时候，怎么怎么样。但是这样Stub有一个不好的地方，Stub的时候会首先执行<code>actualSignV3</code>的原版函数，然后再进行替换。可向而知，由于很多Bean都没有定义，直接抛<code>NullPointerException</code>。</p>
<h3 id="执行测试代码"><a href="#执行测试代码" class="headerlink" title="执行测试代码"></a>执行测试代码</h3><p>执行测试代码的方法和普通调用一样：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SigninResult</span> <span class="variable">result</span> <span class="operator">=</span> spy.signV3(staffId, signType, wifiName, wifiMac, longitude, latitude, radius, locationName, mobileId,</span><br><span class="line">        signDate, companyId, isSigninOnlyOnce);</span><br></pre></td></tr></table></figure>
<p>但这里仍有需要注意的地方：当调用的时候，只能使用被spy的对象<code>spy</code>，而不能使用原对象<code>signService</code>。因为只有<code>spy</code>被Stubbed了，而<code>signService</code>仍然保持不变。</p>
<h3 id="校验函数调用情况"><a href="#校验函数调用情况" class="headerlink" title="校验函数调用情况"></a>校验函数调用情况</h3><p>校验<code>checkOutSign</code>函数是否以给定的参数<code>signType, companyId, staffId, signDate</code>被调用了<strong>一次</strong>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">verifyPrivate(spy, times(<span class="number">1</span>)).invoke(<span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br></pre></td></tr></table></figure>

<h3 id="校验具有不确定参数的函数时"><a href="#校验具有不确定参数的函数时" class="headerlink" title="校验具有不确定参数的函数时"></a>校验具有不确定参数的函数时</h3><p>和Stubbing的时候一样，校验时如果有任意一个参数使用了<code>Matcher</code>形式，则其他所有函数都必须使用<code>Matcher</code>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">verify(spy, times(<span class="number">1</span>)).actualSignV3(eq(staffId), eq(signType), eq(wifiName), eq(wifiMac),</span><br><span class="line">        eq(longitude), eq(latitude), eq(radius), eq(locationName), eq(mobileId), eq(signDate), eq(companyId),</span><br><span class="line">        any(), eq(isSigninOnlyOnce), eq(<span class="literal">false</span>));</span><br></pre></td></tr></table></figure>

<h3 id="校验输出结果"><a href="#校验输出结果" class="headerlink" title="校验输出结果"></a>校验输出结果</h3><p>这个没什么好说的</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">assertTrue(signinResult == result);</span><br></pre></td></tr></table></figure>

<h3 id="对私有函数进行测试"><a href="#对私有函数进行测试" class="headerlink" title="对私有函数进行测试"></a>对私有函数进行测试</h3><p>私有函数测试的难点在于我们没有办法调用私有函数，但是PowerMock帮我们解决了这个问题。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Whitebox.invokeMethod(signService, <span class="string">&quot;checkOutSign&quot;</span>, signType, companyId, staffId, signDate);</span><br></pre></td></tr></table></figure>
<p>PowerMock使用<code>Writebox</code>，通过反射的方式调用<code>checkOutSign</code>这个函数。</p>
<h3 id="正确运行会抛出异常"><a href="#正确运行会抛出异常" class="headerlink" title="正确运行会抛出异常"></a>正确运行会抛出异常</h3><p>这个也没什么好说的，JUnit4原生的处理方式。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test(expected = IrenshiException.class)</span></span><br></pre></td></tr></table></figure>

<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>一个框架+一个Mock+一个Mock增强，基本可以满足大部分单元测试的需求了，在配合使用Jenkins等CI工具，单元测试是要飞起来的节奏！</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/spring/2016-07-25-spring-unit-test-with-junit-mockito-powermock.html" target="_blank">Spring中使用JUnit+mockito+powermock进行单元测试</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/spring/2016-07-25-spring-unit-test-with-junit-mockito-powermock.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>单元测试</tag>
        <tag>JUnit</tag>
        <tag>Mockito</tag>
        <tag>PowerMock</tag>
      </tags>
  </entry>
  <entry>
    <title>在生产环境中查出占用大量CPU的Java线程</title>
    <url>/linux/2016-07-26-find-high-cpu-thread.html</url>
    <content><![CDATA[<p>生产环境中，有的时候会发现某一个Java进程占用了大量CPU，在测试环境又很难重现。这时候就需要在线进行保护现场和Debug。</p>
<h3 id="定位大量占用CPU的进程"><a href="#定位大量占用CPU的进程" class="headerlink" title="定位大量占用CPU的进程"></a>定位大量占用CPU的进程</h3><p>执行<code>top</code>命令，然后按<code>P</code>按照CPU使用率排序</p>
<figure class="highlight tap"><table><tr><td class="code"><pre><span class="line">top - 16:08:03 up<span class="number"> 54 </span>days, 20:22, <span class="number"> 1 </span>user,  load average: 0.67, 1.00, 1.01</span><br><span class="line">Tasks:<span class="number"> 477 </span>total,  <span class="number"> 2 </span>running,<span class="number"> 475 </span>sleeping,  <span class="number"> 0 </span>stopped,  <span class="number"> 0 </span>zombie</span><br><span class="line">%Cpu(s):  1.3 us,  1.3 sy,  0.3 ni, 96.5 id,  0.4 wa,  0.0 hi,  0.3 si,  0.0 st</span><br><span class="line">KiB Mem: <span class="number"> 32898100 </span>total,<span class="number"> 29648584 </span>used, <span class="number"> 3249516 </span>free,  <span class="number"> 474052 </span>buffers</span><br><span class="line">KiB Swap:<span class="number"> 33505276 </span>total, <span class="number"> 4258368 </span>used,<span class="number"> 29246908 </span>free. <span class="number"> 8192840 </span>cached Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                  </span><br><span class="line">36730 jenkins  <span class="number"> 20 </span> <span class="number"> 0 </span>13.068g 1.185g  <span class="number"> 8228 </span>S  11.6  3.8   3673:10 java                                                                                                                     </span><br><span class="line">35378 root     <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 110784 </span><span class="number"> 34768 </span> <span class="number"> 3748 </span>S   5.0  0.1 249:51.07 gunicorn                                                                                                                 </span><br><span class="line">39103 root     <span class="number"> 39 </span><span class="number"> 19 </span>  <span class="number"> 7980 </span> <span class="number"> 3172 </span> <span class="number"> 1524 </span>S   3.3  0.0   0:13.06 apps.plugin                                                                                                              </span><br><span class="line"><span class="number"> 1329 </span>mongodb  <span class="number"> 20 </span> <span class="number"> 0 </span>28.476g<span class="number"> 122940 </span><span class="number"> 55292 </span>S   1.7  0.4 286:41.33 mongod                                                                                                                   </span><br><span class="line"><span class="number"> 2073 </span>redis    <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 495752 </span>181572  <span class="number"> 2024 </span>S   1.7  0.6 213:49.77 redis-server                                                                                                             </span><br><span class="line"><span class="number"> 5053 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 110956 </span><span class="number"> 15216 </span> <span class="number"> 2376 </span>S   1.7  0.0 228:35.26 gunicorn                                                                                                                 </span><br><span class="line">14444 root     <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 110784 </span><span class="number"> 34720 </span> <span class="number"> 3636 </span>S   1.7  0.1 122:03.66 gunicorn                                                                                                                 </span><br><span class="line">20403 ubuntu   <span class="number"> 20 </span> <span class="number"> 0 </span> <span class="number"> 82616 </span> <span class="number"> 2644 </span> <span class="number"> 2564 </span>S   1.7  0.0  11:49.45 zabbix_agentd                                                                                                            </span><br><span class="line">35032 root     <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 110528 </span><span class="number"> 34944 </span> <span class="number"> 4088 </span>S   1.7  0.1 134:09.61 gunicorn                                                                                                                 </span><br><span class="line">40879 ubuntu   <span class="number"> 20 </span> <span class="number"> 0 </span><span class="number"> 103576 </span> <span class="number"> 3356 </span> <span class="number"> 2400 </span>S   1.7  0.0   0:00.01 sshd                                                                                                                     </span><br><span class="line">45221 root     <span class="number"> 20 </span> <span class="number"> 0 </span>8979028<span class="number"> 921240 </span><span class="number"> 15540 </span>S   1.7  2.8   4:38.85 java                                                                                                                     </span><br><span class="line">45666 root     <span class="number"> 20 </span> <span class="number"> 0 </span>8704800<span class="number"> 748200 </span><span class="number"> 17084 </span>S   1.7  2.3   3:53.45 java                                                                                                                     </span><br><span class="line">   <span class="number"> 1 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span> <span class="number"> 33732 </span> <span class="number"> 3892 </span> <span class="number"> 2448 </span>S   0.0  0.0   1:49.23 init                                                                                                                     </span><br><span class="line">   <span class="number"> 2 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   0:00.66 kthreadd                                                                                                                 </span><br><span class="line">   <span class="number"> 3 </span>root     <span class="number"> 20 </span> <span class="number"> 0 </span>     <span class="number"> 0 </span>    <span class="number"> 0 </span>    <span class="number"> 0 </span>S   0.0  0.0   2:18.79 </span><br></pre></td></tr></table></figure>
<p>可以看到，Jenkins占用了较大的CPU资源，进程ID为<strong>36730</strong></p>
<h3 id="找到占用资源最多的线程"><a href="#找到占用资源最多的线程" class="headerlink" title="找到占用资源最多的线程"></a>找到占用资源最多的线程</h3><p>执行以下命令显示<strong>36730</strong>的所有线程ID：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ubuntu@linasvr:~$ ps -mp 36730 -o THREAD,tid,time</span><br><span class="line">USER     %CPU PRI SCNT WCHAN  USER SYSTEM   TID     TIME</span><br><span class="line">jenkins   0.2   -    - -         -      -     - 03:18:59</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 36730 00:00:00</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32117 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32118 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32119 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32120 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32121 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32122 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32123 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32124 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32125 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32126 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32127 00:00:01</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32128 00:00:07</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32129 00:00:00</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32131 00:00:00</span><br><span class="line">jenkins   0.0  19    - futex_    -      - 32132 00:00:00</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>注：这里只是演示命令，其实没有异常的线程。</p>
<h3 id="查看某线程正在做什么"><a href="#查看某线程正在做什么" class="headerlink" title="查看某线程正在做什么"></a>查看某线程正在做什么</h3><p>假设我们要查看<strong>43255</strong>线程正在执行什么代码，首先需要将<strong>43255</strong>转换为16进制表示：</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">ubuntu<span class="variable">@linasvr</span><span class="symbol">:~</span><span class="variable">$ </span>printf <span class="string">&quot;%x\n&quot;</span> <span class="number">43255</span></span><br><span class="line">a8f7</span><br></pre></td></tr></table></figure>
<p>然后可以使用<strong>jstack</strong>查看<strong>36730</strong>中的<strong>a8f7</strong>线程在执行什么：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo -u jenkins -H jstack 36730 |grep a8f7 -A 30</span><br></pre></td></tr></table></figure>
<p>输出以下内容：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;RemoteInvocationHandler [#1]&quot;</span> <span class="number">#125</span> daemon prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0</span>x00007fe2ac017000 nid=<span class="number">0</span>xa8f7 <span class="keyword">in</span> Object<span class="selector-class">.wait</span>() <span class="selector-attr">[0x00007fe34e64e000]</span></span><br><span class="line">   java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.State</span>: TIMED_WAITING (on <span class="selector-tag">object</span> monitor)</span><br><span class="line">        at java<span class="selector-class">.lang</span><span class="selector-class">.Object</span><span class="selector-class">.wait</span>(Native Method)</span><br><span class="line">        at java<span class="selector-class">.lang</span><span class="selector-class">.ref</span><span class="selector-class">.ReferenceQueue</span><span class="selector-class">.remove</span>(ReferenceQueue<span class="selector-class">.java</span>:<span class="number">143</span>)</span><br><span class="line">        - locked &lt;<span class="number">0</span>x00000005c3c49870&gt; (<span class="selector-tag">a</span> java<span class="selector-class">.lang</span><span class="selector-class">.ref</span>.ReferenceQueue<span class="variable">$Lock</span>)</span><br><span class="line">        at hudson<span class="selector-class">.remoting</span>.RemoteInvocationHandler<span class="variable">$Unexporter</span><span class="selector-class">.run</span>(RemoteInvocationHandler<span class="selector-class">.java</span>:<span class="number">415</span>)</span><br><span class="line">        at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span>.Executors<span class="variable">$RunnableAdapter</span><span class="selector-class">.call</span>(Executors<span class="selector-class">.java</span>:<span class="number">511</span>)</span><br><span class="line">        at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.FutureTask</span><span class="selector-class">.run</span>(FutureTask<span class="selector-class">.java</span>:<span class="number">266</span>)</span><br><span class="line">        at hudson<span class="selector-class">.remoting</span>.AtmostOneThreadExecutor<span class="variable">$Worker</span><span class="selector-class">.run</span>(AtmostOneThreadExecutor<span class="selector-class">.java</span>:<span class="number">110</span>)</span><br><span class="line">        at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">745</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Thread-12&quot;</span> <span class="number">#118</span> daemon prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0</span>x00007fe2ac020000 nid=<span class="number">0</span>xa89c runnable <span class="selector-attr">[0x00007fe34e44c000]</span></span><br><span class="line">   java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.State</span>: RUNNABLE</span><br><span class="line">        at java<span class="selector-class">.net</span><span class="selector-class">.SocketInputStream</span><span class="selector-class">.socketRead0</span>(Native Method)</span><br><span class="line">        at java<span class="selector-class">.net</span><span class="selector-class">.SocketInputStream</span><span class="selector-class">.socketRead</span>(SocketInputStream<span class="selector-class">.java</span>:<span class="number">116</span>)</span><br><span class="line">        at java<span class="selector-class">.net</span><span class="selector-class">.SocketInputStream</span><span class="selector-class">.read</span>(SocketInputStream<span class="selector-class">.java</span>:<span class="number">170</span>)</span><br><span class="line">        at java<span class="selector-class">.net</span><span class="selector-class">.SocketInputStream</span><span class="selector-class">.read</span>(SocketInputStream<span class="selector-class">.java</span>:<span class="number">141</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.crypto</span><span class="selector-class">.cipher</span><span class="selector-class">.CipherInputStream</span><span class="selector-class">.fill_buffer</span>(CipherInputStream<span class="selector-class">.java</span>:<span class="number">41</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.crypto</span><span class="selector-class">.cipher</span><span class="selector-class">.CipherInputStream</span><span class="selector-class">.internal_read</span>(CipherInputStream<span class="selector-class">.java</span>:<span class="number">52</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.crypto</span><span class="selector-class">.cipher</span><span class="selector-class">.CipherInputStream</span><span class="selector-class">.getBlock</span>(CipherInputStream<span class="selector-class">.java</span>:<span class="number">79</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.crypto</span><span class="selector-class">.cipher</span><span class="selector-class">.CipherInputStream</span><span class="selector-class">.read</span>(CipherInputStream<span class="selector-class">.java</span>:<span class="number">108</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.transport</span><span class="selector-class">.TransportConnection</span><span class="selector-class">.receiveMessage</span>(TransportConnection<span class="selector-class">.java</span>:<span class="number">232</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.transport</span><span class="selector-class">.TransportManager</span><span class="selector-class">.receiveLoop</span>(TransportManager<span class="selector-class">.java</span>:<span class="number">693</span>)</span><br><span class="line">        at com<span class="selector-class">.trilead</span><span class="selector-class">.ssh2</span><span class="selector-class">.transport</span>.TransportManager$<span class="number">1</span><span class="selector-class">.run</span>(TransportManager<span class="selector-class">.java</span>:<span class="number">489</span>)</span><br><span class="line">        at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">745</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Scheduler-248609774&quot;</span> #<span class="number">92</span> prio=<span class="number">5</span> os_prio=<span class="number">0</span> tid=<span class="number">0</span>x00007fe2fc007000 nid=<span class="number">0</span>x91d5 waiting on condition <span class="selector-attr">[0x00007fe34e24a000]</span></span><br><span class="line">   java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.State</span>: WAITING (parking)</span><br><span class="line">        at sun<span class="selector-class">.misc</span><span class="selector-class">.Unsafe</span><span class="selector-class">.park</span>(Native Method)</span><br><span class="line">        - parking to wait <span class="keyword">for</span>  &lt;<span class="number">0</span>x00000005c002e830&gt; (<span class="selector-tag">a</span> java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.locks</span>.AbstractQueuedSynchronizer<span class="variable">$ConditionObject</span>)</span><br><span class="line">        at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.locks</span><span class="selector-class">.LockSupport</span><span class="selector-class">.park</span>(LockSupport<span class="selector-class">.java</span>:<span class="number">175</span>)</span><br></pre></td></tr></table></figure>
<p>可以看到<code>nid=0xa8f7</code>线程的调用栈。如果有问题的话一目了然。</p>
<h3 id="jstack的权限问题"><a href="#jstack的权限问题" class="headerlink" title="jstack的权限问题"></a>jstack的权限问题</h3><p>如果执行jstack发现以下异常：</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">ubuntu@linasvr:~$ sudo jstack <span class="number">38275</span></span><br><span class="line"><span class="number">38275</span>: Unable <span class="built_in">to</span> <span class="built_in">open</span> <span class="built_in">socket</span> <span class="built_in">file</span>: target <span class="built_in">process</span> <span class="keyword">not</span> responding <span class="keyword">or</span> HotSpot VM <span class="keyword">not</span> loaded</span><br><span class="line">The -F option can be used when <span class="keyword">the</span> target <span class="built_in">process</span> is <span class="keyword">not</span> responding</span><br></pre></td></tr></table></figure>
<p>或者：</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">ubuntu<span class="variable">@linasvr</span><span class="symbol">:~</span><span class="variable">$ </span>sudo jstack <span class="number">36730</span></span><br><span class="line"><span class="number">36730</span>: well-known file is <span class="keyword">not</span> secure</span><br></pre></td></tr></table></figure>
<p>那么八成是权限的问题。我们可以用<code>sudo -u</code>命令使用某特定用户执行jstack。比如以上的例子，我们使用jenkins用户来执行<code>jstack</code>命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo -u jenkins -H jstack 36730</span><br></pre></td></tr></table></figure>



<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-07-26-find-high-cpu-thread.html" target="_blank">在生产环境中查出占用大量CPU的Java线程</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-07-26-find-high-cpu-thread.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CPU</tag>
        <tag>JVM</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>使用zabbix监控Nginx</title>
    <url>/%E8%BF%90%E7%BB%B4/2016-07-30-monitor-nginx-with-zabbix.html</url>
    <content><![CDATA[<h4 id="系统环境"><a href="#系统环境" class="headerlink" title="系统环境"></a>系统环境</h4><ul>
<li>Zabbix Server：2.4.8</li>
<li>ZABBIX服务端：192.168.5.254</li>
<li>ZABBIX客户端：192.168.5.251</li>
<li>依赖软件包： net-tools</li>
</ul>
<h4 id="配置nginx-conf"><a href="#配置nginx-conf" class="headerlink" title="配置nginx.conf"></a>配置nginx.conf</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master zabbix_agentd.d]<span class="comment"># vim /etc/nginx/nginx.conf</span></span><br></pre></td></tr></table></figure>
<p>添加以下内容：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> /nginx_status &#123;</span><br><span class="line">  <span class="attribute">stub_status</span> <span class="literal">on</span>;</span><br><span class="line">  <span class="attribute">access_log</span>  <span class="literal">off</span>;</span><br><span class="line">  <span class="attribute">allow</span> <span class="number">127.0.0.1</span>;</span><br><span class="line">  <span class="attribute">allow</span> <span class="number">192.168.5.251</span>;</span><br><span class="line">  <span class="attribute">deny</span> all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重启服务，测试是否可以正常访问nginx_status网页</p>
<h4 id="添加nginx-conf至-etc-zabbix-zabbix-agentd-d"><a href="#添加nginx-conf至-etc-zabbix-zabbix-agentd-d" class="headerlink" title="添加nginx.conf至/etc/zabbix/zabbix_agentd.d/"></a>添加<code>nginx.conf</code>至<code>/etc/zabbix/zabbix_agentd.d/</code></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@master zabbix_agentd.d]<span class="comment"># vim /etc/zabbix/zabbix_agentd.d/nginx.conf</span></span><br></pre></td></tr></table></figure>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">UserParameter</span>=nginx.accepts,/etc/zabbix/zabbix_scripts/nginx_status.sh accepts</span><br><span class="line"><span class="attr">UserParameter</span>=nginx.handled,/etc/zabbix/zabbix_scripts/nginx_status.sh handled</span><br><span class="line"><span class="attr">UserParameter</span>=nginx.requests,/etc/zabbix/zabbix_scripts/nginx_status.sh requests</span><br><span class="line"><span class="attr">UserParameter</span>=nginx.connections.active,/etc/zabbix/zabbix_scripts/nginx_status.sh active</span><br><span class="line"><span class="attr">UserParameter</span>=nginx.connections.reading,/etc/zabbix/zabbix_scripts/nginx_status.sh reading</span><br><span class="line"><span class="attr">UserParameter</span>=nginx.connections.writing,/etc/zabbix/zabbix_scripts/nginx_status.sh writing</span><br><span class="line"><span class="attr">UserParameter</span>=nginx.connections.waiting,/etc/zabbix/zabbix_scripts/nginx_status.sh waiting</span><br></pre></td></tr></table></figure>
<h4 id="添加nginx-status-sh至-etc-zabbix-zabbix-scripts"><a href="#添加nginx-status-sh至-etc-zabbix-zabbix-scripts" class="headerlink" title="添加nginx_status.sh至/etc/zabbix/zabbix_scripts/"></a>添加<code>nginx_status.sh</code>至<code>/etc/zabbix/zabbix_scripts/</code></h4><p>内容如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># Author: krish@toonheart.com </span></span><br><span class="line"><span class="comment"># License: GPLv2</span></span><br><span class="line"><span class="comment"># Set Variables </span></span><br><span class="line">HOST=`/sbin/ifconfig eno16777736 | grep <span class="string">&quot;inet &quot;</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>`</span><br><span class="line">PORT=<span class="string">&quot;80&quot;</span></span><br><span class="line">URI=<span class="string">&quot;nginx_status&quot;</span></span><br><span class="line"><span class="comment"># Functions to return nginx stats</span></span><br><span class="line"><span class="keyword">function</span> active &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| grep <span class="string">&#x27;Active&#x27;</span> | awk <span class="string">&#x27;&#123;print $NF&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> reading &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| grep <span class="string">&#x27;Reading&#x27;</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> writing &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| grep <span class="string">&#x27;Writing&#x27;</span> | awk <span class="string">&#x27;&#123;print $4&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> waiting &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| grep <span class="string">&#x27;Waiting&#x27;</span> | awk <span class="string">&#x27;&#123;print $6&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> accepts &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| awk NR==3 | awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> handled &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| awk NR==3 | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> requests &#123;</span><br><span class="line">	/usr/bin/curl <span class="string">&quot;http://<span class="variable">$HOST</span>:<span class="variable">$PORT</span>/<span class="variable">$URI</span>&quot;</span> 2&gt; /dev/null| awk NR==3 | awk <span class="string">&#x27;&#123;print $3&#125;&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># Run the requested function </span></span><br><span class="line"><span class="variable">$1</span></span><br></pre></td></tr></table></figure>

<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-07-30-monitor-nginx-with-zabbix.html" target="_blank">使用zabbix监控Nginx</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-07-30-monitor-nginx-with-zabbix.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Zabbix</tag>
        <tag>监控</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>RC4被JDK8默认禁用导致腾讯QQ邮箱无法访问</title>
    <url>/java/2016-07-30-use-rc4-in-tencent-mail.html</url>
    <content><![CDATA[<p>7月29日开始，腾讯修改了邮箱的加密方式，导致我们线上的所有的腾讯代收、代发邮件的功能全部失效。解决方法在最后，如果需要可直接跳转至<a href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95">解决方法</a>一节</p>
<h3 id="问题出现"><a href="#问题出现" class="headerlink" title="问题出现"></a>问题出现</h3><p>7月29日开始，线上的所有的腾讯代收、代发邮件的功能全部失效，报<code>handshake_error</code>:</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">javax.mail.MessagingException: Connect failed;</span><br><span class="line">  nested <span class="keyword">exception</span> is:</span><br><span class="line">	javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure</span><br><span class="line">	at com.sun.mail.pop3.<span class="module-access"><span class="module"><span class="identifier">POP3Store</span>.</span></span>protocol<span class="constructor">Connect(POP3Store.<span class="params">java</span>:209)</span></span><br><span class="line">	at javax.mail.<span class="module-access"><span class="module"><span class="identifier">Service</span>.</span></span>connect(<span class="module-access"><span class="module"><span class="identifier">Service</span>.</span></span>java:<span class="number">295</span>)</span><br><span class="line">	at javax.mail.<span class="module-access"><span class="module"><span class="identifier">Service</span>.</span></span>connect(<span class="module-access"><span class="module"><span class="identifier">Service</span>.</span></span>java:<span class="number">176</span>)</span><br><span class="line">	at cn.irenshi.biz.recruit.service.impl.<span class="module-access"><span class="module"><span class="identifier">RecruitReceiveMailServiceImpl</span>.</span></span>test<span class="constructor">Connect(RecruitReceiveMailServiceImpl.<span class="params">java</span>:507)</span></span><br><span class="line">	at cn.irenshi.biz.recruit.service.impl.<span class="module-access"><span class="module"><span class="identifier">RecruitReceiveMailServiceImpl</span>.</span></span>test<span class="constructor">MailConnect(RecruitReceiveMailServiceImpl.<span class="params">java</span>:534)</span></span><br><span class="line">	at sun.reflect.<span class="module-access"><span class="module"><span class="identifier">NativeMethodAccessorImpl</span>.</span></span>invoke0(Native Method)</span><br><span class="line">	at sun.reflect.<span class="module-access"><span class="module"><span class="identifier">NativeMethodAccessorImpl</span>.</span></span>invoke(<span class="module-access"><span class="module"><span class="identifier">NativeMethodAccessorImpl</span>.</span></span>java:<span class="number">62</span>)</span><br><span class="line">	at sun.reflect.<span class="module-access"><span class="module"><span class="identifier">DelegatingMethodAccessorImpl</span>.</span></span>invoke(<span class="module-access"><span class="module"><span class="identifier">DelegatingMethodAccessorImpl</span>.</span></span>java:<span class="number">43</span>)</span><br><span class="line">	at java.lang.reflect.<span class="module-access"><span class="module"><span class="identifier">Method</span>.</span></span>invoke(<span class="module-access"><span class="module"><span class="identifier">Method</span>.</span></span>java:<span class="number">497</span>)</span><br><span class="line">	at org.springframework.aop.support.<span class="module-access"><span class="module"><span class="identifier">AopUtils</span>.</span></span>invoke<span class="constructor">JoinpointUsingReflection(AopUtils.<span class="params">java</span>:302)</span></span><br><span class="line">	at org.springframework.aop.framework.<span class="module-access"><span class="module"><span class="identifier">ReflectiveMethodInvocation</span>.</span></span>invoke<span class="constructor">Joinpoint(ReflectiveMethodInvocation.<span class="params">java</span>:190)</span></span><br><span class="line">	at org.springframework.aop.framework.<span class="module-access"><span class="module"><span class="identifier">ReflectiveMethodInvocation</span>.</span></span>proceed(<span class="module-access"><span class="module"><span class="identifier">ReflectiveMethodInvocation</span>.</span></span>java:<span class="number">157</span>)<span class="operator"></span></span><br><span class="line"><span class="operator">	... </span>more</span><br><span class="line"></span><br><span class="line">Caused by: javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure</span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">Alerts</span>.</span></span>get<span class="constructor">SSLException(Alerts.<span class="params">java</span>:192)</span></span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">Alerts</span>.</span></span>get<span class="constructor">SSLException(Alerts.<span class="params">java</span>:154)</span></span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">SSLSocketImpl</span>.</span></span>recv<span class="constructor">Alert(SSLSocketImpl.<span class="params">java</span>:2023)</span></span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">SSLSocketImpl</span>.</span></span>read<span class="constructor">Record(SSLSocketImpl.<span class="params">java</span>:1125)</span></span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">SSLSocketImpl</span>.</span></span>perform<span class="constructor">InitialHandshake(SSLSocketImpl.<span class="params">java</span>:1375)</span></span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">SSLSocketImpl</span>.</span></span>start<span class="constructor">Handshake(SSLSocketImpl.<span class="params">java</span>:1403)</span></span><br><span class="line">	at sun.security.ssl.<span class="module-access"><span class="module"><span class="identifier">SSLSocketImpl</span>.</span></span>start<span class="constructor">Handshake(SSLSocketImpl.<span class="params">java</span>:1387)</span></span><br><span class="line">	at com.sun.mail.util.<span class="module-access"><span class="module"><span class="identifier">SocketFetcher</span>.</span></span>configure<span class="constructor">SSLSocket(SocketFetcher.<span class="params">java</span>:549)</span></span><br><span class="line">	at com.sun.mail.util.<span class="module-access"><span class="module"><span class="identifier">SocketFetcher</span>.</span></span>create<span class="constructor">Socket(SocketFetcher.<span class="params">java</span>:354)</span></span><br><span class="line">	at com.sun.mail.util.<span class="module-access"><span class="module"><span class="identifier">SocketFetcher</span>.</span></span>get<span class="constructor">Socket(SocketFetcher.<span class="params">java</span>:237)</span></span><br><span class="line">	at com.sun.mail.pop3.Protocol.&lt;init&gt;(<span class="module-access"><span class="module"><span class="identifier">Protocol</span>.</span></span>java:<span class="number">112</span>)</span><br><span class="line">	at com.sun.mail.pop3.<span class="module-access"><span class="module"><span class="identifier">POP3Store</span>.</span></span>get<span class="constructor">Port(POP3Store.<span class="params">java</span>:260)</span></span><br><span class="line">	at com.sun.mail.pop3.<span class="module-access"><span class="module"><span class="identifier">POP3Store</span>.</span></span>protocol<span class="constructor">Connect(POP3Store.<span class="params">java</span>:205)</span><span class="operator"></span></span><br><span class="line"><span class="operator">	... </span><span class="number">132</span> more</span><br></pre></td></tr></table></figure>
<p>记得当时用客户端链接腾讯的企业邮箱时，报证书警告，警告原因是<code>pop.exmail.qq.com</code>这个域名使用了<code>pop.qq.com</code>这个证书，应该是为了省钱吧。但是当用QQ个人邮箱连接的时候，确实使用了正确的证书，那错误原因应该不同。</p>
<h3 id="问题定位"><a href="#问题定位" class="headerlink" title="问题定位"></a>问题定位</h3><p>把问题交给做邮箱连接的同事，结果同事很快告诉我，他在windows上运行代码完全没有任何问题，并且JDK都用了相同的版本：1.8.0_u60。难道这个错误和系统相关？<br>打开Thunderbird尝试连接腾讯邮箱，发现一切也正常。可以断定这个问题不是系统相关的，问题一定出在我们的代码中。网上搜了一些<code>handshake_failure</code>相关的原因如下（<a href="http://stackoverflow.com/a/6353956" title="StackOverflow">StackOverflow</a>）：</p>
<blockquote>
<ul>
<li>Incompatible cipher suites in use by the client and the server. This would require the client to use (or enable) a cipher suite that is supported by the server.</li>
<li>Incompatible versions of SSL in use (the server might accept only TLS v1, while the client is capable of only using SSL v3). Again, the client might have to ensure that it uses a compatible version of the SSL/TLS protocol.</li>
<li>Incomplete trust path for the server certificate; the server’s certificate is probably not trusted by the client. This would usually result in a more verbose error, but it is quite possible. Usually the fix is to import the server’s CA certificate into the client’s trust store.</li>
<li>The cerificate is issued for a different domain. Again, this would have resulted in a more verbose message, but I’ll state the fix here in case this is the cause. The resolution in this case would be get the server (it does not appear to be yours) to use the correct certificate.</li>
</ul>
</blockquote>
<p>问题来了，如果以上是问题所在的话，一定会有一些错误信息输出，但为什么在我的系统中没有任何输出？</p>
<p>想到telnet，因为一般测试邮箱连接都直接使用telnet明文测试一下。当然这个想法是不可行的，如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">fify@fify-PC:~$ telnet pop.qq.com 995</span><br><span class="line">Trying 163.177.72.198...</span><br><span class="line">Connected to pop.qq.com.</span><br><span class="line">Escape character is <span class="string">&#x27;^]&#x27;</span>.</span><br></pre></td></tr></table></figure>
<p>没有办法输入任何东西，原因也很简单，995端口使用了加密。（这里犯迷糊了，现在握手错误就是因为加密问题…）</p>
<p>换一个方式连接POP邮箱：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl s_client -connect pop.qq.com:995</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">CONNECTED(00000003)</span></span><br><span class="line"><span class="string">depth=2</span> <span class="string">C</span> <span class="string">=</span> <span class="string">US,</span> <span class="string">O</span> <span class="string">=</span> <span class="string">GeoTrust</span> <span class="string">Inc.,</span> <span class="string">CN</span> <span class="string">=</span> <span class="string">GeoTrust</span> <span class="string">Global</span> <span class="string">CA</span></span><br><span class="line"><span class="string">verify</span> <span class="string">return:1</span></span><br><span class="line"><span class="string">depth=1</span> <span class="string">C</span> <span class="string">=</span> <span class="string">US,</span> <span class="string">O</span> <span class="string">=</span> <span class="string">GeoTrust</span> <span class="string">Inc.,</span> <span class="string">CN</span> <span class="string">=</span> <span class="string">GeoTrust</span> <span class="string">SSL</span> <span class="string">CA</span> <span class="bullet">-</span> <span class="string">G3</span></span><br><span class="line"><span class="string">verify</span> <span class="string">return:1</span></span><br><span class="line"><span class="string">depth=0</span> <span class="string">C</span> <span class="string">=</span> <span class="string">CN,</span> <span class="string">ST</span> <span class="string">=</span> <span class="string">Guangdong,</span> <span class="string">L</span> <span class="string">=</span> <span class="string">Shenzhen,</span> <span class="string">O</span> <span class="string">=</span> <span class="string">Shenzhen</span> <span class="string">Tencent</span> <span class="string">Computer</span> <span class="string">Systems</span> <span class="string">Company</span> <span class="string">Limited,</span> <span class="string">OU</span> <span class="string">=</span> <span class="string">R&amp;D,</span> <span class="string">CN</span> <span class="string">=</span> <span class="string">pop.qq.com</span></span><br><span class="line"><span class="string">verify</span> <span class="string">return:1</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">Certificate</span> <span class="string">chain</span></span><br><span class="line"> <span class="number">0</span> <span class="string">s:/C=CN/ST=Guangdong/L=Shenzhen/O=Shenzhen</span> <span class="string">Tencent</span> <span class="string">Computer</span> <span class="string">Systems</span> <span class="string">Company</span> <span class="string">Limited/OU=R&amp;D/CN=pop.qq.com</span></span><br><span class="line">   <span class="string">i:/C=US/O=GeoTrust</span> <span class="string">Inc./CN=GeoTrust</span> <span class="string">SSL</span> <span class="string">CA</span> <span class="bullet">-</span> <span class="string">G3</span></span><br><span class="line"> <span class="number">1</span> <span class="string">s:/C=US/O=GeoTrust</span> <span class="string">Inc./CN=GeoTrust</span> <span class="string">SSL</span> <span class="string">CA</span> <span class="bullet">-</span> <span class="string">G3</span></span><br><span class="line">   <span class="string">i:/C=US/O=GeoTrust</span> <span class="string">Inc./CN=GeoTrust</span> <span class="string">Global</span> <span class="string">CA</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">Server</span> <span class="string">certificate</span></span><br><span class="line"><span class="string">-----BEGIN</span> <span class="string">CERTIFICATE-----</span></span><br><span class="line"><span class="string">MIIGbzCCBVegAwIBAgIQZlTnxqFc/rVo50RzuVnejDANBgkqhkiG9w0BAQsFADBE</span></span><br><span class="line"><span class="string">MQswCQYDVQQGEwJVUzEWMBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEdMBsGA1UEAxMU</span></span><br><span class="line"><span class="string">R2VvVHJ1c3QgU1NMIENBIC0gRzMwHhcNMTYwMTI3MDAwMDAwWhcNMTYxMDIzMjM1</span></span><br><span class="line"><span class="string">OTU5WjCBkzELMAkGA1UEBhMCQ04xEjAQBgNVBAgTCUd1YW5nZG9uZzERMA8GA1UE</span></span><br><span class="line"><span class="string">BxQIU2hlbnpoZW4xOjA4BgNVBAoUMVNoZW56aGVuIFRlbmNlbnQgQ29tcHV0ZXIg</span></span><br><span class="line"><span class="string">U3lzdGVtcyBDb21wYW55IExpbWl0ZWQxDDAKBgNVBAsUA1ImRDETMBEGA1UEAxQK</span></span><br><span class="line"><span class="string">cG9wLnFxLmNvbTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALeSY7Vb</span></span><br><span class="line"><span class="string">60Cvv7P2O+zhaZnqlz/KFs//DH4It3xmyMPFOPUFopzN1h8n3/4FPqGBtqEEuWBE</span></span><br><span class="line"><span class="string">/o7soZT30E8bw30Tl07VOcYm/fPKi1pyro3hNEdLi5Wlta9fKxDAvw0U3clSq39R</span></span><br><span class="line"><span class="string">qihYIDAA3QrDuqI54gULa5IZnqM16A9VBULPfIDaXbdgaAIJ5Ak92nC13YcdQYuv</span></span><br><span class="line"><span class="string">egL6jOWSKzCRTqeRAg+6dWkfce1+gAOCuCUDgAso2EJ+k9nFe/LAMMGdGbe4KI9H</span></span><br><span class="line"><span class="string">CwpDCMo+2k2u4SQtXOmuYke7nNmRnpJeL3qZnGWsqT7l3N0mYCc/+3zcMfAcmyuo</span></span><br><span class="line"><span class="string">H90stoWF/G2T2rcCAwEAAaOCAwswggMHMIIBggYDVR0RBIIBeTCCAXWCCm14Mi5x</span></span><br><span class="line"><span class="string">cS5jb22CEmltYXAuZXhtYWlsLnFxLmNvbYISdXBsb2FkLm1haWwucXEuY29tgg90</span></span><br><span class="line"><span class="string">ZWwubWFpbC5xcS5jb22CFGh3c210cC5leG1haWwucXEuY29tgg9tb2IubWFpbC5x</span></span><br><span class="line"><span class="string">cS5jb22CEXJ0eC5leG1haWwucXEuY29tgg1teGJpejIucXEuY29tgg1teGJpejEu</span></span><br><span class="line"><span class="string">cXEuY29tgg5oay5tYWlsLnFxLmNvbYIOY2xvdWRteC5xcS5jb22CFGh3aW1hcC5l</span></span><br><span class="line"><span class="string">eG1haWwucXEuY29tggpteDEucXEuY29tghJzbXRwLmV4bWFpbC5xcS5jb22CEXBv</span></span><br><span class="line"><span class="string">cC5leG1haWwucXEuY29tghNod3BvcC5leG1haWwucXEuY29tggpteDMucXEuY29t</span></span><br><span class="line"><span class="string">ggtzbXRwLnFxLmNvbYIKZGF2LnFxLmNvbYIJZXgucXEuY29tgg9jbmMubWFpbC5x</span></span><br><span class="line"><span class="string">cS5jb22CC2ltYXAucXEuY29tggpwb3AucXEuY29tMAkGA1UdEwQCMAAwDgYDVR0P</span></span><br><span class="line"><span class="string">AQH/BAQDAgWgMCsGA1UdHwQkMCIwIKAeoByGGmh0dHA6Ly9nbi5zeW1jYi5jb20v</span></span><br><span class="line"><span class="string">Z24uY3JsMIGdBgNVHSAEgZUwgZIwgY8GBmeBDAECAjCBhDA/BggrBgEFBQcCARYz</span></span><br><span class="line"><span class="string">aHR0cHM6Ly93d3cuZ2VvdHJ1c3QuY29tL3Jlc291cmNlcy9yZXBvc2l0b3J5L2xl</span></span><br><span class="line"><span class="string">Z2FsMEEGCCsGAQUFBwICMDUMM2h0dHBzOi8vd3d3Lmdlb3RydXN0LmNvbS9yZXNv</span></span><br><span class="line"><span class="string">dXJjZXMvcmVwb3NpdG9yeS9sZWdhbDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYB</span></span><br><span class="line"><span class="string">BQUHAwIwHwYDVR0jBBgwFoAU0m/3lvSFP3I8MH0j2oV4m6N8WnwwVwYIKwYBBQUH</span></span><br><span class="line"><span class="string">AQEESzBJMB8GCCsGAQUFBzABhhNodHRwOi8vZ24uc3ltY2QuY29tMCYGCCsGAQUF</span></span><br><span class="line"><span class="string">BzAChhpodHRwOi8vZ24uc3ltY2IuY29tL2duLmNydDANBgkqhkiG9w0BAQsFAAOC</span></span><br><span class="line"><span class="string">AQEAvta4aGvK5qe31ZnLbmtblhgLD11dAdSom3sEnkF8UHtoi+gPiHBmHy1t39Du</span></span><br><span class="line"><span class="string">2w+5aeriqwsetdDNuAhh6ckKJhGjc9ochWw2lvyuHPko8sSDdBd/oUYBh60lREwB</span></span><br><span class="line"><span class="string">DoAi7x37QIjia4yprFCNs/+bV+bee+2nijeNYibgwLQ+5jZL89jC6BVXxLSTenVw</span></span><br><span class="line"><span class="string">B2bzQPauNo+DOsB6ubY/i5r9p2E1DHAO9AluN/epJZ1gwZhYlOey71s59341w/ql</span></span><br><span class="line"><span class="string">ZJImDrWch+Gj1ZgnXWnttgOSafqynPA6VtiFyYGF4zLboxIkNiyuwj+ZzuugV97z</span></span><br><span class="line"><span class="string">IurYVE9FA7vTlfeJhAkG2gIwsA==</span></span><br><span class="line"><span class="string">-----END</span> <span class="string">CERTIFICATE-----</span></span><br><span class="line"><span class="string">subject=/C=CN/ST=Guangdong/L=Shenzhen/O=Shenzhen</span> <span class="string">Tencent</span> <span class="string">Computer</span> <span class="string">Systems</span> <span class="string">Company</span> <span class="string">Limited/OU=R&amp;D/CN=pop.qq.com</span></span><br><span class="line"><span class="string">issuer=/C=US/O=GeoTrust</span> <span class="string">Inc./CN=GeoTrust</span> <span class="string">SSL</span> <span class="string">CA</span> <span class="bullet">-</span> <span class="string">G3</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="literal">No</span> <span class="string">client</span> <span class="string">certificate</span> <span class="string">CA</span> <span class="string">names</span> <span class="string">sent</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">SSL</span> <span class="string">handshake</span> <span class="string">has</span> <span class="string">read</span> <span class="number">3070 </span><span class="string">bytes</span> <span class="string">and</span> <span class="string">written</span> <span class="number">619</span> <span class="string">bytes</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">New,</span> <span class="string">TLSv1/SSLv3,</span> <span class="string">Cipher</span> <span class="string">is</span> <span class="string">RC4-SHA</span></span><br><span class="line"><span class="string">Server</span> <span class="string">public</span> <span class="string">key</span> <span class="string">is</span> <span class="number">2048 </span><span class="string">bit</span></span><br><span class="line"><span class="string">Secure</span> <span class="string">Renegotiation</span> <span class="string">IS</span> <span class="string">supported</span></span><br><span class="line"><span class="attr">Compression:</span> <span class="string">NONE</span></span><br><span class="line"><span class="attr">Expansion:</span> <span class="string">NONE</span></span><br><span class="line"><span class="literal">No</span> <span class="string">ALPN</span> <span class="string">negotiated</span></span><br><span class="line"><span class="attr">SSL-Session:</span></span><br><span class="line">    <span class="attr">Protocol  :</span> <span class="string">TLSv1.2</span></span><br><span class="line">    <span class="attr">Cipher    :</span> <span class="string">RC4-SHA</span></span><br><span class="line">    <span class="attr">Session-ID:</span> <span class="string">E278833690D2364F44B8E2B6D3F3708888411AD55298F02A0710C73FE229BBE9</span></span><br><span class="line">    <span class="attr">Session-ID-ctx:</span> </span><br><span class="line">    <span class="attr">Master-Key:</span> <span class="string">AF8A9394C87F52872A31DCC5ED62FF5F97B6F621CC9337E151D5F6229E9F231626F10B392A1938669EE72911ABD860D6</span></span><br><span class="line">    <span class="attr">Key-Arg   :</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">PSK identity:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">PSK identity hint:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">SRP username:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">TLS session ticket lifetime hint:</span> <span class="number">300</span> <span class="string">(seconds)</span></span><br><span class="line">    <span class="attr">TLS session ticket:</span></span><br><span class="line">    <span class="number">0000</span> <span class="bullet">-</span> <span class="string">6c</span> <span class="number">30</span> <span class="number">25</span> <span class="string">d9</span> <span class="number">92</span> <span class="number">71</span> <span class="number">25</span> <span class="string">7c-3e</span> <span class="string">bd</span> <span class="string">7b</span> <span class="string">e6</span> <span class="string">e2</span> <span class="string">a5</span> <span class="number">13</span> <span class="string">d1</span>   <span class="string">l0%..q%|&gt;.&#123;.....</span></span><br><span class="line">    <span class="number">0010</span> <span class="bullet">-</span> <span class="string">9b</span> <span class="string">f9</span> <span class="number">61</span> <span class="string">e6</span> <span class="string">3d</span> <span class="string">dc</span> <span class="string">e6</span> <span class="string">ea-96</span> <span class="string">9d</span> <span class="number">04</span> <span class="number">02</span> <span class="string">ea</span> <span class="string">6f</span> <span class="number">68</span> <span class="string">0f</span>   <span class="string">..a.=........oh.</span></span><br><span class="line">    <span class="number">0020</span> <span class="bullet">-</span> <span class="number">18</span> <span class="string">a3</span> <span class="string">a3</span> <span class="string">e6</span> <span class="number">39</span> <span class="number">02</span> <span class="string">b9</span> <span class="string">d2-dd</span> <span class="string">d1</span> <span class="string">2c</span> <span class="number">18</span> <span class="string">6d</span> <span class="string">9c</span> <span class="number">87</span> <span class="string">e5</span>   <span class="string">....9.....,.m...</span></span><br><span class="line">    <span class="number">0030</span> <span class="bullet">-</span> <span class="number">31</span> <span class="string">a9</span> <span class="number">53</span> <span class="string">a0</span> <span class="string">6c</span> <span class="string">2d</span> <span class="string">4c</span> <span class="string">b6-d4</span> <span class="string">d6</span> <span class="number">35</span> <span class="string">ef</span> <span class="string">d9</span> <span class="number">04</span> <span class="string">b0</span> <span class="string">b9</span>   <span class="number">1.</span><span class="string">S.l-L...5.....</span></span><br><span class="line">    <span class="number">0040</span> <span class="bullet">-</span> <span class="number">70</span> <span class="string">af</span> <span class="number">82</span> <span class="number">74</span> <span class="string">1e</span> <span class="string">1d</span> <span class="number">26</span> <span class="string">9a-00</span> <span class="number">00</span> <span class="string">6b</span> <span class="number">90</span> <span class="string">2e</span> <span class="string">eb</span> <span class="number">56</span> <span class="string">e9</span>   <span class="string">p..t..&amp;...k...V.</span></span><br><span class="line">    <span class="number">0050</span> <span class="bullet">-</span> <span class="string">d8</span> <span class="string">f4</span> <span class="string">cd</span> <span class="number">56</span> <span class="string">d5</span> <span class="string">c2</span> <span class="number">02</span> <span class="number">80</span><span class="string">-0e</span> <span class="string">d9</span> <span class="number">15</span> <span class="string">e5</span> <span class="string">2a</span> <span class="string">b9</span> <span class="string">1f</span> <span class="string">f3</span>   <span class="string">...V........*...</span></span><br><span class="line">    <span class="number">0060</span> <span class="bullet">-</span> <span class="string">8a</span> <span class="number">90</span> <span class="string">7b</span> <span class="string">c0</span> <span class="number">72</span> <span class="string">6e</span> <span class="string">c5</span> <span class="string">2a-04</span> <span class="string">2c</span> <span class="number">91</span> <span class="string">1c</span> <span class="number">11</span> <span class="string">fd</span> <span class="number">40</span> <span class="string">ba</span>   <span class="string">..&#123;.rn.*.,....@.</span></span><br><span class="line">    <span class="number">0070</span> <span class="bullet">-</span> <span class="number">38</span> <span class="string">fb</span> <span class="string">db</span> <span class="string">fb</span> <span class="string">eb</span> <span class="string">b7</span> <span class="number">65</span> <span class="string">e1-e1</span> <span class="number">51</span> <span class="string">1a</span> <span class="string">e3</span> <span class="string">b2</span> <span class="string">f3</span> <span class="number">64</span> <span class="string">4e</span>   <span class="number">8</span><span class="string">.....e..Q....dN</span></span><br><span class="line">    <span class="number">0080</span> <span class="bullet">-</span> <span class="number">54</span> <span class="string">6b</span> <span class="string">5f</span> <span class="string">0e</span> <span class="string">9d</span> <span class="string">be</span> <span class="number">40</span> <span class="number">60</span><span class="string">-dd</span> <span class="number">68</span> <span class="string">8f</span> <span class="number">52</span> <span class="string">5d</span> <span class="string">f3</span> <span class="number">48</span> <span class="number">36</span>   <span class="string">Tk_...@`.h.R].H6</span></span><br><span class="line">    <span class="number">0090</span> <span class="bullet">-</span> <span class="number">40</span> <span class="string">7b</span> <span class="number">11</span> <span class="number">68</span> <span class="number">10</span> <span class="string">7f</span> <span class="string">7d</span> <span class="string">e2-d6</span> <span class="number">93</span> <span class="number">19</span> <span class="number">48</span> <span class="number">42</span> <span class="string">f0</span> <span class="string">da</span> <span class="string">bc</span>   <span class="string">@&#123;.h..&#125;....HB...</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">Start Time:</span> <span class="number">1470455760</span></span><br><span class="line">    <span class="attr">Timeout   :</span> <span class="number">300</span> <span class="string">(sec)</span></span><br><span class="line">    <span class="attr">Verify return code:</span> <span class="number">0</span> <span class="string">(ok)</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">+OK</span> <span class="string">QQMail</span> <span class="string">POP3</span> <span class="string">Server</span> <span class="string">v1.0</span> <span class="string">Service</span> <span class="string">Ready(QQMail</span> <span class="string">v2.0)</span></span><br></pre></td></tr></table></figure>
<p>注意到以下片段</p>
<blockquote>
<p>SSL-Session:<br>   Protocol  : TLSv1.2<br>   Cipher    : RC4-SHA</p>
</blockquote>
<p>可以看到，加密使用的协议是<code>TLSv1.2</code>，Cipher使用的是<code>RC4-SHA</code>。</p>
<p>那么问题是出在这两个地方吗？</p>
<h3 id="JavaMail握手时的Protocol和Cipher"><a href="#JavaMail握手时的Protocol和Cipher" class="headerlink" title="JavaMail握手时的Protocol和Cipher"></a>JavaMail握手时的Protocol和Cipher</h3><p>在Java启动中增加参数<code>-Djavax.net.debug=all</code>可以开启加密协议的调试模式。详情可以参考<a href="http://docs.oracle.com/javase/6/docs/technotes/guides/security/jsse/ReadDebug.html">Oracle提供的文档</a>。</p>
<p>开启之后，连接邮箱握手的过程中打出了以下日志：</p>
<figure class="highlight roboconf"><table><tr><td class="code"><pre><span class="line">trigger seeding of SecureRandom</span><br><span class="line">done seeding SecureRandom</span><br><span class="line">Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_GCM_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_GCM_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_CBC_SHA256</span><br><span class="line">Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_GCM_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_RSA_WITH_AES_256_GCM_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDH_ECDSA_WITH_AES_256_CBC_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDH_RSA_WITH_AES_256_GCM_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384</span><br><span class="line">Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA256</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_DHE_DSS_WITH_AES_256_CBC_SHA256</span><br><span class="line">Ignoring unavailable cipher suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA</span><br><span class="line">Ignoring unavailable cipher suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</span><br><span class="line">Allow unsafe renegotiation: false</span><br><span class="line">Allow legacy hello messages: true</span><br><span class="line">Is initial handshake: true</span><br><span class="line">Is secure renegotiation: false</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_RSA_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_DHE_DSS_WITH_AES_128_CBC_SHA256 for TLSv1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_RSA_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">Ignoring unsupported cipher suite: TLS_DHE_DSS_WITH_AES_128_CBC_SHA256 for TLSv1.1</span><br><span class="line">%% No cached client session</span><br><span class="line">*** ClientHello, TLSv1.2</span><br><span class="line">RandomCookie:  GMT: 1453331365 bytes = &#123; 172, 246, 197, 31, 208, 63, 31, 30, 107, 70, 211, 242, 90, 243, 100, 108, 44, 192, 70, 4, 238, 84, 176, 59, 5, 75, 162, 127 &#125;</span><br><span class="line">Session ID:  &#123;&#125;</span><br><span class="line">Cipher Suites: [TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256, TLS_DHE_RSA_WITH_AES_128_CBC_SHA256, TLS_DHE_DSS_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDH_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_DSS_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDH_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDH_RSA_WITH_AES_128_GCM_SHA256, TLS_DHE_RSA_WITH_AES_128_GCM_SHA256, TLS_DHE_DSS_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA, TLS_EMPTY_RENEGOTIATION_INFO_SCSV]</span><br><span class="line">Compression Methods:  &#123; 0 &#125;</span><br><span class="line">Extension elliptic_curves, curve names: &#123;<span class="attribute">secp256r1, sect163k1, sect163r2, secp192r1, secp224r1, sect233k1, sect233r1, sect283k1, sect283r1, secp384r1, sect409k1, sect409r1, secp521r1, sect571k1, sect571r1, secp160k1, secp160r1, secp160r2, sect163r1, secp192k1, sect193r1, sect193r2, secp224k1, sect239k1, secp256k1&#125;</span></span><br><span class="line"><span class="attribute">Extension ec_point_formats, formats</span>: [uncompressed]</span><br><span class="line">Extension signature_algorithms, signature_algorithms: SHA512withECDSA, SHA512withRSA, SHA384withECDSA, SHA384withRSA, SHA256withECDSA, SHA256withRSA, SHA224withECDSA, SHA224withRSA, SHA1withECDSA, SHA1withRSA, SHA1withDSA, MD5withRSA</span><br><span class="line">Extension server_name, server_name: [type=host_name (0), value=pop<span class="variable">.qq</span><span class="variable">.com</span>]</span><br><span class="line">***</span><br><span class="line">[write] MD5 and SHA1 hashes:  len = 214</span><br><span class="line">0000: 01 00 00 D2 03 03 57 A0   14 A5 AC F6 C5 1F D0 3F  .....<span class="variable">.W</span>........?</span><br><span class="line">0010: 1F 1E 6B 46 D3 F2 5A F3   64 6C 2C C0 46 04 EE 54  .<span class="variable">.kF</span>.<span class="variable">.Z</span><span class="variable">.dl</span>,<span class="variable">.F</span>.<span class="variable">.T</span></span><br><span class="line">0020: B0 3B 05 4B A2 7F 00 00   3A C0 23 C0 27 00 3C C0  .;.<span class="attribute">K....</span>:.#.&#x27;.&lt;.</span><br><span class="line">0030: 25 C0 29 00 67 00 40 C0   09 C0 13 00 2F C0 04 C0  %.)<span class="variable">.g</span>.@...../...</span><br><span class="line">0040: 0E 00 33 00 32 C0 2B C0   2F 00 9C C0 2D C0 31 00  ..3.2.+./..<span class="variable">.-</span>.1.</span><br><span class="line">0050: 9E 00 A2 C0 08 C0 12 00   0A C0 03 C0 0D 00 16 00  ................</span><br><span class="line">0060: 13 00 FF 01 00 00 6F 00   0A 00 34 00 32 00 17 00  .....<span class="variable">.o</span>...4.2...</span><br><span class="line">0070: 01 00 03 00 13 00 15 00   06 00 07 00 09 00 0A 00  ................</span><br><span class="line">0080: 18 00 0B 00 0C 00 19 00   0D 00 0E 00 0F 00 10 00  ................</span><br><span class="line">0090: 11 00 02 00 12 00 04 00   05 00 14 00 08 00 16 00  ................</span><br><span class="line">00A0: 0B 00 02 01 00 00 0D 00   1A 00 18 06 03 06 01 05  ................</span><br><span class="line">00B0: 03 05 01 04 03 04 01 03   03 03 01 02 03 02 01 02  ................</span><br><span class="line">00C0: 02 01 01 00 00 00 0F 00   0D 00 00 0A 70 6F 70 2E  ...........<span class="variable">.pop</span>.</span><br><span class="line">00D0: 71 71 2E 63 6F 6D                                  qq<span class="variable">.com</span></span><br><span class="line">http-nio-8080-exec-2, WRITE: TLSv1.2 Handshake, length = 214</span><br><span class="line">[Raw write]: length = 219</span><br><span class="line">0000: 16 03 03 00 D6 01 00 00   D2 03 03 57 A0 14 A5 AC  ..........<span class="variable">.W</span>....</span><br><span class="line">0010: F6 C5 1F D0 3F 1F 1E 6B   46 D3 F2 5A F3 64 6C 2C  ....?.<span class="variable">.kF</span>.<span class="variable">.Z</span><span class="variable">.dl</span>,</span><br><span class="line">0020: C0 46 04 EE 54 B0 3B 05   4B A2 7F 00 00 3A C0 23  <span class="variable">.F</span>.<span class="variable">.T</span>.;.<span class="attribute">K....</span>:.#</span><br><span class="line">0030: C0 27 00 3C C0 25 C0 29   00 67 00 40 C0 09 C0 13  .&#x27;.&lt;.%.)<span class="variable">.g</span>.@....</span><br><span class="line">0040: 00 2F C0 04 C0 0E 00 33   00 32 C0 2B C0 2F 00 9C  ./.....3.2.+./..</span><br><span class="line">0050: C0 2D C0 31 00 9E 00 A2   C0 08 C0 12 00 0A C0 03  <span class="variable">.-</span>.1............</span><br><span class="line">0060: C0 0D 00 16 00 13 00 FF   01 00 00 6F 00 0A 00 34  ..........<span class="variable">.o</span>...4</span><br><span class="line">0070: 00 32 00 17 00 01 00 03   00 13 00 15 00 06 00 07  .2..............</span><br><span class="line">0080: 00 09 00 0A 00 18 00 0B   00 0C 00 19 00 0D 00 0E  ................</span><br><span class="line">0090: 00 0F 00 10 00 11 00 02   00 12 00 04 00 05 00 14  ................</span><br><span class="line">00A0: 00 08 00 16 00 0B 00 02   01 00 00 0D 00 1A 00 18  ................</span><br><span class="line">00B0: 06 03 06 01 05 03 05 01   04 03 04 01 03 03 03 01  ................</span><br><span class="line">00C0: 02 03 02 01 02 02 01 01   00 00 00 0F 00 0D 00 00  ................</span><br><span class="line">00D0: 0A 70 6F 70 2E 71 71 2E   63 6F 6D                 <span class="variable">.pop</span><span class="variable">.qq</span><span class="variable">.com</span></span><br><span class="line">javax<span class="variable">.mail</span><span class="variable">.MessagingException</span>: Connect failed;</span><br><span class="line">  <span class="attribute">nested exception is</span>:</span><br><span class="line">	javax<span class="variable">.net</span><span class="variable">.ssl</span><span class="variable">.SSLHandshakeException</span>: Received fatal alert: handshake_failure</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.pop</span>3<span class="variable">.POP</span>3Store<span class="variable">.protocolConnect</span>(POP3Store<span class="variable">.java</span>:209)</span><br><span class="line">	at javax<span class="variable">.mail</span><span class="variable">.Service</span><span class="variable">.connect</span>(Service<span class="variable">.java</span>:295)</span><br><span class="line">	at javax<span class="variable">.mail</span><span class="variable">.Service</span><span class="variable">.connect</span>(Service<span class="variable">.java</span>:176)</span><br><span class="line">	at cn<span class="variable">.irenshi</span><span class="variable">.biz</span><span class="variable">.recruit</span><span class="variable">.service</span><span class="variable">.impl</span><span class="variable">.RecruitReceiveMailServiceImpl</span><span class="variable">.testConnect</span>(RecruitReceiveMailServiceImpl<span class="variable">.java</span>:507)</span><br><span class="line">	at cn<span class="variable">.irenshi</span><span class="variable">.biz</span><span class="variable">.recruit</span><span class="variable">.service</span><span class="variable">.impl</span><span class="variable">.RecruitReceiveMailServiceImpl</span><span class="variable">.testMailConnect</span>(RecruitReceiveMailServiceImpl<span class="variable">.java</span>:534)</span><br><span class="line">	at sun<span class="variable">.reflect</span><span class="variable">.NativeMethodAccessorImpl</span><span class="variable">.invoke</span>0(Native Method)</span><br><span class="line">	at sun<span class="variable">.reflect</span><span class="variable">.NativeMethodAccessorImpl</span><span class="variable">.invoke</span>(NativeMethodAccessorImpl<span class="variable">.java</span>:62)</span><br><span class="line">	at sun<span class="variable">.reflect</span><span class="variable">.DelegatingMethodAccessorImpl</span><span class="variable">.invoke</span>(DelegatingMethodAccessorImpl<span class="variable">.java</span>:43)</span><br><span class="line">	at java<span class="variable">.lang</span><span class="variable">.reflect</span><span class="variable">.Method</span><span class="variable">.invoke</span>(Method<span class="variable">.java</span>:497)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.support</span><span class="variable">.AopUtils</span><span class="variable">.invokeJoinpointUsingReflection</span>(AopUtils<span class="variable">.java</span>:302)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.ReflectiveMethodInvocation</span><span class="variable">.invokeJoinpoint</span>(ReflectiveMethodInvocation<span class="variable">.java</span>:190)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.ReflectiveMethodInvocation</span><span class="variable">.proceed</span>(ReflectiveMethodInvocation<span class="variable">.java</span>:157)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.transaction</span><span class="variable">.interceptor</span><span class="variable">.TransactionInterceptor</span>$1<span class="variable">.proceedWithInvocation</span>(TransactionInterceptor<span class="variable">.java</span>:99)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.transaction</span><span class="variable">.interceptor</span><span class="variable">.TransactionAspectSupport</span><span class="variable">.invokeWithinTransaction</span>(TransactionAspectSupport<span class="variable">.java</span>:281)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.transaction</span><span class="variable">.interceptor</span><span class="variable">.TransactionInterceptor</span><span class="variable">.invoke</span>(TransactionInterceptor<span class="variable">.java</span>:96)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.ReflectiveMethodInvocation</span><span class="variable">.proceed</span>(ReflectiveMethodInvocation<span class="variable">.java</span>:179)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.JdkDynamicAopProxy</span><span class="variable">.invoke</span>(JdkDynamicAopProxy<span class="variable">.java</span>:207)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.proxy</span>.$Proxy1083<span class="variable">.testMailConnect</span>(Unknown Source)</span><br><span class="line">	at cn<span class="variable">.irenshi</span><span class="variable">.web</span><span class="variable">.controller</span><span class="variable">.recruit</span><span class="variable">.RecruitReceiveMailController</span><span class="variable">.testMailConnect</span>(RecruitReceiveMailController<span class="variable">.java</span>:116)</span><br><span class="line">	at cn<span class="variable">.irenshi</span><span class="variable">.web</span><span class="variable">.controller</span><span class="variable">.recruit</span><span class="variable">.RecruitReceiveMailController</span>$$FastClassBySpringCGLIB$$4d626811<span class="variable">.invoke</span>(&lt;generated&gt;)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.cglib</span><span class="variable">.proxy</span><span class="variable">.MethodProxy</span><span class="variable">.invoke</span>(MethodProxy<span class="variable">.java</span>:204)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.CglibAopProxy</span>$CglibMethodInvocation<span class="variable">.invokeJoinpoint</span>(CglibAopProxy<span class="variable">.java</span>:717)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.ReflectiveMethodInvocation</span><span class="variable">.proceed</span>(ReflectiveMethodInvocation<span class="variable">.java</span>:157)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.security</span><span class="variable">.access</span><span class="variable">.intercept</span><span class="variable">.aopalliance</span><span class="variable">.MethodSecurityInterceptor</span><span class="variable">.invoke</span>(MethodSecurityInterceptor<span class="variable">.java</span>:68)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.ReflectiveMethodInvocation</span><span class="variable">.proceed</span>(ReflectiveMethodInvocation<span class="variable">.java</span>:179)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.interceptor</span><span class="variable">.ExposeInvocationInterceptor</span><span class="variable">.invoke</span>(ExposeInvocationInterceptor<span class="variable">.java</span>:92)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.ReflectiveMethodInvocation</span><span class="variable">.proceed</span>(ReflectiveMethodInvocation<span class="variable">.java</span>:179)</span><br><span class="line">	at org<span class="variable">.springframework</span><span class="variable">.aop</span><span class="variable">.framework</span><span class="variable">.CglibAopProxy</span>$DynamicAdvisedInterceptor<span class="variable">.intercept</span>(CglibAopProxy<span class="variable">.java</span>:653)</span><br><span class="line">    at ...</span><br><span class="line">Caused by: javax<span class="variable">.net</span><span class="variable">.ssl</span><span class="variable">.SSLHandshakeException</span>: Received fatal alert: handshake_failure</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.Alerts</span><span class="variable">.getSSLException</span>(Alerts<span class="variable">.java</span>:192)</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.Alerts</span><span class="variable">.getSSLException</span>(Alerts<span class="variable">.java</span>:154)</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.SSLSocketImpl</span><span class="variable">.recvAlert</span>(SSLSocketImpl<span class="variable">.java</span>:2023)</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.SSLSocketImpl</span><span class="variable">.readRecord</span>(SSLSocketImpl<span class="variable">.java</span>:1125)</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.SSLSocketImpl</span><span class="variable">.performInitialHandshake</span>(SSLSocketImpl<span class="variable">.java</span>:1375)</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.SSLSocketImpl</span><span class="variable">.startHandshake</span>(SSLSocketImpl<span class="variable">.java</span>:1403)</span><br><span class="line">	at sun<span class="variable">.security</span><span class="variable">.ssl</span><span class="variable">.SSLSocketImpl</span><span class="variable">.startHandshake</span>(SSLSocketImpl<span class="variable">.java</span>:1387)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.util</span><span class="variable">.SocketFetcher</span><span class="variable">.configureSSLSocket</span>(SocketFetcher<span class="variable">.java</span>:549)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.util</span><span class="variable">.SocketFetcher</span><span class="variable">.createSocket</span>(SocketFetcher<span class="variable">.java</span>:354)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.util</span><span class="variable">.SocketFetcher</span><span class="variable">.getSocket</span>(SocketFetcher<span class="variable">.java</span>:237)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.pop</span>3<span class="variable">.Protocol</span>.&lt;init&gt;(Protocol<span class="variable">.java</span>:112)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.pop</span>3<span class="variable">.POP</span>3Store<span class="variable">.getPort</span>(POP3Store<span class="variable">.java</span>:260)</span><br><span class="line">	at com<span class="variable">.sun</span><span class="variable">.mail</span><span class="variable">.pop</span>3<span class="variable">.POP</span>3Store<span class="variable">.protocolConnect</span>(POP3Store<span class="variable">.java</span>:205)</span><br><span class="line">	... 132 more</span><br><span class="line">[Raw read]: length = 5</span><br><span class="line">0000: 15 03 03 00 02                                     .....</span><br><span class="line">[Raw read]: length = 2</span><br><span class="line">0000: 02 28                                              .(</span><br><span class="line">http-nio-8080-exec-2, READ: TLSv1.2 Alert, length = 2</span><br><span class="line">http-nio-8080-exec-2, RECV TLSv1.2 ALERT:  fatal, handshake_failure</span><br><span class="line">http-nio-8080-exec-2, called closeSocket()</span><br><span class="line">http-nio-8080-exec-2, handling exception: javax<span class="variable">.net</span><span class="variable">.ssl</span><span class="variable">.SSLHandshakeException</span>: Received fatal alert: handshake_failure</span><br></pre></td></tr></table></figure>
<p>注意到：</p>
<blockquote>
<p>Cipher Suites: [TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDH_RSA_WITH_AES_128_CBC_SHA256, TLS_DHE_RSA_WITH_AES_128_CBC_SHA256, TLS_DHE_DSS_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDH_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_DSS_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDH_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDH_RSA_WITH_AES_128_GCM_SHA256, TLS_DHE_RSA_WITH_AES_128_GCM_SHA256, TLS_DHE_DSS_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA, TLS_EMPTY_RENEGOTIATION_INFO_SCSV]</p>
</blockquote>
<p>发现其中果然没有<code>RC4</code>相关的Cipher Suites。</p>
<p>在同事Windows机器上试了以下，输入果然不同，如下：</p>
<blockquote>
<p>Cipher Suites: [TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDH_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_RSA_WITH_AES_128_CBC_SHA, TLS_DHE_DSS_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_RC4_128_SHA, TLS_ECDHE_RSA_WITH_RC4_128_SHA, SSL_RSA_WITH_RC4_128_SHA, TLS_ECDH_ECDSA_WITH_RC4_128_SHA, TLS_ECDH_RSA_WITH_RC4_128_SHA, TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA, SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA, SSL_RSA_WITH_RC4_128_MD5, TLS_EMPTY_RENEGOTIATION_INFO_SCSV]</p>
</blockquote>
<p>赫然发现：SSL_RSA_WITH_RC4_128_SHA。这正是我们想要的东西。</p>
<h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>问题找到了，解决办法应该也比较容易找到。查看POP协议相关的<a href="https://javamail.java.net/nonav/docs/api/com/sun/mail/pop3/package-summary.html">所有参数</a>，找到了<code>mail.pop3.ssl.ciphersuites</code>。在JavaMail的Properties中增加相关的<code>SSL_RSA_WITH_RC4_128_SHA</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">prop.setProperties(<span class="string">&quot;mail.pop3s.ssl.ciphersuites&quot;</span>, <span class="string">&quot;SSL_RSA_WITH_RC4_128_SHA&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>重启服务器，测试，一气呵成，结果：<code>handshake_failure</code></p>
<h3 id="还是系统问题？"><a href="#还是系统问题？" class="headerlink" title="还是系统问题？"></a>还是系统问题？</h3><p>以<code>SSL_RSA_WITH_RC4_128_SHA</code>为关键字搜索，搜到了这篇文章：<a href="https://support.blancco.com/index.php?/Knowledgebase/Article/View/497/117/java-8-update-60-disables-rc4-cipher-suites-causes-issues-with-blancco-erasure-software-and-mc-3-communication">Java 8 update 60 disables “RC4” cipher suites: Causes issues with Blancco erasure software and MC 3 communication</a>。这是别的软件遇到的问题，但原因是一样的。</p>
<p>原来从JDK 1.8.0_u60开始，默认禁止了RC4这个算法。可以在<code>&#123;JRE_HOME&#125;/lib/security/java.security</code>找到相关配置：</p>
<blockquote>
<p>534 jdk.tls.disabledAlgorithms=SSLv3, RC4, MD5withRSA, DH keySize &lt; 768</p>
</blockquote>
<p>以及</p>
<blockquote>
<p>586 jdk.tls.legacyAlgorithms= <br>587         K_NULL, C_NULL, M_NULL, <br>588         DHE_DSS_EXPORT, DHE_RSA_EXPORT, DH_anon_EXPORT, DH_DSS_EXPORT, <br>589         DH_RSA_EXPORT, RSA_EXPORT, <br>590         DH_anon, ECDH_anon, <br>591         RC4_128, RC4_40, DES_CBC, DES40_CBC</p>
</blockquote>
<p>那Windows中同样的JDK版本，为什么却可以正常使用呢？比较发现在Windows安装之后的Java目录中，有两个部分，一个是JDK目录（其中包含一个JRE目录），一个是直接的JRE目录。打开两个<code>java.security</code>文件，惊奇的发现两个文件并不相同，JRE目录中的<code>java.security</code>并不包含禁用RC4算法这些配置。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><h4 id="启用Java的RC4算法"><a href="#启用Java的RC4算法" class="headerlink" title="启用Java的RC4算法"></a>启用Java的RC4算法</h4><p>没有去深研究为什么JDK会默认禁止这个算法，也不知道腾讯为什么会重新选择了一个JDK默认禁用的算法（7月29日之前是没有问题的）。但由于需要用到QQ邮箱，所以必须得开启这个算法。开启步骤如下：</p>
<ol>
<li>Go to the Java JRE installation folder: {JRE_HOME}\lib\security\</li>
<li>Locate java.security file.</li>
<li>Make a backup copy of the file.</li>
<li>Edit the java.security file with a text editor software (for example Notepad) according to the example further below.</li>
</ol>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">534c534</span><br><span class="line"><span class="deletion">- jdk.tls.disabledAlgorithms=SSLv3, RC4, MD5withRSA, DH keySize &lt; 768</span></span><br><span class="line"><span class="addition">+ jdk.tls.disabledAlgorithms=SSLv3, MD5withRSA, DH keySize &lt; 768</span></span><br><span class="line">591c591</span><br><span class="line"><span class="deletion">-         RC4_128, RC4_40, DES_CBC, DES40_CBC</span></span><br><span class="line"><span class="addition">+         DES_CBC, DES40_CBC</span></span><br></pre></td></tr></table></figure>

<h4 id="启用协议"><a href="#启用协议" class="headerlink" title="启用协议"></a>启用协议</h4><p>在POP/SMTP的协议中增加最新的TLSv1.2协议：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">prop.setProperties(<span class="string">&quot;mail.pop3s.ssl.protocols&quot;</span>, <span class="string">&quot;TSLv1 TSLv1.1 TLSv1.2&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">prop.setProperties(<span class="string">&quot;mail.smtps.ssl.protocols&quot;</span>, <span class="string">&quot;TSLv1 TSLv1.1 TLSv1.2&quot;</span>);</span><br></pre></td></tr></table></figure>

<h4 id="启用Cipher-Scites"><a href="#启用Cipher-Scites" class="headerlink" title="启用Cipher Scites"></a>启用Cipher Scites</h4><p>因为我需要兼容的不只是RC4这个算法，所以我启用了大部分的Cipher Suites</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">prop.setProperties(<span class="string">&quot;mail.pop3s.ssl.ciphersuites&quot;</span>, <span class="string">&quot;TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDH_RSA_WITH_AES_128_CBC_SHA TLS_DHE_RSA_WITH_AES_128_CBC_SHA TLS_DHE_DSS_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_RC4_128_SHA TLS_ECDHE_RSA_WITH_RC4_128_SHA SSL_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_RC4_128_SHA TLS_ECDH_RSA_WITH_RC4_128_SHA TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_RC4_128_MD5 TLS_EMPTY_RENEGOTIATION_INFO_SCSV&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">prop.setProperties(<span class="string">&quot;mail.smtps.ssl.ciphersuites&quot;</span>, <span class="string">&quot;TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA TLS_RSA_WITH_AES_128_CBC_SHA TLS_ECDH_ECDSA_WITH_AES_128_CBC_SHA TLS_ECDH_RSA_WITH_AES_128_CBC_SHA TLS_DHE_RSA_WITH_AES_128_CBC_SHA TLS_DHE_DSS_WITH_AES_128_CBC_SHA TLS_ECDHE_ECDSA_WITH_RC4_128_SHA TLS_ECDHE_RSA_WITH_RC4_128_SHA SSL_RSA_WITH_RC4_128_SHA TLS_ECDH_ECDSA_WITH_RC4_128_SHA TLS_ECDH_RSA_WITH_RC4_128_SHA TLS_ECDHE_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_ECDSA_WITH_3DES_EDE_CBC_SHA TLS_ECDH_RSA_WITH_3DES_EDE_CBC_SHA SSL_DHE_RSA_WITH_3DES_EDE_CBC_SHA SSL_DHE_DSS_WITH_3DES_EDE_CBC_SHA SSL_RSA_WITH_RC4_128_MD5 TLS_EMPTY_RENEGOTIATION_INFO_SCSV&quot;</span>);</span><br></pre></td></tr></table></figure>

<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/java/2016-07-30-use-rc4-in-tencent-mail.html" target="_blank">RC4被JDK8默认禁用导致腾讯QQ邮箱无法访问</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/java/2016-07-30-use-rc4-in-tencent-mail.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JavaMail</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx加速：启用gzip压缩和浏览器缓存</title>
    <url>/web%E6%9C%8D%E5%8A%A1%E5%99%A8/2016-08-04-enable-gzip-in-nginx.html</url>
    <content><![CDATA[<p>Nginx是一个高性能的Web服务器，之前也写过一些关于nginx的文章。为了提高博客的响应速度，可以从设置nginx的gzip和浏览器缓存这两个方面入手。为字体开启gzip和缓存能大大减少带宽的消耗。</p>
<h3 id="开启gzip"><a href="#开启gzip" class="headerlink" title="开启gzip"></a>开启gzip</h3><h4 id="Nginx配置参数"><a href="#Nginx配置参数" class="headerlink" title="Nginx配置参数"></a>Nginx配置参数</h4><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开启gzip</span></span><br><span class="line">gzip on;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用gzip压缩的最小文件，小于设置值的文件将不会压缩</span></span><br><span class="line">gzip_min_length <span class="number">1</span>k;</span><br><span class="line"></span><br><span class="line"><span class="comment"># gzip 压缩级别，1-10，数字越大压缩的越好，也越占用CPU时间，后面会有详细说明</span></span><br><span class="line">gzip_comp_level <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行压缩的文件类型。javascript有多种形式。其中的值可以在 mime.types 文件中找到。</span></span><br><span class="line">gzip_types text<span class="regexp">/plain application/</span>javascript application<span class="regexp">/x-javascript text/</span>css application<span class="regexp">/xml text/</span>javascript application<span class="regexp">/x-httpd-php image/</span>jpeg image<span class="regexp">/gif image/</span>png;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 是否在http header中添加Vary: Accept-Encoding，建议开启</span></span><br><span class="line">gzip_vary on;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用IE 6 gzip</span></span><br><span class="line">gzip_disable <span class="string">&quot;MSIE [1-6]\.&quot;</span>;</span><br></pre></td></tr></table></figure>

<h4 id="gzip-comp-level参数的推荐值"><a href="#gzip-comp-level参数的推荐值" class="headerlink" title="gzip_comp_level参数的推荐值"></a><code>gzip_comp_level</code>参数的推荐值</h4><p>来自<a href="http://serverfault.com/questions/253074/what-is-the-best-nginx-compression-gzip-level">serverfault</a>的一个讨论，有人做了压缩比的实验，结果如下：</p>
<p><strong>压缩HTML文件</strong></p>
<figure class="highlight erlang-repl"><table><tr><td class="code"><pre><span class="line">级别	压缩之后的大小（压缩比）</span><br><span class="line"><span class="number">0</span>    <span class="number">55.38</span> KiB (<span class="number">100.00</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">1</span>    <span class="number">11.22</span> KiB ( <span class="number">20.26</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">2</span>    <span class="number">10.89</span> KiB ( <span class="number">19.66</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">3</span>    <span class="number">10.60</span> KiB ( <span class="number">19.14</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">4</span>    <span class="number">10.17</span> KiB ( <span class="number">18.36</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">5</span>     <span class="number">9.79</span> KiB ( <span class="number">17.68</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">6</span>     <span class="number">9.62</span> KiB ( <span class="number">17.37</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">7</span>     <span class="number">9.50</span> KiB ( <span class="number">17.15</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">8</span>     <span class="number">9.45</span> KiB ( <span class="number">17.06</span><span class="comment">% of original size)</span></span><br><span class="line"><span class="number">9</span>     <span class="number">9.44</span> KiB ( <span class="number">17.05</span><span class="comment">% of original size)</span></span><br></pre></td></tr></table></figure>

<p><strong>压缩JS文件（jQuery 1.8.3）</strong></p>
<pre><code>级别    压缩之后的大小（压缩比）
0    261.46 KiB (100.00% of original size)
1     95.01 KiB ( 36.34% of original size)
2     90.60 KiB ( 34.65% of original size)
3     87.16 KiB ( 33.36% of original size)
4     81.89 KiB ( 31.32% of original size)
5     79.33 KiB ( 30.34% of original size)
6     78.04 KiB ( 29.85% of original size)
7     77.85 KiB ( 29.78% of original size)
8     77.74 KiB ( 29.73% of original size)
9     77.75 KiB ( 29.74% of original size)
</code></pre>
<p>从图中可以看出<code>gzip_comp_level</code>大于2时效果并不是很明显。所以可以将值设置为1或者2。</p>
<h4 id="选择性的开启字体压缩"><a href="#选择性的开启字体压缩" class="headerlink" title="选择性的开启字体压缩"></a>选择性的开启字体压缩</h4><p>为静态资源开启缓存能够较少服务器带宽的消耗，特别是在css中使用字体时，同时配合gzip压缩能够大大减少下载字体造成的带宽影响。</p>
<blockquote>
<p><strong>需要注意</strong>：只需要为ttf、otf和svg字体启用gzip，对其他字体格式进行gzip压缩时效果不明显。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gzip_types  font/ttf font/otf image/svg+xml</span><br></pre></td></tr></table></figure>
<p>各种字体类型压缩效果可以参考引用原文<a href="http://www.darrenfang.com/2015/01/setting-up-http-cache-and-gzip-with-nginx/" title="引用原文">reference</a>。</p>
<p><strong>字体压缩总结</strong></p>
<table>
<thead>
<tr>
<th>扩展名</th>
<th>是否压缩</th>
<th>Content-type</th>
</tr>
</thead>
<tbody><tr>
<td>.eot</td>
<td>否</td>
<td>application/vnd.ms-fontobject</td>
</tr>
<tr>
<td>.ttf</td>
<td>是</td>
<td>font/ttf</td>
</tr>
<tr>
<td>.otf</td>
<td>是</td>
<td>font/opentype</td>
</tr>
<tr>
<td>.woff</td>
<td>否</td>
<td>font/x-woff</td>
</tr>
<tr>
<td>.svg</td>
<td>是</td>
<td>image/svg+xml</td>
</tr>
</tbody></table>
<h3 id="开启浏览器缓存"><a href="#开启浏览器缓存" class="headerlink" title="开启浏览器缓存"></a>开启浏览器缓存</h3><h4 id="Nginx配置"><a href="#Nginx配置" class="headerlink" title="Nginx配置"></a>Nginx配置</h4><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> <span class="regexp">~* ^.+\.(ico|gif|jpg|jpeg|png)$</span> &#123; </span><br><span class="line">        <span class="attribute">access_log</span>   <span class="literal">off</span>; </span><br><span class="line">        <span class="attribute">expires</span>      <span class="number">30d</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> <span class="regexp">~* ^.+\.(css|js|txt|xml|swf|wav)$</span> &#123;</span><br><span class="line">    <span class="attribute">access_log</span>   <span class="literal">off</span>;</span><br><span class="line">    <span class="attribute">expires</span>      <span class="number">24h</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">location</span> <span class="regexp">~* ^.+\.(html|htm)$</span> &#123;</span><br><span class="line">        <span class="attribute">expires</span>      <span class="number">1h</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中的缓存时间可以自己根据需要修改。</p>
<h4 id="开启字体缓存"><a href="#开启字体缓存" class="headerlink" title="开启字体缓存"></a>开启字体缓存</h4><figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="section">location</span> <span class="regexp">~* ^.+\.(eot|ttf|otf|woff|svg)$</span> &#123;</span><br><span class="line">        <span class="attribute">access_log</span>   <span class="literal">off</span>;</span><br><span class="line">        <span class="attribute">expires</span> max;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/web%E6%9C%8D%E5%8A%A1%E5%99%A8/2016-08-04-enable-gzip-in-nginx.html" target="_blank">Nginx加速：启用gzip压缩和浏览器缓存</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/web%E6%9C%8D%E5%8A%A1%E5%99%A8/2016-08-04-enable-gzip-in-nginx.html]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx的浏览器缓存和Gzip压缩参数</title>
    <url>/web%E6%9C%8D%E5%8A%A1%E5%99%A8/2016-08-04-nginx-gzip-cache-parameters.html</url>
    <content><![CDATA[<h3 id="浏览器缓存（Browser-Caching）"><a href="#浏览器缓存（Browser-Caching）" class="headerlink" title="浏览器缓存（Browser Caching）"></a>浏览器缓存（Browser Caching）</h3><p>浏览器缓存是为了加速浏览并节约网络资源，浏览器在用户磁盘上对最近请求过的文档进行存储。nginx可以通过 expires 指令来设置浏览器的Header。</p>
<blockquote>
<p>语法： <code>expires [time|epoch|max|off]</code><br>默认值： <code>expires off</code><br>作用域： <code>http</code>, <code>server</code>, <code>location</code></p>
</blockquote>
<p>使用本指令可以控制HTTP应答中的“Expires”和“Cache-Control”的头标，（起到控制页面缓存的作用）。可以在time值中使用正数或负数。“Expires”头标的值将通过当前系统时间加上您设定的<code>time</code>值来获得。</p>
<ul>
<li><code>epoch</code>指定“Expires”的值为 1 January, 1970, 00:00:01 GMT。</li>
<li><code>max</code>指定“Expires”的值为 31 December 2037 23:59:59 GMT，“Cache-Control”的值为10年。</li>
<li><code>-1</code>指定“Expires”的值为 服务器当前时间 -1s,即永远过期</li>
</ul>
<p>例子：图片缓存30天</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 图片缓存30天</span></span><br><span class="line"><span class="section">location</span> ~.*\.(jpg|png|jpeg)$ &#123;</span><br><span class="line">   <span class="attribute">expires</span> <span class="number">30d</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># js css缓存一小时</span></span><br><span class="line"><span class="section">location</span> ~.*\.(js|css)?$ &#123;</span><br><span class="line">   <span class="attribute">expires</span> <span class="number">1h</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Nginx-gzip压缩"><a href="#Nginx-gzip压缩" class="headerlink" title="Nginx gzip压缩"></a>Nginx gzip压缩</h3><p>使用 gzip 压缩可以降低网站带宽消耗，同时提升访问速度。主要在nginx服务端将页面进行压缩，然后在浏览器端进行解压和解析，目前大多数流行的浏览器都迟滞gzip格式的压缩，所以不用担心。默认情况下，Nginx的gzip压缩是关闭的，同时，Nginx默认只对text/html进行压缩。</p>
<p>主要配置如下：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">gzip</span>  <span class="literal">on</span>;<span class="comment">#开启</span></span><br><span class="line"><span class="attribute">gzip_http_version</span> <span class="number">1</span>.<span class="number">0</span>;<span class="comment">#默认1.1</span></span><br><span class="line"><span class="attribute">gzip_vary</span> <span class="literal">on</span>;</span><br><span class="line"><span class="attribute">gzip_comp_level</span> <span class="number">6</span>;</span><br><span class="line"><span class="attribute">gzip_proxied</span> any;</span><br><span class="line"><span class="attribute">gzip_types</span> text/plain text/html text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;<span class="comment">#压缩的文件类型</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">gzip_buffers</span> <span class="number">16</span> <span class="number">8k</span>;<span class="comment">#设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Disable gzip for certain browsers.</span></span><br><span class="line"><span class="attribute">gzip_disable</span> “MSIE [<span class="number">1</span>-<span class="number">6</span>].(?!.*SV1)”;<span class="comment">#ie6不支持gzip，需要禁用掉ie6，可恶啊!!!!</span></span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong> 其中的<code>gzip_http_version</code>的设置，它的默认值是<code>1.1</code>，就是说对HTTP/1.1协议的请求才会进行gzip压缩。如果我们使用了<code>proxy_pass</code>进行反向代理，那么nginx和后端的<code>upstream server</code>之间是用HTTP/1.0协议通信的。</p>
<p><strong>参数说明</strong></p>
<p><code>gzip</code>决定是否开启gzip模块</p>
<blockquote>
<p>param:on|off</p>
</blockquote>
<p><code>gzip_buffers</code>设置gzip申请内存的大小,其作用是按块大小的倍数申请内存空间</p>
<blockquote>
<p>param1:int 增加的倍数<br>param2:int(k) 后面单位是k</p>
</blockquote>
<p><code>gzip_comp_level</code>设置gzip压缩等级，等级越底压缩速度越快文件压缩比越小，反之速度越慢文件压缩比越大</p>
<blockquote>
<p>param:1-9</p>
</blockquote>
<p><code>gzip_min_length</code>当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩</p>
<blockquote>
<p>param:int</p>
</blockquote>
<p><code>gzip_http_version</code>用于识别http协议的版本，早期的浏览器不支持gzip压缩，用户会看到乱码，所以为了支持前期版本加了此选项,目前此项基本可以忽略</p>
<blockquote>
<p>param: 1.0|1.1</p>
</blockquote>
<p><code>gzip_proxied</code>Nginx做为反向代理的时候启用，</p>
<blockquote>
<p>param:off|expired|no-cache|no-sotre|private|no_last_modified|no_etag|auth|any]</p>
</blockquote>
<ul>
<li>off – 关闭所有的代理结果数据压缩</li>
<li>expired – 启用压缩，如果header中包含”Expires”头信息</li>
<li>no-cache – 启用压缩，如果header中包含”Cache-Control:no-cache”头信息</li>
<li>no-store – 启用压缩，如果header中包含”Cache-Control:no-store”头信息</li>
<li>private – 启用压缩，如果header中包含”Cache-Control:private”头信息</li>
<li>no_last_modified – 启用压缩，如果header中包含”Last_Modified”头信息</li>
<li>no_etag – 启用压缩，如果header中包含“ETag”头信息</li>
<li>auth – 启用压缩，如果header中包含“Authorization”头信息</li>
<li>any – 无条件压缩所有结果数据</li>
</ul>
<p><code>zip_types</code>设置需要压缩的MIME类型,非设置值不进行压缩</p>
<blockquote>
<p>param:text/html|application/x-javascript|text/css|application/xml</p>
</blockquote>
<p><code>gzip_vary on;</code>和http头有关系，加个vary头，给代理服务器用的，有的浏览器支持压缩，有的不支持，所以避免浪费不支持的也压缩，所以根据客户端的HTTP头来判断，是否需要压缩。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/web%E6%9C%8D%E5%8A%A1%E5%99%A8/2016-08-04-nginx-gzip-cache-parameters.html" target="_blank">Nginx的浏览器缓存和Gzip压缩参数</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/web%E6%9C%8D%E5%8A%A1%E5%99%A8/2016-08-04-nginx-gzip-cache-parameters.html]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Browser Caching</tag>
        <tag>Gzip</tag>
      </tags>
  </entry>
  <entry>
    <title>Install the latest Node.js on Ubuntu 14.04</title>
    <url>/linux/2016-08-05-install-nodejs-on-ubuntu.html</url>
    <content><![CDATA[<blockquote>
<p><strong>NOTE:</strong> If you are using Ubuntu Precise or Debian Wheezy, you might want to read about <a href="https://github.com/nodesource/distributions/blob/master/OLDER_DISTROS.md" title="running Node.js &gt;= 4.x on older distros">running Node.js &gt;= 4.x on older distros</a>.</p>
</blockquote>
<h4 id="Node-js-v6-x"><a href="#Node-js-v6-x" class="headerlink" title="Node.js v6.x:"></a>Node.js v6.x:</h4><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"># Using Ubuntu</span><br><span class="line">curl -sL https://<span class="keyword">deb</span>.nodesource.<span class="keyword">com</span>/setup_6.<span class="keyword">x</span> | sudo -E bash -</span><br><span class="line">sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> nodejs</span><br><span class="line"></span><br><span class="line"># Using Debian, <span class="keyword">as</span> root</span><br><span class="line">curl -sL https://<span class="keyword">deb</span>.nodesource.<span class="keyword">com</span>/setup_6.<span class="keyword">x</span> | bash -</span><br><span class="line">apt-<span class="built_in">get</span> install -<span class="keyword">y</span> nodejs</span><br></pre></td></tr></table></figure>

<h4 id="Node-js-v5-x"><a href="#Node-js-v5-x" class="headerlink" title="Node.js v5.x:"></a>Node.js v5.x:</h4><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"># Using Ubuntu</span><br><span class="line">curl -sL https://<span class="keyword">deb</span>.nodesource.<span class="keyword">com</span>/setup_5.<span class="keyword">x</span> | sudo -E bash -</span><br><span class="line">sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> nodejs</span><br><span class="line"></span><br><span class="line"># Using Debian, <span class="keyword">as</span> root</span><br><span class="line">curl -sL https://<span class="keyword">deb</span>.nodesource.<span class="keyword">com</span>/setup_5.<span class="keyword">x</span> | bash -</span><br><span class="line">apt-<span class="built_in">get</span> install -<span class="keyword">y</span> nodejs</span><br></pre></td></tr></table></figure>

<h4 id="Node-js-v4-x"><a href="#Node-js-v4-x" class="headerlink" title="Node.js v4.x:"></a>Node.js v4.x:</h4><figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"># Using Ubuntu</span><br><span class="line">curl -sL https://<span class="keyword">deb</span>.nodesource.<span class="keyword">com</span>/setup_4.<span class="keyword">x</span> | sudo -E bash -</span><br><span class="line">sudo apt-<span class="built_in">get</span> install -<span class="keyword">y</span> nodejs</span><br><span class="line"></span><br><span class="line"># Using Debian, <span class="keyword">as</span> root</span><br><span class="line">curl -sL https://<span class="keyword">deb</span>.nodesource.<span class="keyword">com</span>/setup_4.<span class="keyword">x</span> | bash -</span><br><span class="line">apt-<span class="built_in">get</span> install -<span class="keyword">y</span> nodejs</span><br></pre></td></tr></table></figure>

<p>For installations on other platforms, you can refer to: <a href="https://github.com/nodesource/distributions#debinstall">https://github.com/nodesource/distributions#debinstall</a></p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-08-05-install-nodejs-on-ubuntu.html" target="_blank">Install the latest Node.js on Ubuntu 14.04</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-08-05-install-nodejs-on-ubuntu.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nodejs</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis提示Could not get a resource from the pool（jedis连接池配置）</title>
    <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-08-05-redis-jedis-pool.html</url>
    <content><![CDATA[<p>起初在JedisPool中配置了50个活动连接，但是程序还是经常报错：Could not get a resource from the pool</p>
<p>连接池刚开始是这样配置的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">JedisPoolConfig</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPoolConfig</span>();</span><br><span class="line">config.setMaxTotal(<span class="number">50</span>);</span><br><span class="line">config.setMaxIdle(<span class="number">20</span>); </span><br><span class="line">config.setMaxWaitMillis(<span class="number">1000</span> * <span class="number">1</span>);</span><br><span class="line">config.setTestOnBorrow(<span class="literal">true</span>);</span><br><span class="line">config.setTestOnReturn(<span class="literal">true</span>);</span><br><span class="line"><span class="type">JedisPool</span> <span class="variable">pool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPool</span>(config, <span class="string">&quot;10.10.10.167&quot;</span>, <span class="number">6379</span>);</span><br></pre></td></tr></table></figure>
<p>经过测试发现程序的活动连接基本上只有1个，程序刚启动的时候可能会有2-5个活动的连接，但是过一段时间后就获取不到第二个活动的连接了。</p>
<p>后来修改为：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">JedisPoolConfig</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPoolConfig</span>();</span><br><span class="line">config.setMaxTotal(<span class="number">200</span>); </span><br><span class="line">config.setMaxIdle(<span class="number">50</span>);</span><br><span class="line">config.setMinIdle(<span class="number">8</span>);<span class="comment">//设置最小空闲数 </span></span><br><span class="line">config.setMaxWaitMillis(<span class="number">10000</span>);</span><br><span class="line">config.setTestOnBorrow(<span class="literal">true</span>);</span><br><span class="line">config.setTestOnReturn(<span class="literal">true</span>); <span class="comment">//Idle时进行连接扫描 </span></span><br><span class="line">config.setTestWhileIdle(<span class="literal">true</span>); <span class="comment">//表示idle object evitor两次扫描之间要sleep的毫秒数</span></span><br><span class="line">config.setTimeBetweenEvictionRunsMillis(<span class="number">30000</span>); <span class="comment">//表示idle object evitor每次扫描的最多的对象数</span></span><br><span class="line">config.setNumTestsPerEvictionRun(<span class="number">10</span>); <span class="comment">//表示一个对象至少停留在idle状态的最短时间，然后才能被idle object evitor扫描并驱逐；这一项只有在timeBetweenEvictionRunsMillis大于0时才有意义 </span></span><br><span class="line">config.setMinEvictableIdleTimeMillis(<span class="number">60000</span>);</span><br><span class="line"><span class="type">JedisPool</span> <span class="variable">pool</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JedisPool</span>(config, ip, port, <span class="number">10000</span>, <span class="string">&quot;密码&quot;</span>, <span class="number">0</span>);</span><br></pre></td></tr></table></figure>

<p>经过几个小时的测试，读取redis了上百万次再也没有发生上述错误。</p>
<p>在这里进行简单的猜测：连接池中空闲的连接过一阵子就会自动断开，但是连接池还以为连接正常，就出现了这个错误。</p>
<p>另外，从连接池中获取连接的时候，可以写个循环，直到获取成功才让出循环。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-08-05-redis-jedis-pool.html" target="_blank">Redis提示Could not get a resource from the pool（jedis连接池配置）</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-08-05-redis-jedis-pool.html]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>转载</tag>
        <tag>Jedis</tag>
      </tags>
  </entry>
  <entry>
    <title>Where to find all available Java mail properties?</title>
    <url>/java/2016-08-06-all-available-java-mail-properties.html</url>
    <content><![CDATA[<p>In the api is a reference to the properties for the specific sun protocol providers.</p>
<ul>
<li><code>IMAP</code> <a href="https://javamail.java.net/nonav/docs/api/com/sun/mail/imap/package-summary.html">https://javamail.java.net/nonav/docs/api/com/sun/mail/imap/package-summary.html</a></li>
<li><code>POP3</code> <a href="https://javamail.java.net/nonav/docs/api/com/sun/mail/pop3/package-summary.html">https://javamail.java.net/nonav/docs/api/com/sun/mail/pop3/package-summary.html</a></li>
<li><code>SMTP</code> <a href="https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html">https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html</a></li>
</ul>
<p>These are also set on the session object but you use them on your own risk since in other mail implementations they are maybe not supported or they change in the future.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/java/2016-08-06-all-available-java-mail-properties.html" target="_blank">Where to find all available Java mail properties?</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/java/2016-08-06-all-available-java-mail-properties.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java Mail</tag>
      </tags>
  </entry>
  <entry>
    <title>Download specified oracle JDK (archived) version</title>
    <url>/java/2016-08-06-download-specified-jdk-version.html</url>
    <content><![CDATA[<p>You can go to the <a href="http://www.oracle.com/technetwork/java/archive-139210.html">Oracle Java Archive</a> page to download any version of JDK.</p>
<p>Over!</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/java/2016-08-06-download-specified-jdk-version.html" target="_blank">Download specified oracle JDK (archived) version</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/java/2016-08-06-download-specified-jdk-version.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDK</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>万亿级调用系统：微信序列号生成器架构设计及演变</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-09-weixin-sequence-generator.html</url>
    <content><![CDATA[<blockquote>
<p><strong>曾钦松</strong>，微信高级工程师，目前负责微信后台基础服务、朋友圈后台等开发优化，致力于高可用高性能后台系统的设计与研发。2011年毕业于西安电子科技大学，早先曾在腾讯搜搜从事检索架构、分布式数据库方面的工作。</p>
</blockquote>
<p>微信在立项之初，就已确立了利用数据版本号实现终端与后台的数据增量同步机制，确保发消息时消息可靠送达对方手机，避免了大量潜在的家庭纠纷。时至今日，微信已经走过第五个年头，这套同步机制仍然在消息收发、朋友圈通知、好友数据更新等需要数据同步的地方发挥着核心的作用。</p>
<p>而在这同步机制的背后，需要一个高可用、高可靠的序列号生成器来产生同步数据用的版本号。这个序列号生成器我们称之为seqsvr，目前已经发展为一个每天万亿级调用的重量级系统，其中每次申请序列号平时调用耗时1ms，99.9%的调用耗时小于3ms，服务部署于数百台4核CPU服务器上。<strong>本文会重点介绍seqsvr的架构核心思想，以及seqsvr随着业务量快速上涨所做的架构演变。</strong></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><strong>微信服务器端为每一份需要与客户端同步的数据（例如消息）都会赋予一个唯一的、递增的序列号（后文称为sequence），作为这份数据的版本号。</strong>在客户端与服务器端同步的时候，客户端会带上已经同步下去数据的最大版本号，后台会根据客户端最大版本号与服务器端的最大版本号，计算出需要同步的增量数据，返回给客户端。这样不仅保证了客户端与服务器端的数据同步的可靠性，同时也大幅减少了同步时的冗余数据。</p>
<p>这里不用乐观锁机制来生成版本号，而是使用了一个独立的seqsvr来处理序列号操作，一方面因为业务有大量的sequence查询需求——查询已经分配出去的最后一个sequence，而基于seqsvr的查询操作可以做到非常轻量级，避免对存储层的大量IO查询操作；另一方面微信用户的不同种类的数据存在不同的Key-Value系统中，使用统一的序列号有助于避免重复开发，同时业务逻辑可以很方便地判断一个用户的各类数据是否有更新。</p>
<p>从seqsvr申请的、用作数据版本号的sequence，具有两种基本的性质：</p>
<ol>
<li>递增的64位整型变量</li>
<li>每个用户都有自己独立的64位sequence空间</li>
</ol>
<p>举个例子，小明当前申请的sequence为100，那么他下一次申请的sequence，可能为101，也可能是110，总之一定大于之前申请的100。而小红呢，她的sequence与小明的sequence是独立开的，假如她当前申请到的sequence为50，然后期间不管小明申请多少次sequence怎么折腾，都不会影响到她下一次申请到的值（很可能是51）。</p>
<p>这里用了每个用户独立的64位sequence的体系，而不是用一个全局的64位（或更高位）sequence，很大原因是全局唯一的sequence会有非常严重的申请互斥问题，不容易去实现一个高性能高可靠的架构。对微信业务来说，每个用户独立的64位sequence空间已经满足业务要求。</p>
<p><strong>目前sequence用在终端与后台的数据同步外，同时也广泛用于微信后台逻辑层的基础数据一致性cache中，大幅减少逻辑层对存储层的访问。</strong>虽然一个用于终端——后台数据同步，一个用于后台cache的一致性保证，场景大不相同。</p>
<p>但我们仔细分析就会发现，两个场景都是利用sequence可靠递增的性质来实现数据的一致性保证，这就要求我们的seqsvr保证分配出去的sequence是稳定递增的，一旦出现回退必然导致各种数据错乱、消息消失；另外，这两个场景都非常普遍，我们在使用微信的时候会不知不觉地对应到这两个场景：小明给小红发消息、小红拉黑小明、小明发一条失恋状态的朋友圈，一次简单的分手背后可能申请了无数次sequence。</p>
<p>微信目前拥有数亿的活跃用户，每时每刻都会有海量sequence申请，这对seqsvr的设计也是个极大的挑战。那么，既要sequence可靠递增，又要能顶住海量的访问，要如何设计seqsvr的架构？我们先从seqsvr的架构原型说起。</p>
<p>##架构原型</p>
<p>不考虑seqsvr的具体架构的话，它应该是一个巨大的64位数组，而我们每一个微信用户，都在这个大数组里独占一格8bytes的空间，这个格子就放着用户已经分配出去的最后一个sequence：cur_seq。每个用户来申请sequence的时候，只需要将用户的cur_seq+=1，保存回数组，并返回给用户。</p>
<p><img src="/upload/images/1.riff"><br>图1. 小明申请了一个sequence，返回101</p>
<h3 id="预分配中间层"><a href="#预分配中间层" class="headerlink" title="预分配中间层"></a>预分配中间层</h3><p><strong>任何一件看起来很简单的事，在海量的访问量下都会变得不简单。</strong>前文提到，seqsvr需要保证分配出去的sequence递增（数据可靠），还需要满足海量的访问量（每天接近万亿级别的访问）。满足数据可靠的话，我们很容易想到把数据持久化到硬盘，但是按照目前每秒千万级的访问量（~10^7 QPS），基本没有任何硬盘系统能扛住。</p>
<p>后台架构设计很多时候是一门关于权衡的哲学，针对不同的场景去考虑能不能降低某方面的要求，以换取其它方面的提升。仔细考虑我们的需求，我们只要求递增，并没有要求连续，也就是说出现一大段跳跃是允许的（例如分配出的sequence序列：1,2,3,10,100,101）。于是我们实现了一个简单优雅的策略：</p>
<ol>
<li>内存中储存最近一个分配出去的sequence：cur_seq，以及分配上限：max_seq</li>
<li>分配sequence时，将cur_seq++，同时与分配上限max_seq比较：如果cur_seq &gt; max_seq，将分配上限提升一个步长max_seq += step，并持久化max_seq</li>
<li>重启时，读出持久化的max_seq，赋值给cur_seq</li>
</ol>
<p><img src="/upload/images/2.riff"><br>图2. 小明、小红、小白都各自申请了一个sequence，但只有小白的max_seq增加了步长100</p>
<p>这样通过增加一个预分配sequence的中间层，在保证sequence不回退的前提下，大幅地提升了分配sequence的性能。实际应用中每次提升的步长为10000，那么持久化的硬盘IO次数从之前<del>10^7 QPS降低到</del>10^3 QPS，处于可接受范围。在正常运作时分配出去的sequence是顺序递增的，只有在机器重启后，第一次分配的sequence会产生一个比较大的跳跃，跳跃大小取决于步长大小。</p>
<h3 id="分号段共享存储"><a href="#分号段共享存储" class="headerlink" title="分号段共享存储"></a>分号段共享存储</h3><p>请求带来的硬盘IO问题解决了，可以支持服务平稳运行，但该模型还是存在一个问题：重启时要读取大量的max_seq数据加载到内存中。</p>
<p>我们可以简单计算下，以目前uid（用户唯一ID）上限2^32个、一个max_seq 8bytes的空间，数据大小一共为32GB，从硬盘加载需要不少时间。另一方面，出于数据可靠性的考虑，必然需要一个可靠存储系统来保存max_seq数据，重启时通过网络从该可靠存储系统加载数据。如果max_seq数据过大的话，会导致重启时在数据传输花费大量时间，造成一段时间不可服务。</p>
<p>为了解决这个问题，我们引入号段Section的概念，uid相邻的一段用户属于一个号段，而同个号段内的用户共享一个max_seq，这样大幅减少了max_seq数据的大小，同时也降低了IO次数。</p>
<p><img src="/upload/images/3.riff"><br>图3. 小明、小红、小白属于同个Section，他们共用一个max_seq。在每个人都申请一个sequence的时候，只有小白突破了max_seq上限，需要更新max_seq并持久化</p>
<p>目前seqsvr一个Section包含10万个uid，max_seq数据只有300+KB，为我们实现从可靠存储系统读取max_seq数据重启打下基础。</p>
<h3 id="工程实现"><a href="#工程实现" class="headerlink" title="工程实现"></a>工程实现</h3><p>工程实现在上面两个策略上做了一些调整，主要是出于数据可靠性及灾难隔离考虑</p>
<ol>
<li><p>把存储层和缓存中间层分成两个模块StoreSvr及AllocSvr。StoreSvr为存储层，利用了多机NRW策略来保证数据持久化后不丢失；AllocSvr则是缓存中间层，部署于多台机器，每台AllocSvr负责若干号段的sequence分配，分摊海量的sequence申请请求。</p>
</li>
<li><p>整个系统又按uid范围进行分Set，每个Set都是一个完整的、独立的StoreSvr+AllocSvr子系统。分Set设计目的是为了做灾难隔离，一个Set出现故障只会影响该Set内的用户，而不会影响到其它用户。</p>
</li>
</ol>
<p><img src="/upload/images/4.riff"><br>图4. 原型架构图</p>
<h3 id="容灾设计"><a href="#容灾设计" class="headerlink" title="容灾设计"></a>容灾设计</h3><p>接下来我们会介绍seqsvr的容灾架构。我们知道，后台系统绝大部分情况下并没有一种唯一的、完美的解决方案，同样的需求在不同的环境背景下甚至有可能演化出两种截然不同的架构。既然架构是多变的，那纯粹讲架构的意义并不是特别大，期间也会讲下seqsvr容灾设计时的一些思考和权衡，希望对大家有所帮助。</p>
<p>seqsvr的容灾模型在五年中进行过一次比较大的重构，提升了可用性、机器利用率等方面。其中不管是重构前还是重构后的架构，seqsvr一直遵循着两条架构设计原则：</p>
<ol>
<li>保持自身架构简单</li>
<li>避免对外部模块的强依赖</li>
</ol>
<p>这两点都是基于seqsvr可靠性考虑的，毕竟seqsvr是一个与整个微信服务端正常运行息息相关的模块。按照我们对这个世界的认识，系统的复杂度往往是跟可靠性成反比的，想得到一个可靠的系统一个关键点就是要把它做简单。相信大家身边都有一些这样的例子，设计方案里有很多高大上、复杂的东西，同时也总能看到他们在默默地填一些高大上的坑。当然简单的系统不意味着粗制滥造，我们要做的是理出最核心的点，然后在满足这些核心点的基础上，针对性地提出一个足够简单的解决方案。</p>
<p>那么，seqsvr最核心的点是什么呢？每个uid的sequence申请要递增不回退。这里我们发现，如果seqsvr满足这么一个约束：任意时刻任意uid有且仅有一台AllocSvr提供服务，就可以比较容易地实现sequence递增不回退的要求。</p>
<p><img src="/upload/images/5.riff"><br>图5. 两台AllocSvr服务同个uid造成sequence回退。Client读取到的sequence序列为101、201、102</p>
<p>但也由于这个约束，多台AllocSvr同时服务同一个号段的多主机模型在这里就不适用了。我们只能采用单点服务的模式，当某台AllocSvr发生服务不可用时，将该机服务的uid段切换到其它机器来实现容灾。这里需要引入一个仲裁服务，探测AllocSvr的服务状态，决定每个uid段由哪台AllocSvr加载。出于可靠性的考虑，仲裁模块并不直接操作AllocSvr，而是将加载配置写到StoreSvr持久化，然后AllocSvr定期访问StoreSvr读取最新的加载配置，决定自己的加载状态。</p>
<p><img src="/upload/images/6.riff"><br>图6. 号段迁移示意。通过更新加载配置把0~2号段从AllocSvrA迁移到AllocSvrB</p>
<p>同时，为了避免失联AllocSvr提供错误的服务，返回脏数据，AllocSvr需要跟StoreSvr保持租约。这个租约机制由以下两个条件组成：</p>
<ol>
<li><p>租约失效：AllocSvr N秒内无法从StoreSvr读取加载配置时，AllocSvr停止服务</p>
</li>
<li><p>租约生效：AllocSvr读取到新的加载配置后，立即卸载需要卸载的号段，需要加载的新号段等待N秒后提供服务</p>
</li>
</ol>
<p><img src="/upload/images/7.riff"><br>图7. 租约机制。AllocSvrB严格保证在AllocSvrA停止服务后提供服务</p>
<p>这两个条件保证了切换时，新AllocSvr肯定在旧AllocSvr下线后才开始提供服务。但这种租约机制也会造成切换的号段存在小段时间的不可服务，不过由于微信后台逻辑层存在重试机制及异步重试队列，小段时间的不可服务是用户无感知的，而且出现租约失效、切换是小概率事件，整体上是可以接受的。</p>
<p>到此讲了AllocSvr容灾切换的基本原理，接下来会介绍整个seqsvr架构容灾架构的演变</p>
<h2 id="容灾1-0架构：主备容灾"><a href="#容灾1-0架构：主备容灾" class="headerlink" title="容灾1.0架构：主备容灾"></a>容灾1.0架构：主备容灾</h2><p>最初版本的seqsvr采用了主机+冷备机容灾模式：全量的uid空间均匀分成N个Section，连续的若干个Section组成了一个Set，每个Set都有一主一备两台AllocSvr。正常情况下只有主机提供服务；在主机出故障时，仲裁服务切换主备，原来的主机下线变成备机，原备机变成主机后加载uid号段提供服务。</p>
<p><img src="/upload/images/8.riff"><br>图8. 容灾1.0架构：主备容灾</p>
<p>可能看到前文的叙述，有些同学已经想到这种容灾架构。一主机一备机的模型设计简单，并且具有不错的可用性——毕竟主备两台机器同时不可用的概率极低，相信很多后台系统也采用了类似的容灾策略。</p>
<h3 id="设计权衡"><a href="#设计权衡" class="headerlink" title="设计权衡"></a>设计权衡</h3><p>主备容灾存在一些明显的缺陷，比如备机闲置导致有一半的空闲机器；比如主备切换的时候，备机在瞬间要接受主机所有的请求，容易导致备机过载。既然一主一备容灾存在这样的问题，为什么一开始还要采用这种容灾模型？事实上，架构的选择往往跟当时的背景有关，seqsvr诞生于微信发展初期，也正是微信快速扩张的时候，选择一主一备容灾模型是出于以下的考虑：</p>
<ol>
<li>架构简单，可以快速开发</li>
<li>机器数少，机器冗余不是主要问题</li>
<li>Client端更新AllocSvr的路由状态很容易实现</li>
</ol>
<p>前两点好懂，人力、机器都不如时间宝贵。而第三点比较有意思，下面展开讲下</p>
<p>微信后台绝大部分模块使用了一个自研的RPC框架，seqsvr也不例外。在这个RPC框架里，调用端读取本地机器的client配置文件，决定去哪台服务端调用。这种模型对于无状态的服务端，是很好用的，也很方便实现容灾。我们可以在client配置文件里面写“对于号段x，可以去SvrA、SvrB、SvrC三台机器的任意一台访问”，实现三主机容灾。</p>
<p>但在seqsvr里，AllocSvr是预分配中间层，并不是无状态的。而前面我们提到，AllocSvr加载哪些uid号段，是由保存在StoreSvr的加载配置决定的。那么这时候就尴尬了，业务想要申请某个uid的sequence，Client端其实并不清楚具体去哪台AllocSvr访问，client配置文件只会跟它说“AllocSvrA、AllocSvrB…这堆机器的某一台会有你想要的sequence”。换句话讲，原来负责提供服务的AllocSvrA故障，仲裁服务决定由AllocSvrC来替代AllocSvrA提供服务，Client要如何获知这个路由信息的变更？</p>
<p>这时候假如我们的AllocSvr采用了主备容灾模型的话，事情就变得简单多了。我们可以在client配置文件里写：对于某个uid号段，要么是AllocSvrA加载，要么是AllocSvrB加载。Client端发起请求时，尽管Client端并不清楚AllocSvrA和AllocSvrB哪一台真正加载了目标uid号段，但是Client端可以先尝试给其中任意一台AllocSvr发请求，就算这次请求了错误的AllocSvr，那么就知道另外一台是正确的AllocSvr，再发起一次请求即可。</p>
<p>也就是说，对于主备容灾模型，最多也只会浪费一次的试探请求来确定AllocSvr的服务状态，额外消耗少，编码也简单。可是，如果Svr端采用了其它复杂的容灾策略，那么基于静态配置的框架就很难去确定Svr端的服务状态：Svr发生状态变更，Client端无法确定应该向哪台Svr发起请求。这也是为什么一开始选择了主备容灾的原因之一。</p>
<h3 id="主备容灾的缺陷"><a href="#主备容灾的缺陷" class="headerlink" title="主备容灾的缺陷"></a>主备容灾的缺陷</h3><p>在我们的实际运营中，容灾1.0架构存在两个重大的不足：</p>
<ol>
<li>扩容、缩容非常麻烦</li>
<li>一个Set的主备机都过载，无法使用其他Set的机器进行容灾</li>
</ol>
<p>在主备容灾中，Client和AllocSvr需要使用完全一致的配置文件。变更这个配置文件的时候，由于无法实现在同一时间更新给所有的Client和AllocSvr，因此需要非常复杂的人工操作来保证变更的正确性（包括需要使用iptables来做请求转发，具体的详情这里不做展开）。</p>
<p>对于第二个问题，常见的方法是用一致性Hash算法替代主备，一个Set有多台机器，过载机器的请求被分摊到多台机器，容灾效果会更好。在seqsvr中使用类似一致性Hash的容灾策略也是可行的，只要Client端与仲裁服务都使用完全一样的一致性Hash算法，这样Client端可以启发式地去尝试，直到找到正确的AllocSvr。</p>
<p>例如对于某个uid，仲裁服务会优先把它分配到AllocSvrA，如果AllocSvrA挂掉则分配到AllocSvrB，再不行分配到AllocSvrC。那么Client在访问AllocSvr时，按照AllocSvrA -&gt; AllocSvrB -&gt; AllocSvrC的顺序去访问，也能实现容灾的目的。但这种方法仍然没有克服前面主备容灾面临的配置文件变更的问题，运营起来也很麻烦。</p>
<h2 id="容灾2-0架构：嵌入式路由表容灾"><a href="#容灾2-0架构：嵌入式路由表容灾" class="headerlink" title="容灾2.0架构：嵌入式路由表容灾"></a>容灾2.0架构：嵌入式路由表容灾</h2><p>最后我们另辟蹊径，采用了一种不同的思路：既然Client端与AllocSvr存在路由状态不一致的问题，那么让AllocSvr把当前的路由状态传递给Client端，打破之前只能根据本地Client配置文件做路由决策的限制，从根本上解决这个问题。</p>
<p>所以在2.0架构中，我们把AllocSvr的路由状态嵌入到Client请求sequence的响应包中，在不带来额外的资源消耗的情况下，实现了Client端与AllocSvr之间的路由状态一致。具体实现方案如下：</p>
<p>seqsvr所有模块使用了统一的路由表，描述了uid号段到AllocSvr的全映射。这份路由表由仲裁服务根据AllocSvr的服务状态生成，写到StoreSvr中，由AllocSvr当作租约读出，最后在业务返回包里旁路给Client端。</p>
<p><img src="/upload/images/9.png"><br>图9. 容灾2.0架构：动态号段迁移容灾</p>
<p><strong>把路由表嵌入到请求响应包看似很简单的架构变动，却是整个seqsvr容灾架构的技术奇点。</strong>利用它解决了路由状态不一致的问题后，可以实现一些以前不容易实现的特性。例如灵活的容灾策略，让所有机器都互为备机，在机器故障时，把故障机上的号段均匀地迁移到其它可用的AllocSvr上；还可以根据AllocSvr的负载情况，进行负载均衡，有效缓解AllocSvr请求不均的问题，大幅提升机器使用率。</p>
<p>另外在运营上也得到了大幅简化。之前对机器进行运维操作有着繁杂的操作步骤，而新架构只需要更新路由即可轻松实现上线、下线、替换机器，不需要关心配置文件不一致的问题，避免了一些由于人工误操作引发的故障。</p>
<p><img src="/upload/images/10.riff"><br>图10. 机器故障号段迁移</p>
<h3 id="路由同步优化"><a href="#路由同步优化" class="headerlink" title="路由同步优化"></a>路由同步优化</h3><p>把路由表嵌入到取sequence的请求响应包中，那么会引入一个类似“先有鸡还是先有蛋”的哲学命题：没有路由表，怎么知道去哪台AllocSvr取路由表？另外，取sequence是一个超高频的请求，如何避免嵌入路由表带来的带宽消耗？</p>
<p>这里通过在Client端内存缓存路由表以及路由版本号来解决，请求步骤如下：</p>
<ol>
<li><p>Client根据本地共享内存缓存的路由表，选择对应的AllocSvr；如果路由表不存在，随机选择一台AllocSvr</p>
</li>
<li><p>对选中的AllocSvr发起请求，请求带上本地路由表的版本号</p>
</li>
<li><p>AllocSvr收到请求，除了处理sequence逻辑外，判断Client带上版本号是否最新，如果是旧版则在响应包中附上最新的路由表</p>
</li>
<li><p>Client收到响应包，除了处理sequence逻辑外，判断响应包是否带有新路由表。如果有，更新本地路由表，并决策是否返回第1步重试</p>
</li>
</ol>
<p>基于以上的请求步骤，在本地路由表失效的时候，使用少量的重试便可以拉到正确的路由，正常提供服务。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>到此把seqsvr的架构设计和演变基本讲完了，正是如此简单优雅的模型，为微信的其它模块提供了一种简单可靠的一致性解决方案，支撑着微信五年来的高速发展，相信在可预见的未来仍然会发挥着重要的作用。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-09-weixin-sequence-generator.html" target="_blank">万亿级调用系统：微信序列号生成器架构设计及演变</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-09-weixin-sequence-generator.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>序号生成器</tag>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Redis SETNX命令实现分布式锁</title>
    <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-08-10-dist-lock-using-redis.html</url>
    <content><![CDATA[<blockquote>
<p>版权声明：本文为博主原创文章，转载自: <a href="http://blog.csdn.net/lihao21">http://blog.csdn.net/lihao21</a></p>
</blockquote>
<h2 id="SETNX命令简介"><a href="#SETNX命令简介" class="headerlink" title="SETNX命令简介"></a>SETNX命令简介</h2><h3 id="命令格式"><a href="#命令格式" class="headerlink" title="命令格式"></a>命令格式</h3><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">SETNX key value</span></span><br></pre></td></tr></table></figure>
<p>**<code>SETNX</code>**是<code>SET if Not eXists</code>的简写。</p>
<p>如果<code>key</code>值不存在，在设置<code>key</code>的值为<code>value</code>；如果<code>key</code>值存在，则不做任何动作。</p>
<h3 id="返回值"><a href="#返回值" class="headerlink" title="返回值"></a>返回值</h3><p>返回整数，具体为:</p>
<blockquote>
<p><code>1</code>，当<code>key</code>的值被设置<br><code>0</code>，当<code>key</code>的值没被设置</p>
</blockquote>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">redis&gt; SETNX mykey &quot;hello&quot;</span><br><span class="line">(<span class="type">integer</span>) <span class="number">1</span> </span><br><span class="line">redis&gt; SETNX mykey &quot;hello&quot;</span><br><span class="line">(<span class="type">integer</span>) <span class="number">0</span> </span><br><span class="line">redis&gt; <span class="keyword">GET</span> mykey </span><br><span class="line">&quot;hello&quot;</span><br><span class="line">redis&gt;</span><br></pre></td></tr></table></figure>

<h2 id="使用SETNX实现分布式锁"><a href="#使用SETNX实现分布式锁" class="headerlink" title="使用SETNX实现分布式锁"></a>使用SETNX实现分布式锁</h2><p>多个进程执行以下Redis命令：</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">SETNX <span class="keyword">lock</span>.foo &lt;<span class="keyword">current</span> Unix <span class="type">time</span> + <span class="keyword">lock</span> timeout + <span class="number">1</span>&gt;</span><br></pre></td></tr></table></figure>
<p>如果<code>SETNX</code>返回<code>1</code>，说明该进程获得锁，<code>SETNX</code>将键<code>lock.foo</code>的值设置为锁的超时时间（当前时间 + 锁的有效时间）。<br>如果<code>SETNX</code>返回<code>0</code>，说明其他进程已经获得了锁，进程不能进入临界区。进程可以在一个循环中不断地尝试<code>SETNX</code>操作，以获得锁。</p>
<h3 id="解决死锁"><a href="#解决死锁" class="headerlink" title="解决死锁"></a>解决死锁</h3><p>考虑一种情况，如果进程获得锁后，断开了与 Redis 的连接（可能是进程挂掉，或者网络中断），如果没有有效的释放锁的机制，那么其他进程都会处于一直等待的状态，即出现“死锁”。</p>
<p>上面在使用<code>SETNX</code>获得锁时，我们将键 lock.foo 的值设置为锁的有效时间，进程获得锁后，其他进程还会不断的检测锁是否已超时，如果超时，那么等待的进程也将有机会获得锁。</p>
<p>然而，锁超时时，我们不能简单地使用<code>DEL</code>命令删除键<code>lock.foo</code>以释放锁。考虑以下情况，进程P1已经首先获得了锁<code>lock.foo</code>，然后进程P1挂掉了。进程P2，P3正在不断地检测锁是否已释放或者已超时，执行流程如下：</p>
<ol>
<li>P2和P3进程读取键<code>lock.foo</code>的值，检测锁是否已超时（通过比较当前时间和键<code>lock.foo</code>的值来判断是否超时）</li>
<li>P2和P3进程发现锁<code>lock.foo</code>已超时</li>
<li>P2执行<code>DEL lock.foo</code>命令</li>
<li>P2执行<code>SETNX lock.foo</code>命令，并返回<code>1</code>，即P2获得锁</li>
<li>P3执行<code>DEL lock.foo</code>命令将P2刚刚设置的键<code>lock.foo</code>删除（这步是由于P3刚才已检测到锁已超时）</li>
<li>P3执行<code>SETNX lock.foo</code>命令，并返回<code>1</code>，即P3获得锁</li>
<li>P2和P3同时获得了锁</li>
</ol>
<p>从上面的情况可以得知，在检测到锁超时后，进程不能直接简单地执行<code>DEL</code>删除键的操作以获得锁。</p>
<p>为了解决上述算法可能出现的多个进程同时获得锁的问题，我们再来看以下的算法。<br>我们同样假设进程P1已经首先获得了锁<code>lock.foo</code>，然后进程P1挂掉了。接下来的情况：</p>
<ol>
<li>进程P4执行<code>SETNX lock.foo</code>以尝试获取锁</li>
<li>由于进程P1已获得了锁，所以P4执行<code>SETNX lock.foo</code>返回<code>0</code>，即获取锁失败</li>
<li>P4执行<code>GET lock.foo</code>来检测锁是否已超时，如果没超时，则等待一段时间，再次检测</li>
<li>如果P4检测到锁已超时，即当前的时间大于键<code>lock.foo</code>的值，P4会执行以下操作 <code>GETSET lock.foo &lt;current Unix timestamp + lock timeout + 1&gt;</code></li>
<li>由于<code>GETSET</code>操作在设置键的值的同时，还会返回键的旧值，通过比较键<code>lock.foo</code>的旧值是否小于当前时间，可以判断进程是否已获得锁</li>
<li>假如另一个进程P5也检测到锁已超时，并在P4之前执行了<code>GETSET</code>操作，那么P4的<code>GETSET</code>操作返回的是一个大于当前时间的时间戳，这样P4就不会获得锁而继续等待。注意到，即使P4接下来将键<code>lock.foo</code>的值设置了比P5设置的更大的值也没影响。</li>
</ol>
<p>另外，值得注意的是，在进程释放锁，即执行<code>DEL lock.foo</code>操作前，需要先判断锁是否已超时。如果锁已超时，那么锁可能已由其他进程获得，这时直接执行<code>DEL lock.foo</code>操作会导致把其他进程已获得的锁释放掉。</p>
<h2 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h2><p>用以下python代码来实现上述的使用 SETNX 命令作分布式锁的算法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">LOCK_TIMEOUT = <span class="number">3</span></span><br><span class="line">lock = <span class="number">0</span></span><br><span class="line">lock_timeout = <span class="number">0</span></span><br><span class="line">lock_key = <span class="string">&#x27;lock.foo&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取锁</span></span><br><span class="line"><span class="keyword">while</span> lock != <span class="number">1</span>:</span><br><span class="line">    now = <span class="built_in">int</span>(time.time())</span><br><span class="line">    lock_timeout = now + LOCK_TIMEOUT + <span class="number">1</span></span><br><span class="line">    lock = redis_client.setnx(lock_key, lock_timeout)</span><br><span class="line">    <span class="keyword">if</span> lock == <span class="number">1</span> <span class="keyword">or</span> (now &gt; <span class="built_in">int</span>(redis_client.get(lock_key))) <span class="keyword">and</span> now &gt; <span class="built_in">int</span>(redis_client.getset(lock_key, lock_timeout)):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        time.sleep(<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 已获得锁</span></span><br><span class="line">do_job()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 释放锁</span></span><br><span class="line">now = <span class="built_in">int</span>(time.time())</span><br><span class="line"><span class="keyword">if</span> now &lt; lock_timeout:</span><br><span class="line">    redis_client.delete(lock_key)</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="http://redis.io/commands/setnx">http://redis.io/commands/setnx</a></li>
<li><a href="http://redis.io/topics/distlock">http://redis.io/topics/distlock</a></li>
<li><a href="http://redis.io/commands/getset">http://redis.io/commands/getset</a></li>
<li><a href="http://redis.readthedocs.org/en/latest/string/setnx.html">http://redis.readthedocs.org/en/latest/string/setnx.html</a></li>
<li><a href="http://my.oschina.net/u/1995545/blog/366381">http://my.oschina.net/u/1995545/blog/366381</a></li>
</ul>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-08-10-dist-lock-using-redis.html" target="_blank">使用Redis SETNX命令实现分布式锁</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-08-10-dist-lock-using-redis.html]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>转载</tag>
        <tag>分布式锁</tag>
      </tags>
  </entry>
  <entry>
    <title>Partial selection of Spring Data JPA</title>
    <url>/spring/2016-08-10-partial-selection-with-jpa.html</url>
    <content><![CDATA[<p>When we use <code>select</code> to retrive some data from MySQL, we do not want to get the whole row with all columns.<br>For example, I have the following <code>tab_staff_info</code> table with nearly 100 columns:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Entity</span></span><br><span class="line"><span class="meta">@Table(name = &quot;tab_staff_info&quot;)</span></span><br><span class="line"><span class="meta">@DynamicUpdate</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StaffInfo</span> <span class="keyword">extends</span> <span class="title class_">BaseEntity</span> &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * qq号</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 40)</span></span><br><span class="line">    <span class="keyword">private</span> String qqNo;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 公司Id</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 40)</span></span><br><span class="line">    <span class="keyword">private</span> String companyId;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 工号</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 32)</span></span><br><span class="line">    <span class="keyword">private</span> String staffNo;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 姓名</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 32)</span></span><br><span class="line">    <span class="keyword">private</span> String staffName;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 证件号</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 30)</span></span><br><span class="line">    <span class="keyword">private</span> String idCardNo;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 证件类型</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 20)</span></span><br><span class="line">    <span class="meta">@Enumerated(EnumType.STRING)</span></span><br><span class="line">    <span class="keyword">private</span> IdCardType idCardType;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 生日</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column</span></span><br><span class="line">    <span class="keyword">private</span> Date birthday;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 性别</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 10)</span></span><br><span class="line">    <span class="meta">@Enumerated(EnumType.STRING)</span></span><br><span class="line">    <span class="keyword">private</span> SexType sex;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 手机号码</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Column(length = 18)</span></span><br><span class="line">    <span class="keyword">private</span> String mobileNo;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// A lot more columns..</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>In most cases, I only want to get some (not all) of the columns. For example, I want to get the basic information, which are: <code>companyId</code>, <code>staffNo</code>, <code>staffName</code> and <code>idCardNo</code>.</p>
<p>In order to do this, I need to modify the <code>StaffInfoDao</code> interface.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">interface</span> <span class="title class_">StaffInfoDao</span> <span class="keyword">extends</span> <span class="title class_">JpaRepository</span>&lt;StaffInfo, String&gt; &#123;</span><br><span class="line">      <span class="meta">@Query(&quot;select new StaffInfo(s.companyId, s.staffNo, s.staffName, s.idCardNo) from StaffInfo s where s.companyId = :companyId&quot;)</span></span><br><span class="line">      List&lt;StaffInfo&gt; <span class="title function_">findStaffBasicInfoByCompanyId</span><span class="params">(<span class="meta">@Param(&quot;companyId&quot;)</span> String companyId)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>And of couse we need to add a constructor to support <code>new StaffInfo(s.companyId, s.staffNo, s.staffName, s.idCardNo)</code> in the JPA QL:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">StaffInfo</span><span class="params">(String companyId, String staffNo, String staffName, String idCardNo)</span> &#123;</span><br><span class="line">      <span class="built_in">this</span>.companyId = companyId;</span><br><span class="line">      <span class="built_in">this</span>.staffNo = staffNo;</span><br><span class="line">      <span class="built_in">this</span>.staffName = staffName;</span><br><span class="line">      <span class="built_in">this</span>.idCardNo = idCardNo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Change log level of hibernate library to debug and we can see the following output:</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">[<span class="number">20160808</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">14</span>][<span class="keyword">DEBUG</span>][org.hibernate.<span class="keyword">SQL</span>](SqlStatementLogger.java:<span class="number">109</span>) - <span class="keyword">select</span> staffinfo0_.companyId <span class="keyword">as</span> col_0_0_, staffinfo0_.staffNo <span class="keyword">as</span> col_1_0_, staffinfo0_.staffName <span class="keyword">as</span> col_2_0_, staffinfo0_.idCardNo <span class="keyword">as</span> col_3_0_ <span class="keyword">from</span> tab_staff_info staffinfo0_ <span class="keyword">where</span> staffinfo0_.companyId=?</span><br><span class="line">[<span class="number">20160808</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">14</span>][<span class="keyword">DEBUG</span>][org.hibernate.engine.jdbc.internal.LogicalConnectionImpl](LogicalConnectionImpl.java:<span class="number">226</span>) - Obtaining JDBC <span class="keyword">connection</span></span><br><span class="line">[<span class="number">20160808</span> <span class="number">14</span>:<span class="number">30</span>:<span class="number">14</span>][<span class="keyword">DEBUG</span>][org.hibernate.engine.jdbc.internal.LogicalConnectionImpl](LogicalConnectionImpl.java:<span class="number">232</span>) - Obtained JDBC <span class="keyword">connection</span></span><br></pre></td></tr></table></figure>



<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/spring/2016-08-10-partial-selection-with-jpa.html" target="_blank">Partial selection of Spring Data JPA</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/spring/2016-08-10-partial-selection-with-jpa.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Spring Data JPA</tag>
        <tag>ORM</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Goaccess监控Nginx的运行状态</title>
    <url>/%E8%BF%90%E7%BB%B4/2016-08-12-monitor-nginx-with-goaccess.html</url>
    <content><![CDATA[<h2 id="最终启动命令"><a href="#最终启动命令" class="headerlink" title="最终启动命令"></a>最终启动命令</h2><p>如果你只需要知道最终的启动命令，可以跳过下边所有内容。启动命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">goaccess -f /var/log/nginx/access.log -o /data/www/access/index.html --real-time-html --ws-url=access1.xiaotanzhu.com</span><br></pre></td></tr></table></figure>

<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>系统版本：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">root</span>@www:~# lsb_release -a</span><br><span class="line"><span class="attribute">No</span> LSB modules are available.</span><br><span class="line"><span class="attribute">Distributor</span> ID: Ubuntu</span><br><span class="line"><span class="attribute">Description</span>:    Ubuntu <span class="number">14</span>.<span class="number">04</span>.<span class="number">2</span> LTS</span><br><span class="line"><span class="attribute">Release</span>:        <span class="number">14</span>.<span class="number">04</span></span><br><span class="line"><span class="attribute">Codename</span>:       trusty</span><br></pre></td></tr></table></figure>
<p>Nginx日志配置</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">log_format</span> access <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; <span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &quot;<span class="variable">$http_user_agent</span>&quot; <span class="variable">$http_x_forwarded_for</span> <span class="variable">$request_time</span> <span class="variable">$upstream_response_time</span>&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>Nginx日志样例</p>
<figure class="highlight accesslog"><table><tr><td class="code"><pre><span class="line"><span class="number">180.98.186.40</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/heartbeat/alive HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">73</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">002</span> <span class="number">0</span>.<span class="number">002</span></span><br><span class="line"><span class="number">202.112.25.39</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/attendance/signin/time/detail/v2 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">110</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">197</span> <span class="number">0</span>.<span class="number">197</span></span><br><span class="line"><span class="number">180.98.186.40</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/message/unread/v5 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">2322</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">085</span> <span class="number">0</span>.<span class="number">085</span></span><br><span class="line"><span class="number">180.98.186.40</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/common/app/advertisement/v2 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">59</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">076</span> <span class="number">0</span>.<span class="number">076</span></span><br><span class="line"><span class="number">180.98.186.40</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/common/version/v1 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">532</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">097</span> <span class="number">0</span>.<span class="number">097</span></span><br><span class="line"><span class="number">180.98.186.40</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/honour/queryFavoriteImageList/v1 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">1172</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">108</span> <span class="number">0</span>.<span class="number">108</span></span><br><span class="line"><span class="number">180.98.186.40</span> - - <span class="string">[12/Aug/2016:14:39:43 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/log/info HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">47</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">119</span> <span class="number">0</span>.<span class="number">119</span></span><br><span class="line"><span class="number">202.112.25.39</span> - - <span class="string">[12/Aug/2016:14:39:44 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/attendance/signin/time/detail/v2 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">110</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">235</span> <span class="number">0</span>.<span class="number">235</span></span><br><span class="line"><span class="number">202.112.25.39</span> - - <span class="string">[12/Aug/2016:14:39:44 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/attendance/signin/condition/v4 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">305</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">134</span> <span class="number">0</span>.<span class="number">134</span></span><br><span class="line"><span class="number">202.112.25.39</span> - - <span class="string">[12/Aug/2016:14:39:44 +0800]</span> <span class="string">&quot;<span class="keyword">POST</span> /api/attendance/signin/time/detail/v2 HTTP/1.1&quot;</span> <span class="number">200</span> <span class="number">110</span> <span class="string">&quot;-&quot;</span> <span class="string">&quot;okhttp/3.3.1&quot;</span> - <span class="number">0</span>.<span class="number">165</span> <span class="number">0</span>.<span class="number">165</span></span><br></pre></td></tr></table></figure>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>安装方法官方网站给的很清楚，传送门：<a href="https://goaccess.io/download">https://goaccess.io/download</a></p>
<p>这里节选出Ubuntu上的安装方法</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb http://deb.goaccess.io/ <span class="subst">$(lsb_release -cs)</span> main&quot;</span> | sudo <span class="built_in">tee</span> -a /etc/apt/sources.list.d/goaccess.list</span><br><span class="line">wget -O - https://deb.goaccess.io/gnugpg.key | sudo apt-key add - </span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install goaccess</span><br></pre></td></tr></table></figure>
<p>最简单的使用方法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">goaccess -f /var/log/nginx/access.log</span><br></pre></td></tr></table></figure>
<p>分析完成之后可以看到一个终端显示（libncurses）的页面，也可以对这个页面进行交互，具体的交互方式可以参考<code>man goaccess</code>。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>如果使用Nginx默认的日志格式，那么Goaccess不需要任何设置即可使用。但是我们的日志为自定义格式，在默认日志的最后增加了响应时间<code>$request_time</code>和upstream的响应时间<code>$upstream_response_time</code>，如下：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">log_format</span> access <span class="string">&#x27;<span class="variable">$remote_addr</span> - <span class="variable">$remote_user</span> [<span class="variable">$time_local</span>] &quot;<span class="variable">$request</span>&quot; <span class="variable">$status</span> <span class="variable">$body_bytes_sent</span> &quot;<span class="variable">$http_referer</span>&quot; &quot;<span class="variable">$http_user_agent</span>&quot; <span class="variable">$http_x_forwarded_for</span> <span class="variable">$request_time</span> <span class="variable">$upstream_response_time</span>&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>于是需要修改Goaccess监控的日志的格式，原格式</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="deletion">- log-format %h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot;</span></span><br><span class="line"><span class="addition">+ log-format %h %^[%d:%t %^] &quot;%r&quot; %s %b &quot;%R&quot; &quot;%u&quot; %^ %^ %T</span></span><br></pre></td></tr></table></figure>
<p>最后三个元素<code>%^ %^ %T</code>，<code>%^</code>表示忽略，<code>%T</code>表示“以秒为单位的响应时间，精确到毫秒”。</p>
<p>完整的日志格式可以参考<code>man goaccess</code>，这里节选其中的日志格式部分：</p>
<pre><code>   log-format
          The log-format variable followed by a space or \t , specifies the log format string.

   %x     A date and time field matching the time-format and date-format variables. This is used when a timestamp is given instead of the date and time being in two separated vari‐
          ables.
   %t     time field matching the time-format variable.
   %d     date field matching the date-format variable.
   %v     The canonical Server Name of the server serving the request (Virtual Host).
   %h     host (the client IP address, either IPv4 or IPv6)
   %r     The request line from the client. This requires specific delimiters around the request (as single quotes, double quotes, or anything else) to be parsable. If not, we have
          to use a combination of special format specifiers as %m %U %H.
   %q     The query string.
   %m     The request method.
   %U     The URL path requested.
          Note:  If the query string is in %U, there is no need to use %q.  However, if the URL path, does not include any query string, you may use %q and the query string will be
          appended to the request.
   %H     The request protocol.
   %s     The status code that the server sends back to the client.
   %b     The size of the object returned to the client.
   %R     The &quot;Referrer&quot; HTTP request header.
   %u     The user-agent HTTP request header.
   %D     The time taken to serve the request, in microseconds as a decimal number.
   %T     The time taken to serve the request, in seconds with milliseconds resolution.
   %L     The time taken to serve the request, in milliseconds as a decimal number.

          Note: If multiple time served specifiers are used at the same time, the first option specified in the format string will take priority over the other specifiers.

   %^     Ignore this field.
   %~     Move forward through the log string until a non-space (!isspace) char is found.

   GoAccess requires the following fields:
          %h a valid IPv4/6
          %d a valid date
          %r the request
</code></pre>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>实际监控还是用HTML来的方便，而且Goaccess号称实时监控，那这个特性肯定也要用一下了。</p>
<p>实时监控启动命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">goaccess -f /var/log/nginx/access.log -o /data/www/access/index.html --real-time-html --ws-url=access1.xiaotanzhu.com</span><br></pre></td></tr></table></figure>

<p>下边每个参数分别介绍一下。</p>
<ol>
<li><code>-f /var/log/nginx/access.log</code> 指定要分析的Nginx日志文件，没什么好说的</li>
<li><code>-o /data/www/access/index.html</code> 指定输出的HTML文件</li>
<li><code>--real-time-html</code> 启动实时HTML。这里需要注意的是，所谓实时并不是goaccess不停的更新HTML文件。事实上，HTML文件生成之后，就不再变化，而页面上是通过WebSocket对页面上的数据进行更新</li>
<li><code>--ws-url=access1.irenshi.cn</code> 指定WebSocket的地址。由于我使用<code>access1.xiaotanzhu.com</code>访问生成的HTML，所以<code>--ws-url</code>必须指定为<code>access1.xiaotanzhu.com</code>，这样生成的HTML才知道应该去<code>ws://access1.xiaotanzhu.com:7890</code>访问这个WebSocket。</li>
<li><code>--port=7890</code> 我们这里并没有使用这个参数。这个参数用来控制goaccess生成的WebSocket的端口。默认值：7890。</li>
</ol>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><h3 id="监控界面"><a href="#监控界面" class="headerlink" title="监控界面"></a>监控界面</h3><p><img src="/upload/images/10.png"></p>
<p>我们可以看到其中的数据在实时变化。</p>
<h3 id="资源占用"><a href="#资源占用" class="headerlink" title="资源占用"></a>资源占用</h3><p>使用<code>top</code>命令查看内存占用情况如下：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line">  <span class="attribute">PID</span> USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"><span class="attribute">26727</span> root      <span class="number">20</span>   <span class="number">0</span>  <span class="number">219624</span>  <span class="number">51136</span>   <span class="number">1612</span> S   <span class="number">1</span>.<span class="number">3</span>  <span class="number">0</span>.<span class="number">6</span>   <span class="number">0</span>:<span class="number">52</span>.<span class="number">13</span> goaccess</span><br></pre></td></tr></table></figure>
<p>现在来看处理百兆的日志时，资源还是比较省的。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-08-12-monitor-nginx-with-goaccess.html" target="_blank">使用Goaccess监控Nginx的运行状态</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-08-12-monitor-nginx-with-goaccess.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>监控</tag>
        <tag>Nginx</tag>
        <tag>Goaccess</tag>
      </tags>
  </entry>
  <entry>
    <title>创建支持emoji表情的MySQL数据库（utf8mb4）</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-create-mysql-database-with-utf8mb4.html</url>
    <content><![CDATA[<blockquote>
<p>本文只介绍在创建全新数据库的情况下，如何支持emoji表情等字符。如果需要对现有的数据库修改以支持emoji表情，请参考：<a href="/2016/08/14/how-to-support-full-unicode-in-mysql.html">How to support full Unicode in MySQL databases</a></p>
</blockquote>
<p>UTF-8编码有可能是两个、三个、四个字节。Emoji表情是4个字节，而MySQL的utf8编码最多3个字节，当使用iPhone等插入表情的时候，会抛出如下错误：</p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">java<span class="selector-class">.sql</span><span class="selector-class">.SQLException</span>: Incorrect string value: <span class="string">&#x27;\xF0\x9F\x92\x94&#x27;</span> <span class="keyword">for</span> column <span class="string">&#x27;name&#x27;</span> at row <span class="number">1</span></span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.SQLError</span><span class="selector-class">.createSQLException</span>(SQLError<span class="selector-class">.java</span>:<span class="number">1073</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.MysqlIO</span><span class="selector-class">.checkErrorPacket</span>(MysqlIO<span class="selector-class">.java</span>:<span class="number">3593</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.MysqlIO</span><span class="selector-class">.checkErrorPacket</span>(MysqlIO<span class="selector-class">.java</span>:<span class="number">3525</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.MysqlIO</span><span class="selector-class">.sendCommand</span>(MysqlIO<span class="selector-class">.java</span>:<span class="number">1986</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.MysqlIO</span><span class="selector-class">.sqlQueryDirect</span>(MysqlIO<span class="selector-class">.java</span>:<span class="number">2140</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.ConnectionImpl</span><span class="selector-class">.execSQL</span>(ConnectionImpl<span class="selector-class">.java</span>:<span class="number">2620</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.StatementImpl</span><span class="selector-class">.executeUpdate</span>(StatementImpl<span class="selector-class">.java</span>:<span class="number">1662</span>)</span><br><span class="line">    at com<span class="selector-class">.mysql</span><span class="selector-class">.jdbc</span><span class="selector-class">.StatementImpl</span><span class="selector-class">.executeUpdate</span>(StatementImpl<span class="selector-class">.java</span>:<span class="number">1581</span>)</span><br></pre></td></tr></table></figure>
<p>解决方案就是：**将MySQL的编码从<code>utf8</code>转换成<code>utf8mb4</code>**。</p>
<h2 id="MySQL服务器配置"><a href="#MySQL服务器配置" class="headerlink" title="MySQL服务器配置"></a>MySQL服务器配置</h2><p>修改MySQL配置文件<code>/etc/mysql/my.cnf</code>：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">character-set-server</span>=utf8mb4</span><br><span class="line"><span class="section">[mysql]</span></span><br><span class="line"><span class="attr">default-character-set</span>=utf8mb4</span><br></pre></td></tr></table></figure>
<p>这样，在创建数据库或数据库表的时候，如果不指定编码格式，则默认使用<code>utf8mb4</code>。</p>
<h2 id="创建库的时候指定"><a href="#创建库的时候指定" class="headerlink" title="创建库的时候指定"></a>创建库的时候指定</h2><p>如果已经配置了服务器的默认编码集，则创建数据库的时候不需要指定<code>CHARACTER</code>和<code>COLLATE</code>。如果无法修改服务器默认设置，则可以使用该方法创建数据库。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE `irenshi` <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure>

<p>可以使用以下SQL查看字符集是否正确：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> <span class="keyword">CREATE</span> DATABASE `irenshi`;</span><br></pre></td></tr></table></figure>
<p>输出如下即可：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="section">mysql&gt; SHOW CREATE DATABASE `irenshi`;</span></span><br><span class="line"><span class="section">+----------+---------------------------------------------------------------------+</span></span><br><span class="line"><span class="section">| Database | Create Database                                                     |</span></span><br><span class="line"><span class="section">+----------+---------------------------------------------------------------------+</span></span><br><span class="line"><span class="section">| irenshi  | CREATE DATABASE `irenshi` /*!40100 DEFAULT CHARACTER SET utf8mb4 */ |</span></span><br><span class="line"><span class="section">+----------+---------------------------------------------------------------------+</span></span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>创建数据库之后，该数据库中所有表的列的默认字符集都为<code>utf8mb4</code>。</p>
<h2 id="创建表的时候指定"><a href="#创建表的时候指定" class="headerlink" title="创建表的时候指定"></a>创建表的时候指定</h2><p>如果无法设置数据库的字符集或者只想指定特定表使用<code>utf8mb4</code>，可以在创建表的时候设置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `tab_staff` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `staffName` <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span></span><br><span class="line">) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_general_ci;</span><br></pre></td></tr></table></figure>

<h2 id="创建列的时候指定"><a href="#创建列的时候指定" class="headerlink" title="创建列的时候指定"></a>创建列的时候指定</h2><p>如果无法设置数据库表的字符集或者只想设置某些字段为<code>utf8mb4</code>，可以在创建表的时候指定列的编码集：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `tab_staff` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">11</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `staffName` <span class="type">varchar</span>(<span class="number">100</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `idCardNo` <span class="type">varchar</span>(<span class="number">18</span>) <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span></span><br><span class="line">) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">collate</span> utf8_general_ci;</span><br></pre></td></tr></table></figure>

<h2 id="使用Docker时"><a href="#使用Docker时" class="headerlink" title="使用Docker时"></a>使用Docker时</h2><p>如果你使用MySQL的<a href="https://hub.docker.com/_/mysql/">官方Docker</a>启动并创建数据库，官方文档也给出了启动命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure>

<h2 id="检查MySQL是否启用了utf8mb4"><a href="#检查MySQL是否启用了utf8mb4" class="headerlink" title="检查MySQL是否启用了utf8mb4"></a>检查MySQL是否启用了utf8mb4</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> VARIABLES <span class="keyword">WHERE</span> Variable_name <span class="keyword">LIKE</span> <span class="string">&#x27;character_set_%&#x27;</span> <span class="keyword">OR</span> Variable_name <span class="keyword">LIKE</span> <span class="string">&#x27;collation%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下说明<code>utf8mb4</code>已经生效：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+--------------------------+----------------------------+</span><br><span class="line">|<span class="string"> Variable_name            </span>|<span class="string"> Value                      </span>|</span><br><span class="line">+--------------------------+----------------------------+</span><br><span class="line">|<span class="string"> character_set_client     </span>|<span class="string"> utf8mb4                    </span>|</span><br><span class="line">|<span class="string"> character_set_connection </span>|<span class="string"> utf8mb4                    </span>|</span><br><span class="line">|<span class="string"> character_set_database   </span>|<span class="string"> utf8mb4                    </span>|</span><br><span class="line">|<span class="string"> character_set_filesystem </span>|<span class="string"> binary                     </span>|</span><br><span class="line">|<span class="string"> character_set_results    </span>|<span class="string"> utf8mb4                    </span>|</span><br><span class="line">|<span class="string"> character_set_server     </span>|<span class="string"> utf8mb4                    </span>|</span><br><span class="line">|<span class="string"> character_set_system     </span>|<span class="string"> utf8                       </span>|</span><br><span class="line">|<span class="string"> character_sets_dir       </span>|<span class="string"> /usr/share/mysql/charsets/ </span>|</span><br><span class="line">|<span class="string"> collation_connection     </span>|<span class="string"> utf8mb4_general_ci         </span>|</span><br><span class="line">|<span class="string"> collation_database       </span>|<span class="string"> utf8mb4_general_ci         </span>|</span><br><span class="line">|<span class="string"> collation_server         </span>|<span class="string"> utf8mb4_general_ci         </span>|</span><br><span class="line">+--------------------------+----------------------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-create-mysql-database-with-utf8mb4.html" target="_blank">创建支持emoji表情的MySQL数据库（utf8mb4）</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-create-mysql-database-with-utf8mb4.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>emoji</tag>
        <tag>utf8mb4</tag>
      </tags>
  </entry>
  <entry>
    <title>How to support full Unicode in MySQL databases</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-how-to-support-full-unicode-in-mysql.html</url>
    <content><![CDATA[<p>如果你完全从头建立一个数据库，那么事情简单了很多，直接参考：<a href="/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-create-mysql-database-with-utf8mb4.html">创建支持emoji表情的MySQL数据库（utf8mb4）</a>。</p>
<p>如果你的数据库已经在投入使用，那么可以参考文章的以下部分。</p>
<blockquote>
<p><strong>Reference:</strong> <a href="https://mathiasbynens.be/notes/mysql-utf8mb4">https://mathiasbynens.be/notes/mysql-utf8mb4</a></p>
</blockquote>
<h2 id="UTF-8"><a href="#UTF-8" class="headerlink" title="UTF-8"></a>UTF-8</h2><p><a href="https://encoding.spec.whatwg.org/#utf-8">The UTF-8 encoding</a> can represent every symbol in the Unicode character set, which ranges from <code>U+000000</code> to <code>U+10FFFF</code>. That’s 1,114,112 possible symbols. (Not all of these Unicode code points have been assigned characters yet, but that doesn’t stop UTF-8 from being able to encode them.)</p>
<p>UTF-8 is a variable-width encoding; it encodes each symbol using <strong>one to four 8-bit bytes</strong>. Symbols with lower numerical code point values are encoded using fewer bytes. This way, UTF-8 is optimized for the common case where ASCII characters and other <a href="https://mathiasbynens.be/notes/javascript-encoding#bmp">BMP symbols</a> (whose code points range from <code>U+000000</code> to <code>U+00FFFF</code>) are used — while still allowing astral symbols (whose code points range from <code>U+010000</code> to <code>U+10FFFF</code>) to be stored.</p>
<h2 id="MySQL’s-utf8"><a href="#MySQL’s-utf8" class="headerlink" title="MySQL’s utf8"></a>MySQL’s <code>utf8</code></h2><p>MySQL’s utf8 charset only partially implements proper UTF-8 encoding. It can only store UTF-8-encoded symbols that consist of one to three bytes; encoded symbols that take up four bytes aren’t supported.</p>
<p>Since astral symbols (whose code points range from U+010000 to U+10FFFF) each consist of four bytes in UTF-8, you cannot store them using MySQL’s utf8 implementation. And if you are doing so, you’ll get the following warning:</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="section">mysql&gt; SHOW WARNINGS;</span></span><br><span class="line"><span class="section">+---------+------+------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="section">| Level   | Code | Message                                                                      |</span></span><br><span class="line"><span class="section">+---------+------+------------------------------------------------------------------------------+</span></span><br><span class="line"><span class="section">| Warning | 1366 | Incorrect string value: &#x27;\xF0\x9D\x8C\x86&#x27; for column &#x27;column_name&#x27; at row 1 |</span></span><br><span class="line"><span class="section">+---------+------+------------------------------------------------------------------------------+</span></span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>this behavior can lead to data loss, but it gets worse — it can result in security vulnerabilities. Here are some examples, all of which were discovered after publishing this write-up:</p>
<ol>
<li><a href="https://tom.vg/2013/09/wordpress-php-object-injection/">PHP object injection vulnerability in WordPress &lt; 3.6.1</a>, leading to <a href="https://tom.vg/2013/12/wordpress-rce-exploit/">remote code execution in combination with certain WordPress plugins</a></li>
<li><a href="https://hackerone.com/reports/2233">Email authentication bypass in Phabricator</a></li>
<li><a href="https://cedricvb.be/post/wordpress-stored-xss-vulnerability-4-1-2/">Stored XSS in WordPress 4.1.2</a></li>
<li><a href="https://www.reddit.com/r/netsec/comments/3wt0yk/critical_0day_remote_command_execution/cxz2qtc">Remote command execution in the Joomla! CMS</a></li>
</ol>
<p>MySQL’s <code>utf8</code> encoding is awkwardly named, as it’s different from proper UTF-8 encoding. It doesn’t offer full Unicode support, which can lead to data loss or security vulnerabilities.</p>
<h2 id="MySQL’s-utf8mb4"><a href="#MySQL’s-utf8mb4" class="headerlink" title="MySQL’s utf8mb4"></a>MySQL’s <code>utf8mb4</code></h2><p>Luckily, <a href="https://dev.mysql.com/doc/relnotes/mysql/5.5/en/news-5-5-3.html">MySQL 5.5.3 (released in early 2010)</a> introduced a new encoding called utf8mb4 which maps to proper UTF-8 and thus fully supports Unicode, including astral symbols.</p>
<h3 id="Switching-from-MySQL’s-utf8-to-utf8mb4"><a href="#Switching-from-MySQL’s-utf8-to-utf8mb4" class="headerlink" title="Switching from MySQL’s utf8 to utf8mb4"></a>Switching from MySQL’s <code>utf8</code> to <code>utf8mb4</code></h3><p><strong>Step 1: Create a backup</strong></p>
<p>Create a backup of all the databases on the server you want to upgrade. Safety first!</p>
<p><strong>Step 2: Upgrade the MySQL server</strong></p>
<p><a href="https://dev.mysql.com/downloads/mysql/">Upgrade the MySQL server to v5.5.3+</a>, or ask your server administrator to do it for you.</p>
<p><strong>Step 3: Modify databases, tables, and columns</strong></p>
<p>Change the character set and collation properties of the databases, tables, and columns to use <code>utf8mb4</code> instead of <code>utf8</code>.</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"># <span class="keyword">For</span> <span class="keyword">each</span> database:</span><br><span class="line"><span class="keyword">ALTER</span> DATABASE database_name <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="operator">=</span> utf8mb4 <span class="keyword">COLLATE</span> <span class="operator">=</span> utf8mb4_unicode_ci;</span><br><span class="line"># <span class="keyword">For</span> <span class="keyword">each</span> <span class="keyword">table</span>:</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">CONVERT</span> <span class="keyword">TO</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci;</span><br><span class="line"># <span class="keyword">For</span> <span class="keyword">each</span> <span class="keyword">column</span>:</span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name CHANGE column_name column_name <span class="type">VARCHAR</span>(<span class="number">191</span>) <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci;</span><br><span class="line"># (Don’t blindly <span class="keyword">copy</span><span class="operator">-</span>paste this<span class="operator">!</span> The exact statement depends <span class="keyword">on</span> the <span class="keyword">column</span> type, maximum length, <span class="keyword">and</span> other properties. The above line <span class="keyword">is</span> just an example <span class="keyword">for</span> a `<span class="type">VARCHAR</span>` column.)</span><br></pre></td></tr></table></figure>
<p>Since <code>utf8mb4</code> is fully backwards compatible with <code>utf8</code>, no mojibake or other forms of data loss should occur. (But you have a backup, right?)</p>
<p><strong>Step 4: Check the maximum length of columns and index keys</strong></p>
<p>This is probably the most tedious part of the whole upgrading process.</p>
<p>When converting from <code>utf8</code> to <code>utf8mb4</code>, the maximum length of a column or index key is unchanged in terms of bytes. Therefore, it is smaller in terms of characters, because the maximum length of a character is now four bytes instead of three.</p>
<p>For example, a <code>TINYTEXT</code> column can hold up to 255 bytes, which correlates to 85 three-byte or 63 four-byte characters. Let’s say you have a <code>TINYTEXT</code> column that uses <code>utf8</code> but must be able to contain more than 63 characters. Given this requirement, you can’t convert this column to <code>utf8mb4</code> unless you also change the data type to a longer type such as <code>TEXT</code> — because if you’d try to fill it with four-byte characters, you’d only be able to enter 63 characters, but not more.</p>
<p>The same goes for index keys. The InnoDB storage engine has a maximum index length of 767 bytes, so for <code>utf8</code> or <code>utf8mb4</code> columns, you can index a maximum of 255 or 191 characters, respectively. If you currently have <code>utf8</code> columns with indexes longer than 191 characters, you will need to index a smaller number of characters when using <code>utf8mb4</code>. (Because of this, I had to change some indexed VARCHAR(255) columns to VARCHAR(191).)</p>
<p><strong>Step 5: Modify connection, client, and server character sets</strong></p>
<p>In your application code, set the connection character set to utf8mb4. This can be done by simply replacing any variants of <code>SET NAMES utf8</code> with <code>SET NAMES utf8mb4</code>. If your old <code>SET NAMES</code> statement specified the collation, make sure to change that as well, e.g. <code>SET NAMES utf8 COLLATE utf8_unicode_ci</code> becomes <code>SET NAMES utf8mb4 COLLATE utf8mb4_unicode_ci</code>.</p>
<p>Make sure to set the client and server character set as well. I have the following in my MySQL configuration file (/etc/my.cnf):</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[client]</span></span><br><span class="line"><span class="attr">default-character-set</span> = utf8mb4</span><br><span class="line"></span><br><span class="line"><span class="section">[mysql]</span></span><br><span class="line"><span class="attr">default-character-set</span> = utf8mb4</span><br><span class="line"></span><br><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">character-set-client-handshake</span> = <span class="literal">FALSE</span></span><br><span class="line"><span class="attr">character-set-server</span> = utf8mb4</span><br><span class="line"><span class="attr">collation-server</span> = utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure>

<p>You can easily confirm these settings work correctly:</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">mysql&gt; SHOW VARIABLES WHERE Variable_name LIKE &#x27;character\_set\_%&#x27; OR Variable_name LIKE &#x27;collation%&#x27;;</span><br><span class="line">+--------------------------+--------------------+</span><br><span class="line">|<span class="string"> Variable_name            </span>|<span class="string"> Value              </span>|</span><br><span class="line">+--------------------------+--------------------+</span><br><span class="line">|<span class="string"> character_set_client     </span>|<span class="string"> utf8mb4            </span>|</span><br><span class="line">|<span class="string"> character_set_connection </span>|<span class="string"> utf8mb4            </span>|</span><br><span class="line">|<span class="string"> character_set_database   </span>|<span class="string"> utf8mb4            </span>|</span><br><span class="line">|<span class="string"> character_set_filesystem </span>|<span class="string"> binary             </span>|</span><br><span class="line">|<span class="string"> character_set_results    </span>|<span class="string"> utf8mb4            </span>|</span><br><span class="line">|<span class="string"> character_set_server     </span>|<span class="string"> utf8mb4            </span>|</span><br><span class="line">|<span class="string"> character_set_system     </span>|<span class="string"> utf8               </span>|</span><br><span class="line">|<span class="string"> collation_connection     </span>|<span class="string"> utf8mb4_unicode_ci </span>|</span><br><span class="line">|<span class="string"> collation_database       </span>|<span class="string"> utf8mb4_unicode_ci </span>|</span><br><span class="line">|<span class="string"> collation_server         </span>|<span class="string"> utf8mb4_unicode_ci </span>|</span><br><span class="line">+--------------------------+--------------------+</span><br><span class="line">10 rows in set (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>As you can see, all the relevant options are set to utf8mb4, except for <code>character_set_filesystem</code> which should be binary unless you’re on a file system that supports multi-byte UTF-8-encoded characters in file names, and <code>character_set_system</code> which is always utf8 and can’t be overridden.</p>
<p><strong>Step 6: Repair and optimize all tables</strong></p>
<p>You only need this when you meet some wired bugs. The details are in the reference: <a href="https://mathiasbynens.be/notes/mysql-utf8mb4">How to support full Unicode in MySQL databases</a></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Never use <code>utf8</code> in MySQL — always use <code>utf8mb4</code> instead. Updating your databases and code might take some time, but it’s definitely worth the effort. Why would you arbitrarily limit the set of symbols that can be used in your database? Why would you lose data every time a user enters an astral symbol as part of a comment or message or whatever it is you store in your database? There’s no reason not to strive for full Unicode support everywhere. Do the right thing, and use utf8mb4. 🍻</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-how-to-support-full-unicode-in-mysql.html" target="_blank">How to support full Unicode in MySQL databases</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-14-how-to-support-full-unicode-in-mysql.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>utf8mb4</tag>
        <tag>Emoji</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux常用命令</title>
    <url>/linux/2016-08-14-linux-commands.html</url>
    <content><![CDATA[<p><strong>注意：</strong>常用命令中，会有一些命令仅限于特定的操作系统使用，如Ubuntu或CentOS等特定的Linux发行版本。</p>
<h2 id="系统相关"><a href="#系统相关" class="headerlink" title="系统相关"></a>系统相关</h2><h3 id="显示当前内核版本"><a href="#显示当前内核版本" class="headerlink" title="显示当前内核版本"></a>显示当前内核版本</h3><p>命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">uname</span> -a</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">fify</span>@fify-PC:~$ uname -a</span><br><span class="line"><span class="attribute">Linux</span> fify-PC <span class="number">4</span>.<span class="number">4</span>.<span class="number">0</span>-<span class="number">31</span>-generic #<span class="number">50</span>-Ubuntu SMP Wed Jul <span class="number">13</span> <span class="number">00</span>:<span class="number">07</span>:<span class="number">12</span> UTC <span class="number">2016</span> x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure>

<h3 id="显示当前Ubuntu的系统版本"><a href="#显示当前Ubuntu的系统版本" class="headerlink" title="显示当前Ubuntu的系统版本"></a>显示当前Ubuntu的系统版本</h3><p>命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsb_release -a</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">fify</span>@fify-PC:~$ lsb_release -a</span><br><span class="line"><span class="attribute">No</span> LSB modules are available.</span><br><span class="line"><span class="attribute">Distributor</span> ID: Ubuntu</span><br><span class="line"><span class="attribute">Description</span>:    Ubuntu <span class="number">16</span>.<span class="number">04</span>.<span class="number">1</span> LTS</span><br><span class="line"><span class="attribute">Release</span>:        <span class="number">16</span>.<span class="number">04</span></span><br><span class="line"><span class="attribute">Codename</span>:       xenial</span><br></pre></td></tr></table></figure>

<h2 id="用户和组"><a href="#用户和组" class="headerlink" title="用户和组"></a>用户和组</h2><h3 id="显示当前登录的用户名"><a href="#显示当前登录的用户名" class="headerlink" title="显示当前登录的用户名"></a>显示当前登录的用户名</h3><p>命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">whoami</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">fify<span class="variable">@fify</span>-<span class="variable constant_">PC</span><span class="symbol">:~</span><span class="variable">$ </span>whoami</span><br><span class="line">fify</span><br></pre></td></tr></table></figure>
<p>这个命令在组合其他命令一起使用的时候会比较好用，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo usermod -aG docker $(<span class="built_in">whoami</span>)</span><br></pre></td></tr></table></figure>

<h3 id="查看用户所属的组"><a href="#查看用户所属的组" class="headerlink" title="查看用户所属的组"></a>查看用户所属的组</h3><p>可以查看当前用户的组或者指定用户所属的组。</p>
<h4 id="查看当前用户所属的组"><a href="#查看当前用户所属的组" class="headerlink" title="查看当前用户所属的组"></a>查看当前用户所属的组</h4><p>命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">groups</span></span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">fify<span class="variable">@fify</span>-<span class="variable constant_">PC</span><span class="symbol">:~</span><span class="variable">$ </span>groups</span><br><span class="line">fify adm cdrom sudo dip plugdev lpadmin sambashare</span><br></pre></td></tr></table></figure>

<h4 id="查看其他用户所属的组"><a href="#查看其他用户所属的组" class="headerlink" title="查看其他用户所属的组"></a>查看其他用户所属的组</h4><p>命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">groups</span> fify</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">fify<span class="variable">@fify</span>-<span class="variable constant_">PC</span><span class="symbol">:~</span><span class="variable">$ </span>groups fify</span><br><span class="line">fify : fify adm cdrom sudo dip plugdev lpadmin sambashare docker</span><br></pre></td></tr></table></figure>

<h4 id="以其他用户的身份执行命令"><a href="#以其他用户的身份执行命令" class="headerlink" title="以其他用户的身份执行命令"></a>以其他用户的身份执行命令</h4><p>以下命令以jenkins用户的身份执行<code>jstack 36730</code>命令。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo -u jenkins -H jstack 36730</span><br></pre></td></tr></table></figure>

<h2 id="实用工具"><a href="#实用工具" class="headerlink" title="实用工具"></a>实用工具</h2><h3 id="文字处理"><a href="#文字处理" class="headerlink" title="文字处理"></a>文字处理</h3><h4 id="替换某行中间的文字"><a href="#替换某行中间的文字" class="headerlink" title="替换某行中间的文字"></a>替换某行中间的文字</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">&#x27;s/\(.*\)wrapper.daemonize=FALSE\(.*\)/\1wrapper.daemonize=TRUE\2/g&#x27;</span> -i mycat</span><br></pre></td></tr></table></figure>
<p>替换mycat文件中包含<code>wrapper.daemonize=FALSE</code>的行，并把<code>wrapper.daemonize=FALSE</code>替换为<code>wrapper.daemonize=TRUE</code>。</p>
<h4 id="查看文件的第m-n行"><a href="#查看文件的第m-n行" class="headerlink" title="查看文件的第m-n行"></a>查看文件的第m-n行</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -n <span class="string">&#x27;5,10p&#x27;</span> filename</span><br></pre></td></tr></table></figure>
<p>这样你就可以只查看文件的第5行到第10行。</p>
<h4 id="删除文件的某一行"><a href="#删除文件的某一行" class="headerlink" title="删除文件的某一行"></a>删除文件的某一行</h4><p>删除文件的第三行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;3d&#x27;</span> 1.txt</span><br></pre></td></tr></table></figure>
<p>删除文件的第三至第五行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;3,5d&#x27;</span> 1.txt</span><br></pre></td></tr></table></figure>
<p>删除符合特定正则表达式的行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;/^Love/d&#x27;</span> 1.txt</span><br></pre></td></tr></table></figure>
<h4 id="在sed正则表达式匹配中使用Lazy策略："><a href="#在sed正则表达式匹配中使用Lazy策略：" class="headerlink" title="在sed正则表达式匹配中使用Lazy策略："></a>在<code>sed</code>正则表达式匹配中使用Lazy策略：</h4><p><code>sed</code>命令的正则表达式并不支持懒匹配，但是我们可以通过绕过的方法来做。比如我要查找以下内容中”和”之间的单词：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">&quot;departmentId&quot; <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">&quot;departmentName&quot; <span class="type">varchar</span>(<span class="number">128</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">&quot;monthly&quot; <span class="type">varchar</span>(<span class="number">10</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">&quot;positionName&quot; <span class="type">varchar</span>(<span class="number">100</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">DEFAULT</span> <span class="keyword">NULL</span>,</span><br><span class="line">&quot;staffId&quot; <span class="type">varchar</span>(<span class="number">40</span>) <span class="keyword">COLLATE</span> utf8mb4_unicode_ci <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br></pre></td></tr></table></figure>
<p>那么我们可以通过`”[^&quot;]*”查找””之间的内容。如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">&#x27;s/&quot;\([^&quot;]*\)&quot;[^,]*,/\1,/g&#x27;</span></span><br></pre></td></tr></table></figure>
<p>可以获取到：</p>
<figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;departmentId&quot;</span>,</span><br><span class="line"><span class="string">&quot;departmentName&quot;</span>,</span><br><span class="line"><span class="string">&quot;monthly&quot;</span>,</span><br><span class="line"><span class="string">&quot;positionName&quot;</span>,</span><br><span class="line"><span class="string">&quot;staffId&quot;</span>,</span><br></pre></td></tr></table></figure>
<p>将文字分隔显示：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep abc.pl * | awk -F <span class="string">&#x27;abc.pl&#x27;</span> <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="文件工具"><a href="#文件工具" class="headerlink" title="文件工具"></a>文件工具</h3><h4 id="获取目录中最新的文件"><a href="#获取目录中最新的文件" class="headerlink" title="获取目录中最新的文件"></a>获取目录中最新的文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> *.war -Art | <span class="built_in">tail</span> -n 1</span><br></pre></td></tr></table></figure>

<h4 id="查看文件类型"><a href="#查看文件类型" class="headerlink" title="查看文件类型"></a>查看文件类型</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">file xxxx.jpg</span><br></pre></td></tr></table></figure>

<p><code>file</code>命令不跟据文件后缀名判断文件类型，而是根据文件最头部的几位Magic Number进行判断。对于乱改文件后缀的情况非常适合。</p>
<p>如：</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">fify<span class="variable">@fify</span>-<span class="title class_">Vostro</span><span class="number">-3902</span><span class="symbol">:~/Desktop</span><span class="variable">$ </span>file <span class="number">1945300044</span>.png</span><br><span class="line"><span class="number">1945300044</span>.<span class="symbol">png:</span> <span class="title class_">JPEG</span> image data</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-08-14-linux-commands.html" target="_blank">Linux常用命令</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-08-14-linux-commands.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>Script</tag>
      </tags>
  </entry>
  <entry>
    <title>开始使用MyCAT</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-17-mycat-startup.html</url>
    <content><![CDATA[<p>MyCAT是基于阿里巴巴开源数据库中间件Cobar开发并维护的数据库中间件，弥补了Cobar无人维护的尴尬境地。详细介绍可以参考官网：<a href="http://mycat.io/">http://mycat.io/</a></p>
<p>相比Cobar来说，MyCAT的坑算是少很多了，下面是开始使用MyCAT的一些步骤。</p>
<h2 id="准备数据库"><a href="#准备数据库" class="headerlink" title="准备数据库"></a>准备数据库</h2><h3 id="创建MySQL数据库实例"><a href="#创建MySQL数据库实例" class="headerlink" title="创建MySQL数据库实例"></a>创建MySQL数据库实例</h3><p>用Docker启动，其他安装方式不再介绍。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name mysql-001 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:5.6 --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci</span><br></pre></td></tr></table></figure>

<h3 id="修改MySQL服务器配置"><a href="#修改MySQL服务器配置" class="headerlink" title="修改MySQL服务器配置"></a>修改MySQL服务器配置</h3><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line">skip-host-cache</span><br><span class="line">skip-name-resolve</span><br><span class="line"><span class="attr">user</span>            = mysql</span><br><span class="line"><span class="attr">pid-file</span>        = /var/run/mysqld/mysqld.pid</span><br><span class="line"><span class="attr">socket</span>          = /var/run/mysqld/mysqld.sock</span><br><span class="line"><span class="attr">port</span>            = <span class="number">3306</span></span><br><span class="line"><span class="attr">basedir</span>         = /usr</span><br><span class="line"><span class="attr">datadir</span>         = /var/lib/mysql</span><br><span class="line"><span class="attr">tmpdir</span>          = /tmp</span><br><span class="line"><span class="attr">lc-messages-dir</span> = /usr/share/mysql</span><br><span class="line">explicit_defaults_for_timestamp</span><br><span class="line"><span class="attr">lower-case-table-names</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">max_allowed_packet</span>=<span class="number">32</span>M</span><br></pre></td></tr></table></figure>
<p>其中<code>lower-case-table-names=1</code>和<code>max_allowed_packet=32M</code>为非默认参数：</p>
<ul>
<li><code>lower-case-table-names=1</code>忽略表格名字大小写，否则MyCAT会无法找到表格</li>
<li><code>max_allowed_packet=32M</code>该参数需要配合mysqldump，参考<a href="#%E4%BD%BF%E7%94%A8mysqldump%E5%AF%BC%E5%87%BA">使用<code>mysqldump</code>导出</a>。</li>
</ul>
<h2 id="准备MyCAT"><a href="#准备MyCAT" class="headerlink" title="准备MyCAT"></a>准备MyCAT</h2><h3 id="设置MyCAT虚拟schema"><a href="#设置MyCAT虚拟schema" class="headerlink" title="设置MyCAT虚拟schema"></a>设置MyCAT虚拟schema</h3><h4 id="定义虚拟schema：schema-xml"><a href="#定义虚拟schema：schema-xml" class="headerlink" title="定义虚拟schema：schema.xml"></a>定义虚拟schema：schema.xml</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">mycat</span>:schema <span class="keyword">SYSTEM</span> <span class="string">&quot;schema.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mycat:schema</span> <span class="attr">xmlns:mycat</span>=<span class="string">&quot;http://org.opencloudb/&quot;</span> &gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">schema</span> <span class="attr">name</span>=<span class="string">&quot;irenshi&quot;</span> <span class="attr">checkSQLschema</span>=<span class="string">&quot;false&quot;</span> <span class="attr">sqlMaxLimit</span>=<span class="string">&quot;10000&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn001&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">&quot;tab_sign_record_info&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;id&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn001,dn002,dn003&quot;</span> <span class="attr">rule</span>=<span class="string">&quot;sharding-by-company-id&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">schema</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">schema</span> <span class="attr">name</span>=<span class="string">&quot;linahr&quot;</span> <span class="attr">checkSQLschema</span>=<span class="string">&quot;false&quot;</span> <span class="attr">sqlMaxLimit</span>=<span class="string">&quot;10000&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn004&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">&quot;tab_web_user&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;id&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn004,dn005&quot;</span> <span class="attr">rule</span>=<span class="string">&quot;sharding-by-company-id-murmur&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">schema</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">&quot;dn001&quot;</span> <span class="attr">dataHost</span>=<span class="string">&quot;mysql-001&quot;</span> <span class="attr">database</span>=<span class="string">&quot;irenshi001&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">&quot;dn002&quot;</span> <span class="attr">dataHost</span>=<span class="string">&quot;mysql-001&quot;</span> <span class="attr">database</span>=<span class="string">&quot;irenshi002&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">&quot;dn003&quot;</span> <span class="attr">dataHost</span>=<span class="string">&quot;mysql-001&quot;</span> <span class="attr">database</span>=<span class="string">&quot;irenshi003&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dataHost</span> <span class="attr">name</span>=<span class="string">&quot;mysql-001&quot;</span> <span class="attr">maxCon</span>=<span class="string">&quot;1000&quot;</span> <span class="attr">minCon</span>=<span class="string">&quot;10&quot;</span> <span class="attr">balance</span>=<span class="string">&quot;0&quot;</span> <span class="attr">writeType</span>=<span class="string">&quot;0&quot;</span> <span class="attr">dbType</span>=<span class="string">&quot;mysql&quot;</span> <span class="attr">dbDriver</span>=<span class="string">&quot;native&quot;</span> <span class="attr">switchType</span>=<span class="string">&quot;1&quot;</span>  <span class="attr">slaveThreshold</span>=<span class="string">&quot;100&quot;</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">heartbeat</span>&gt;</span>select user();<span class="tag">&lt;/<span class="name">heartbeat</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">writeHost</span> <span class="attr">host</span>=<span class="string">&quot;m001&quot;</span> <span class="attr">url</span>=<span class="string">&quot;192.168.1.4:3306&quot;</span> <span class="attr">user</span>=<span class="string">&quot;root&quot;</span> <span class="attr">password</span>=<span class="string">&quot;root&quot;</span>&gt;</span></span><br><span class="line">                        <span class="comment">&lt;!--&lt;readHost host=&quot;s001&quot; url=&quot;192.168.1.4:3306&quot; user=&quot;root&quot; password=&quot;root&quot; /&gt;--&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">writeHost</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dataHost</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mycat:schema</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p><strong><code>&lt;schema&gt;</code>标签：</strong></p>
<ul>
<li><code>name=&quot;irenshi&quot;</code>定义的数据库名称为<code>irenshi</code></li>
<li><code>checkSQLschema=&quot;false&quot;</code>不对select语句中的schema名称做处理。该值置为<code>true</code>时，如果我们执行询句<code>select * from TESTDB.travelrecord;</code>则MyCat会把询句修改为<code>select * from travelrecord;</code>。即把表示schema字符去捧，避免发送到后端数据库执行时报：<em>（ERROR1146 (42S02): Table ‘testdb.travelrecord’ doesn’t exist）</em>。</li>
<li><code>sqlMaxLimit=&quot;10000&quot;</code>在selecct语句不指定<code>limit</code>的时候，最多返回10000条数据</li>
<li><code>dataNode=&quot;dn001&quot;</code>在不使用<code>&lt;table&gt;</code>指明的情况下，数据库表存放到<code>dn001</code>节点</li>
</ul>
<p><strong><code>&lt;table&gt;</code>标签：</strong><br><code>&lt;table&gt;</code>标签不指定的数据库表均以<code>&lt;schema&gt;</code>的设置为准，指定的话以指定的为准。</p>
<ul>
<li><code>name=&quot;tab_sign_record_info&quot;</code>指定要设置的数据库表</li>
<li><code>primaryKey=&quot;id&quot;</code>指定数据库表的主键。设置该值之后，如果MyCAT第一次执行主键查询时，会把请求发送到所有后端服务器，并且将主键所对应的数据库位置缓存，下次查询的时候直接根据该缓存向对应的数据库发送请求</li>
<li><code>dataNode=&quot;dn001,dn002,dn003&quot;</code>表明该表将被存放到<code>dn001,dn002,dn003</code>三个MySQL中</li>
<li><code>rule=&quot;sharding-by-company-id&quot;</code>给出表中的数据如何分布到上边给定的三个MySQL中</li>
</ul>
<p><strong><code>&lt;dataNode&gt;</code>标签：</strong><br><code>&lt;dataNode</code>标签定义MyCAT的数据节点。每个数据节点定位到某个MySQL主机的某个数据库schema上。</p>
<p><strong><code>&lt;dataHost&gt;</code>标签：</strong><br><code>&lt;dataHost&gt;</code>定义MySQL物理节点以及其连接方式。具体可以参考<a href="http://mycat.io/document/Mycat_V1.6.0.pdf">《MyCAT权威指南》</a>。</p>
<h3 id="设置MyCAT读写分离"><a href="#设置MyCAT读写分离" class="headerlink" title="设置MyCAT读写分离"></a>设置MyCAT读写分离</h3><p>MyCAT的读写分离通过<code>schema.xml</code>中的<code>&lt;dataNode&gt;</code>标签来定义。其中一个<code>&lt;dataNode&gt;</code>可以对应一个或者多个<code>&lt;writeHost&gt;</code>，而一个<code>&lt;writeHost&gt;</code>又可以有零个或者多个<code>&lt;readHost&gt;</code>。<br>其中<code>&lt;writeHost&gt;</code>之间可以互为备份，取决于<code>balance=&quot;0&quot;</code>的设置；当一个<code>&lt;writeNode&gt;</code>挂掉的时候，它下边的所有<code>&lt;readHost&gt;</code>也不可访问。</p>
<p><strong><code>balance</code>参数可取的值：</strong></p>
<ul>
<li><code>balance=&quot;0&quot;</code>, 不开启读写分离机制，所有读操作都都发送到当前可用的<code>writeHost</code>上</li>
<li><code>balance=&quot;1&quot;</code>，全部<code>readHost</code>与<code>stand by writeHost</code>参与<code>select</code>语句的负载均衡，简单的说，当双主双从模式(M1-&gt;S1，M2-&gt;S2，并且 M1 与 M2 互为主备)，正常情冴下，M2,S1,S2 都参与<code>select</code>语句的负载均衡</li>
<li><code>balance=&quot;2&quot;</code>，所有读操作都随机在<code>writeHost</code>、<code>readhost</code>上分发</li>
<li><code>balance=&quot;3&quot;</code>，所有读请求随机分发到<code>wiriterHost</code>对应的<code>readhost</code>执行，<code>writerHost</code>不负担读压力，注意<code>balance=3</code>只在1.4 及其以后版本有，1.3没有</li>
</ul>
<h3 id="设置MyCAT水平切分"><a href="#设置MyCAT水平切分" class="headerlink" title="设置MyCAT水平切分"></a>设置MyCAT水平切分</h3><h4 id="使用字符串前缀切分"><a href="#使用字符串前缀切分" class="headerlink" title="使用字符串前缀切分"></a>使用字符串前缀切分</h4><p><code>&lt;table&gt;</code>指定了数据库表<code>tab_sign_record_info</code>的水平切分方式：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">schema</span> <span class="attr">name</span>=<span class="string">&quot;irenshi&quot;</span> <span class="attr">checkSQLschema</span>=<span class="string">&quot;false&quot;</span> <span class="attr">sqlMaxLimit</span>=<span class="string">&quot;10000&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn001&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">&quot;tab_sign_record_info&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;id&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn001,dn002,dn003&quot;</span> <span class="attr">rule</span>=<span class="string">&quot;sharding-by-company-id&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其中的数据由<code>rule=&quot;sharding-by-company-id&quot;</code>指定的算法切分。</p>
<p>在<code>rule.xml</code>中我们可以看到<code>sharding-by-company-id</code>的定义：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tableRule</span> <span class="attr">name</span>=<span class="string">&quot;sharding-by-company-id&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">columns</span>&gt;</span>companyId<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>sharding-by-pattern<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">function</span> <span class="attr">name</span>=<span class="string">&quot;sharding-by-pattern&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.opencloudb.route.function.PartitionByPrefixPattern&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;patternValue&quot;</span>&gt;</span>64<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;prefixLength&quot;</span>&gt;</span>5<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;mapFile&quot;</span>&gt;</span>partition-pattern.txt<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">function</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>由于CompanyID使用了UUID，为字符串类型。所以使用<code>PartitionByPrefixPattern</code>来进行计算：</p>
<ul>
<li><code>prefixLength</code> 将CompanyId中的前5个字母以ASCII的方式求和</li>
<li><code>patternValue</code> 将求和之后数值MOD 64得出最终结果</li>
<li><code>mapFile</code> 将计算的最终结果按照<code>partition-pattern.txt</code>文件给定的分片规则进行分片</li>
</ul>
<p>其中partition-pattern.txt内容如下：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="comment"># range start-end ,data node index</span></span><br><span class="line"><span class="comment"># ASCII</span></span><br><span class="line"><span class="comment"># 8-57=0-9 阿拉伯数字</span></span><br><span class="line"><span class="comment"># 64、65-90=@、A-Z</span></span><br><span class="line"><span class="comment"># 97-122=a-z</span></span><br><span class="line"><span class="comment">###### first host configuration</span></span><br><span class="line"><span class="attribute">0</span>-<span class="number">20</span>=<span class="number">0</span></span><br><span class="line"><span class="attribute">21</span>-<span class="number">40</span>=<span class="number">1</span></span><br><span class="line"><span class="attribute">41</span>-<span class="number">63</span>=<span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>结合<code>dataNode=&quot;dn001,dn002,dn003&quot;</code>设置，结果为0-20的数据将分布在dn001中，21-40的数据将分布到dn002中，41-63的数据将分布到dn003中。</p>
<h4 id="使用一致性哈希切分"><a href="#使用一致性哈希切分" class="headerlink" title="使用一致性哈希切分"></a>使用一致性哈希切分</h4><p><code>&lt;table&gt;</code>标签的配置如下：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">schema</span> <span class="attr">name</span>=<span class="string">&quot;linahr&quot;</span> <span class="attr">checkSQLschema</span>=<span class="string">&quot;false&quot;</span> <span class="attr">sqlMaxLimit</span>=<span class="string">&quot;10000&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn004&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">&quot;tab_web_user&quot;</span> <span class="attr">primaryKey</span>=<span class="string">&quot;id&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn004,dn005&quot;</span> <span class="attr">rule</span>=<span class="string">&quot;sharding-by-company-id-murmur&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>同样查看rule.xml中<code>sharding-by-company-id-murmur</code>的定义：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tableRule</span> <span class="attr">name</span>=<span class="string">&quot;sharding-by-company-id-murmur&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">columns</span>&gt;</span>companyId<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>murmur<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">function</span> <span class="attr">name</span>=<span class="string">&quot;murmur&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.opencloudb.route.function.PartitionByMurmurHash&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;seed&quot;</span>&gt;</span>0<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;count&quot;</span>&gt;</span>2<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;virtualBucketTimes&quot;</span>&gt;</span>160<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">function</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>&lt;property name=&quot;seed&quot;&gt;0&lt;/property&gt;</code>指定了murmur算法的种子。一般不需要改，使用默认的0即可</li>
<li><code>&lt;property name=&quot;count&quot;&gt;2&lt;/property&gt;</code>表示物理节点的个数，对应实际dataNode的数量。如上配置中，dataNode为<code>dn004,dn005</code>，则此处值为2</li>
<li><code>&lt;property name=&quot;virtualBucketTimes&quot;&gt;160&lt;/property&gt;</code>指定一致性哈希中虚拟bucket的数量。默认为160，在这里节点数为2，那么虚拟bucket的数量为320个（假设下边介绍的weight值为默认值1）。若扩容把count的数量改为3，则虚拟bucket的数量变为480。</li>
<li><code>&lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt;</code>默认值为1。每个节点对应一个weight值，假设第i个节点的weight值为<code>weight[i]</code>，则第i个节点对应的虚拟bucket数量为<code>weight[i]*virtualBucketTimes</code>。所有虚拟节点的总数为<code>sum(weight[i]*virtualBucketTimes)</code>。</li>
</ul>
<p>当在机器中增加节点时，即增大count值时，对于每一条数据，则要么落到原有节点中、要么落到新节点中。<strong>但是如果增大<code>virtualBucketTimes</code>或者<code>weight</code>的值，则一致性哈希的这个性质不能被保证。</strong>所以对<code>virtualBucketTimes</code>和<code>weight</code>的修改一定要谨慎！</p>
<p>之前<code>murmur</code>的配置中还包含<code>bucketMapPath</code>参数，但在1.5的代码中该参数相关的代码已经被注释掉，不能使用了：<a href="https://github.com/MyCATApache/Mycat-Server/commit/c9cb201992564c315436792572e96c3beaed3b37">https://github.com/MyCATApache/Mycat-Server/commit/c9cb201992564c315436792572e96c3beaed3b37</a></p>
<h2 id="导入数据I：使用mysqldump-source命令"><a href="#导入数据I：使用mysqldump-source命令" class="headerlink" title="导入数据I：使用mysqldump+source命令"></a>导入数据I：使用<code>mysqldump</code>+<code>source</code>命令</h2><h3 id="使用mysqldump导出"><a href="#使用mysqldump导出" class="headerlink" title="使用mysqldump导出"></a>使用<code>mysqldump</code>导出</h3><p>设置<code>mysqldump</code>的一些参数</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqldump]</span></span><br><span class="line">quick</span><br><span class="line">quote-names</span><br><span class="line"><span class="attr">max_allowed_packet</span>      = <span class="number">16</span>M</span><br><span class="line"><span class="attr">default-character-set</span>   = utf8mb4</span><br></pre></td></tr></table></figure>
<p>当然这些也可以在执行<code>mysqldump</code>命令的时候指定。</p>
<ul>
<li><code>max_allowed_packet</code>指定了最大允许的包大小。如果不指定则默认为24MB，导入的时候可能会报<code>ERROR 1153 (08S01) at line 1133809: Got a packet bigger than &#39;max_allowed_packet&#39; bytes</code>错误，因为MySQL允许的默认大小为1MB。</li>
<li><code>default-character-set</code>保证在导出数据库的时候使用<code>utf8mb4</code>编码。关于<code>utf8mb4</code>可以参考：<a href="http://www.xiaotanzhu.com/2016/08/14/create-mysql-database-with-utf8mb4.html">创建支持emoji表情的MySQL数据库（utf8mb4）</a>。</li>
</ul>
<p>导出命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqldump -h192.168.1.3 -ulinahr -plinahr -c --skip-add-locks --skip-extended-insert --no-autocommit linahr &gt; irenshi-data.sql</span><br></pre></td></tr></table></figure>
<p>其中每个参数都几乎是必选项，<code>-h</code>, <code>-u</code>, <code>-p</code>三个参数不多说，下面介绍其他参数：</p>
<ul>
<li><code>-c</code>，全称为<code>--complete-insert</code>，告诉mysqldump导出的时候把列名一起导出。这在MyCAT中要求是必选的，因为MyCAT在执行插入的时候只能执行带列名的插入语句</li>
<li><code>--skip-add-locks</code> 默认情况下，mysqldump会在每个表前后分别增加<code>LOCK TABLES</code>和<code>UNLOCK TABLES</code>语句，但在MyCAT中使用<code>LOCK TABLES </code>和<code>UNLOCK TABLES</code>会造成潜在的死锁风险，所以尽量避免使用</li>
<li><code>--skip-extended-insert</code>默认情况下，mysqldump会把每个表格的所有数据写到同一个SQL中。但在分库分表情况下执行导入的时候，对于Boolean类型的数据并且值为<code>True</code>的数据，会报<a href="https://github.com/MyCATApache/Mycat-Server/issues/1054">Data too long</a>错误。目前还不能确认是否是MyCAT的Bug。增加该参数，将每行数据输出为一个单独的insert语句，就不会出现类似错误了。</li>
<li><code>--no-autocommit</code>参数在每个表格所有的插入语句的前后分别增加<code>SET autocommit = 0</code>和<code>COMMIT</code>语句。相比没有这个参数，插入速度能差出至少200倍，分别是10000QPS和50QPS。</li>
</ul>
<p><strong>如果需要在mysqldump的时候忽略一些表格</strong>，可以使用<code>--ignore-table</code>参数。如果需要一次性忽略一批表格，可以使用这个脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">PASSWORD=linahr</span><br><span class="line">HOST=192.168.1.3</span><br><span class="line">USER=linahr</span><br><span class="line">DATABASE=linahr</span><br><span class="line">DB_FILE=linahr.sql</span><br><span class="line">EXCLUDED_TABLES=(</span><br><span class="line">                qrtz_blob_triggers</span><br><span class="line">                qrtz_calendars</span><br><span class="line">                qrtz_cron_triggers</span><br><span class="line">                qrtz_fired_triggers</span><br><span class="line">                qrtz_job_details</span><br><span class="line">                qrtz_locks</span><br><span class="line">                qrtz_paused_trigger_grps</span><br><span class="line">                qrtz_scheduler_state</span><br><span class="line">                qrtz_simple_triggers</span><br><span class="line">                qrtz_simprop_triggers</span><br><span class="line">                qrtz_triggers</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">IGNORED_TABLES_STRING=<span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> TABLE <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;EXCLUDED_TABLES@]&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">do</span> :</span><br><span class="line">	IGNORED_TABLES_STRING+=<span class="string">&quot; --ignore-table=<span class="variable">$&#123;DATABASE&#125;</span>.<span class="variable">$&#123;TABLE&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#echo &quot;Dump structure&quot;</span></span><br><span class="line"><span class="comment">#mysqldump --host=$&#123;HOST&#125; --user=$&#123;USER&#125; --password=$&#123;PASSWORD&#125; --single-transaction --no-data $&#123;IGNORED_TABLES_STRING&#125; $&#123;DATABASE&#125; &gt; irenshi-tables.sql</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Dump content&quot;</span></span><br><span class="line">mysqldump --host=<span class="variable">$&#123;HOST&#125;</span> --user=<span class="variable">$&#123;USER&#125;</span> --password=<span class="variable">$&#123;PASSWORD&#125;</span> --opt -c --skip-add-locks --no-autocommit --skip-extended-insert <span class="variable">$&#123;DATABASE&#125;</span> <span class="variable">$&#123;IGNORED_TABLES_STRING&#125;</span> &gt; irenshi-data.sql</span><br></pre></td></tr></table></figure>

<h3 id="使用mysql命令导入"><a href="#使用mysql命令导入" class="headerlink" title="使用mysql命令导入"></a>使用<code>mysql</code>命令导入</h3><p>首先需要修改<code>[mysqld]</code>的<code>max_allowed_packet</code>参数。这个参数默认为1MB，但mysqldump导出的最大允许为16MB，会造成错误，见<a href="#%E4%BD%BF%E7%94%A8mysqldump%E5%AF%BC%E5%87%BA">使用<code>mysqldump</code>导出</a>章节</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">max_allowed_packet</span>=<span class="number">32</span>M</span><br></pre></td></tr></table></figure>

<p>开始导入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -ulinahr -plinahr -h192.168.1.4 -P8066 irenshi &lt; irenshi-data.sql</span><br></pre></td></tr></table></figure>
<p>或者也可以执行SQL命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">source irenshi<span class="operator">-</span>data.sql</span><br></pre></td></tr></table></figure>

<h2 id="导入数据II：使用mysqldump-LOAD-DATA-INFILE命令"><a href="#导入数据II：使用mysqldump-LOAD-DATA-INFILE命令" class="headerlink" title="导入数据II：使用mysqldump+LOAD DATA INFILE命令"></a>导入数据II：使用<code>mysqldump</code>+<code>LOAD DATA INFILE</code>命令</h2><blockquote>
<p><strong>注意：</strong>以下内容适合导入单个表，如果需要批量导入大量表，可以参考：<a href="http://www.xiaotanzhu.com/2016/08/24/import-data-into-mycat.html">http://www.xiaotanzhu.com/2016/08/24/import-data-into-mycat.html</a></p>
</blockquote>
<p>在某些数据库表比较大的情况下，使用以上方法导入的速度就比较难以接受了。MyCAT1.4以后还提供了类似MySQL的<code>LOAD DATA INFILE</code>命令，供导入大批量数据使用。据说这种方式比<code>insert</code>语句要快20倍。</p>
<h3 id="同样使用mysqldump导出"><a href="#同样使用mysqldump导出" class="headerlink" title="同样使用mysqldump导出"></a>同样使用<code>mysqldump</code>导出</h3><p>对于小表，使用上面的导入方式还是比较方便的。我们只针对大表使用<code>LOAD DATA INFILE</code>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqldump -h192.168.1.3 -uroot -proot --fields-optionally-enclosed-by=<span class="string">&#x27;&quot;&#x27;</span> --fields-terminated-by=<span class="string">&#x27;,&#x27;</span> --tab /tmp/irenshi/ --lines-terminated-by=<span class="string">&#x27;\n&#x27;</span> linahr tab_sign_record_info</span><br></pre></td></tr></table></figure>
<p>这个命令会将<code>irenshi</code>库中的<code>tab_sign_record_info</code>以文件形式导入到<code>/tmp/irenshi/</code>目录下。对于每一个导出的数据库表，将生成两个文件：tab_sign_record_info.sql和tab_sign_record_info.txt，其中tab_sign_record_info.sql存放了数据库表DDL，tab_sign_record_info.txt存放数据库表中的数据。</p>
<p><code>--fields-optionally-enclosed-by=&#39;&quot;&#39;</code>，<code>--fields-terminated-by=&#39;,&#39;</code>和<code>--lines-terminated-by=&#39;\n&#39;</code>分别指定了数据库文件的格式。这几个命令应和<code>LOAD DATA INFILE</code>给定的参数一致。</p>
<p><strong>执行此命令需要注意几点：</strong></p>
<ol>
<li><code>mysqldump</code>必须在MySQL服务器同一台主机上执行</li>
<li>必须拥有写文件权限</li>
<li>MySQL服务器必须对给定的目录<code>/tmp/irenshi/</code>有写权限</li>
</ol>
<h3 id="使用LOAD-DATA-INFILE导入数据"><a href="#使用LOAD-DATA-INFILE导入数据" class="headerlink" title="使用LOAD DATA INFILE导入数据"></a>使用<code>LOAD DATA INFILE</code>导入数据</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">LOAD DATA <span class="keyword">local</span> INFILE <span class="string">&#x27;/tmp/irenshi/tab_sign_record_info.txt&#x27;</span></span><br><span class="line">IGNORE <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tab_sign_record_info <span class="type">CHARACTER</span> <span class="keyword">SET</span> <span class="string">&#x27;utf8mb4&#x27;</span> FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;,&#x27;</span> OPTIONALLY ENCLOSED <span class="keyword">BY</span> <span class="string">&#x27;&quot;&#x27;</span> LINES TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\n&#x27;</span> (column1, column2, column3, ...)</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>local</code>表示从执行该命令的机器上获取文件。如果没有该参数，则从MySQL服务器上获取文件</li>
<li><code>IGNORE</code>指定了在服务器上如果已经存在了相同数据则忽略该行。还可以为<code>REPLACE</code>，表示替换已经存在的数据</li>
<li><code>CHARACTER SET &#39;utf8mb4&#39;</code>指定数据库表的编码集。这里需要和数据的编码保持一致，否则可能会出现乱码甚至执行失败</li>
<li><code>FIELDS TERMINATED BY &#39;,&#39; OPTIONALLY ENCLOSED BY &#39;&quot;&#39; LINES TERMINATED BY &#39;\n&#39;</code>和<code>mysqldump</code>中的参数对应</li>
<li><code>(column1, column2, column3, ...)</code>给定数据库的列。在MyCAT中必须要给定所有列，并且列的顺序要和建表时的顺序一致</li>
</ul>
<p><strong>使用<code>local</code>文件加载数据时，需指定<code>local-infile = 1</code>参数</strong>。如果不指定可能会报以下错误：<br>在MySQL上报以下错误：</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ERROR </span>1148 (42000): The used command is not allowed with this MySQL version</span><br></pre></td></tr></table></figure>
<p>而在MyCAT上则会报：</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ERROR </span>2027 (HY000): Malformed packet</span><br></pre></td></tr></table></figure>
<p>这个错误着实让人莫名其妙。</p>
<p><strong>使用该参数的方法有三种：</strong></p>
<ul>
<li><p>直接在<code>mysql</code>命令中指定：</p>
<blockquote>
<p>mysql -h192.168.1.4 -ulinahr –local-infile=1 -plinahr -P 8066 irenshi</p>
</blockquote>
</li>
<li><p>在mysql客户端的配置文件中设置：</p>
<blockquote>
<p>[client]<br>local-infile = 1</p>
</blockquote>
</li>
<li><p>在mysql连接之后的session中执行SQL命令:</p>
<blockquote>
<p>SET local_infile=1;</p>
</blockquote>
</li>
</ul>
<h2 id="数据库扩容"><a href="#数据库扩容" class="headerlink" title="数据库扩容"></a>数据库扩容</h2><p><em>&lt;等用到的时候我再写吧&gt;</em></p>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>MyCAT官方提供了MyCAT-Eye作为监控软件。如图所示：<br><img src="/upload/images/11.png"></p>
<p>启动MyCAT-Eye需要指定ZooKeeper的服务路径，修改<code>$MYCAT_WEB_DIR/mycat-web/WEB-INF/classes/mycat.properties</code>：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="deletion">- zookeeper=localhost:2181</span></span><br><span class="line"><span class="addition">+ zookeeper=192.168.1.2:2181</span></span><br></pre></td></tr></table></figure>

<p>然后进入MyCAT-Eye所在目录，执行<code>./start.sh</code>即可启动MyCAT-Eye。MyCAT-Eye默认服务路径为：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">http:<span class="regexp">//</span>localhost:<span class="number">8082</span><span class="regexp">/mycat/</span></span><br></pre></td></tr></table></figure>
<p>进入后可以对MyCAT和MySQL等进行配置。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-17-mycat-startup.html" target="_blank">开始使用MyCAT</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-17-mycat-startup.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MyCAT</tag>
        <tag>Cobar</tag>
        <tag>分库分表</tag>
        <tag>读写分离</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Moint监控Docker中运行的Web服务器</title>
    <url>/%E8%BF%90%E7%BB%B4/2016-08-19-monitor-tomcat-in-docker.html</url>
    <content><![CDATA[<p>Monit是一个Linux系统中常用的监控软件，可以监控CPU、内存、文件系统、TCP端口、UDP端口、HTTP等基本上所有的资源。可以参考其官方网站：<a href="https://mmonit.com/monit/%E3%80%82">https://mmonit.com/monit/。</a></p>
<p>本次要对Docker（Docker中运行了一个Web服务器）进行监控，需要满足以下几个需求：</p>
<ol>
<li>当Docker挂掉的时候自动启动；</li>
<li>当Docker中的Web服务器300秒内无响应的时候重启Docker；</li>
<li>当Docker发生异常或者重启时，发送邮件警告通知。</li>
</ol>
<h2 id="安装Moint软件"><a href="#安装Moint软件" class="headerlink" title="安装Moint软件"></a>安装Moint软件</h2><p>Moint的安装比较容易，如果使用Ubuntu/Debian，则可以直接执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get install monit</span><br></pre></td></tr></table></figure>
<p>如果使用源代码编译安装，则是经典三部曲：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>

<h2 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h2><p>这里只提及几个比较重要的设置，其他设置可以参考Linux手册。</p>
<h3 id="监控进程检查周期"><a href="#监控进程检查周期" class="headerlink" title="监控进程检查周期"></a>监控进程检查周期</h3><p>默认为120秒检查一次</p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">###############################################################################</span><br><span class="line">## Global section</span><br><span class="line">###############################################################################</span><br><span class="line">##</span><br><span class="line">## Start Monit <span class="keyword">in</span> the background (run <span class="keyword">as</span> a daemon):</span><br><span class="line">#</span><br><span class="line">  set daemon <span class="number">30</span>            # check services at <span class="number">30</span>-seconds intervals</span><br><span class="line">#   <span class="keyword">with</span> start delay <span class="number">120</span>   # optional: delay the first check by <span class="number">4</span>-minutes (by</span><br><span class="line">#                          # default Monit check immediately after Monit start)</span><br><span class="line">#</span><br></pre></td></tr></table></figure>
<h3 id="使用本地Sendmail发送邮件"><a href="#使用本地Sendmail发送邮件" class="headerlink" title="使用本地Sendmail发送邮件"></a>使用本地Sendmail发送邮件</h3><figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Set the list of mail servers for alert delivery. Multiple servers may be </span></span><br><span class="line"><span class="comment">## specified using a comma separator. If the first mail server fails, Monit </span></span><br><span class="line"><span class="comment"># will use the second mail server in the list and so on. By default Monit uses </span></span><br><span class="line"><span class="comment"># port 25 - it is possible to override this with the PORT option.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># set mailserver mail.bar.baz,               # primary mailserver</span></span><br><span class="line"><span class="comment">#                backup.bar.baz port 10025,  # backup mailserver on port 10025</span></span><br><span class="line"><span class="comment">#                localhost                   # fallback relay</span></span><br><span class="line"> <span class="keyword">set</span> mailserver localhost               <span class="comment"># primary mailserver</span></span><br></pre></td></tr></table></figure>
<h3 id="邮件发件人"><a href="#邮件发件人" class="headerlink" title="邮件发件人"></a>邮件发件人</h3><p>我用来区别是哪台服务器发送的报警</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># You can override this message format or parts of it, such as subject</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># or sender using the MAIL-FORMAT statement. Macros such as $DATE, etc.</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># are expanded at runtime. For example, to override the sender, use:</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"> <span class="built_in">set</span> mail-format &#123; from: node1@anying.me &#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="报警邮件接收人"><a href="#报警邮件接收人" class="headerlink" title="报警邮件接收人"></a>报警邮件接收人</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># You can set alert recipients whom will receive alerts if/when a</span></span> </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># service defined in this file has errors. Alerts may be restricted on</span></span> </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># events by using a filter as in the second example below.</span></span> </span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"></span></span><br><span class="line"><span class="language-bash"> <span class="built_in">set</span> alert fify@xiaotanzhu.com                       <span class="comment"># receive all alerts</span></span></span><br></pre></td></tr></table></figure>
<h3 id="监控的Web服务"><a href="#监控的Web服务" class="headerlink" title="监控的Web服务"></a>监控的Web服务</h3><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Monit has an embedded web server which can be used to view status of </span></span><br><span class="line"><span class="comment">## services monitored and manage services from a web interface. See the</span></span><br><span class="line"><span class="comment">## Monit Wiki if you want to enable SSL for the web server. </span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"> <span class="built_in">set</span> httpd<span class="built_in"> port </span>2812 <span class="keyword">and</span></span><br><span class="line">    use<span class="built_in"> address </span>localhost  # only accept<span class="built_in"> connection </span><span class="keyword">from</span> localhost</span><br><span class="line">    allow localhost        # allow localhost <span class="keyword">to</span> connect <span class="keyword">to</span> the<span class="built_in"> server </span><span class="keyword">and</span></span><br><span class="line">    allow admin:monit      # require<span class="built_in"> user </span><span class="string">&#x27;admin&#x27;</span> with password <span class="string">&#x27;monit&#x27;</span></span><br><span class="line">    allow @monit           # allow<span class="built_in"> users </span>of<span class="built_in"> group </span><span class="string">&#x27;monit&#x27;</span> <span class="keyword">to</span> connect (rw)</span><br><span class="line">    allow @users readonly  # allow<span class="built_in"> users </span>of<span class="built_in"> group </span><span class="string">&#x27;users&#x27;</span> <span class="keyword">to</span> connect readonly</span><br></pre></td></tr></table></figure>

<h2 id="监听Docker服务"><a href="#监听Docker服务" class="headerlink" title="监听Docker服务"></a>监听Docker服务</h2><p>在<code>/etc/monit/conf.d</code>目录下增加监控文件<code>irenshi-web</code>：</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">check <span class="built_in">process</span> irenshi-web matching <span class="string">&quot;docker-proxy.*-host-port 8081.*&quot;</span></span><br><span class="line">  <span class="built_in">start</span> program <span class="string">&quot;/usr/bin/docker start irenshi-web&quot;</span></span><br><span class="line">  <span class="built_in">stop</span>  program <span class="string">&quot;/usr/bin/docker stop irenshi-web&quot;</span></span><br><span class="line">  <span class="keyword">if</span> failed host localhost port <span class="number">8081</span> protocol <span class="keyword">http</span> request <span class="string">&quot;/web/&quot;</span> <span class="keyword">for</span> <span class="number">10</span> times <span class="keyword">within</span> <span class="number">12</span> cycles <span class="keyword">then</span> restart</span><br></pre></td></tr></table></figure>

<p>其中：</p>
<ul>
<li><code>irenshi-web</code>为监控项目名称，这个名称将显示在报警邮件中。另外，启动和关闭项目也需要使用该名称，见<a href="#%E9%9C%80%E8%A6%81%E5%81%9C%E6%AD%A2Docker%E6%97%B6">需要停止Docker时</a></li>
<li><code>matching &quot;docker-proxy.*-host-port 8081.*&quot;</code>通过正则表达式来识别进程。通常情况下可以使用pidfile来识别进程，但Docker的实例没有进程pidfile，所以我们通过正则表达式匹配进程。Monit判断进程是否存在的时候会根据该正则表达式进行进程名搜索。</li>
<li><code>start program</code>启动进程的方法，这里必须使用完整路径<code>/usr/bin/docker</code>，否则会无法找到命令</li>
<li><code>stop program</code>关闭进程的方法。当Monit执行重启的时候，会先调用<code>stop program</code>，然后再调用<code>start program</code></li>
<li><code>if failed host localhost port 8081 protocol http request &quot;/web/&quot; for 10 times within 12 cycles then restart</code><ol>
<li><code>if failed</code>指定访问失败时的情形。当进程还在，但是Web服务器已经挂掉时，会触发<code>fail</code></li>
<li><code>localhost port 8081</code>监听本地的8081端口，这是Docker映射给主机的端口</li>
<li><code>protocol http request &quot;/web/&quot;</code>使用HTTP协议请求<code>/web/</code>这个页面</li>
<li><code>for 10 times within 12 cycles</code>出现次数设定：在12个检测周期中，如果出现了10次无法访问</li>
<li><code>then restart</code>满足以上条件时执行的操作，这里执行<code>restart</code></li>
</ol>
</li>
</ul>
<p>备注：Docker的完整进程名为</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">docker</span>-proxy -proto tcp -host-ip <span class="number">0.0.0.0</span> -host-port <span class="number">8081</span> -container-ip <span class="number">192.168.42.253</span> -container-port <span class="number">8080</span></span><br></pre></td></tr></table></figure>
<p>由于同一台机器上启动了若干个Docker，为防止干扰我们采用了取巧的方法，用<code>-host-port 8086</code>来识别进程实例。</p>
<h2 id="需要停止Docker时"><a href="#需要停止Docker时" class="headerlink" title="需要停止Docker时"></a>需要停止Docker时</h2><p>如果使用<code>docker stop irenshi-web</code>命令停止Docker的话，Monit检测到应用不存在会立即重新启动。所以应该使用以下命令关闭Docker：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">monit -c /etc/monit/monitrc stop irenshi-web</span><br></pre></td></tr></table></figure>

<p>如果需要重新启动，则对应执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">monit -c /etc/monit/monitrc start irenshi-web</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-08-19-monitor-tomcat-in-docker.html" target="_blank">使用Moint监控Docker中运行的Web服务器</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-08-19-monitor-tomcat-in-docker.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>监控</tag>
        <tag>Docker</tag>
        <tag>Moint</tag>
      </tags>
  </entry>
  <entry>
    <title>在MySQL中创建库和用户</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-23-create-db-user-in-mysql.html</url>
    <content><![CDATA[<h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE `irenshi` <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8mb4 <span class="keyword">COLLATE</span> utf8mb4_unicode_ci;</span><br></pre></td></tr></table></figure>

<h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;irenshi&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;irenshi&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="授权数据库访问"><a href="#授权数据库访问" class="headerlink" title="授权数据库访问"></a>授权数据库访问</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> irenshi.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;irenshi&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-23-create-db-user-in-mysql.html" target="_blank">在MySQL中创建库和用户</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-23-create-db-user-in-mysql.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>将现有数据库的数据导入MyCAT</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-24-import-data-into-mycat.html</url>
    <content><![CDATA[<p><strong>特别注意：</strong>请谨慎使用该方法，目前遇到了两个问题，还尚未确定是Bug还是设置问题：</p>
<ol>
<li>当导入数据的某列很大时（其实也不大，大于4096的时候就会出问题），导入失败：<a href="https://github.com/MyCATApache/Mycat-Server/issues/1073">https://github.com/MyCATApache/Mycat-Server/issues/1073</a></li>
<li>导入表格的Boolean类型的数据都变成了False：<a href="https://github.com/MyCATApache/Mycat-Server/issues/1074">https://github.com/MyCATApache/Mycat-Server/issues/1074</a></li>
</ol>
<h2 id="版本及其他信息"><a href="#版本及其他信息" class="headerlink" title="版本及其他信息"></a>版本及其他信息</h2><ul>
<li>MySQL： 5.6</li>
<li>数据库名：linahr</li>
<li>MySQL Node 1: 192.168.1.3:3307</li>
<li>MySQL Node 2: 192.168.1.3:3308</li>
<li>MyCat Data: 192.168.1.3:8066</li>
<li>MyCat Console: 192.168.1.3:9066</li>
</ul>
<h2 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h2><h3 id="修改mysqldump配置"><a href="#修改mysqldump配置" class="headerlink" title="修改mysqldump配置"></a>修改mysqldump配置</h3><p>在/etc/mysql/my.cnf中增加以下内容：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqldump]</span></span><br><span class="line">quick</span><br><span class="line">quote-names</span><br><span class="line"><span class="attr">max_allowed_packet</span>      = <span class="number">16</span>M</span><br><span class="line"><span class="attr">default-character-set</span>   = utf8mb4</span><br></pre></td></tr></table></figure>

<h3 id="导出数据-1"><a href="#导出数据-1" class="headerlink" title="导出数据"></a>导出数据</h3><p>创建/tmp/irenshi目录并修改其访问权限为777：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /tmp/irenshi</span><br><span class="line"><span class="built_in">chmod</span> 777 /tmp/irenshi</span><br></pre></td></tr></table></figure>
<p>执行mysqldump命令导出数据：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqldump -uroot -proot --fields-optionally-enclosed-by=<span class="string">&#x27;&quot;&#x27;</span> --fields-terminated-by=<span class="string">&#x27;,&#x27;</span> --tab /tmp/irenshi/ --lines-terminated-by=<span class="string">&#x27;\n&#x27;</span> linahr</span><br></pre></td></tr></table></figure>
<p>数据将导出到/tmp/irenshi目录下。每个表格有两个文件，SQL(<em>.sql)和数据文件(</em>.txt)。</p>
<h2 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h2><h3 id="合并建表语句"><a href="#合并建表语句" class="headerlink" title="合并建表语句"></a>合并建表语句</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> *.sql &gt; irenshi-tables.sql</span><br></pre></td></tr></table></figure>

<h3 id="在MyCAT中创建表格"><a href="#在MyCAT中创建表格" class="headerlink" title="在MyCAT中创建表格"></a>在MyCAT中创建表格</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -uirenshi -pirenshi -h192.168.1.3 -P8066 irenshi &lt; irenshi-tables.sql</span><br></pre></td></tr></table></figure>

<h3 id="生成LOAD-DATA语句"><a href="#生成LOAD-DATA语句" class="headerlink" title="生成LOAD DATA语句"></a>生成LOAD DATA语句</h3><p>为保险期间，删除刚才用到的建表语句：irenshi-tables.sql</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> irenshi-tables.sql</span><br></pre></td></tr></table></figure>
<p>在/tmp/irenshi目录下增加以下两个Shell脚本：<br><strong>read-columns.sh</strong>，该文件会把每个SQL建表语句中的列名信息抽取出来：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">sed -e <span class="string">&#x27;s#^\s*`\([^`]*\)`.*,#\1, #g&#x27;</span> <span class="variable">$1</span> | sed <span class="string">&#x27;:label;N;s/\n//;b label&#x27;</span> | sed -e <span class="string">&quot;s/.*CREATE TABLE[^(]*(\(.*\)PRIMARY.*/\1/g&quot;</span> | sed -e <span class="string">&quot;s/\(.*\),/\1/g&quot;</span></span><br></pre></td></tr></table></figure>
<p><strong>generate-sql.sh</strong>，该文件会根据每个建表语句生成对应的LOAD DATA语句：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">OUTPUT_FILE=load-data.sql</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> FILE <span class="keyword">in</span> $(<span class="built_in">ls</span> tab*.sql) ; <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="variable">$FILE</span></span><br><span class="line">        TABLE_NAME=`<span class="built_in">echo</span> <span class="variable">$FILE</span> | <span class="built_in">cut</span> -d <span class="string">&quot;.&quot;</span> -f1`</span><br><span class="line">        COLUMNS=$(./read-columns.sh <span class="variable">$FILE</span>)</span><br><span class="line">        <span class="comment">#LOAD DATA local INFILE &#x27;/tmp/irenshi/tab_sign_record_info.txt&#x27;</span></span><br><span class="line">        <span class="comment">#IGNORE INTO TABLE tab_sign_record_info CHARACTER SET &#x27;utf8mb4&#x27; </span></span><br><span class="line">        <span class="comment">#FIELDS TERMINATED BY &#x27;,&#x27; OPTIONALLY ENCLOSED BY &#x27;&quot;&#x27; LINES TERMINATED BY &#x27;\n&#x27; (column1, column2, column3, ...)</span></span><br><span class="line">        SQL=<span class="string">&quot;LOAD DATA local INFILE &#x27;/tmp/irenshi/<span class="variable">$&#123;TABLE_NAME&#125;</span>.txt&#x27;&quot;</span></span><br><span class="line">        SQL=<span class="string">&quot;<span class="variable">$&#123;SQL&#125;</span> IGNORE INTO TABLE <span class="variable">$&#123;TABLE_NAME&#125;</span> CHARACTER SET &#x27;utf8&#x27;&quot;</span></span><br><span class="line">        SQL=<span class="string">&quot;<span class="variable">$&#123;SQL&#125;</span> FIELDS TERMINATED BY &#x27;,&#x27; OPTIONALLY ENCLOSED BY &#x27;\&quot;&#x27; LINES TERMINATED BY &#x27;\n&#x27;&quot;</span></span><br><span class="line">        SQL=<span class="string">&quot;<span class="variable">$&#123;SQL&#125;</span> (<span class="variable">$&#123;COLUMNS&#125;</span>);&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="variable">$SQL</span> &gt;&gt; load-data.sql</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>在/tmp/irenshi目录下执行generate-sql.sh，生成LOAD DATA文件：load-data.sql</p>
<h3 id="导入数据-1"><a href="#导入数据-1" class="headerlink" title="导入数据"></a>导入数据</h3><p>使用以下命令登录mysql，需要特别注意添加<code>--local-infile=1</code>参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -uirenshi -pirenshi -h192.168.1.3 --local-infile=1 -P8066 irenshi</span><br></pre></td></tr></table></figure>
<p>执行导入命令：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">source load<span class="operator">-</span>data.sql</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-24-import-data-into-mycat.html" target="_blank">将现有数据库的数据导入MyCAT</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-24-import-data-into-mycat.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MyCAT</tag>
        <tag>mysqldump</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL服务器配置</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-25-mysql-basic-config.html</url>
    <content><![CDATA[<p>MySQL版本信息：</p>
<blockquote>
<p>mysqld  Ver 5.6.31-0ubuntu0.14.04.2 for debian-linux-gnu on x86_64 ((Ubuntu))</p>
</blockquote>
<h2 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h2><figure class="highlight diff"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line"># The MySQL database server configuration file.</span><br><span class="line">#</span><br><span class="line"># You can copy this to one of:</span><br><span class="line"># - &quot;/etc/mysql/my.cnf&quot; to set global options,</span><br><span class="line"># - &quot;~/.my.cnf&quot; to set user-specific options.</span><br><span class="line"># </span><br><span class="line"># One can use all long options that the program supports.</span><br><span class="line"># Run program with --help to get a list of available options and with</span><br><span class="line"># --print-defaults to see which it would actually understand and use.</span><br><span class="line">#</span><br><span class="line"># For explanations see</span><br><span class="line"># http://dev.mysql.com/doc/mysql/en/server-system-variables.html</span><br><span class="line"></span><br><span class="line"># This will be passed to all mysql clients</span><br><span class="line"># It has been reported that passwords should be enclosed with ticks/quotes</span><br><span class="line"># escpecially if they contain &quot;#&quot; chars...</span><br><span class="line"># Remember to edit /etc/mysql/debian.cnf when changing the socket location.</span><br><span class="line">[client]</span><br><span class="line">port            = 3306</span><br><span class="line">socket          = /var/run/mysqld/mysqld.sock</span><br><span class="line"><span class="addition">+ default-character-set = utf8mb4</span></span><br><span class="line"></span><br><span class="line"># Here is entries for some specific programs</span><br><span class="line"># The following values assume you have at least 32M ram</span><br><span class="line"></span><br><span class="line"># This was formally known as [safe_mysqld]. Both versions are currently parsed.</span><br><span class="line">[mysqld_safe]</span><br><span class="line">socket          = /var/run/mysqld/mysqld.sock</span><br><span class="line">nice            = 0</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">#</span><br><span class="line"># * Basic Settings</span><br><span class="line">#</span><br><span class="line"><span class="addition">+ skip-host-cache</span></span><br><span class="line">user            = mysql</span><br><span class="line">pid-file        = /var/run/mysqld/mysqld.pid</span><br><span class="line">socket          = /var/run/mysqld/mysqld.sock</span><br><span class="line">port            = 3306</span><br><span class="line">basedir         = /usr</span><br><span class="line">datadir         = /var/lib/mysql</span><br><span class="line">tmpdir          = /tmp</span><br><span class="line">lc-messages-dir = /usr/share/mysql</span><br><span class="line"><span class="addition">+ explicit_defaults_for_timestamp</span></span><br><span class="line">skip-external-locking</span><br><span class="line">#</span><br><span class="line"># Instead of skip-networking the default is now to listen only on</span><br><span class="line"># localhost which is more compatible and is not less secure.</span><br><span class="line"><span class="deletion">- bind-address           = 127.0.0.1</span></span><br><span class="line"><span class="addition">+ #bind-address           = 127.0.0.1</span></span><br><span class="line">#</span><br><span class="line"># * Fine Tuning</span><br><span class="line">#</span><br><span class="line">key_buffer              = 16M</span><br><span class="line">max_allowed_packet      = 16M</span><br><span class="line">thread_stack            = 192K</span><br><span class="line">thread_cache_size       = 8</span><br><span class="line"># This replaces the startup script and checks MyISAM tables if needed</span><br><span class="line"># the first time they are touched</span><br><span class="line">myisam-recover         = BACKUP</span><br><span class="line"><span class="deletion">- #max_connections        = 100</span></span><br><span class="line"><span class="addition">+ max_connections        = 1000</span></span><br><span class="line">#table_cache            = 64</span><br><span class="line">thread_concurrency     = 10</span><br><span class="line">#</span><br><span class="line"># * Query Cache Configuration</span><br><span class="line">#</span><br><span class="line">query_cache_limit       = 1M</span><br><span class="line">query_cache_size        = 16M</span><br><span class="line"><span class="addition">+ skip_name_resolve       = 1</span></span><br><span class="line"><span class="addition">+ lower_case_table_names  = 1</span></span><br><span class="line"><span class="addition">+ max_allowed_packet      = 32M</span></span><br><span class="line">#</span><br><span class="line"># * Logging and Replication</span><br><span class="line">#</span><br><span class="line"># Both location gets rotated by the cronjob.</span><br><span class="line"># Be aware that this log type is a performance killer.</span><br><span class="line"># As of 5.1 you can enable the log at runtime!</span><br><span class="line">#general_log_file        = /var/log/mysql/mysql.log</span><br><span class="line">#general_log             = 1</span><br><span class="line">#</span><br><span class="line"># Error log - should be very few entries.</span><br><span class="line">#</span><br><span class="line">log_error = /var/log/mysql/error.log</span><br><span class="line">#</span><br><span class="line"># Here you can see queries with especially long duration</span><br><span class="line">#log_slow_queries       = /var/log/mysql/mysql-slow.log</span><br><span class="line">#long_query_time = 2</span><br><span class="line">#log-queries-not-using-indexes</span><br><span class="line"><span class="addition">+ # 千万不要使用log_slow_queries，这是一个错误的参数，会导致MySQL无法启动</span></span><br><span class="line"><span class="addition">+ slow_query_log          = 1</span></span><br><span class="line"><span class="addition">+ slow_query_log_file     = /var/log/mysql/slow.log</span></span><br><span class="line"><span class="addition">+ long_query_time         = 10</span></span><br><span class="line">#</span><br><span class="line"># The following can be used as easy to replay backup logs or for replication.</span><br><span class="line"># note: if you are setting up a replication slave, see README.Debian about</span><br><span class="line">#       other settings you may need to change.</span><br><span class="line"><span class="deletion">- #server-id              = 1</span></span><br><span class="line"><span class="addition">+ server-id               = 2</span></span><br><span class="line"><span class="deletion">- #log_bin                 = /var/log/mysql/mysql-bin.log</span></span><br><span class="line"><span class="addition">+ log_bin                 = /var/log/mysql/mysql-bin.log</span></span><br><span class="line">expire_logs_days        = 10</span><br><span class="line">max_binlog_size         = 100M</span><br><span class="line"><span class="addition">+ read-only               = 0</span></span><br><span class="line">#binlog_do_db           = include_database_name</span><br><span class="line">#binlog_ignore_db       = include_database_name</span><br><span class="line"><span class="addition">+ binlog-ignore-db        = mysql</span></span><br><span class="line"><span class="addition">+ binlog-ignore-db        = information_schema</span></span><br><span class="line"><span class="addition">+ binlog-ignore-db        = performance_schema</span></span><br><span class="line"><span class="addition">+ ## GTID: Global Transaction ID</span></span><br><span class="line"><span class="addition">+ gtid_mode               = on</span></span><br><span class="line"><span class="addition">+ enforce_gtid_consistency= on</span></span><br><span class="line"><span class="addition">+ log-slave-updates       = 1</span></span><br><span class="line"><span class="addition">+ # For all slave servers</span></span><br><span class="line"><span class="addition">+ skip_slave_start        = 1</span></span><br><span class="line">#</span><br><span class="line"># * InnoDB</span><br><span class="line">#</span><br><span class="line"># InnoDB is enabled by default with a 10MB datafile in /var/lib/mysql/.</span><br><span class="line"># Read the manual for more InnoDB related options. There are many!</span><br><span class="line">#</span><br><span class="line"># * Security Features</span><br><span class="line">#</span><br><span class="line"># Read the manual, too, if you want chroot!</span><br><span class="line"># chroot = /var/lib/mysql/</span><br><span class="line">#</span><br><span class="line"># For generating SSL certificates I recommend the OpenSSL GUI &quot;tinyca&quot;.</span><br><span class="line">#</span><br><span class="line"># ssl-ca=/etc/mysql/cacert.pem</span><br><span class="line"># ssl-cert=/etc/mysql/server-cert.pem</span><br><span class="line"># ssl-key=/etc/mysql/server-key.pem</span><br><span class="line"></span><br><span class="line"><span class="addition">+ max_connect_errors      = 20</span></span><br><span class="line"><span class="addition">+ interactive_timeout     = 172800</span></span><br><span class="line"><span class="addition">+ wait_timeout            = 172800</span></span><br><span class="line"></span><br><span class="line"># Character sets</span><br><span class="line"><span class="addition">+ character-set-client-handshake = FALSE</span></span><br><span class="line"><span class="addition">+ character-set-server    = utf8mb4</span></span><br><span class="line"><span class="addition">+ collation-server        = utf8mb4_unicode_ci</span></span><br><span class="line"></span><br><span class="line">[mysqldump]</span><br><span class="line">quick</span><br><span class="line">quote-names</span><br><span class="line"><span class="addition">+ max_allowed_packet      = 32M</span></span><br><span class="line"></span><br><span class="line">[mysql]</span><br><span class="line">#no-auto-rehash # faster start of mysql but no tab completition</span><br><span class="line"><span class="addition">+ default-character-set   = utf8mb4</span></span><br><span class="line"></span><br><span class="line">[isamchk]</span><br><span class="line">key_buffer              = 16M</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># * IMPORTANT: Additional settings that can override those from this file!</span><br><span class="line">#   The files must end with &#x27;.cnf&#x27;, otherwise they&#x27;ll be ignored.</span><br><span class="line">#</span><br><span class="line"><span class="addition">!includedir /etc/mysql/conf.d/</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-25-mysql-basic-config.html" target="_blank">MySQL服务器配置</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-25-mysql-basic-config.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>使用GTID机制创建MySQL主从备份和主主备份</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-25-mysql-gtid-master-slave.html</url>
    <content><![CDATA[<blockquote>
<p><strong>注意：</strong>GTID机制只适用与MySQL 5.6.10及更新版本。</p>
</blockquote>
<h2 id="GTID比传统复制的优势"><a href="#GTID比传统复制的优势" class="headerlink" title="GTID比传统复制的优势"></a>GTID比传统复制的优势</h2><ol>
<li>更简单的实现failover，不用以前那样在需要找log_file和log_Pos。</li>
<li>更简单的搭建主从复制。</li>
<li>比传统复制更加安全。</li>
<li>GTID是连续没有空洞的，因此主从库出现数据冲突时，可以用添加空事物的方式进行跳过。</li>
</ol>
<h2 id="GTID的工作原理："><a href="#GTID的工作原理：" class="headerlink" title="GTID的工作原理："></a>GTID的工作原理：</h2><ol>
<li>master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。</li>
<li>slave端的i/o 线程将变更的binlog，写入到本地的relay log中。</li>
<li>sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。</li>
<li>如果有记录，说明该GTID的事务已经执行，slave会忽略。</li>
<li>如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。</li>
<li>在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。</li>
</ol>
<p><strong>要点：</strong></p>
<ol>
<li>slave在接受master的binlog时，会校验master的GTID是否已经执行过（一个服务器只能执行一次）。</li>
<li>为了保证主从数据的一致性，多线程只能同时执行一个GTID。</li>
</ol>
<h2 id="MySQL启动GTID机制"><a href="#MySQL启动GTID机制" class="headerlink" title="MySQL启动GTID机制"></a>MySQL启动GTID机制</h2><p>主从MySQL的配置基本一致，区别在于<code>server_id</code><strong>必须</strong>不同：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">server-id</span>               = <span class="number">2</span></span><br><span class="line"><span class="comment"># 在GTID机制下从服务器也必须开启</span></span><br><span class="line"><span class="attr">log_bin</span>                 = /var/log/mysql/mysql-bin.log</span><br><span class="line"><span class="comment"># 参考下文说明，强烈推荐使用row</span></span><br><span class="line"><span class="attr">binlog_format</span>           = row</span><br><span class="line"><span class="attr">expire_logs_days</span>        = <span class="number">10</span></span><br><span class="line"><span class="attr">max_binlog_size</span>         = <span class="number">100</span>M</span><br><span class="line"><span class="attr">read-only</span>               = <span class="number">0</span></span><br><span class="line"><span class="attr">binlog-ignore-db</span>        = mysql</span><br><span class="line"><span class="attr">binlog-ignore-db</span>        = information_schema</span><br><span class="line"><span class="attr">binlog-ignore-db</span>        = performance_schema</span><br><span class="line"><span class="comment">#binlog_ignore_db       = include_database_name</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## GTID: Global Transaction ID</span></span><br><span class="line"><span class="attr">gtid_mode</span>               = <span class="literal">on</span></span><br><span class="line"><span class="comment"># 使用主从复制的时候必须启用</span></span><br><span class="line"><span class="attr">enforce_gtid_consistency</span>= <span class="literal">on</span></span><br><span class="line"><span class="comment"># 使用主从复制的时候必须启用</span></span><br><span class="line"><span class="attr">log-slave-updates</span>       = <span class="number">1</span></span><br><span class="line"><span class="comment"># For all slave servers</span></span><br><span class="line"><span class="attr">skip_slave_start</span>        = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>关于<code>binlog-format = row</code>的<a href="http://dev.mysql.com/doc/refman/5.7/en/binary-log-setting.html">官方描述</a>：</p>
<blockquote>
<p><strong>Warning</strong><br>When using statement-based logging for replication, it is possible for the data on the master and slave to become different if a statement is designed in such a way that the data modification is nondeterministic; that is, it is left to the will of the query optimizer. In general, this is not a good practice even outside of replication. For a detailed explanation of this issue, see Section B.5.7, “Known Issues in MySQL”.</p>
</blockquote>
<p>重新启动MySQL服务器，可以查看GTID是否正常启动：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">mysql&gt; show global variables like &#x27;%gtid%&#x27;;</span><br><span class="line">+---------------------------------+-----------------------------------------------+</span><br><span class="line">|<span class="string"> Variable_name                   </span>|<span class="string"> Value                                         </span>|</span><br><span class="line">+---------------------------------+-----------------------------------------------+</span><br><span class="line">|<span class="string"> binlog_gtid_simple_recovery     </span>|<span class="string"> OFF                                           </span>|</span><br><span class="line">|<span class="string"> enforce_gtid_consistency        </span>|<span class="string"> ON                                            </span>|</span><br><span class="line">|<span class="string"> gtid_executed                   </span>|<span class="string"> 3591a291-699c-11e6-8386-0242ac1100f2:1-1830   </span>|</span><br><span class="line">|<span class="string"> gtid_mode                       </span>|<span class="string"> ON                                            </span>|</span><br><span class="line">|<span class="string"> gtid_owned                      </span>|<span class="string"> 3591a291-699c-11e6-8386-0242ac1100f2:1831#127 </span>|</span><br><span class="line">|<span class="string"> gtid_purged                     </span>|<span class="string">                                               </span>|</span><br><span class="line">|<span class="string"> simplified_binlog_gtid_recovery </span>|<span class="string"> OFF                                           </span>|</span><br><span class="line">+---------------------------------+-----------------------------------------------+</span><br><span class="line">7 rows in set (0.02 sec)</span><br></pre></td></tr></table></figure>

<p>执行一条更新语句，然后就可以看到GTID的状态了：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">mysql&gt; show master status\G;</span><br><span class="line"><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">**<span class="emphasis">* 1. row *</span>**</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span><span class="strong">****</span></span><br><span class="line"><span class="code">             File: mysql-bin.000001</span></span><br><span class="line"><span class="code">         Position: 1070635555</span></span><br><span class="line"><span class="code">     Binlog_Do_DB: </span></span><br><span class="line"><span class="code"> Binlog_Ignore_DB: mysql,information_schema,performance_schema</span></span><br><span class="line"><span class="code">Executed_Gtid_Set: 3591a291-699c-11e6-8386-0242ac1100f2:1-1745</span></span><br><span class="line"><span class="code">1 row in set (0.00 sec)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">ERROR: </span><br><span class="line">No query specified</span><br></pre></td></tr></table></figure>

<h2 id="启动主从复制"><a href="#启动主从复制" class="headerlink" title="启动主从复制"></a>启动主从复制</h2><h3 id="创建Master的Replica帐号："><a href="#创建Master的Replica帐号：" class="headerlink" title="创建Master的Replica帐号："></a>创建Master的Replica帐号：</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;repl&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;slave&#x27;</span>;</span><br><span class="line"><span class="keyword">GRANT</span> REPLICATION SLAVE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;repl&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="在新系统中启动Slave"><a href="#在新系统中启动Slave" class="headerlink" title="在新系统中启动Slave"></a>在新系统中启动Slave</h3><p>如果所有的Binlog都存在Master中，我们认为这是一个新的MySQL系统，此时可以非常容易的启动Slave，只需要在Slave中执行：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">stop slave;</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;192.168.1.3&#x27;</span>, master_port<span class="operator">=</span><span class="number">3307</span>, master_user<span class="operator">=</span><span class="string">&#x27;repl&#x27;</span>, master_password<span class="operator">=</span><span class="string">&#x27;slave&#x27;</span>, master_auto_position<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"><span class="keyword">start</span> slave;</span><br></pre></td></tr></table></figure>
<p>最后一个参数<code>master_auto_position=1</code>告诉Slave服务器自动去寻找Binlog的位置，并且启动Slave。</p>
<p>此时可以查看Slave的状态：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">mysql&gt;</span> <span class="string">show</span> <span class="string">slave</span> <span class="string">status\G;</span></span><br><span class="line"><span class="string">***************************</span> <span class="number">1</span><span class="string">.</span> <span class="string">row</span> <span class="string">***************************</span></span><br><span class="line">               <span class="attr">Slave_IO_State:</span> <span class="string">Waiting</span> <span class="string">for</span> <span class="string">master</span> <span class="string">to</span> <span class="string">send</span> <span class="string">event</span></span><br><span class="line">                  <span class="attr">Master_Host:</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.3</span></span><br><span class="line">                  <span class="attr">Master_User:</span> <span class="string">repl</span></span><br><span class="line">                  <span class="attr">Master_Port:</span> <span class="number">3307</span></span><br><span class="line">                <span class="attr">Connect_Retry:</span> <span class="number">60</span></span><br><span class="line">              <span class="attr">Master_Log_File:</span> <span class="string">mysql-bin.000005</span></span><br><span class="line">          <span class="attr">Read_Master_Log_Pos:</span> <span class="number">22069</span></span><br><span class="line">               <span class="attr">Relay_Log_File:</span> <span class="string">mysqld-relay-bin.000005</span></span><br><span class="line">                <span class="attr">Relay_Log_Pos:</span> <span class="number">29521031</span></span><br><span class="line">        <span class="attr">Relay_Master_Log_File:</span> <span class="string">mysql-bin.000003</span></span><br><span class="line">             <span class="attr">Slave_IO_Running:</span> <span class="literal">Yes</span></span><br><span class="line">            <span class="attr">Slave_SQL_Running:</span> <span class="literal">Yes</span></span><br><span class="line">              <span class="attr">Replicate_Do_DB:</span> </span><br><span class="line">          <span class="attr">Replicate_Ignore_DB:</span> </span><br><span class="line">           <span class="attr">Replicate_Do_Table:</span> </span><br><span class="line">       <span class="attr">Replicate_Ignore_Table:</span> </span><br><span class="line">      <span class="attr">Replicate_Wild_Do_Table:</span> </span><br><span class="line">  <span class="attr">Replicate_Wild_Ignore_Table:</span> </span><br><span class="line">                   <span class="attr">Last_Errno:</span> <span class="number">0</span></span><br><span class="line">                   <span class="attr">Last_Error:</span> </span><br><span class="line">                 <span class="attr">Skip_Counter:</span> <span class="number">0</span></span><br><span class="line">          <span class="attr">Exec_Master_Log_Pos:</span> <span class="number">29520821</span></span><br><span class="line">              <span class="attr">Relay_Log_Space:</span> <span class="number">973528215</span></span><br><span class="line">              <span class="attr">Until_Condition:</span> <span class="string">None</span></span><br><span class="line">               <span class="attr">Until_Log_File:</span> </span><br><span class="line">                <span class="attr">Until_Log_Pos:</span> <span class="number">0</span></span><br><span class="line">           <span class="attr">Master_SSL_Allowed:</span> <span class="literal">No</span></span><br><span class="line">           <span class="attr">Master_SSL_CA_File:</span> </span><br><span class="line">           <span class="attr">Master_SSL_CA_Path:</span> </span><br><span class="line">              <span class="attr">Master_SSL_Cert:</span> </span><br><span class="line">            <span class="attr">Master_SSL_Cipher:</span> </span><br><span class="line">               <span class="attr">Master_SSL_Key:</span> </span><br><span class="line">        <span class="attr">Seconds_Behind_Master:</span> <span class="number">6454</span></span><br><span class="line"><span class="attr">Master_SSL_Verify_Server_Cert:</span> <span class="literal">No</span></span><br><span class="line">                <span class="attr">Last_IO_Errno:</span> <span class="number">0</span></span><br><span class="line">                <span class="attr">Last_IO_Error:</span> </span><br><span class="line">               <span class="attr">Last_SQL_Errno:</span> <span class="number">0</span></span><br><span class="line">               <span class="attr">Last_SQL_Error:</span> </span><br><span class="line">  <span class="attr">Replicate_Ignore_Server_Ids:</span> </span><br><span class="line">             <span class="attr">Master_Server_Id:</span> <span class="number">1</span></span><br><span class="line">                  <span class="attr">Master_UUID:</span> <span class="string">3591a291-699c-11e6-8386-0242ac1100f2</span></span><br><span class="line">             <span class="attr">Master_Info_File:</span> <span class="string">/var/lib/mysql/master.info</span></span><br><span class="line">                    <span class="attr">SQL_Delay:</span> <span class="number">0</span></span><br><span class="line">          <span class="attr">SQL_Remaining_Delay:</span> <span class="literal">NULL</span></span><br><span class="line">      <span class="attr">Slave_SQL_Running_State:</span> <span class="string">executing</span></span><br><span class="line">           <span class="attr">Master_Retry_Count:</span> <span class="number">86400</span></span><br><span class="line">                  <span class="attr">Master_Bind:</span> </span><br><span class="line">      <span class="attr">Last_IO_Error_Timestamp:</span> </span><br><span class="line">     <span class="attr">Last_SQL_Error_Timestamp:</span> </span><br><span class="line">               <span class="attr">Master_SSL_Crl:</span> </span><br><span class="line">           <span class="attr">Master_SSL_Crlpath:</span> </span><br><span class="line">           <span class="attr">Retrieved_Gtid_Set:</span> <span class="string">3591a291-699c-11e6-8386-0242ac1100f2:1-2114</span></span><br><span class="line">            <span class="attr">Executed_Gtid_Set:</span> <span class="string">3591a291-699c-11e6-8386-0242ac1100f2:1-1750</span></span><br><span class="line">                <span class="attr">Auto_Position:</span> <span class="number">1</span></span><br><span class="line"><span class="number">1</span> <span class="string">row</span> <span class="string">in</span> <span class="string">set</span> <span class="string">(0.00</span> <span class="string">sec)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ERROR:</span> </span><br><span class="line"><span class="literal">No</span> <span class="string">query</span> <span class="string">specified</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是以下两个字段都应该为Yes：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"> <span class="attr">Slave_IO_Running:</span> <span class="literal">Yes</span></span><br><span class="line"><span class="attr">Slave_SQL_Running:</span> <span class="literal">Yes</span></span><br></pre></td></tr></table></figure>

<h3 id="在已有系统中启动Slave"><a href="#在已有系统中启动Slave" class="headerlink" title="在已有系统中启动Slave"></a>在已有系统中启动Slave</h3><p>使用mysqldump的方式：</p>
<ol>
<li>在备份的时候指定–master-data=2（来保存binlog的文件号和位置的命令）。</li>
<li>使用mysqldump的命令在dump文件里可以看到下面两个信息：<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="built_in">SET</span> @@SESSION.<span class="attribute">SQL_LOG_BIN</span>=0;</span><br><span class="line"><span class="built_in">SET</span> @@GLOBAL.<span class="attribute">GTID_PURGED</span>=<span class="string">&#x27;7800a22c-95ae-11e4-983d-080027de205a:1-8&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>将备份还原到slave后，使用change master to命令挂载master端。</li>
</ol>
<h2 id="启动主主复制"><a href="#启动主主复制" class="headerlink" title="启动主主复制"></a>启动主主复制</h2><p>主主复制只是需要将两个MySQL服务器互为主从。在上节的从服务器中执行主服务器的操作：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">&#x27;repl&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;slave&#x27;</span>;</span><br><span class="line"><span class="keyword">GRANT</span> REPLICATION SLAVE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;repl&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>在上节中的主服务器执行从服务器的操作：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">stop slave;</span><br><span class="line">change master <span class="keyword">to</span> master_host<span class="operator">=</span><span class="string">&#x27;192.168.1.3&#x27;</span>, master_port<span class="operator">=</span><span class="number">3308</span>, master_user<span class="operator">=</span><span class="string">&#x27;repl&#x27;</span>, master_password<span class="operator">=</span><span class="string">&#x27;slave&#x27;</span>, master_auto_position<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line"><span class="keyword">start</span> slave;</span><br></pre></td></tr></table></figure>
<p>这时候两台服务器为互为备份的状态。</p>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="如果mysql导入的过程中失败"><a href="#如果mysql导入的过程中失败" class="headerlink" title="如果mysql导入的过程中失败"></a>如果mysql导入的过程中失败</h3><p>如果导入过程中MySQL报错，则再次执行的时候会报：</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line">fify@server-base:/tmp/irenshi⟫ mysql -uroot -proot -h192.168.1.4 -P3307 &lt; irenshi.sql</span><br><span class="line"><span class="keyword">ERROR </span>1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty.</span><br></pre></td></tr></table></figure>
<p>此时只需要在从服务器中执行reset命令即可：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">reset master</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>参考：</strong><a href="https://avdeo.com/tag/error-1840-hy000-global-gtid_purged-can-only-be-set-when/">https://avdeo.com/tag/error-1840-hy000-global-gtid_purged-can-only-be-set-when/</a></p>
</blockquote>
<h3 id="启动salve之后报错"><a href="#启动salve之后报错" class="headerlink" title="启动salve之后报错"></a>启动salve之后报错</h3><p>如我的slave报了如下错误：</p>
<figure class="highlight vbnet"><table><tr><td class="code"><pre><span class="line"><span class="symbol">Last_SQL_Errno:</span> <span class="number">1049</span></span><br><span class="line"><span class="symbol">Last_SQL_Error:</span> <span class="keyword">Error</span> <span class="comment">&#x27;Unknown database &#x27;irenshi&#x27;&#x27; on query. Default database: &#x27;irenshi&#x27;. Query: &#x27;CREATE TABLE `C3P0_TEST_TABLE` (</span></span><br><span class="line">  `a` <span class="type">char</span>(<span class="number">1</span>) <span class="keyword">DEFAULT</span> NULL</span><br><span class="line">) ENGINE=InnoDB <span class="keyword">DEFAULT</span> CHARSET=utf8<span class="comment">&#x27;</span></span><br><span class="line"><span class="symbol">Retrieved_Gtid_Set:</span> <span class="number">3591</span>a291-<span class="number">699</span>c-<span class="number">11e6</span>-<span class="number">8386</span>-<span class="number">0242</span>ac1100f2:<span class="number">1</span>-<span class="number">1751</span></span><br><span class="line"><span class="symbol">Executed_Gtid_Set:</span> <span class="number">3591</span>a291-<span class="number">699</span>c-<span class="number">11e6</span>-<span class="number">8386</span>-<span class="number">0242</span>ac1100f2:<span class="number">1</span>-<span class="number">7</span></span><br></pre></td></tr></table></figure>
<p>因为我的从数据库中多了<code>irenshi</code>这个表格，并且默认表格也为<code>irenshi</code>，导致无法执行。</p>
<p>可以看到我的从库目前获取到主库的GtidSet为1-1751，但是只执行到了1-7，那么可以通过以下方式跳过第8个GTID：</p>
<blockquote>
<ol>
<li>stop slave;</li>
<li>set GTID_NEXT=’3591a291-699c-11e6-8386-0242ac1100f2:8’;</li>
<li>begin;</li>
<li>commit;</li>
<li>set GTID_NEXT=’AUTOMATIC’;</li>
<li>start slave;</li>
</ol>
</blockquote>
<p>此时再看slave的状态，已经跳过了第8个GTID。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-25-mysql-gtid-master-slave.html" target="_blank">使用GTID机制创建MySQL主从备份和主主备份</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-25-mysql-gtid-master-slave.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>GTID</tag>
        <tag>主从复制</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL导入数据错误：ERROR 2006 (HY000) at line 1&amp;#58; MySQL server has gone away</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-26-mysql-error-2006.html</url>
    <content><![CDATA[<p>这个问题出在使用mysqldump进行数据迁移的过程中，问题的原因就是单条SQL的大小比数据库的设置更大。</p>
<p>检查两个地方的配置：</p>
<ol>
<li>mysqldump的配置</li>
<li>mysqld的配置</li>
</ol>
<p>主要关注<strong>max_allowed_packet</strong>参数。</p>
<p><strong>mysqldump在/etc/mysql/my.cnf的配置</strong></p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqldump]</span></span><br><span class="line"><span class="attr">max_allowed_packet</span> = <span class="number">64</span>M</span><br></pre></td></tr></table></figure>

<p><strong>mysqld在/etc/mysql/my.cnf的配置</strong></p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">max_allowed_packet</span> = <span class="number">64</span>M</span><br></pre></td></tr></table></figure>
<p>只要保证mysqld中的max_allowed_packet不小于mysqldump的配置即可。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-26-mysql-error-2006.html" target="_blank">MySQL导入数据错误：ERROR 2006 (HY000) at line 1&#58; MySQL server has gone away</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-26-mysql-error-2006.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>mysqldump</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里云ECS Linux开启swap（虚拟内存）</title>
    <url>/%E8%BF%90%E7%BB%B4/2016-08-26-turn-on-swap-on-aliyun-linux.html</url>
    <content><![CDATA[<p>阿里云的服务器默认是不开启虚拟内存的，官方给出的理由如下：</p>
<blockquote>
<p>由于开启swap分区会导致硬盘IO性能下降，因此阿里云服务器初始状态未配置swap。</p>
</blockquote>
<p>这确实是个理由，开启swap对阿里云并没有什么太多的好处：</p>
<ol>
<li>开启swap分区会造成阿里云宿主机的磁盘负载增大，其一会影响磁盘IO性能，其次还会降低磁盘使用寿命；</li>
<li>在阿里云推出SSD之后，SSD的性能和内存性能的差距相对机械硬盘来说减小很多，SSD设置可以当内存使用。但是SSD和内存的价格差别不是一点半点。</li>
</ol>
<p>但是不开启swap，会造成很严重的后果：</p>
<ol>
<li>内存使用波动的时候会导致系统直接杀死某些进程，造成严重的系统不稳定因素，触发只是因为系统偶尔的一次波动而已。</li>
</ol>
<h2 id="开启swap的方法"><a href="#开启swap的方法" class="headerlink" title="开启swap的方法"></a>开启swap的方法</h2><h3 id="创建用于交换分区的文件"><a href="#创建用于交换分区的文件" class="headerlink" title="创建用于交换分区的文件"></a>创建用于交换分区的文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=/mnt/swap bs=1M count=4096</span><br></pre></td></tr></table></figure>
<p>注：<code>block_size</code>、<code>number_of_block</code>大小可以自定义，比如bs=1M count=4096代表设置4G大小swap分区</p>
<h3 id="设置交换分区文件"><a href="#设置交换分区文件" class="headerlink" title="设置交换分区文件"></a>设置交换分区文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkswap /mnt/swap</span><br></pre></td></tr></table></figure>

<h3 id="立即启用交换分区文件"><a href="#立即启用交换分区文件" class="headerlink" title="立即启用交换分区文件"></a>立即启用交换分区文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">swapon /mnt/swap</span><br></pre></td></tr></table></figure>
<p>如果在/etc/rc.local中有swapoff -a 需要修改为swapon -a</p>
<h3 id="设置开机时自启用swap分区"><a href="#设置开机时自启用swap分区" class="headerlink" title="设置开机时自启用swap分区"></a>设置开机时自启用swap分区</h3><p>需要修改文件/etc/fstab中的swap行。添加以下内容：</p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line">/mnt/<span class="keyword">swap</span> <span class="keyword">swap</span> <span class="keyword">swap</span> defaults <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>注：/mnt/swap 路径可以修改，可以根据创建的swap文件具体路径来配置。</p>
<p>设置后可以执行free -m命令查看效果：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">root@www:~#</span> <span class="string">free</span> <span class="string">-m</span></span><br><span class="line">             <span class="string">total</span>       <span class="string">used</span>       <span class="string">free</span>     <span class="string">shared</span>    <span class="string">buffers</span>     <span class="string">cached</span></span><br><span class="line"><span class="attr">Mem:</span>          <span class="number">7983       </span><span class="number">7784        </span><span class="number">199</span>          <span class="number">2</span>         <span class="number">70</span>       <span class="number">1158</span></span><br><span class="line"><span class="string">-/+</span> <span class="attr">buffers/cache:</span>       <span class="number">6555       </span><span class="number">1428</span></span><br><span class="line"><span class="attr">Swap:</span>         <span class="number">4095       </span><span class="number">1052       </span><span class="number">3043</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-08-26-turn-on-swap-on-aliyun-linux.html" target="_blank">阿里云ECS Linux开启swap（虚拟内存）</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-08-26-turn-on-swap-on-aliyun-linux.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>阿里云</tag>
        <tag>ECS</tag>
        <tag>swap</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL性能查看及调优参考</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-30-mysql-performance-and-tunning.html</url>
    <content><![CDATA[<p>网上有很多的文章教怎么配置MySQL服务器，但考虑到服务器硬件配置的不同，具体应用的差别，那些文章的做法只能作为初步设置参考，我们需要根据自己的情况进行配置优化，好的做法是MySQL服务器稳定运行了一段时间后运行，根据服务器的”状态”进行优化。</p>
<p>主要依赖两个命令，1）可以列出MySQL服务器运行各种状态值：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status;</span><br></pre></td></tr></table></figure>
<p>2）查询MySQL服务器配置信息语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables;</span><br></pre></td></tr></table></figure>

<h2 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">where</span> Variable_name <span class="keyword">like</span> <span class="string">&#x27;%slow_query_log%&#x27;</span> <span class="keyword">or</span> Variable_name <span class="keyword">like</span> <span class="string">&#x27;long_query%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+---------------------+-------------------------+</span><br><span class="line">|<span class="string"> Variable_name       </span>|<span class="string"> Value                   </span>|</span><br><span class="line">+---------------------+-------------------------+</span><br><span class="line">|<span class="string"> long_query_time     </span>|<span class="string"> 5.000000                </span>|</span><br><span class="line">|<span class="string"> slow_query_log      </span>|<span class="string"> ON                      </span>|</span><br><span class="line">|<span class="string"> slow_query_log_file </span>|<span class="string"> /var/log/mysql/slow.log </span>|</span><br><span class="line">+---------------------+-------------------------+</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;%slow%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+---------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name       | Value |</span></span><br><span class="line"><span class="section">+---------------------+-------+</span></span><br><span class="line">| Slow<span class="emphasis">_launch_threads | 0     |</span></span><br><span class="line"><span class="emphasis">| Slow_</span>queries        | 457   |</span><br><span class="line"><span class="code">+---------------------+</span>-------+</span><br></pre></td></tr></table></figure>
<p>配置中打开了记录慢查询，执行时间超过5秒的即为慢查询，系统显示有457个慢查询，你可以分析慢查询日志，找出有问题的SQL语句，慢查询时间不宜设置过长，否则意义不大，最好在5秒以内。</p>
<p><strong>Hint：</strong>打开慢查询日志可能会对系统性能有一点点影响，如果你的MySQL是主-从结构，可以考虑打开其中一台从服务器的慢查询日志，这样既可以监控慢查询，对系统性能影响又小。</p>
<h2 id="连接数"><a href="#连接数" class="headerlink" title="连接数"></a>连接数</h2><p>经常会遇见”MySQL: ERROR 1040: Too many connections”的情况，一种是访问量确实很高，MySQL服务器抗不住，这个时候就要考虑增加从服务器分散读压力，另外一种情况是MySQL配置文件中max_connections值过小：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;max_connections&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+-----------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name   | Value |</span></span><br><span class="line"><span class="section">+-----------------+-------+</span></span><br><span class="line"><span class="section">| max_connections | 1000  |</span></span><br><span class="line"><span class="section">+-----------------+-------+</span></span><br></pre></td></tr></table></figure>
<p>这台MySQL服务器最大连接数是1000，然后查询一下服务器响应的最大连接数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;Max_used_connections&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+----------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name        | Value |</span></span><br><span class="line"><span class="section">+----------------------+-------+</span></span><br><span class="line"><span class="section">| Max_used_connections | 299   |</span></span><br><span class="line"><span class="section">+----------------------+-------+</span></span><br></pre></td></tr></table></figure>

<p>MySQL服务器过去的最大连接数是299，没有达到服务器连接数上限1000，应该没有出现1040错误，比较理想的设置是：</p>
<blockquote>
<p>Max_used_connections / max_connections * 100% ≈ 85%</p>
</blockquote>
<p>最大连接数占上限连接数的85%左右，如果发现比例在10%以下，MySQL服务器连接数上限设置的过高了。</p>
<h2 id="临时表"><a href="#临时表" class="headerlink" title="临时表"></a>临时表</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;created_tmp%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+-------------------------+--------+</span><br><span class="line">|<span class="string"> Variable_name           </span>|<span class="string"> Value  </span>|</span><br><span class="line">+-------------------------+--------+</span><br><span class="line">|<span class="string"> Created_tmp_disk_tables </span>|<span class="string"> 15259  </span>|</span><br><span class="line">|<span class="string"> Created_tmp_files       </span>|<span class="string"> 3237   </span>|</span><br><span class="line">|<span class="string"> Created_tmp_tables      </span>|<span class="string"> 244972 </span>|</span><br><span class="line">+-------------------------+--------+</span><br></pre></td></tr></table></figure>
<p>每次创建临时表，Created_tmp_tables增加，如果是在磁盘上创建临时表，Created_tmp_disk_tables也增加,Created_tmp_files表示MySQL服务创建的临时文件文件数，比较理想的配置是：</p>
<blockquote>
<p>Created_tmp_disk_tables / Created_tmp_tables * 100% &lt;= 25%</p>
</blockquote>
<p>比如上面的服务器Created_tmp_disk_tables / Created_tmp_tables * 100% = 6.2%，应该可以了。我们再看一下MySQL服务器对临时表的配置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">where</span> Variable_name <span class="keyword">in</span> (<span class="string">&#x27;tmp_table_size&#x27;</span>, <span class="string">&#x27;max_heap_table_size&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+---------------------+</span>----------+</span><br><span class="line"><span class="section">| Variable_name       | Value    |</span></span><br><span class="line"><span class="section">+---------------------+----------+</span></span><br><span class="line">| max<span class="emphasis">_heap_table_size | 16777216 |</span></span><br><span class="line"><span class="emphasis">| tmp_table_</span>size      | 16777216 |</span><br><span class="line"><span class="code">+---------------------+</span>----------+</span><br></pre></td></tr></table></figure>
<p>只有16MB以下的临时表才能全部放内存，超过的就会用到硬盘临时表。</p>
<h2 id="Open-Table情况"><a href="#Open-Table情况" class="headerlink" title="Open Table情况"></a>Open Table情况</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;open%tables%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+---------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name | Value |</span></span><br><span class="line"><span class="section">+---------------+-------+</span></span><br><span class="line">| Open<span class="emphasis">_tables   | 953   |</span></span><br><span class="line"><span class="emphasis">| Opened_</span>tables | 1935  |</span><br><span class="line"><span class="code">+---------------+</span>-------+</span><br></pre></td></tr></table></figure>
<p>Open_tables表示打开表的数量，Opened_tables表示打开过的表数量，如果Opened_tables数量过大，说明配置中table_cache(5.1.3之后这个值叫做table_open_cache)值可能太小，我们查询一下服务器table_cache值：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%table_open%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+----------------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name              | Value |</span></span><br><span class="line"><span class="section">+----------------------------+-------+</span></span><br><span class="line">| table<span class="emphasis">_open_cache           | 2000  |</span></span><br><span class="line"><span class="emphasis">| table_open_cache_</span>instances | 1     |</span><br><span class="line"><span class="code">+----------------------------+</span>-------+</span><br></pre></td></tr></table></figure>
<p>比较合适的值为：</p>
<blockquote>
<p>Open_tables / Opened_tables * 100% &gt;= 85%<br>Open_tables / table_open_cache * 100% &lt;= 95%</p>
</blockquote>
<h2 id="进程使用情况"><a href="#进程使用情况" class="headerlink" title="进程使用情况"></a>进程使用情况</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;Thread%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+-------------------+-------+</span><br><span class="line">|<span class="string"> Variable_name     </span>|<span class="string"> Value </span>|</span><br><span class="line">+-------------------+-------+</span><br><span class="line">|<span class="string"> Threads_cached    </span>|<span class="string"> 1     </span>|</span><br><span class="line">|<span class="string"> Threads_connected </span>|<span class="string"> 280   </span>|</span><br><span class="line">|<span class="string"> Threads_created   </span>|<span class="string"> 12368 </span>|</span><br><span class="line">|<span class="string"> Threads_running   </span>|<span class="string"> 2     </span>|</span><br><span class="line">+-------------------+-------+</span><br></pre></td></tr></table></figure>
<p>如果我们在MySQL服务器配置文件中设置了thread_cache_size，当客户端断开之后，服务器处理此客户的线程将会缓存起来以响应下一个客户而不是销毁(前提是缓存数未达上限)。Threads_created表示创建过的线程数，如果发现Threads_created值过大的话，表明MySQL服务器一直在创建线程，这也是比较耗资源，可以适当增加配置文件中thread_cache_size值，查询服务器thread_cache_size配置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;thread_cache_size&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+-------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name     | Value |</span></span><br><span class="line"><span class="section">+-------------------+-------+</span></span><br><span class="line"><span class="section">| thread_cache_size | 64    |</span></span><br><span class="line"><span class="section">+-------------------+-------+</span></span><br></pre></td></tr></table></figure>

<h2 id="排序使用情况"><a href="#排序使用情况" class="headerlink" title="排序使用情况"></a>排序使用情况</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;sort%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+-------------------+----------+</span><br><span class="line">|<span class="string"> Variable_name     </span>|<span class="string"> Value    </span>|</span><br><span class="line">+-------------------+----------+</span><br><span class="line">|<span class="string"> Sort_merge_passes </span>|<span class="string"> 1012     </span>|</span><br><span class="line">|<span class="string"> Sort_range        </span>|<span class="string"> 519624   </span>|</span><br><span class="line">|<span class="string"> Sort_rows         </span>|<span class="string"> 14179389 </span>|</span><br><span class="line">|<span class="string"> Sort_scan         </span>|<span class="string"> 846266   </span>|</span><br><span class="line">+-------------------+----------+</span><br></pre></td></tr></table></figure>

<p>Sort_merge_passes 包括两步。MySQL 首先会尝试在内存中做排序，使用的内存大小由系统变量 Sort_buffer_size 决定，如果它的大小不够把所有的记录都读到内存中，MySQL 就会把每次在内存中排序的结果存到临时文件中，等 MySQL 找到所有记录之后，再把临时文件中的记录做一次排序。这再次排序就会增加 Sort_merge_passes。实际上，MySQL 会用另一个临时文件来存再次排序的结果，所以通常会看到 Sort_merge_passes 增加的数值是建临时文件数的两倍。因为用到了临时文件，所以速度可能会比较慢，增加 Sort_buffer_size 会减少 Sort_merge_passes 和 创建临时文件的次数。</p>
<p>另外，增加read_rnd_buffer_size(3.2.3是record_rnd_buffer_size)的值对排序的操作也有一点的好处，参见：<a href="http://www.mysqlperformanceblog.com/2007/07/24/what-exactly-is-read_rnd_buffer_size/">http://www.mysqlperformanceblog.com/2007/07/24/what-exactly-is-read_rnd_buffer_size/</a></p>
<h2 id="文件打开数"><a href="#文件打开数" class="headerlink" title="文件打开数"></a>文件打开数</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;open_files&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+---------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name | Value |</span></span><br><span class="line"><span class="section">+---------------+-------+</span></span><br><span class="line"><span class="section">| Open_files    | 30    |</span></span><br><span class="line"><span class="section">+---------------+-------+</span></span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;open_files_limit&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name    | Value |</span></span><br><span class="line"><span class="section">+------------------+-------+</span></span><br><span class="line"><span class="section">| open_files_limit | 65535 |</span></span><br><span class="line"><span class="section">+------------------+-------+</span></span><br></pre></td></tr></table></figure>

<p>比较合适的设置：</p>
<blockquote>
<p>Open_files / open_files_limit * 100% &lt;= 75%</p>
</blockquote>
<h2 id="表扫描情况"><a href="#表扫描情况" class="headerlink" title="表扫描情况"></a>表扫描情况</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;handler_read%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+-----------------------+-------------+</span><br><span class="line">|<span class="string"> Variable_name         </span>|<span class="string"> Value       </span>|</span><br><span class="line">+-----------------------+-------------+</span><br><span class="line">|<span class="string"> Handler_read_first    </span>|<span class="string"> 8525687     </span>|</span><br><span class="line">|<span class="string"> Handler_read_key      </span>|<span class="string"> 192321231   </span>|</span><br><span class="line">|<span class="string"> Handler_read_last     </span>|<span class="string"> 120         </span>|</span><br><span class="line">|<span class="string"> Handler_read_next     </span>|<span class="string"> 351154252   </span>|</span><br><span class="line">|<span class="string"> Handler_read_prev     </span>|<span class="string"> 46717985    </span>|</span><br><span class="line">|<span class="string"> Handler_read_rnd      </span>|<span class="string"> 13564471    </span>|</span><br><span class="line">|<span class="string"> Handler_read_rnd_next </span>|<span class="string"> 44813383354 </span>|</span><br><span class="line">+-----------------------+-------------+</span><br></pre></td></tr></table></figure>
<p>服务器完成的查询请求次数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;com_select&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+---------------+</span>----------+</span><br><span class="line"><span class="section">| Variable_name | Value    |</span></span><br><span class="line"><span class="section">+---------------+----------+</span></span><br><span class="line"><span class="section">| Com_select    | 27320750 |</span></span><br><span class="line"><span class="section">+---------------+----------+</span></span><br></pre></td></tr></table></figure>

<p>计算表扫描率：</p>
<blockquote>
<p>表扫描率 = Handler_read_rnd_next / Com_select</p>
</blockquote>
<p>如果表扫描率超过4000，说明进行了太多表扫描，很有可能索引没有建好，增加read_buffer_size值会有一些好处，但最好不要超过8MB。</p>
<h2 id="表锁情况"><a href="#表锁情况" class="headerlink" title="表锁情况"></a>表锁情况</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;table_locks%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+-----------------------+</span>----------+</span><br><span class="line"><span class="section">| Variable_name         | Value    |</span></span><br><span class="line"><span class="section">+-----------------------+----------+</span></span><br><span class="line">| Table<span class="emphasis">_locks_immediate | 28770420 |</span></span><br><span class="line"><span class="emphasis">| Table_locks_</span>waited    | 0        |</span><br><span class="line"><span class="code">+-----------------------+</span>----------+</span><br></pre></td></tr></table></figure>
<p>Table_locks_immediate表示立即释放表锁数，Table_locks_waited表示需要等待的表锁数，如果Table_locks_immediate / Table_locks_waited &gt; 5000，最好采用InnoDB引擎，因为InnoDB是行锁而MyISAM是表锁，对于高并发写入的应用InnoDB效果会好些。示例中的服务器Table_locks_immediate / Table_locks_waited = 235，MyISAM就足够了。</p>
<h2 id="Key-buffer-size"><a href="#Key-buffer-size" class="headerlink" title="Key_buffer_size"></a>Key_buffer_size</h2><p>key_buffer_size是对MyISAM表性能影响最大的一个参数，下面一台以MyISAM为主要存储引擎服务器的配置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;key_buffer_size&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+-----------------+</span>----------+</span><br><span class="line"><span class="section">| Variable_name   | Value    |</span></span><br><span class="line"><span class="section">+-----------------+----------+</span></span><br><span class="line"><span class="section">| key_buffer_size | 16777216 |</span></span><br><span class="line"><span class="section">+-----------------+----------+</span></span><br></pre></td></tr></table></figure>

<p>分配了16MB内存给key_buffer_size，我们再看一下key_buffer_size的使用情况：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;key_read%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+-------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name     | Value |</span></span><br><span class="line"><span class="section">+-------------------+-------+</span></span><br><span class="line">| Key<span class="emphasis">_read_requests | 31424 |</span></span><br><span class="line"><span class="emphasis">| Key_</span>reads         | 4     |</span><br><span class="line"><span class="code">+-------------------+</span>-------+</span><br></pre></td></tr></table></figure>

<p>一共有31424个索引读取请求，有4个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率：</p>
<blockquote>
<p>key_cache_miss_rate = Key_reads / Key_read_requests * 100%</p>
</blockquote>
<p>比如上面的数据，key_cache_miss_rate为0.0244%，4000个索引读取请求才有一个直接读硬盘，已经很BT了,key_cache_miss_rate在0.1%以下都很好(每1000个请求有一个直接读硬盘)，如果key_cache_miss_rate在0.01%以下的话，key_buffer_size分配的过多，可以适当减少。</p>
<p>MySQL服务器还提供了key_blocks_*参数：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;key_blocks_u%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+-------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name     | Value |</span></span><br><span class="line"><span class="section">+-------------------+-------+</span></span><br><span class="line">| Key<span class="emphasis">_blocks_unused | 13392 |</span></span><br><span class="line"><span class="emphasis">| Key_blocks_</span>used   | 51    |</span><br><span class="line"><span class="code">+-------------------+</span>-------+</span><br></pre></td></tr></table></figure>

<p>Key_blocks_unused表示未使用的缓存簇(blocks)数，Key_blocks_used表示曾经用到的最大的blocks数，比如这台服务器，所有的缓存都用到了，要么增加key_buffer_size，要么就是过渡索引了，把缓存占满了。比较理想的设置：</p>
<blockquote>
<p>Key_blocks_used / (Key_blocks_unused + Key_blocks_used) * 100% ≈ 80%</p>
</blockquote>
<h2 id="查询缓存-query-cache"><a href="#查询缓存-query-cache" class="headerlink" title="查询缓存(query cache)"></a>查询缓存(query cache)</h2><p><strong>注意：</strong>很多人不建议对这个选项调优，所以放到了最后。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">global</span> status <span class="keyword">like</span> <span class="string">&#x27;qcache%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+-------------------------+----------+</span><br><span class="line">|<span class="string"> Variable_name           </span>|<span class="string"> Value    </span>|</span><br><span class="line">+-------------------------+----------+</span><br><span class="line">|<span class="string"> Qcache_free_blocks      </span>|<span class="string"> 1        </span>|</span><br><span class="line">|<span class="string"> Qcache_free_memory      </span>|<span class="string"> 1031360  </span>|</span><br><span class="line">|<span class="string"> Qcache_hits             </span>|<span class="string"> 0        </span>|</span><br><span class="line">|<span class="string"> Qcache_inserts          </span>|<span class="string"> 0        </span>|</span><br><span class="line">|<span class="string"> Qcache_lowmem_prunes    </span>|<span class="string"> 0        </span>|</span><br><span class="line">|<span class="string"> Qcache_not_cached       </span>|<span class="string"> 27326355 </span>|</span><br><span class="line">|<span class="string"> Qcache_queries_in_cache </span>|<span class="string"> 0        </span>|</span><br><span class="line">|<span class="string"> Qcache_total_blocks     </span>|<span class="string"> 1        </span>|</span><br><span class="line">+-------------------------+----------+</span><br></pre></td></tr></table></figure>

<p>MySQL查询缓存变量解释：</p>
<ul>
<li>Qcache_free_blocks：缓存中相邻内存块的个数。数目大说明可能有碎片。FLUSH QUERY CACHE会对缓存中的碎片进行整理，从而得到一个空闲块。</li>
<li>Qcache_free_memory：缓存中的空闲内存。 </li>
<li>Qcache_hits：每次查询在缓存中命中时就增大</li>
<li>Qcache_inserts：每次插入一个查询时就增大。命中次数除以插入次数就是不中比率。</li>
<li>Qcache_lowmem_prunes：缓存出现内存不足并且必须要进行清理以便为更多查询提供空间的次数。这个数字最好长时间来看;如果这个数字在不断增长，就表示可能碎片非常严重，或者内存很少。(上面的 free_blocks和free_memory可以告诉您属于哪种情况) </li>
<li>Qcache_not_cached：不适合进行缓存的查询的数量，通常是由于这些查询不是 SELECT 语句或者用了now()之类的函数。</li>
<li>Qcache_queries_in_cache：当前缓存的查询(和响应)的数量。</li>
<li>Qcache_total_blocks：缓存中块的数量。</li>
</ul>
<p>我们再查询一下服务器关于query_cache的配置：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;query_cache%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">+------------------------------+---------+</span><br><span class="line">|<span class="string"> Variable_name                </span>|<span class="string"> Value   </span>|</span><br><span class="line">+------------------------------+---------+</span><br><span class="line">|<span class="string"> query_cache_limit            </span>|<span class="string"> 1048576 </span>|</span><br><span class="line">|<span class="string"> query_cache_min_res_unit     </span>|<span class="string"> 4096    </span>|</span><br><span class="line">|<span class="string"> query_cache_size             </span>|<span class="string"> 1048576 </span>|</span><br><span class="line">|<span class="string"> query_cache_type             </span>|<span class="string"> OFF     </span>|</span><br><span class="line">|<span class="string"> query_cache_wlock_invalidate </span>|<span class="string"> OFF     </span>|</span><br><span class="line">+------------------------------+---------+</span><br></pre></td></tr></table></figure>
<p>各字段的解释：</p>
<ul>
<li>query_cache_limit：超过此大小的查询将不缓存</li>
<li>query_cache_min_res_unit：缓存块的最小大小</li>
<li>query_cache_size：查询缓存大小</li>
<li>query_cache_type：缓存类型，决定缓存什么样的查询，示例中表示不缓存 select sql_no_cache 查询</li>
<li>query_cache_wlock_invalidate：当有其他客户端正在对MyISAM表进行写操作时，如果查询在query cache中，是否返回cache结果还是等写操作完成再读表获取结果。</li>
<li>query_cache_min_res_unit的配置是一柄”双刃剑”，默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费。</li>
<li>查询缓存碎片率 = Qcache_free_blocks / Qcache_total_blocks * 100%</li>
<li>如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。</li>
<li>查询缓存利用率 = (query_cache_size - Qcache_free_memory) / query_cache_size * 100%</li>
<li>查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小;查询缓存利用率在80%以上而且Qcache_lowmem_prunes &gt; 50的话说明query_cache_size可能有点小，要不就是碎片太多。</li>
<li>查询缓存命中率 = (Qcache_hits - Qcache_inserts) / Qcache_hits * 100%</li>
</ul>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-30-mysql-performance-and-tunning.html" target="_blank">MySQL性能查看及调优参考</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-08-30-mysql-performance-and-tunning.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Performance</tag>
        <tag>Tuning</tag>
      </tags>
  </entry>
  <entry>
    <title>开始使用Mesos和Marathon</title>
    <url>/%E8%BF%90%E7%BB%B4/2016-09-09-apache-mesos-getstarted.html</url>
    <content><![CDATA[<p>Marathon 是可以跟 Mesos 一起协作的一个 framework，用来运行持久性的应用。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>一共需要安装四种组件，mesos-master、marathon、zookeeper 需要安装到所有的主节点，mesos-slave 需要安装到从节点。mesos 利用 zookeeper 来进行主节点的同步，以及从节点发现主节点的过程。</p>
<h3 id="获取Docker镜像"><a href="#获取Docker镜像" class="headerlink" title="获取Docker镜像"></a>获取Docker镜像</h3><p>在主节点上拉取mesos-master、marathon、zookeeper相关镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull mesoscloud/zookeeper</span><br><span class="line">docker pull mesoscloud/mesos-master</span><br><span class="line">docker pull fify/marathon</span><br></pre></td></tr></table></figure>
<p>在从节点上拉取mesos-slave镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull mesoscloud/mesos-slave</span><br></pre></td></tr></table></figure>

<h3 id="启动主节点相关服务"><a href="#启动主节点相关服务" class="headerlink" title="启动主节点相关服务"></a>启动主节点相关服务</h3><p><strong>启动zookeeper</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -e MYID=1 -e SERVERS=192.168.1.2 --name=zookeeper --net=host --restart=always mesoscloud/zookeeper</span><br></pre></td></tr></table></figure>
<p>如果有多个节点，则<code>SERVERS</code>参数为多个IP，用“,”隔开。</p>
<p><strong>启动mesos-master</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -e MESOS_HOSTNAME=192.168.1.2 -e MESOS_IP=192.168.1.2 -e MESOS_QUORUM=1 -e MESOS_ZK=zk://192.168.1.2:2181/mesos --name mesos-master --net host --restart always mesoscloud/mesos-master</span><br></pre></td></tr></table></figure>

<p><strong>启动marathon</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -e MARATHON_HOSTNAME=192.168.1.2 -e MARATHON_MASTER=zk://192.168.1.2:2181/mesos -e MARATHON_ZK=zk://192.168.1.2:2181/marathon --name marathon -p 8097:8080 --restart always fify/marathon</span><br></pre></td></tr></table></figure>

<h3 id="启动从节点相关服务"><a href="#启动从节点相关服务" class="headerlink" title="启动从节点相关服务"></a>启动从节点相关服务</h3><p>分别启动三个从节点：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -e MESOS_HOSTNAME=192.168.1.2 -e MESOS_IP=192.168.1.2 -e MESOS_MASTER=zk://192.168.1.2:2181/mesos -v /sys/fs/cgroup:/sys/fs/cgroup -v /var/run/docker.sock:/var/run/docker.sock --name mesos-slave --net host --privileged --restart always mesoscloud/mesos-slave</span><br><span class="line">docker run -d -e MESOS_HOSTNAME=192.168.1.3 -e MESOS_IP=192.168.1.3 -e MESOS_MASTER=zk://192.168.1.2:2181/mesos -v /sys/fs/cgroup:/sys/fs/cgroup -v /var/run/docker.sock:/var/run/docker.sock --name mesos-slave --net host --privileged --restart always mesoscloud/mesos-slave</span><br><span class="line">docker run -d -e MESOS_HOSTNAME=192.168.1.4 -e MESOS_IP=192.168.1.4 -e MESOS_MASTER=zk://192.168.1.2:2181/mesos -v /sys/fs/cgroup:/sys/fs/cgroup -v /var/run/docker.sock:/var/run/docker.sock --name mesos-slave --net host --privileged --restart always mesoscloud/mesos-slave</span><br></pre></td></tr></table></figure>



<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-09-09-apache-mesos-getstarted.html" target="_blank">开始使用Mesos和Marathon</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/2016-09-09-apache-mesos-getstarted.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Mesos</tag>
        <tag>Marathon</tag>
      </tags>
  </entry>
  <entry>
    <title>ZooKeeper典型使用场景总结</title>
    <url>/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-09-09-zookeeper-senarios.html</url>
    <content><![CDATA[<blockquote>
<p>转载自：<a href="http://blog.csdn.net/derekjiang/article/details/8751100">http://blog.csdn.net/derekjiang/article/details/8751100</a></p>
</blockquote>
<p>ZooKeeper是一个高可用的分布式数据管理与系统协调框架。基于对Paxos算法的实现，使该框架保证了分布式环境中数据的强一致性，也正是基于这样的特性，使得zookeeper能够应用于很多场景。网上对zk的使用场景也有不少介绍，本文将结合作者身边的项目例子，系统的对zk的使用场景进行归类介绍。 值得注意的是，zk并不是生来就为这些场景设计，都是后来众多开发者根据框架的特性，摸索出来的典型使用方法。因此，也非常欢迎你分享你在ZK使用上的奇技淫巧。</p>
<h2 id="数据发布与订阅"><a href="#数据发布与订阅" class="headerlink" title="数据发布与订阅"></a>数据发布与订阅</h2><p>发布与订阅即所谓的配置管理，顾名思义就是将数据发布到zk节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，地址列表等就非常适合使用。</p>
<ol>
<li><strong>索引信息和集群中机器节点状态存</strong>放在zk的一些指定节点，供各个客户端订阅使用。</li>
<li><strong>系统日志（经过处理后的）存储</strong>，这些日志通常2-3天后被清除。</li>
<li><strong>应用中用到的一些配置信息</strong>集中管理，在应用启动的时候主动来获取一次，并且在节点上注册一个Watcher，以后每次配置有更新，实时通知到应用，获取最新配置信息。</li>
<li><strong>业务逻辑中需要用到的一些全局变量</strong>，比如一些消息中间件的消息队列通常有个offset，这个offset存放在zk上，这样集群中每个发送者都能知道当前的发送进度。</li>
<li><strong>系统中有些信息需要动态获取</strong>，并且还会存在人工手动去修改这个信息。以前通常是暴露出接口，例如JMX接口，有了zk后，只要将这些信息存放到zk节点上即可。</li>
</ol>
<h2 id="Name-Service"><a href="#Name-Service" class="headerlink" title="Name Service"></a>Name Service</h2><p>这个主要是作为分布式命名服务，通过调用zk的create node api，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。</p>
<h2 id="分布通知-协调"><a href="#分布通知-协调" class="headerlink" title="分布通知/协调"></a>分布通知/协调</h2><p>ZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理。</p>
<ol>
<li><strong>另一种心跳检测机制</strong>：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。</li>
<li><strong>另一种系统调度模式</strong>：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而zk就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。</li>
<li><strong>另一种工作汇报模式</strong>：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。</li>
</ol>
<p>总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合。</p>
<h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性，即用户只要完全相信每时每刻，zk集群中任意节点（一个zk server）上的相同znode的数据是一定是相同的。<strong>锁服务可以分为两类，一个是保持独占，另一个是控制时序</strong>。</p>
<p>所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。</p>
<p>控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。</p>
<h2 id="集群管理"><a href="#集群管理" class="headerlink" title="集群管理"></a>集群管理</h2><h3 id="集群机器监控"><a href="#集群机器监控" class="headerlink" title="集群机器监控"></a>集群机器监控</h3><p>这通常<strong>用于那种对集群中机器状态，机器在线率有较高要求的场景</strong>，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：1. 集群中机器有变动的时候，牵连修改的东西比较多。2. 有一定的延时。</p>
<p>利用ZooKeeper有两个特性，就可以实时另一种集群机器存活性监控系统：a. 客户端在节点 x 上注册一个Watcher，那么如果 x 的子节点变化了，会通知该客户端。b. 创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。</p>
<p>例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。</p>
<blockquote>
<p>在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成，然后同步到集群中其它机器。</p>
</blockquote>
<h3 id="Master选举"><a href="#Master选举" class="headerlink" title="Master选举"></a>Master选举</h3><p>在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。</p>
<p>利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。</p>
<p>利用这个特性，就能很轻易的在分布式环境中进行集群选取了。</p>
<p>另外，这种场景演化一下，就是动态Master选举。这就要用到 EPHEMERAL_SEQUENTIAL类型节点的特性了。</p>
<p>上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 , /currentMaster/{sessionId}-2 , /currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。</p>
<blockquote>
<p>Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。</p>
</blockquote>
<h2 id="分布式队列"><a href="#分布式队列" class="headerlink" title="分布式队列"></a>分布式队列</h2><p>队列方面，我目前感觉有两种，<strong>一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行</strong>。对于第一种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致，这里不再赘述。</p>
<p>第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-09-09-zookeeper-senarios.html" target="_blank">ZooKeeper典型使用场景总结</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/2016-09-09-zookeeper-senarios.html]]></content>
      <categories>
        <category>分布式系统</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu上使用USB安装APK到手机</title>
    <url>/%E5%AE%89%E5%8D%93/2016-09-20-install-apk-on-ubuntu.html</url>
    <content><![CDATA[<p>Ubuntu上可以使用<code>adb</code>命令安装APK到手机上。</p>
<h2 id="安装adb"><a href="#安装adb" class="headerlink" title="安装adb"></a>安装adb</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt-get install android-tools-adb</span><br></pre></td></tr></table></figure>

<h2 id="查看已经连接的设备"><a href="#查看已经连接的设备" class="headerlink" title="查看已经连接的设备"></a>查看已经连接的设备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adb devices</span><br></pre></td></tr></table></figure>
<p>输出如下结果：</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">fify<span class="variable">@fify</span>-<span class="title class_">Vostro</span><span class="number">-3902</span><span class="symbol">:~</span><span class="variable">$ </span>adb devices</span><br><span class="line"><span class="title class_">List</span> of devices attached</span><br><span class="line"><span class="title class_">ZLPFCI6L4LEUJJUG</span>        device</span><br></pre></td></tr></table></figure>

<h2 id="安装APK包到指定设备"><a href="#安装APK包到指定设备" class="headerlink" title="安装APK包到指定设备"></a>安装APK包到指定设备</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adb -s ZLPFCI6L4LEUJJUG install ~/Desktop/Irenshi_V3.3.1-27_release.apk</span><br></pre></td></tr></table></figure>
<p>其中<code>-s</code>指定要安装到哪一台设备。</p>
<p>输出如下，当出现<strong>Success</strong>的时候表示安装成功，这时可以在手机上运行已经安装的程序：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">fify</span>@fify-Vostro-<span class="number">3902</span>:~$ adb -s ZLPFCI6L4LEUJJUG install ~/Desktop/Irenshi_V3.<span class="number">3</span>.<span class="number">1</span>-<span class="number">27</span>_release.apk</span><br><span class="line"><span class="attribute">12243</span> KB/s (<span class="number">27987100</span> bytes in <span class="number">2</span>.<span class="number">232</span>s)</span><br><span class="line">        <span class="attribute">pkg</span>: /data/local/tmp/Irenshi_V3.<span class="number">3</span>.<span class="number">1</span>-<span class="number">27</span>_release.apk</span><br><span class="line"><span class="attribute">Success</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%AE%89%E5%8D%93/2016-09-20-install-apk-on-ubuntu.html" target="_blank">Ubuntu上使用USB安装APK到手机</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%AE%89%E5%8D%93/2016-09-20-install-apk-on-ubuntu.html]]></content>
      <categories>
        <category>安卓</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Android</tag>
        <tag>安卓</tag>
        <tag>USB</tag>
      </tags>
  </entry>
  <entry>
    <title>Android包（apk）手动签名</title>
    <url>/%E5%AE%89%E5%8D%93/2016-09-21-sign-apk-with-jarsigner.html</url>
    <content><![CDATA[<p>语法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jarsigner -verbose -keystore &lt;keystore file&gt; -signedjar &lt;output signed file&gt; &lt;apk to be signed&gt; &lt;<span class="built_in">alias</span>&gt;</span><br></pre></td></tr></table></figure>

<p>举例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jarsigner -verbose -keystore IrenshiRelease.keystore -signedjar signed.apk unsign.apk i人事</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%AE%89%E5%8D%93/2016-09-21-sign-apk-with-jarsigner.html" target="_blank">Android包（apk）手动签名</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%AE%89%E5%8D%93/2016-09-21-sign-apk-with-jarsigner.html]]></content>
      <categories>
        <category>安卓</category>
      </categories>
      <tags>
        <tag>安卓</tag>
        <tag>apk</tag>
        <tag>签名</tag>
      </tags>
  </entry>
  <entry>
    <title>批量转换文件编码</title>
    <url>/linux/2016-09-22-convert-file-charsets-batch.html</url>
    <content><![CDATA[<p>Linux上可以使用<code>enca</code>查看和转换文件编码。</p>
<h2 id="查看文件编码"><a href="#查看文件编码" class="headerlink" title="查看文件编码"></a>查看文件编码</h2><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line">enca [-<span class="symbol">L</span> <span class="symbol">LANGUAGE</span>] [<span class="symbol">FILE</span>]...</span><br></pre></td></tr></table></figure>

<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>以下命令可以查看一个中文文档采用了什么编码格式。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">enca -L zh_CN file.txt</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">fify</span>@fify-Vostro-<span class="number">3902</span>:~$ enca -L zh_CN password.txt</span><br><span class="line"><span class="attribute">Universal</span> transformation format <span class="number">8</span> bits; UTF-<span class="number">8</span></span><br></pre></td></tr></table></figure>

<h3 id="特别注意"><a href="#特别注意" class="headerlink" title="特别注意"></a>特别注意</h3><p>这个命令并不能100%正确的检测到文件编码，当文件中的汉字较少的时候就可能无法判断文件编码格式。（由此可见，<code>enca</code>命令也是根据文件中出现的特殊文字的编码范围“猜测”文件编码格式的。）</p>
<p>无法判断编码时输出如下：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">.<span class="regexp">/src/m</span>ain<span class="regexp">/res/</span>layout/activity_base_time_range_layout.xml: Unrecognized encoding</span><br></pre></td></tr></table></figure>

<h2 id="批量转换文件编码"><a href="#批量转换文件编码" class="headerlink" title="批量转换文件编码"></a>批量转换文件编码</h2><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">enca <span class="selector-attr">[-L LANGUAGE]</span> -x &lt;charset&gt; <span class="selector-attr">[FILE]</span></span><br></pre></td></tr></table></figure>

<h3 id="举例-1"><a href="#举例-1" class="headerlink" title="举例"></a>举例</h3><p>单个转换一个文件的编码时：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">enca</span> -L zh_CN -x UTF-<span class="number">8</span> file.txt</span><br></pre></td></tr></table></figure>
<p>批量转换某个目录下所有<code>.java</code>文件的编码：</p>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">find</span> . -name <span class="regexp">*.java</span> | xargs enca -L zh_CN -x UTF-<span class="number">8</span></span><br></pre></td></tr></table></figure>
<p><code>enca</code>还有一个好处就是如果文件本来就是你要转换的那种编码，它不会报错，还是会print出结果来。</p>
<h3 id="特别注意-1"><a href="#特别注意-1" class="headerlink" title="特别注意"></a>特别注意</h3><p>虽然<code>enca</code>会跳过已经是目标编码的文件，但是多次转换同一个文件还是有出错的风险，转换完成之后记得检查。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-09-22-convert-file-charsets-batch.html" target="_blank">批量转换文件编码</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-09-22-convert-file-charsets-batch.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>编码</tag>
        <tag>enca</tag>
      </tags>
  </entry>
  <entry>
    <title>设置VIM的编码格式</title>
    <url>/linux/2016-10-10-set-vim-encoding.html</url>
    <content><![CDATA[<p>有的时候使用vim打开中文文件的时候会出现乱码，原因是vim打开文件时使用的编码格式和文件的编码格式不一致。</p>
<h2 id="设置正确的编码格式以正确的显示中文"><a href="#设置正确的编码格式以正确的显示中文" class="headerlink" title="设置正确的编码格式以正确的显示中文"></a>设置正确的编码格式以正确的显示中文</h2><p>如果该文档使用utf8编码，则可以通过以下vim命令将编码格式设置为utf8：</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> encoding=utf-<span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>这样本来以乱码显示的中文就可以恢复本来面貌。</p>
<h2 id="设置VIM保存文件时的编码格式"><a href="#设置VIM保存文件时的编码格式" class="headerlink" title="设置VIM保存文件时的编码格式"></a>设置VIM保存文件时的编码格式</h2><p>为保证VIM编辑器保存的文件以utf8编码格式存储，可以先执行以下命令，然后再进行保存：</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> fileencodings=utf-<span class="number">8</span></span><br><span class="line"><span class="keyword">w</span></span><br></pre></td></tr></table></figure>

<h2 id="设置VIM默认编码格式"><a href="#设置VIM默认编码格式" class="headerlink" title="设置VIM默认编码格式"></a>设置VIM默认编码格式</h2><p>将以上两个命令加入到<code>~/.vimrc</code>文件中，则可以是VIM默认以utf8编码打开文件，并且以utf8编码存储文件：</p>
<figure class="highlight diff"><table><tr><td class="code"><pre><span class="line"><span class="addition">+set encoding=utf-8</span></span><br><span class="line"><span class="addition">+set fileencodings=utf-8</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/2016-10-10-set-vim-encoding.html" target="_blank">设置VIM的编码格式</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/2016-10-10-set-vim-encoding.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>编码</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>关于 Android Service 的介绍</title>
    <url>/%E5%AE%89%E5%8D%93/2016-10-14-introduction-to-android-service.html</url>
    <content><![CDATA[<blockquote>
<p>转载自：<a href="http://www.jianshu.com/p/63792fc84d94#">http://www.jianshu.com/p/63792fc84d94#</a></p>
</blockquote>
<p>Service 是 Android 的四大组件之一，它主要的作用是后台执行操作，Activity 属于带有 UI 界面跟用户进行交互，而 Service 则没有 UI 界面，所有的操作都是基于后台运行完成。并且 Service 跟 Activity 一样也是可以由其它的应用程序调用启动的，而且就算用户切换了应用程序，Service 依旧保持运行。一个组件如果与 Service 进行了绑定( bind ),就可以跟 Service 进行数据的交互，并且也可以跟不同的进程之间进行交互 (IPC)。通常会使用到 Service 的情况有进行网络请求，音乐的操控，文件的 I/O 操作等。</p>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>Service 通常是通过以下两种方式进行启动</p>
<h3 id="startService"><a href="#startService" class="headerlink" title="startService"></a>startService</h3><p>当组件(例如 activity)通过调用<code>startService()</code>来启动 Service 的时候。一旦启动后，Service 就会独立的在后台运行，即使调用的组件已经销毁了，Service 还是可以继续在后台运行。一般情况下，<strong>只需要进行一次单独的操作，不需要将操作后的结果返回给调用者的时候，会使用该方式启动 Service</strong>。例如，进行上传或者下载操作的时候，当操作完成后，Service 应该自行调用 <code>stopService()</code> 或 <code>stopSelf()</code> 来结束运行。</p>
<h3 id="bindService"><a href="#bindService" class="headerlink" title="bindService"></a>bindService</h3><p>当组件(例如 activity)通过调用 <code>bindService()</code> 来启动 Service 的时候。这种方式提供了 client - service 的接口，可以让调用组件跟 Service 进行发送请求及返回结果的操作，设置可以进行进程间的通信 (IPC)。只要有一个组件对该 Service 进行了绑定，那该 Service 就不会销毁。并且多个组件可以同时对一个 Service 进行绑定，只有在所有进行了绑定的组件都解绑的时候，Service 才会销毁。</p>
<p>尽管两种方式是分开讨论的，但是并不是互斥的关系，使用 startService 启动了 Service 后，也是可以进行绑定的。</p>
<blockquote>
<p><strong>注意：</strong>虽然 Service 是在后台运行，但是其实还是在主线程里进行所有的操作的。Service 在启动时除非单独进行了定义，否则不会运行在单独的线程或者进程里，而都是在主线程里。所以这表示任何能堵塞主线程的操作（例如音乐的播放或者网络请求）都应该单独开辟新的线程来进行操作，否则很容易出现 ANR 。</p>
</blockquote>
<hr>
<blockquote>
<p>如果某个组件是通过调用 startService() 的方式来启动了 Service，那这个 Service 就会一直在后台运行直到 Service 内部调用 stopSelf() 或某个组件调用 stopService() 来结束该 Service。</p>
</blockquote>
<blockquote>
<p>如果某个组件是通过调用 bindService() 的方式来启动了 Service，那这个 Service 就会一直在后台运行直到该组件与其解绑。Service 在没有任何组件绑定的时候，系统会将其销毁</p>
</blockquote>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>在创建一个 Service 时，必须要去继承 Service，并且要重写父类一些主要的方法来实现功能。以下是主要方法的介绍</p>
<h3 id="onStartCommand"><a href="#onStartCommand" class="headerlink" title="onStartCommand()"></a>onStartCommand()</h3><p>系统会调用这个函数当某个组件(例如 activity，fragment)通过调用 <code>startService()</code> 启动 Service 时。在该方法被调用后，Service 就会被启动并独立的在后台运行。如果重写了该方法，开发者需要在 Service 执行完操作后自行的调用 <code>stopSelf()</code> 或 <code>stopService()</code>来结束 Service。如果只是会通过绑定的方式 (bind) 的方式来启动 Service 则不需要重写该方法。</p>
<h3 id="onBind"><a href="#onBind" class="headerlink" title="onBind()"></a>onBind()</h3><p>当某个组件(例如 activity, fragment)通过调用 <code>bindService()</code>绑定的方式来启动 Service 的时候，系统会调用这个函数。在实现这个函数的时候，必须要返回一个 IBinder 的继承类，来与 Service 进行通信。这个函数是默认必须要重写的，但是如果不想通过绑定的方式来启动 Service，则可以直接返回 null</p>
<h3 id="onCreate"><a href="#onCreate" class="headerlink" title="onCreate()"></a>onCreate()</h3><p>系统会调用此方法在第一次启动 Service 的时候，用于初始化一些一次性的变量。<strong>如果 Service 已经启动了，则此方法就不会再别调用。</strong></p>
<h3 id="onDestroy"><a href="#onDestroy" class="headerlink" title="onDestroy()"></a>onDestroy()</h3><p>系统在 Service 即将被销毁的时候会调用此方法。Service 中如有用到 thread、listeners、receivers 等的时候，应该将这些的清理方法写在此方法内。</p>
<p>如果某个组件是通过调用 startService() 的方式来启动了 Service，那这个 Service 就会一直在后台运行直到 Service 内部调用 stopSelf() 或某个组件调用 stopService() 来结束该 Service。</p>
<p>如果某个组件是通过调用 bindService() 的方式来启动了 Service，那这个 Service 就会一直在后台运行直到该组件与其解绑。Service 在没有任何组件绑定的时候，系统会将其销毁</p>
<h2 id="使用Service"><a href="#使用Service" class="headerlink" title="使用Service"></a>使用Service</h2><p>下面的环节，将介绍如果通过上面讲述的两种方式来创建 Service</p>
<h3 id="在-Manifest-里声明-Service"><a href="#在-Manifest-里声明-Service" class="headerlink" title="在 Manifest 里声明 Service"></a>在 Manifest 里声明 Service</h3><p>类似于 Activity，所有的 Service 都要在 Manifest 里面进行声明，如下:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">manifest</span> <span class="attr">...</span> &gt;</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="tag">&lt;<span class="name">application</span> <span class="attr">...</span> &gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">service</span> <span class="attr">android:name</span>=<span class="string">&quot;.ExampleService&quot;</span> /&gt;</span></span><br><span class="line">      ...</span><br><span class="line">  <span class="tag">&lt;/<span class="name">application</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>查看 <a href="https://developer.android.com/guide/topics/manifest/service-element.html">&lt;service&gt;</a> 标签的官方文档来获取更多信息</p>
<p>通过在 &lt;service&gt; 标签里将 <code>android:exported</code> 设置为 false。可以防止其他的程序来启动你的 Service。</p>
<h3 id="通过-started-方式来启动-Service"><a href="#通过-started-方式来启动-Service" class="headerlink" title="通过 started 方式来启动 Service"></a>通过 started 方式来启动 Service</h3><p>组件(例如 activity, fragment) 通过调用 <code>startService()</code> 方法，系统随之调用 <code>onStartCommand()</code> 方法来实现 started 方式启动 Service。</p>
<p>当 Service 以该形式启动后，Service 的整个生命周期是完全独立的，即便启动 Service 的组件已经被销毁了，Service 还是可以在后台无限的运行的。但开发者应该在 Service 中的操作执行完成后，调用 <code>stopSelf()</code> 或其它组件调用 <code>stopService()</code> 的方式来结束该 Service。</p>
<p>程序组件(例如 activity) 可以通过传递一个 Intent 给 <code>startService()</code>,来实现组件与 Service 之前的数据传递。Service 是通过系统调用的 <code>onStartCommand()</code> 方法接受传递的Intent ，完成整个数据传递过程。</p>
<blockquote>
<p><strong>注意:</strong> Service 本身默认是运行在主线程里的，所以如果在 Service 要进行一些会堵塞线程的操作，一定要将这些操作放在一个新的线程里。</p>
</blockquote>
<p>Android 的框架提供了 <a href="https://developer.android.com/reference/android/app/IntentService.html">IntentService</a> 来满足后台运行异步线程的需求。</p>
<h4 id="IntentService"><a href="#IntentService" class="headerlink" title="IntentService"></a>IntentService</h4><p>IntentService 是 Service 的子类，并且所有的请求操作都是在异步线程里。<strong>如果不需要 Service 来同时处理多个请求的话，IntentService 将会是最佳的选择。</strong>只需要继承并重写 IntentService 中的 <code>onHandleIntent()</code> 方法，就可以对接受到的 Intent 做后台的异步线程操作了。</p>
<p>IntentService 提供了如下的几个功能:</p>
<ul>
<li>会创建一个异步线程来处理所有从程序主线程发送到 <code>onStartCommand()</code> 的 intents 。</li>
<li>创建了一个队列池来保证每次只有一个 Intent 传递到 <code>onHandleIntent()</code> 方法中，避免了多线程问题。</li>
<li>提供默认 <code>onBind()</code> 方法的实现，返回 null</li>
<li>提供默认 <code>onStartCommand()</code> 方法的实现，将收到的 intent 放到队列池中，然后再交由 <code>onHandleIntent()</code> 做处理</li>
</ul>
<p>所有开发者只需要实现 <code>onHandleIntent()</code> 关注于 Service 要进行的操作即可。关于更多的 IntentService 实用技巧，请查看此文章：<a href="https://github.com/codepath/android_guides/wiki/Starting-Background-Services%E3%80%82">https://github.com/codepath/android_guides/wiki/Starting-Background-Services。</a></p>
<p>如果开发者需要重写其他的一些方法，例如 <code>onCreate()</code>, <code>onStartCommand()</code>, 和 <code>onDestroy()</code>，请保证调用父类的实现，这样可以保证 IntentService 能够正确的来处理线程的生命周期。例如:</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">onStartCommand</span><span class="params">(Intent intent, <span class="type">int</span> flags, <span class="type">int</span> startId)</span> &#123;</span><br><span class="line">    Toast.makeText(<span class="built_in">this</span>, <span class="string">&quot;service starting&quot;</span>, Toast.LENGTH_SHORT).show();</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">super</span>.onStartCommand(intent,flags,startId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="系统回收资源问题"><a href="#系统回收资源问题" class="headerlink" title="系统回收资源问题"></a>系统回收资源问题</h4><p>当系统内存不足的时候，系统会强制回收一些 Activity 和 Service 来获取更多的资源给那些用户正在交互的程序或页面。这就要求当资源充足的时候 Service 能够自动重启。这个功能是通过 <code>onStartCommand()</code> 的返回值来实现的</p>
<h5 id="START-NOT-STICKY"><a href="#START-NOT-STICKY" class="headerlink" title="START_NOT_STICKY"></a>START_NOT_STICKY</h5><p>当系统因回收资源而销毁了 Service，当资源再次充足时不自动启动 Service。除非还有未处理的 Intent 准备发送。当你的程序可以很容易的重新开启未完成的操作时，这是最安全的避免 Service 在不必要的情况下启动的选项。</p>
<h5 id="START-STICKY"><a href="#START-STICKY" class="headerlink" title="START_STICKY"></a>START_STICKY</h5><p>当系统因回收资源而销毁了 Service，当资源再次充足时自动启动 Service，并且再次调用 <code>onStartCommand()</code> 方法，但是不会传递最后一次的 Intent，相反系统在回调<code>onStartCommand()</code> 的时候会传一个空 Intent 。除非还有未处理的 Intent 准备发送。</p>
<h5 id="START-REDELIVER-INTENT"><a href="#START-REDELIVER-INTENT" class="headerlink" title="START_REDELIVER_INTENT"></a>START_REDELIVER_INTENT</h5><p>当系统因回收资源而销毁了 Service，当资源再次充足时自动启动 Service，并且再次调用 <code>onStartCommand()</code> 方法，并会把最后一次 Intent 再次传递给<code>onStartCommand()</code>，相应的在队列里的 Intent 也会按次序依次传递。此模式适用于下载等服务。</p>
<h4 id="Start-Service"><a href="#Start-Service" class="headerlink" title="Start Service"></a>Start Service</h4><p>该方式允许多个组件同时对相同的 Service 进行 startService 操作，但是如果只要有其中有一个组件调用了 <code>stopSelf()</code> 或 <code>stopService()</code>, 该 Service 就会被销毁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Intent</span> <span class="variable">intent</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Intent</span>(<span class="built_in">this</span>, HelloService.class);</span><br><span class="line">startService(intent);</span><br></pre></td></tr></table></figure>

<h4 id="Stop-Service"><a href="#Stop-Service" class="headerlink" title="Stop Service"></a>Stop Service</h4><p>当有多个组件进行了 startService 操作时，不应该直接的去调用 <code>stopSelf()</code> 或 <code>stopService()</code> 来结束 Service， 因为这会对其他已经发起请求的操作产生影响，故在 <code>onStartCommand()</code> 方法中会接受一个 startId, 然后在结束 Service 时，调用 <code>stopService(int)</code> 方法来只是结束一个特定的请求，从而达到保护其他请求不受影响的目的。</p>
<h3 id="通过-Bind-方式启动-Service"><a href="#通过-Bind-方式启动-Service" class="headerlink" title="通过 Bind 方式启动 Service"></a>通过 Bind 方式启动 Service</h3><p>当应用程序中的 activity 或其它组件需要与服务进行交互，或者应用程序的某些功能需要暴露给其它应用程序时，你应该创建一个 Bind 服务，并通过进程间通信（IPC）来完成。</p>
<p>Service 只在为绑定的应用程序组件工作时才会存活，因此，只要没有组件绑定到服务，系统就会自动销毁服务</p>
<h4 id="获取-IBinder-实例"><a href="#获取-IBinder-实例" class="headerlink" title="获取 IBinder 实例"></a>获取 IBinder 实例</h4><h5 id="扩展-Binder-类"><a href="#扩展-Binder-类" class="headerlink" title="扩展 Binder 类"></a>扩展 Binder 类</h5><p>如果服务是你的应用程序所私有的，并且与客户端运行于同一个进程中（通常都是如此），你应该通过扩展 Binder 类来创建你的接口，并从 <code>onBind()</code> 返回一个它的实例。客户端接收该 Binder 对象并用它来直接访问 Binder 甚至 Service中可用的公共方法。</p>
<p><strong>如果你的服务只是为你自己的应用程序执行一些后台工作，那这就是首选的技术方案。</strong>不用这种方式来创建接口的理由只有一个，就是服务要被其它应用程序使用或者要跨多个进程使用。</p>
<h5 id="使用-Messenger"><a href="#使用-Messenger" class="headerlink" title="使用 Messenger"></a>使用 Messenger</h5><p>如果你需要接口跨越多个进程进行工作，可以通过 Messenger 来为服务创建接口。在这种方式下，服务定义一个响应各类消息对象 Message 的 Handler。此 Handler 是 Messenger 与客户端共享同一个 IBinder 的基础，它使得客户端可以用消息对象 Message向服务发送指令。此外，客户端还可以定义自己的 Message ，以便服务能够往回发送消息。</p>
<p>这是执行进程间通信（IPC）最为简便的方式，因为 Messenger 会把所有的请求放入一个独立进程中的队列，这样你就不一定非要把服务设计为线程安全的模式了。</p>
<h5 id="使用-AIDL"><a href="#使用-AIDL" class="headerlink" title="使用 AIDL"></a>使用 AIDL</h5><p>绝大多数应用程序都<strong>不应该</strong>用 AIDL 来创建 bind 服务，因为这可能需要多线程处理能力并且会让代码变得更为复杂。 因此，AIDL 对绝大多数应用程序都不适用，并且本文也不会讨论如何在服务中使用它的内容。如果你确信需要直接使用 AIDL，那请参阅 <a href="https://developer.android.com/guide/components/aidl.html">AIDL 文档</a>。</p>
<h4 id="扩展-Binder-类-1"><a href="#扩展-Binder-类-1" class="headerlink" title="扩展 Binder 类"></a>扩展 Binder 类</h4><p>如果你的服务只用于本地应用程序并且不需要跨进程工作，那你只要实现自己的 Binder 类即可，这样你的客户端就能直接访问服务中的公共方法了。</p>
<blockquote>
<p>注意：仅当客户端和服务位于同一个应用程序和进程中，这也是最常见的情况，这种方式才会有用。比如，一个音乐应用需要把一个 activity 绑定到它自己的后台音乐播放服务上，采用这种方式就会很不错。</p>
</blockquote>
<p>以下是设置步骤:</p>
<ol>
<li>在你的服务中，创建一个 Binder 的实例，其中实现以下三者之一：<ul>
<li>包含了可供客户端调用的公共方法</li>
<li>返回当前 Service 实例，其中包含了可供客户端调用的公共方法</li>
<li>或者，返回内含 Service 类的其它类的一个实例，Service 中包含了可供客户端调用的公共方法</li>
</ul>
</li>
<li>从回调方法 <code>onBind()</code> 中返回 Binder 的该实例</li>
<li>在客户端中，在回调方法 <code>onServiceConnected()</code> 中接收 Binder 并用所提供的方法对绑定的服务进行调用</li>
</ol>
<blockquote>
<p><strong>注意：</strong>服务和客户端之所以必须位于同一个应用程序中，是为了让客户端能够正确转换（cast）返回的对象并调用对象的 API。 服务和客户端也必须位于同一个进程中，因为这种方式不能执行任何跨进程的序列化（marshalling）操作。</p>
</blockquote>
<p>具体的实用案例请查看在<a href="https://android.googlesource.com/platform/development/+/master/samples/ApiDemos/">ApiDemos</a> 中的 <a href="https://android.googlesource.com/platform/development/+/master/samples/ApiDemos/src/com/example/android/apis/app/LocalService.java">LocalService.java</a> 类和 <a href="https://android.googlesource.com/platform/development/+/master/samples/ApiDemos/src/com/example/android/apis/app/LocalServiceActivities.java">LocalServiceActivities.java</a>。</p>
<h2 id="Service-的生命周期"><a href="#Service-的生命周期" class="headerlink" title="Service 的生命周期"></a>Service 的生命周期</h2><p><img src="/upload/images/13.png"></p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%AE%89%E5%8D%93/2016-10-14-introduction-to-android-service.html" target="_blank">关于 Android Service 的介绍</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%AE%89%E5%8D%93/2016-10-14-introduction-to-android-service.html]]></content>
      <categories>
        <category>安卓</category>
      </categories>
      <tags>
        <tag>安卓</tag>
        <tag>Android Service</tag>
      </tags>
  </entry>
  <entry>
    <title>以SQL方式读取MySQL的GTID格式Binlog</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-10-31-read-mysql-binlog-as-sql.html</url>
    <content><![CDATA[<p>将GTID格式的binlog转换为SQL的命令：</p>
<blockquote>
<p><code>mysqlbinlog --no-defaults -v --base64-output=DECODE-ROWS  --skip-gtids mysql-bin.000714</code></p>
</blockquote>
<hr>
<p>下面讲详细介绍每个参数的意义，以及为什么需要添加这些参数。</p>
<h2 id="MySQL及mysqlbinlog的版本"><a href="#MySQL及mysqlbinlog的版本" class="headerlink" title="MySQL及mysqlbinlog的版本"></a>MySQL及mysqlbinlog的版本</h2><h2 id="mysqlbinlog"><a href="#mysqlbinlog" class="headerlink" title="mysqlbinlog"></a>mysqlbinlog</h2><p><code>mysqlbinlog</code>是MySQL官方提供的读取binlog的工具。其执行方法如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqlbinlog [options] log_file ...</span><br></pre></td></tr></table></figure>

<h3 id="no-defaults参数"><a href="#no-defaults参数" class="headerlink" title="--no-defaults参数"></a><code>--no-defaults</code>参数</h3><p>直接执行<code>mysqlbinlog</code>命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqlbinlog mysql-bin.000858</span><br></pre></td></tr></table></figure>
<p>执行失败，报如下错误：</p>
<figure class="highlight tcl"><table><tr><td class="code"><pre><span class="line">mysqlbinlog: <span class="keyword">unknown</span> <span class="keyword">variable</span> &#x27;default-character-<span class="keyword">set</span>=utf8mb4&#x27;</span><br></pre></td></tr></table></figure>
<p>因为使用了默认编码，但是mysqlbinlog又无法正常解析。增加<code>--no-defaults</code>参数直接跳过默认编码格式。</p>
<p>手册中关于该参数的说明：</p>
<blockquote>
<p><strong>–no-defaults</strong></p>
</blockquote>
<blockquote>
<p>Do not read any option files. If program startup fails due to reading unknown options from an option file, –no-defaults can be used to prevent them from being read.</p>
</blockquote>
<blockquote>
<p>The exception is that the .mylogin.cnf file, if it exists, is read in all cases. This permits passwords to be specified in a safer way than on the command line even when –no-defaults is used. (.mylogin.cnf is created by the mysql_config_editor utility. See mysql_config_editor(1).)</p>
</blockquote>
<h3 id="v参数"><a href="#v参数" class="headerlink" title="-v参数"></a>-v参数</h3><p>增加<code>--no-defaults</code>参数，执行以下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqlbinlog --no-defaults mysql-bin.000858</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight gauss"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/</span>;</span><br><span class="line"><span class="comment">/*!40019 SET @@session.max_insert_delayed_threads=0*/</span>;</span><br><span class="line"><span class="comment">/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/</span>;</span><br><span class="line">DELIMITER <span class="comment">/*!*/</span>;</span><br><span class="line"><span class="meta"># at 4</span></span><br><span class="line"><span class="meta">#161123  4:17:00 server id 1  end_log_pos 120 CRC32 0x095b60fa  Start: binlog v 4, server v 5.6.27-0ubuntu0.14.04.1-log created 161123  4:17:00</span></span><br><span class="line">BINLOG &#x27;</span><br><span class="line">vKc0WA8BAAAAdAAAAHgAAAAAAAQANS42LjI3LTB1YnVudHUwLjE0LjA0LjEtbG9nAAAAAAAAAAAA</span><br><span class="line">AAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAAfpg</span><br><span class="line">Wwk=</span><br><span class="line">&#x27;<span class="comment">/*!*/</span>;</span><br><span class="line"><span class="meta"># at 120</span></span><br><span class="line"><span class="meta">#161123  4:17:00 server id 1  end_log_pos 231 CRC32 0xbbec3fba  Previous-GTIDs</span></span><br><span class="line"><span class="meta"># 9dc1a422-aeb6-11e5-80cd-00163e001e5d:1-5846827,</span></span><br><span class="line"><span class="meta"># fd076ada-69cf-11e6-84d8-00163e0c1dbe:1-381819</span></span><br><span class="line"><span class="meta"># at 231</span></span><br><span class="line"><span class="meta">#161123  4:17:00 server id 1  end_log_pos 279 CRC32 0x3f0812c4  GTID [commit=yes]</span></span><br><span class="line">SET <span class="comment">@@</span>SESSION.GTID_NEXT= &#x27;<span class="number">9</span>dc1a422-aeb6<span class="number">-11e5</span><span class="number">-80</span>cd<span class="number">-00163e001</span>e5d:<span class="number">5846828</span>&#x27;<span class="comment">/*!*/</span>;</span><br><span class="line"><span class="meta"># at 279</span></span><br><span class="line"><span class="meta">#161123  4:17:00 server id 1  end_log_pos 353 CRC32 0x6982c05a  Query   thread_id=2662386       exec_time=0     error_code=0</span></span><br><span class="line">SET TIMESTAMP=<span class="number">1479845820</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.pseudo_thread_id=<span class="number">2662386</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.foreign_key_checks=<span class="number">1</span>, <span class="comment">@@</span>session.sql_auto_is_null=<span class="number">0</span>, <span class="comment">@@</span>session.unique_checks=<span class="number">1</span>, <span class="comment">@@</span>session.autocommit=<span class="number">1</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.sql_mode=<span class="number">1075838976</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.auto_increment_increment=<span class="number">1</span>, <span class="comment">@@</span>session.auto_increment_offset=<span class="number">1</span><span class="comment">/*!*/</span>;</span><br><span class="line"><span class="comment">/*!\C utf8mb4 */</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.character_set_client=<span class="number">45</span>,<span class="comment">@@</span>session.collation_connection=<span class="number">45</span>,<span class="comment">@@</span>session.collation_server=<span class="number">224</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.lc_time_names=<span class="number">0</span><span class="comment">/*!*/</span>;</span><br><span class="line">SET <span class="comment">@@</span>session.collation_database=DEFAULT<span class="comment">/*!*/</span>;</span><br><span class="line">BEGIN</span><br><span class="line"><span class="comment">/*!*/</span>;</span><br><span class="line"><span class="meta"># at 353</span></span><br><span class="line"><span class="meta">#161123  4:17:00 server id 1  end_log_pos 450 CRC32 0xb1d11f47  Table_map: `linahr`.`qrtz_fired_triggers` mapped to number 877</span></span><br><span class="line"><span class="meta"># at 450</span></span><br><span class="line"><span class="meta">#161123  4:17:00 server id 1  end_log_pos 825 CRC32 0x0d1392a7  Update_rows: table id 877 flags: STMT_END_F</span></span><br><span class="line"></span><br><span class="line">BINLOG &#x27;</span><br><span class="line">vKc0WBMBAAAAYQAAAMIBAAAAAG0DAAAAAAEABmxpbmFocgATcXJ0el9maXJlZF90cmlnZ2VycwAN</span><br><span class="line">Dw8PDw8ICAMPDw8PDxRoAR0BWAJYAlgCMABYAlgCAwADAAAeRx/RsQ==</span><br><span class="line">vKc0WB8BAAAAdwEAADkDAAAAAG0DAAAAAAEAAgAN<span class="comment">/////wDmDABDUk1zY2hlZHVsZXImADEyYzZl</span></span><br><span class="line">ZWNkMDgwZTE0Nzc1ODMzMjQ0ODYxNDc3NTgzMzc2NjQyGABxY2xvdWRWaWRlb1VwbG9hZFRyaWdn</span><br><span class="line">ZXIHAERFRkFVTFQZADEyYzZlZWNkMDgwZTE0Nzc1ODMzMjQ0ODZTEa+NWAEAAGA2r41YAQAAAAAA</span><br></pre></td></tr></table></figure>
<p>其中并没有出现我们想要的SQL语句。这时候就需要增加<code>-v</code>参数了。</p>
<p><code>-v</code>参数在手册中的描述如下：</p>
<blockquote>
<p>–verbose, -v</p>
<p>Reconstruct row events and display them as commented SQL statements. If this option is given twice, the output includes comments to indicate column data types and some metadata.</p>
<p>For examples that show the effect of –base64-output and –verbose on row event output, see the section called “MYSQLBINLOG ROW EVENT DISPLAY”.</p>
</blockquote>
<p>增加<code>-v</code>参数，可以看到如下的输出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">BINLOG &#x27;</span><br><span class="line">vKc0WBMBAAAAXQAAAJYDAAAAAHQDAAAAAAMABmxpbmFocgANcXJ0el90cmlnZ2VycwAQDw8PDw8P</span><br><span class="line">CAgDDw8ICA8C/BNoAVgCWAJYAlgC7gIwABgAWAIC4PGAPOuQ</span><br><span class="line">vKc0WB8BAAAAOwEAANEEAAAAAHQDAAAAAAEAAgAQ/////yAgDABDUk1zY2hlZHVsZXIYAHFjbG91</span><br><span class="line">ZFZpZGVvVXBsb2FkVHJpZ2dlcgcAREVGQVVMVBcAcWNsb3VkVmlkZW9VcGxvYWREZXRhaWwHAERF</span><br><span class="line">RkFVTFRgNq+NWAEAAABMro1YAQAAAAAAAAhBQ1FVSVJFRARDUk9OeD/UBlgBAAAAAAAAAAAAAAAA</span><br><span class="line">AAAgIAwAQ1JNc2NoZWR1bGVyGABxY2xvdWRWaWRlb1VwbG9hZFRyaWdnZXIHAERFRkFVTFQXAHFj</span><br><span class="line">bG91ZFZpZGVvVXBsb2FkRGV0YWlsBwBERUZBVUxUwCCwjVgBAABgNq+NWAEAAAAAAAAHV0FJVElO</span><br><span class="line">RwRDUk9OeD/UBlgBAAAAAAAAAAAAAAAAAAAIicmV</span><br><span class="line">&#x27;/*!*/;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## UPDATE `linahr`.`qrtz_triggers`</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## WHERE</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @1=&#x27;CRMscheduler&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @2=&#x27;qcloudVideoUploadTrigger&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @3=&#x27;DEFAULT&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @4=&#x27;qcloudVideoUploadDetail&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @5=&#x27;DEFAULT&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @6=NULL</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @7=1479845820000</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @8=1479845760000</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @9=0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @10=&#x27;ACQUIRED&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @11=&#x27;CRON&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @12=1477583323000</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @13=0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @14=NULL</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @15=0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @16=&#x27;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">## SET</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @1=&#x27;CRMscheduler&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @2=&#x27;qcloudVideoUploadTrigger&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @3=&#x27;DEFAULT&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @4=&#x27;qcloudVideoUploadDetail&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @5=&#x27;DEFAULT&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @6=NULL</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @7=1479845880000</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @8=1479845820000</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @9=0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @10=&#x27;WAITING&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @11=&#x27;CRON&#x27;</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @12=1477583323000</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @13=0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @14=NULL</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @15=0</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment">##   @16=&#x27;&#x27;</span></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">at 1233</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">161123  4:17:00 server <span class="built_in">id</span> 1  end_log_pos 1264 CRC32 0x484eacf5         Xid = 447774161</span></span><br><span class="line">COMMIT/*!*/;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">at 1264</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">161123  4:17:00 server <span class="built_in">id</span> 1  end_log_pos 1312 CRC32 0xc364953c         GTID [commit=<span class="built_in">yes</span>]</span></span><br><span class="line">SET @@SESSION.GTID_NEXT= &#x27;9dc1a422-aeb6-11e5-80cd-00163e001e5d:5846829&#x27;/*!*/;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">at 1312</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">161123  4:17:00 server <span class="built_in">id</span> 1  end_log_pos 1386 CRC32 0xbf84bd5c         Query   thread_id=2662325       exec_time=0     error_code=0</span></span><br><span class="line">SET TIMESTAMP=1479845820/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">at 1386</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">161123  4:17:00 server <span class="built_in">id</span> 1  end_log_pos 1483 CRC32 0xb85e9cff         Table_map: `linahr`.`qrtz_fired_triggers` mapped to number 877</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">at 1483</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">161123  4:17:00 server <span class="built_in">id</span> 1  end_log_pos 1691 CRC32 0x1447d61d         Delete_rows: table <span class="built_in">id</span> 877 flags: STMT_END_F</span></span><br></pre></td></tr></table></figure>
<p>增加<code>-vv</code>参数，还可以输出一些额外的数据类型信息。如下：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">BINLOG <span class="string">&#x27;</span></span><br><span class="line"><span class="string">vKc0WBMBAAAAYQAAAMIBAAAAAG0DAAAAAAEABmxpbmFocgATcXJ0el9maXJlZF90cmlnZ2VycwAN</span></span><br><span class="line"><span class="string">Dw8PDw8ICAMPDw8PDxRoAR0BWAJYAlgCMABYAlgCAwADAAAeRx/RsQ==</span></span><br><span class="line"><span class="string">vKc0WB8BAAAAdwEAADkDAAAAAG0DAAAAAAEAAgAN/////wDmDABDUk1zY2hlZHVsZXImADEyYzZl</span></span><br><span class="line"><span class="string">ZWNkMDgwZTE0Nzc1ODMzMjQ0ODYxNDc3NTgzMzc2NjQyGABxY2xvdWRWaWRlb1VwbG9hZFRyaWdn</span></span><br><span class="line"><span class="string">ZXIHAERFRkFVTFQZADEyYzZlZWNkMDgwZTE0Nzc1ODMzMjQ0ODZTEa+NWAEAAGA2r41YAQAAAAAA</span></span><br><span class="line"><span class="string">AAhBQ1FVSVJFRAEwATAA4AwAQ1JNc2NoZWR1bGVyJgAxMmM2ZWVjZDA4MGUxNDc3NTgzMzI0NDg2</span></span><br><span class="line"><span class="string">MTQ3NzU4MzM3NjY0MhgAcWNsb3VkVmlkZW9VcGxvYWRUcmlnZ2VyBwBERUZBVUxUGQAxMmM2ZWVj</span></span><br><span class="line"><span class="string">ZDA4MGUxNDc3NTgzMzI0NDg2dTavjVgBAABgNq+NWAEAAAAAAAAJRVhFQ1VUSU5HFwBxY2xvdWRW</span></span><br><span class="line"><span class="string">aWRlb1VwbG9hZERldGFpbAcAREVGQVVMVAEwATCnkhMN</span></span><br><span class="line"><span class="string">&#x27;</span><span class="comment">/*!*/</span>;</span><br><span class="line">### <span class="keyword">UPDATE</span> `linahr`.`qrtz_fired_triggers`</span><br><span class="line">### <span class="keyword">WHERE</span></span><br><span class="line">###   <span class="variable">@1</span><span class="operator">=</span><span class="string">&#x27;CRMscheduler&#x27;</span> <span class="comment">/* VARSTRING(360) meta=360 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@2</span><span class="operator">=</span><span class="string">&#x27;12c6eecd080e14775833244861477583376642&#x27;</span> <span class="comment">/* VARSTRING(285) meta=285 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@3</span><span class="operator">=</span><span class="string">&#x27;qcloudVideoUploadTrigger&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@4</span><span class="operator">=</span><span class="string">&#x27;DEFAULT&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@5</span><span class="operator">=</span><span class="string">&#x27;12c6eecd080e1477583324486&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@6</span><span class="operator">=</span><span class="number">1479845810515</span> <span class="comment">/* LONGINT meta=0 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@7</span><span class="operator">=</span><span class="number">1479845820000</span> <span class="comment">/* LONGINT meta=0 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@8</span><span class="operator">=</span><span class="number">0</span> <span class="comment">/* INT meta=0 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@9</span><span class="operator">=</span><span class="string">&#x27;ACQUIRED&#x27;</span> <span class="comment">/* VARSTRING(48) meta=48 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@10</span><span class="operator">=</span><span class="keyword">NULL</span> <span class="comment">/* VARSTRING(48) meta=600 nullable=1 is_null=1 */</span></span><br><span class="line">###   <span class="variable">@11</span><span class="operator">=</span><span class="keyword">NULL</span> <span class="comment">/* VARSTRING(48) meta=600 nullable=1 is_null=1 */</span></span><br><span class="line">###   <span class="variable">@12</span><span class="operator">=</span><span class="string">&#x27;0&#x27;</span> <span class="comment">/* VARSTRING(3) meta=3 nullable=1 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@13</span><span class="operator">=</span><span class="string">&#x27;0&#x27;</span> <span class="comment">/* VARSTRING(3) meta=3 nullable=1 is_null=0 */</span></span><br><span class="line">### <span class="keyword">SET</span></span><br><span class="line">###   <span class="variable">@1</span><span class="operator">=</span><span class="string">&#x27;CRMscheduler&#x27;</span> <span class="comment">/* VARSTRING(360) meta=360 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@2</span><span class="operator">=</span><span class="string">&#x27;12c6eecd080e14775833244861477583376642&#x27;</span> <span class="comment">/* VARSTRING(285) meta=285 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@3</span><span class="operator">=</span><span class="string">&#x27;qcloudVideoUploadTrigger&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@4</span><span class="operator">=</span><span class="string">&#x27;DEFAULT&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@5</span><span class="operator">=</span><span class="string">&#x27;12c6eecd080e1477583324486&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@6</span><span class="operator">=</span><span class="number">1479845820021</span> <span class="comment">/* LONGINT meta=0 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@7</span><span class="operator">=</span><span class="number">1479845820000</span> <span class="comment">/* LONGINT meta=0 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@8</span><span class="operator">=</span><span class="number">0</span> <span class="comment">/* INT meta=0 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@9</span><span class="operator">=</span><span class="string">&#x27;EXECUTING&#x27;</span> <span class="comment">/* VARSTRING(48) meta=48 nullable=0 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@10</span><span class="operator">=</span><span class="string">&#x27;qcloudVideoUploadDetail&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=1 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@11</span><span class="operator">=</span><span class="string">&#x27;DEFAULT&#x27;</span> <span class="comment">/* VARSTRING(600) meta=600 nullable=1 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@12</span><span class="operator">=</span><span class="string">&#x27;0&#x27;</span> <span class="comment">/* VARSTRING(3) meta=3 nullable=1 is_null=0 */</span></span><br><span class="line">###   <span class="variable">@13</span><span class="operator">=</span><span class="string">&#x27;0&#x27;</span> <span class="comment">/* VARSTRING(3) meta=3 nullable=1 is_null=0 */</span></span><br><span class="line"># <span class="keyword">at</span> <span class="number">825</span></span><br><span class="line">#<span class="number">161123</span>  <span class="number">4</span>:<span class="number">17</span>:<span class="number">00</span> server id <span class="number">1</span>  end_log_pos <span class="number">918</span> CRC32 <span class="number">0x90eb3c80</span>  Table_map: `linahr`.`qrtz_triggers` mapped <span class="keyword">to</span> number <span class="number">884</span></span><br><span class="line"># <span class="keyword">at</span> <span class="number">918</span></span><br><span class="line">#<span class="number">161123</span>  <span class="number">4</span>:<span class="number">17</span>:<span class="number">00</span> server id <span class="number">1</span>  end_log_pos <span class="number">1233</span> CRC32 <span class="number">0x95c98908</span>         Update_rows: <span class="keyword">table</span> id <span class="number">884</span> flags: STMT_END_F</span><br></pre></td></tr></table></figure>

<h3 id="base64-output-DECODE-ROWS参数"><a href="#base64-output-DECODE-ROWS参数" class="headerlink" title="--base64-output=DECODE-ROWS参数"></a><code>--base64-output=DECODE-ROWS</code>参数</h3><p><code>--base64-decode</code>参数在手册上的说明如下：</p>
<blockquote>
<p>–base64-output=value</p>
<p>This option determines when events should be displayed encoded as base-64 strings using BINLOG statements. The option has these permissible values (not case sensitive):</p>
</blockquote>
<blockquote>
<p>·   AUTO (“automatic”) or UNSPEC (“unspecified”) displays BINLOG statements automatically when necessary (that is, for format description events and row events). If no –base64-output option is given, the effect is the same as –base64-output=AUTO.</p>
</blockquote>
<blockquote>
<pre><code>   Note
   Automatic BINLOG display is the only safe behavior if you intend to use the output of mysqlbinlog to re-execute binary log file contents. The other option values are intended only for debugging or testing purposes because they may produce output that does not include all events in executable form.
</code></pre>
</blockquote>
<blockquote>
<p>·   NEVER causes BINLOG statements not to be displayed.  mysqlbinlog exits with an error if a row event is found that must be displayed using BINLOG.</p>
</blockquote>
<blockquote>
<p>·   DECODE-ROWS specifies to mysqlbinlog that you intend for row events to be decoded and displayed as commented SQL statements by also specifying the –verbose option. Like NEVER, DECODE-ROWS suppresses display of BINLOG statements, but unlike NEVER, it does not exit with an error if a row event is found.</p>
</blockquote>
<blockquote>
<p>For examples that show the effect of –base64-output and –verbose on row event output, see the section called “MYSQLBINLOG ROW EVENT DISPLAY”.</p>
</blockquote>
<p>增加<code>--base64-output=DECODE-ROWS</code>参数执行：</p>
<figure class="highlight brainfuck"><table><tr><td class="code"><pre><span class="line"><span class="comment">mysqlbinlog</span> <span class="literal">--</span><span class="comment">no</span><span class="literal">-</span><span class="comment">defaults</span> <span class="literal">-</span><span class="comment">v</span> <span class="literal">--</span><span class="comment">base64</span><span class="literal">-</span><span class="comment">output=DECODE</span><span class="literal">-</span><span class="comment">ROWS mysql</span><span class="literal">-</span><span class="comment">bin</span><span class="string">.</span><span class="comment">000858</span> &gt; <span class="comment">tmp</span><span class="string">.</span><span class="comment">txt</span></span><br></pre></td></tr></table></figure>
<p>输出如下，可以看到<code>BINLOG &#39;</code>开头，以base64编码的数据没有了：</p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">SET TIMESTAMP=<span class="number">1479845826</span><span class="comment">/*!*/</span>;</span><br><span class="line">BEGIN</span><br><span class="line"><span class="comment">/*!*/</span>;</span><br><span class="line"># at <span class="number">2697</span></span><br><span class="line">#<span class="number">161123</span>  <span class="number">4</span>:<span class="number">17</span>:<span class="number">06</span> server id <span class="number">1</span>  end_log_pos <span class="number">2773</span> CRC32 <span class="number">0x3b984e8d</span>         Table_map: `linahr_pay`.`qrtz_scheduler_state` mapped to number <span class="number">1180</span></span><br><span class="line"># at <span class="number">2773</span></span><br><span class="line">#<span class="number">161123</span>  <span class="number">4</span>:<span class="number">17</span>:<span class="number">06</span> server id <span class="number">1</span>  end_log_pos <span class="number">2925</span> CRC32 <span class="number">0x394f0f8b</span>         Update_rows: table id <span class="number">1180</span> flags: STMT_END_F</span><br><span class="line">### UPDATE `linahr_pay`.`qrtz_scheduler_state`</span><br><span class="line">### WHERE</span><br><span class="line">###   @<span class="number">1</span>=<span class="string">&#x27;CRMscheduler&#x27;</span></span><br><span class="line">###   @<span class="number">2</span>=<span class="string">&#x27;f5589e5e5a731477582086079&#x27;</span></span><br><span class="line">###   @<span class="number">3</span>=<span class="number">1479845806492</span></span><br><span class="line">###   @<span class="number">4</span>=<span class="number">20000</span></span><br><span class="line">### SET</span><br><span class="line">###   @<span class="number">1</span>=<span class="string">&#x27;CRMscheduler&#x27;</span></span><br><span class="line">###   @<span class="number">2</span>=<span class="string">&#x27;f5589e5e5a731477582086079&#x27;</span></span><br><span class="line">###   @<span class="number">3</span>=<span class="number">1479845826494</span></span><br><span class="line">###   @<span class="number">4</span>=<span class="number">20000</span></span><br><span class="line"># at <span class="number">2925</span></span><br><span class="line">#<span class="number">161123</span>  <span class="number">4</span>:<span class="number">17</span>:<span class="number">06</span> server id <span class="number">1</span>  end_log_pos <span class="number">2956</span> CRC32 <span class="number">0x7d1d1eab</span>         Xid = <span class="number">447774290</span></span><br><span class="line">COMMIT<span class="comment">/*!*/</span>;</span><br></pre></td></tr></table></figure>

<h3 id="skip-gtids参数"><a href="#skip-gtids参数" class="headerlink" title="--skip-gtids参数"></a><code>--skip-gtids</code>参数</h3><blockquote>
<p>–skip-gtids[=(true|false)]</p>
</blockquote>
<blockquote>
<p>Do not display any GTIDs in the output. This is needed when writing to a dump file from one or more binary logs containing GTIDs, as shown in this example:</p>
</blockquote>
<blockquote>
<pre><code>   shell&gt; mysqlbinlog --skip-gtids binlog.000001 &gt;  /tmp/dump.sql
   shell&gt; mysqlbinlog --skip-gtids binlog.000002 &gt;&gt; /tmp/dump.sql
   shell&gt; mysql -u root -p -e &quot;source /tmp/dump.sql&quot;
</code></pre>
</blockquote>
<blockquote>
<p>The use of this option is otherwise not normally recommended in production.</p>
</blockquote>
<h2 id="最终命令"><a href="#最终命令" class="headerlink" title="最终命令"></a>最终命令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqlbinlog --no-defaults -v --base64-output=DECODE-ROWS --skip-gtids mysql-bin.000858</span><br></pre></td></tr></table></figure>

<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-10-31-read-mysql-binlog-as-sql.html" target="_blank">以SQL方式读取MySQL的GTID格式Binlog</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/2016-10-31-read-mysql-binlog-as-sql.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>GTID</tag>
        <tag>Binlog</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Framework的整体架构</title>
    <url>/spring/2017-03-02-spring-framework-architecture.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Spring Framework 作为一个优秀的开源框架，是为了解决企业应用程序开发复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许您选择使用哪一个组件，同时为J2EE应用程序开发提供集成的框架。</p>
<h2 id="Spring-Framework的整体架构"><a href="#Spring-Framework的整体架构" class="headerlink" title="Spring Framework的整体架构"></a>Spring Framework的整体架构</h2><p>Spring Framework总共有十几个组件，其中核心组件只有三个：Core、Context和Beans。</p>
<h3 id="Spring-Framework-3-x-的总体架构图"><a href="#Spring-Framework-3-x-的总体架构图" class="headerlink" title="Spring Framework 3.x 的总体架构图"></a>Spring Framework 3.x 的总体架构图</h3><p><img src="/upload/images/14.png" alt="Spring 3.x总体架构图"></p>
<p>组成 Spring Framework的每个模块（或组件）都可以单独存在，或者与其他一个或多个模块联合实现。每个模块的功能如下：</p>
<ul>
<li><p><strong>Spring Core（核心容器）：</strong> 核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转（IOC）模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。</p>
</li>
<li><p><strong>Spring Context（上下文）：</strong> Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如：JNDI、EJB、电子邮件、国际化、校验和调度功能。</p>
</li>
<li><p><strong>Spring AOP：</strong> 通过配置管理特性，Spring AOP 模块直接将面向方面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。</p>
</li>
<li><p><strong>Spring DAO：</strong> JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。</p>
</li>
<li><p><strong>Spring ORM：</strong> Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。</p>
</li>
<li><p><strong>Spring Web 模块：</strong> Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。</p>
</li>
<li><p><strong>Spring MVC 框架：</strong> MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。</p>
</li>
</ul>
<p>从图中可以看出，IOC 的实现包 spring-beans 和 AOP 的实现包 spring-aop 也是整个框架的基础，而 spring-core 是整个框架的核心，基础的功能都在这里。</p>
<p>在此基础之上，spring-context 提供上下文环境，为各个模块提供粘合作用。</p>
<p>在 spring-context 基础之上提供了 spring-tx 和 spring-orm包，而web部分的功能，都是要依赖spring-web来实现的。</p>
<h3 id="Spring-Framework-4-x-的系统架构图"><a href="#Spring-Framework-4-x-的系统架构图" class="headerlink" title="Spring Framework 4.x 的系统架构图"></a>Spring Framework 4.x 的系统架构图</h3><p><img src="/upload/images/15.png" alt="Spring Framework 4.x 的系统架构图"></p>
<p><strong>Spring Framework 4.x对比Spring Framework 3.2.x的系统架构变化：</strong></p>
<ol>
<li><p>Spring 4.0.3去掉了 struts 模块(spring-struts包)</p>
<p>现在的 Spring mvc的确已经足够优秀了，大量的 web 应用均已经使用了 Spring mvc。而 struts1.x 的架构太落后了，struts2.x 是 struts 自身提供了和 Spring 的集成包，但是由于之前版本的 struts2 存在很多致命的安全漏洞，所以，大大影响了其使用度，好在最新的2.3.16版本的 struts 安全有所改善，希望不会再出什么大乱子。</p>
</li>
<li><p>增加 WebSocket 模块(spring-websocket包)</p>
<p>增加了对 WebSocket、SockJS 以及 STOMP 的支持，它与 JSR-356 Java WebSocket API 兼容。另外，还提供了基于 SockJS（对 WebSocket 的模拟）的回调方案，以适应不支持 WebSocket 协议的浏览器。</p>
</li>
<li><p>增加了 messaging 模块(spring-messaging)</p>
<p>提供了对 STOMP 的支持，以及用于路由和处理来自 WebSocket 客户端的 STOMP 消息的注解编程模型。spring-messaging 模块中还 包含了 Spring Integration 项目中的核心抽象类，如 Message、MessageChannel、MessageHandler。</p>
</li>
<li><p>加强了 beans 模块，增加spring-beans-groovy</p>
<p>应用可以部分或完全使用 Groovy 编写。借助于 Spring 4.0，能够使用 Groovy DSL 定义外部的 Bean 配置，这类似于 XML Bean 声明，但是语法更为简洁。使用Groovy还能够在启动代码中直接嵌入Bean的声明。</p>
</li>
</ol>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/spring/2017-03-02-spring-framework-architecture.html" target="_blank">Spring Framework的整体架构</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/spring/2017-03-02-spring-framework-architecture.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Framework: Modules</title>
    <url>/spring/2017-03-09-spring-framework-modules.html</url>
    <content><![CDATA[<blockquote>
<p>Reference: <a href="https://docs.spring.io/spring/docs/4.3.0.BUILD-SNAPSHOT/spring-framework-reference/htmlsingle/#overview-modules">https://docs.spring.io/spring/docs/4.3.0.BUILD-SNAPSHOT/spring-framework-reference/htmlsingle/#overview-modules</a></p>
</blockquote>
<h2 id="Spring-Framework-Modules"><a href="#Spring-Framework-Modules" class="headerlink" title="Spring Framework: Modules"></a>Spring Framework: Modules</h2><p>The Spring Framework consists of features organized into about 20 modules. These modules are grouped into <code>Core Container</code>, <code>Data Access/Integration</code>, <code>Web</code>, <code>AOP (Aspect Oriented Programming)</code>, <code>Instrumentation</code>, <code>Messaging</code>, and <code>Test</code>, as shown in the following diagram.</p>
<p><img src="/upload/images/15.png" alt="Spring Framework 4.x 的系统架构图"></p>
<p>The following sections list the available modules for each feature along with their artifact names and the topics they cover.</p>
<h3 id="1-Core-Container"><a href="#1-Core-Container" class="headerlink" title="1. Core Container"></a>1. Core Container</h3><blockquote>
<ul>
<li>spring-core</li>
<li>spring-beans</li>
<li>spring-context</li>
<li>spring-context-support</li>
<li>spring-expression</li>
</ul>
</blockquote>
<p>The <em>Core Container</em> consists of the <code>spring-core</code>, <code>spring-beans</code>, <code>spring-context</code>, <code>spring-context-support</code>, and <code>spring-expression</code> (Spring Expression Language) modules.</p>
<p>The <code>spring-core</code> and <code>spring-beans</code> modules provide the fundamental parts of the framework, including the <em>IoC</em> and <em>Dependency Injection</em> features. The <code>BeanFactory</code> is a sophisticated implementation of the factory pattern. It removes the need for programmatic singletons and allows you to decouple the configuration and specification of dependencies from your actual program logic.</p>
<p>The Context (<code>spring-context</code>) module builds on the solid base provided by the <em>Core</em> and <em>Beans</em> modules: it is a means to access objects in a framework-style manner that is similar to a JNDI registry. The Context module inherits its features from the <em>Beans</em> module and adds support for <code>internationalization</code> (using, for example, resource bundles), <code>event propagation</code>, <code>resource loading</code>, and <code>the transparent creation of contexts</code> by, for example, a Servlet container. The Context module also supports Java EE features such as EJB, JMX, and basic remoting. The ApplicationContext interface is the focal point of the Context module. spring-context-support provides support for integrating common third-party libraries into a Spring application context for caching (EhCache, Guava, JCache), mailing (JavaMail), scheduling (CommonJ, Quartz) and template engines (FreeMarker, JasperReports, Velocity).</p>
<p>The <code>spring-expression</code> module provides a powerful Expression Language for querying and manipulating an object graph at runtime. It is an extension of the unified expression language (unified EL) as specified in the JSP 2.1 specification. The language supports setting and getting property values, property assignment, method invocation, accessing the content of arrays, collections and indexers, logical and arithmetic operators, named variables, and retrieval of objects by name from Spring’s IoC container. It also supports list projection and selection as well as common list aggregations.</p>
<h3 id="2-AOP-and-Instrumentation"><a href="#2-AOP-and-Instrumentation" class="headerlink" title="2. AOP and Instrumentation"></a>2. AOP and Instrumentation</h3><blockquote>
<ul>
<li>spring-aop</li>
<li>spring-aspect</li>
<li>spring-instrument</li>
<li>spring-instrument-tomcat</li>
</ul>
</blockquote>
<p>The <code>spring-aop</code> module provides an AOP Alliance-compliant aspect-oriented programming implementation allowing you to define, for example, method interceptors and pointcuts to cleanly decouple code that implements functionality that should be separated. Using source-level metadata functionality, you can also incorporate behavioral information into your code, in a manner similar to that of .NET attributes.</p>
<p>The separate <code>spring-aspects</code> module provides integration with AspectJ.</p>
<p>The <code>spring-instrument</code> module provides class instrumentation support and classloader implementations to be used in certain application servers. The <code>spring-instrument-tomcat</code> module contains Spring’s instrumentation agent for Tomcat.</p>
<h3 id="3-Messaging"><a href="#3-Messaging" class="headerlink" title="3. Messaging"></a>3. Messaging</h3><blockquote>
<ul>
<li>spring-messaging</li>
</ul>
</blockquote>
<p>Spring Framework 4 includes a <code>spring-messaging</code> module with key abstractions from the <em>Spring Integration</em> project such as <code>Message</code>, <code>MessageChannel</code>, <code>MessageHandler</code>, and others to serve as a foundation for messaging-based applications. The module also includes a set of annotations for mapping messages to methods, similar to the Spring MVC annotation based programming model.</p>
<h3 id="4-Data-Access-Integration"><a href="#4-Data-Access-Integration" class="headerlink" title="4. Data Access/Integration"></a>4. Data Access/Integration</h3><blockquote>
<ul>
<li>spring-jdbc</li>
<li>spring-tx</li>
<li>spring-orm</li>
<li>spring-oxm</li>
<li>spring-jms</li>
</ul>
</blockquote>
<p>The <em>Data Access/Integration layer</em> consists of the JDBC, ORM, OXM, JMS, and Transaction modules.</p>
<p>The <code>spring-jdbc</code> module provides a JDBC-abstraction layer that removes the need to do tedious JDBC coding and parsing of database-vendor specific error codes.</p>
<p>The <code>spring-tx</code> module supports programmatic and declarative transaction management for classes that implement special interfaces and for all your POJOs (Plain Old Java Objects).</p>
<p>The <code>spring-orm</code> module provides integration layers for popular object-relational mapping APIs, including JPA, JDO, and Hibernate. Using the <code>spring-orm</code> module you can use all of these O/R-mapping frameworks in combination with all of the other features Spring offers, such as the simple declarative transaction management feature mentioned previously.</p>
<p>The <code>spring-oxm</code> module provides an abstraction layer that supports Object/XML mapping implementations such as JAXB, Castor, XMLBeans, JiBX and XStream.</p>
<p>The <code>spring-jms</code> module (Java Messaging Service) contains features for producing and consuming messages. Since Spring Framework 4.1, it provides integration with the <code>spring-messaging</code> module.</p>
<h3 id="5-Web"><a href="#5-Web" class="headerlink" title="5. Web"></a>5. Web</h3><blockquote>
<ul>
<li>spring-web</li>
<li>spring-webmvc: Web-Servlet module</li>
<li>spring-webmvc-portlet: Web-Portlet module</li>
</ul>
</blockquote>
<p>The Web layer consists of the <code>spring-web</code>, <code>spring-webmvc</code>, <code>spring-websocket</code>, and <code>spring-webmvc-portlet</code> modules.</p>
<p>The <code>spring-web</code> module provides basic web-oriented integration features such as multipart file upload functionality and the initialization of the IoC container using Servlet listeners and a web-oriented application context. It also contains an HTTP client and the web-related parts of Spring’s remoting support.</p>
<p>The <code>spring-webmvc</code> module (also known as the Web-Servlet module) contains Spring’s model-view-controller (MVC) and REST Web Services implementation for web applications. Spring’s MVC framework provides a clean separation between domain model code and web forms and integrates with all of the other features of the Spring Framework.</p>
<p>The <code>spring-webmvc-portlet</code> module (also known as the Web-Portlet module) provides the MVC implementation to be used in a Portlet environment and mirrors the functionality of the spring-webmvc module.</p>
<h3 id="6-Test"><a href="#6-Test" class="headerlink" title="6. Test"></a>6. Test</h3><blockquote>
<ul>
<li>spring-test</li>
</ul>
</blockquote>
<p>The <code>spring-test</code> module supports the unit testing and integration testing of Spring components with JUnit or TestNG. It provides consistent loading of Spring ApplicationContexts and caching of those contexts. It also provides mock objects that you can use to test your code in isolation.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/spring/2017-03-09-spring-framework-modules.html" target="_blank">Spring Framework: Modules</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/spring/2017-03-09-spring-framework-modules.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Spring Modules</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Cloud组件介绍</title>
    <url>/spring/2018-03-07-spring-cloud-components.html</url>
    <content><![CDATA[<blockquote>
<p>Reference:</p>
<ul>
<li><a href="https://blog.csdn.net/xlgen157387/article/details/77773908">Spring Cloud全家桶主要组件及简要介绍</a></li>
<li><a href="https://blog.csdn.net/wxb880114/article/details/79467779">SpringCloud分布式开发五大组件详解</a></li>
<li><a href="http://www.ityouknow.com/springcloud/2017/05/26/springcloud-config-eureka-bus.html">配置中心和消息总线（配置中心终结版）</a></li>
</ul>
</blockquote>
<h2 id="什么是微服务？"><a href="#什么是微服务？" class="headerlink" title="什么是微服务？"></a>什么是微服务？</h2><p>微服务的主旨是将一个原本独立的系统拆分成多个小型服务，这些小型服务都在各自独立的进程中运行，服务之间通过基于HTTP的RESTful API进行通信协作，并且每个服务都维护着自身的数据存储、业务开发、自动化测试以及独立部署机制。</p>
<p>一个微服务一般完成某个特定的功能，比如下单管理、客户管理等等。每一个微服务都是微型六角形应用，都有自己的业务逻辑和适配器。一些微服务还会发布API给其它微服务和应用客户端使用。其它微服务完成一个Web UI，运行时，每一个实例可能是一个云VM或者是Docker容器。</p>
<p>以下是一个汽车租赁网站的微服务架构：</p>
<p><img src="/upload/images/16.png" alt="微服务示例"></p>
<h2 id="常见微服务框架"><a href="#常见微服务框架" class="headerlink" title="常见微服务框架"></a>常见微服务框架</h2><h3 id="服务治理框架"><a href="#服务治理框架" class="headerlink" title="服务治理框架"></a>服务治理框架</h3><ol>
<li><p>Dubbo（<a href="http://dubbo.io/">http://dubbo.io/</a>）、Dubbox（当当网对Dubbo的扩展）</p>
</li>
<li><p>Netflix的Eureka、Apache的Consul等。</p>
<blockquote>
<p>Spring Cloud Eureka是对Netflix的Eureka的进一步封装。</p>
</blockquote>
</li>
</ol>
<h3 id="分布式配置管理"><a href="#分布式配置管理" class="headerlink" title="分布式配置管理"></a>分布式配置管理</h3><ol>
<li>百度的Disconf</li>
<li>360的QConf</li>
<li>Spring Cloud组件中的Config</li>
<li>淘宝的Diamond</li>
</ol>
<h3 id="批量任务框架"><a href="#批量任务框架" class="headerlink" title="批量任务框架"></a>批量任务框架</h3><ol>
<li>Spring Cloud组件中的Task</li>
<li>LTS</li>
</ol>
<h3 id="服务追踪框架"><a href="#服务追踪框架" class="headerlink" title="服务追踪框架"></a>服务追踪框架</h3><ol>
<li>Skywalking</li>
</ol>
<h2 id="Spring-Cloud全家桶组件"><a href="#Spring-Cloud全家桶组件" class="headerlink" title="Spring Cloud全家桶组件"></a>Spring Cloud全家桶组件</h2><p>Netflix 公司提供了包括Eureka、Hystrix、Zuul、Archaius等在内的很多组件，在微服务架构中至关重要，Spring在Netflix 的基础上，封装了一系列的组件，命名为：Spring Cloud Eureka、Spring Cloud Hystrix、Spring Cloud Zuul等，下边对各个组件进行分别得介绍：</p>
<h3 id="Spring-Cloud-Eureka"><a href="#Spring-Cloud-Eureka" class="headerlink" title="Spring Cloud Eureka"></a>Spring Cloud Eureka</h3><p>我们可以将自己定义的API 接口注册到Spring Cloud Eureka上，Eureka负责服务的注册于发现，如果学习过Zookeeper的话，就可以很好的理解，Eureka的角色和 Zookeeper的角色差不多，都是服务的注册和发现，构成Eureka体系的包括：服务注册中心、服务提供者、服务消费者。</p>
<p><img src="/upload/images/17.png"></p>
<p>上图中描述了：</p>
<ol>
<li>两台Eureka服务注册中心构成的服务注册中心的主从复制集群；</li>
<li>然后服务提供者向注册中心进行注册、续约、下线服务等；</li>
<li>服务消费者向Eureka注册中心拉去服务列表并维护在本地（这也是客户端发现模式的机制体现！）；</li>
<li>然后服务消费者根据从Eureka服务注册中心获取的服务列表选取一个服务提供者进行消费服务。</li>
</ol>
<h3 id="Spring-Cloud-Ribbon"><a href="#Spring-Cloud-Ribbon" class="headerlink" title="Spring Cloud Ribbon"></a>Spring Cloud Ribbon</h3><p>在上Spring Cloud Eureka描述了服务如何进行注册，注册到哪里，服务消费者如何获取服务生产者的服务信息，但是Eureka只是维护了服务生产者、注册中心、服务消费者三者之间的关系，真正的服务消费者调用服务生产者提供的数据是通过Spring Cloud Ribbon来实现的。</p>
<p><img src="/upload/images/18.png"></p>
<p>Ribbon，主要提供客户侧的软件负载均衡算法。</p>
<p>Ribbon客户端组件提供一系列完善的配置选项，比如连接超时、重试、重试算法等。Ribbon内置可插拔、可定制的负载均衡组件。下面是用到的一些负载均衡策略：</p>
<ul>
<li>简单轮询负载均衡</li>
<li>加权响应时间负载均衡</li>
<li>区域感知轮询负载均衡</li>
<li>随机负载均衡</li>
</ul>
<p>Ribbon中还包括以下功能：</p>
<ul>
<li>易于与服务发现组件（比如Netflix的Eureka）集成</li>
<li>使用Archaius完成运行时配置</li>
<li>使用JMX暴露运维指标，使用Servo发布</li>
<li>多种可插拔的序列化选择</li>
<li>异步和批处理操作（即将推出）</li>
<li>自动SLA框架（即将推出）</li>
<li>系统管理/指标控制台（即将推出）</li>
</ul>
<h3 id="Spring-Cloud-Feign"><a href="#Spring-Cloud-Feign" class="headerlink" title="Spring Cloud Feign"></a>Spring Cloud Feign</h3><p>Spring Cloud Feign 是一个声明web服务客户端，这使得编写Web服务客户端更容易，使用Feign 创建一个接口并对它进行注解，它具有可插拔的注解支持包括Feign注解与JAX-RS注解，Feign还支持可插拔的编码器与解码器，Spring Cloud 增加了对 Spring MVC的注解，Spring Web 默认使用了HttpMessageConverters, Spring Cloud 集成 Ribbon 和 Eureka 提供的负载均衡的HTTP客户端 Feign。</p>
<p>简单的可以理解为：Spring Cloud Feign 的出现使得Eureka和Ribbon的使用更为简单。</p>
<h3 id="Spring-Cloud-Hystrix"><a href="#Spring-Cloud-Hystrix" class="headerlink" title="Spring Cloud Hystrix"></a>Spring Cloud Hystrix</h3><p>当有一个服务出现了故障，而服务的调用方不知道服务出现故障，若此时调用放的请求不断的增加，最后就会等待出现故障的依赖方 相应形成任务的积压，最终导致自身服务的瘫痪。</p>
<p>Spring Cloud Hystrix正是为了解决这种情况的，防止对某一故障服务持续进行访问。Hystrix的含义是：断路器，断路器本身是一种开关装置，用于我们家庭的电路保护，防止电流的过载，当线路中有电器发生短路的时候，断路器能够及时切换故障的电器，防止发生过载、发热甚至起火等严重后果。</p>
<p><img src="/upload/images/19.png"></p>
<p>断路器可以防止一个应用程序多次试图执行一个操作，即很可能失败，允许它继续而不等待故障恢复或者浪费 CPU 周期，而它确定该故障是持久的。断路器模式也使应用程序能够检测故障是否已经解决。如果问题似乎已经得到纠正​​，应用程序可以尝试调用操作。</p>
<p><img src="/upload/images/20.png"></p>
<p>断路器增加了稳定性和灵活性，以一个系统，提供稳定性，而系统从故障中恢复，并尽量减少此故障的对性能的影响。它可以帮助快速地拒绝对一个操作，即很可能失败，而不是等待操作超时（或者不返回）的请求，以保持系统的响应时间。如果断路器提高每次改变状态的时间的事件，该信息可以被用来监测由断路器保护系统的部件的健康状况，或以提醒管理员当断路器跳闸，以在打开状态。</p>
<p>Hystrix断路器的工作流程：</p>
<p><img src="/upload/images/21.png"></p>
<h3 id="Spring-Cloud-Zuul"><a href="#Spring-Cloud-Zuul" class="headerlink" title="Spring Cloud Zuul"></a>Spring Cloud Zuul</h3><p>服务网关是微服务架构中一个不可或缺的部分。通过服务网关统一向外系统提供REST API的过程中，除了具备服务路由、均衡负载功能之外，它还具备了权限控制等功能。Spring Cloud Netflix中的Zuul就担任了这样的一个角色，为微服务架构提供了前门保护的作用，同时将权限控制这些较重的非业务逻辑内容迁移到服务路由层面，使得服务集群主体能够具备更高的可复用性和可测试性。</p>
<p><img src="/upload/images/22.png"></p>
<p>Zuul类似nginx，反向代理的功能，不过netflix自己增加了一些配合其他组件的特性。</p>
<h3 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h3><p>对于微服务还不是很多的时候，各种服务的配置管理起来还相对简单，但是当成百上千的微服务节点起来的时候，服务配置的管理变得会复杂起来。</p>
<p>分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在Spring Cloud中，有分布式配置中心组件Spring Cloud Config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程Git仓库中。在Spring Cloud Config 组件中，分两个角色，一是Config Server，二是Config Client。</p>
<blockquote>
<ul>
<li>Config Server用于配置属性的存储，存储的位置可以为Git仓库、SVN仓库、本地文件等</li>
<li>Config Client用于服务属性的读取</li>
</ul>
</blockquote>
<p><img src="/upload/images/23.png"></p>
<h3 id="Spring-Cloud-Bus"><a href="#Spring-Cloud-Bus" class="headerlink" title="Spring Cloud Bus"></a>Spring Cloud Bus</h3><p>Spring cloud bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其他的消息指令。Spring bus的一个核心思想是通过分布式的启动器对spring boot应用进行扩展，也可以用来建立一个多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道，同样特性的设置（有些取决于通道的设置）在更多通道的文档中。</p>
<p>Spring cloud bus被国内很多都翻译为消息总线，也挺形象的。大家可以将它理解为管理和传播所有分布式项目中的消息既可，其实<strong>本质是利用了MQ的广播机制在分布式的系统中传播消息</strong>，目前常用的有Kafka和RabbitMQ。利用bus的机制可以做很多的事情，其中配置中心客户端刷新就是典型的应用场景之一，我们用一张图来描述bus在配置中心使用的机制。</p>
<p><img src="/upload/images/25.jpg"></p>
<p>根据此图我们可以看出利用Spring Cloud Bus做配置更新的步骤:</p>
<ol>
<li>提交代码触发post给客户端A发送bus/refresh</li>
<li>客户端A接收到请求从Server端更新配置并且发送给Spring Cloud Bus</li>
<li>Spring Cloud bus接到消息并通知给其它客户端</li>
<li>其它客户端接收到通知，请求Server端获取最新配置</li>
<li>全部客户端均获取到最新的配置</li>
</ol>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/spring/2018-03-07-spring-cloud-components.html" target="_blank">Spring Cloud组件介绍</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/spring/2018-03-07-spring-cloud-components.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Microservices</title>
    <url>/%E5%BE%AE%E6%9C%8D%E5%8A%A1/2018-05-19-introduction-to-microservices.html</url>
    <content><![CDATA[<ul>
<li>TOC</li>
</ul>
<p>{:toc}</p>
<h2 id="Introduction-to-Microservices"><a href="#Introduction-to-Microservices" class="headerlink" title="Introduction to Microservices"></a>Introduction to Microservices</h2><p>Microservices are currently getting a lot of attention: articles, blogs, discussions on social media, and conference presentations. They are rapidly heading towards the peak of inflated expectations on the Gartner Hype cycle. At the same time, there are skeptics in the software community who dismiss microservices as nothing new. Naysayers claim that the idea is just a rebranding of SOA. However, despite both the hype and the skepticism, the Microservices Architecture pattern has significant benefits – especially when it comes to enabling the agile development and delivery of complex enterprise applications.</p>
<p>Let’s first look at why you should consider using microservices.</p>
<h3 id="Building-Monolithic-Applications"><a href="#Building-Monolithic-Applications" class="headerlink" title="Building Monolithic Applications"></a>Building Monolithic Applications</h3><p>Let’s imagine that you were starting to build a brand new taxi‑hailing application intended to compete with Uber and Hailo. After some preliminary meetings and requirements gathering, you would create a new project either manually or by using a generator that comes with Rails, Spring Boot, Play, or Maven. This new application would have a modular hexagonal architecture, like in the following diagram:</p>
<p><img src="/upload/images/25.png"></p>
<p>At the core of the application is the business logic, which is implemented by modules that define services, domain objects, and events. Surrounding the core are adapters that interface with the external world. Examples of adapters include database access components, messaging components that produce and consume messages, and web components that either expose APIs or implement a UI.</p>
<p>Despite having a logically modular architecture, the application is packaged and deployed as a monolith. The actual format depends on the application’s language and framework. For example, many Java applications are packaged as WAR files and deployed on application servers such as Tomcat or Jetty. Other Java applications are packaged as self‑contained executable JARs. Similarly, Rails and Node.js applications are packaged as a directory hierarchy.</p>
<p>Applications written in this style are extremely common. They are simple to develop since our IDEs and other tools are focused on building a single application. These kinds of applications are also simple to test. You can implement end‑to‑end testing by simply launching the application and testing the UI with Selenium. Monolithic applications are also simple to deploy. You just have to copy the packaged application to a server. You can also scale the application by running multiple copies behind a load balancer. In the early stages of the project it works well.</p>
<h3 id="Marching-Towards-Monolithic-Hell"><a href="#Marching-Towards-Monolithic-Hell" class="headerlink" title="Marching Towards Monolithic Hell"></a>Marching Towards Monolithic Hell</h3><p>Unfortunately, this simple approach has a huge limitation. Successful applications have a habit of growing over time and eventually becoming huge. During each sprint, your development team implements a few more stories, which, of course, means adding many lines of code. After a few years, your small, simple application will have grown into a monstrous monolith. To give an extreme example, I recently spoke to a developer who was writing a tool to analyze the dependencies between the thousands of JARs in their multi‑million line of code (LOC) application. I’m sure it took the concerted effort of a large number of developers over many years to create such a beast.</p>
<p>Once your application has become a large, complex monolith, <strong>your development organization is probably in a world of pain</strong>. Any attempts at agile development and delivery will flounder. One major problem is that the application is overwhelmingly complex. It’s simply too large for any single developer to fully understand. As a result, fixing bugs and implementing new features correctly becomes difficult and time consuming. What’s more, this tends to be a downwards spiral. If the codebase is difficult to understand, then changes won’t be made correctly. You will end up with a monstrous, incomprehensible big ball of mud.</p>
<p><strong>The sheer size of the application will also slow down development</strong>. The larger the application, the longer the start‑up time is. For example, in a recent survey some developers reported start‑up times as long as 12 minutes. I’ve also heard anecdotes of applications taking as long as 40 minutes to start up. If developers regularly have to restart the application server, then a large part of their day will be spent waiting around and their productivity will suffer.</p>
<p>Another problem with a large, complex monolithic application is that <strong>it is an obstacle to continuous deployment</strong>. Today, the state of the art for SaaS applications is to push changes into production many times a day. This is extremely difficult to do with a complex monolith since you must redeploy the entire application in order to update any one part of it. The lengthy start‑up times that I mentioned earlier won’t help either. Also, since the impact of a change is usually not very well understood, it is likely that you have to do extensive manual testing. Consequently, continuous deployment is next to impossible to do.</p>
<p><strong>Monolithic applications can also be difficult to scale when different modules have conflicting resource requirements</strong>. For example, one module might implement CPU‑intensive image processing logic and would ideally be deployed in Amazon EC2 Compute Optimized instances. Another module might be an in‑memory database and best suited for EC2 Memory‑optimized instances. However, because these modules are deployed together you have to compromise on the choice of hardware.</p>
<p><strong>Another problem with monolithic applications is reliability</strong>. Because all modules are running within the same process, a bug in any module, such as a memory leak, can potentially bring down the entire process. Moreover, since all instances of the application are identical, that bug will impact the availability of the entire application.</p>
<p>Last but not least, <strong>monolithic applications make it extremely difficult to adopt new frameworks and languages</strong>. For example, let’s imagine that you have 2 million lines of code written using the XYZ framework. It would be extremely expensive (in both time and cost) to rewrite the entire application to use the newer ABC framework, even if that framework was considerably better. As a result, there is a huge barrier to adopting new technologies. You are stuck with whatever technology choices you made at the start of the project.</p>
<p>To summarize: you have a successful business‑critical application that has grown into a monstrous monolith that very few, if any, developers understand. It is written using obsolete, unproductive technology that makes hiring talented developers difficult. The application is difficult to scale and is unreliable. As a result, agile development and delivery of applications is impossible.</p>
<p>So what can you do about it?</p>
<h3 id="Microservices-–-Tackling-the-Complexity"><a href="#Microservices-–-Tackling-the-Complexity" class="headerlink" title="Microservices – Tackling the Complexity"></a>Microservices – Tackling the Complexity</h3><p>Many organizations, such as Amazon, eBay, and Netflix, have solved this problem by adopting what is now known as the Microservices Architecture pattern. Instead of building a single monstrous, monolithic application, the idea is to <strong>split your application into set of smaller, interconnected services</strong>.</p>
<p>A service typically implements a set of distinct features or functionality, such as order management, customer management, etc. <strong>Each microservice is a mini‑application that has its own hexagonal architecture consisting of business logic along with various adapters</strong>. Some microservices would expose an API that’s consumed by other microservices or by the application’s clients. Other microservices might implement a web UI. At runtime, each instance is often a cloud VM or a Docker container.</p>
<p>For example, a possible decomposition of the system described earlier is shown in the following diagram:</p>
<p><img src="/upload/images/26.png"></p>
<p><strong>Each functional area of the application is now implemented by its own microservice</strong>. Moreover, the web application is split into a set of simpler web applications (such as one for passengers and one for drivers in our taxi‑hailing example). This makes it easier to deploy distinct experiences for specific users, devices, or specialized use cases.</p>
<p><strong>Each backend service exposes a REST API and most services consume APIs provided by other services</strong>. For example, Driver Management uses the Notification server to tell an available driver about a potential trip. The UI services invoke the other services in order to render web pages. Services might also use asynchronous, message‑based communication. Inter‑service communication will be covered in more detail later in this series.</p>
<p><strong>Some REST APIs are also exposed to the mobile apps used by the drivers and passengers</strong>. The apps don’t, however, have direct access to the backend services. Instead, communication is mediated by an intermediary known as an <strong>API Gateway</strong>. The API Gateway is responsible for tasks such as load balancing, caching, access control, API metering, and monitoring, and can be implemented effectively using NGINX. Later articles in the series will cover the API Gateway.</p>
<p><img src="/upload/images/27.png"></p>
<p>The Microservices Architecture pattern corresponds to the Y‑axis scaling of the Scale Cube, which is a 3D model of scalability from the excellent book <em>The Art of Scalability</em>. The other two scaling axes are X‑axis scaling, which consists of running multiple identical copies of the application behind a load balancer, and Z‑axis scaling (or data partitioning), where an attribute of the request (for example, the primary key of a row or identity of a customer) is used to route the request to a particular server.</p>
<p>Applications typically use the three types of scaling together. Y‑axis scaling decomposes the application into microservices as shown above in the first figure in this section. At runtime, X‑axis scaling runs multiple instances of each service behind a load balancer for throughput and availability. Some applications might also use Z‑axis scaling to partition the services. The following diagram shows how the Trip Management service might be deployed with Docker running on Amazon EC2.</p>
<p><img src="/upload/images/28.png"></p>
<p>At runtime, the Trip Management service consists of multiple service instances. Each service instance is a Docker container. In order to be highly available, the containers are running on multiple Cloud VMs. In front of the service instances is a load balancer such as NGINX that distributes requests across the instances. The load balancer might also handle other concerns such as caching, access control, API metering, and monitoring.</p>
<p>The Microservices Architecture pattern significantly impacts the relationship between the application and the database. Rather than sharing a single database schema with other services, <strong>each service has its own database schema</strong>. On the one hand, this approach is at odds with the idea of an enterprise‑wide data model. Also, it often results in duplication of some data. However, having a database schema per service is essential if you want to benefit from microservices, because it ensures loose coupling. The following diagram shows the database architecture for the example application.</p>
<p><img src="/upload/images/29.png"></p>
<p>Each of the services has its own database. Moreover, a service can use a type of database that is best suited to its needs, the so‑called polyglot persistence architecture. For example, Driver Management, which finds drivers close to a potential passenger, must use a database that supports efficient geo‑queries.</p>
<p>On the surface, the Microservices Architecture pattern is similar to SOA. With both approaches, the architecture consists of a set of services. However, one way to think about the Microservices Architecture pattern is that it’s SOA without the commercialization and perceived baggage of web service specifications (WS‑*) and an Enterprise Service Bus (ESB). Microservice‑based applications favor simpler, lightweight protocols such as REST, rather than WS‑*. They also very much avoid using ESBs and instead implement ESB‑like functionality in the microservices themselves. The Microservices Architecture pattern also rejects other parts of SOA, such as the concept of a canonical schema.</p>
<h3 id="The-Benefits-of-Microservices"><a href="#The-Benefits-of-Microservices" class="headerlink" title="The Benefits of Microservices"></a>The Benefits of Microservices</h3><p>The Microservices Architecture pattern has a number of important benefits. <strong>First, it tackles the problem of complexity</strong>. It decomposes what would otherwise be a monstrous monolithic application into a set of services. While the total amount of functionality is unchanged, the application has been broken up into manageable chunks or services. Each service has a well‑defined boundary in the form of an RPC‑ or message‑driven API. The Microservices Architecture pattern enforces a level of modularity that in practice is extremely difficult to achieve with a monolithic code base. Consequently, individual services are much faster to develop, and much easier to understand and maintain.</p>
<p><strong>Second, this architecture enables each service to be developed independently by a team that is focused on that service</strong>. The developers are free to choose whatever technologies make sense, provided that the service honors the API contract. Of course, most organizations would want to avoid complete anarchy and limit technology options. However, this freedom means that developers are no longer obligated to use the possibly obsolete technologies that existed at the start of a new project. When writing a new service, they have the option of using current technology. Moreover, since services are relatively small it becomes feasible to rewrite an old service using current technology.</p>
<p><strong>Third, the Microservices Architecture pattern enables each microservice to be deployed independently</strong>. Developers never need to coordinate the deployment of changes that are local to their service. These kinds of changes can be deployed as soon as they have been tested. The UI team can, for example, perform A/B testing and rapidly iterate on UI changes. The Microservices Architecture pattern makes continuous deployment possible.</p>
<p><strong>Finally, the Microservices Architecture pattern enables each service to be scaled independently</strong>. You can deploy just the number of instances of each service that satisfy its capacity and availability constraints. Moreover, you can use the hardware that best matches a service’s resource requirements. For example, you can deploy a CPU‑intensive image processing service on EC2 Compute Optimized instances and deploy an in‑memory database service on EC2 Memory‑optimized instances.</p>
<h3 id="The-Drawbacks-of-Microservices"><a href="#The-Drawbacks-of-Microservices" class="headerlink" title="The Drawbacks of Microservices"></a>The Drawbacks of Microservices</h3><p>As Fred Brooks wrote almost 30 years ago, there are no silver bullets. Like every other technology, the Microservices architecture has drawbacks. <strong>One drawback is the name itself. The term <em>microservice</em> places excessive emphasis on service size</strong>. In fact, there are some developers who advocate for building extremely fine‑grained 10–100 LOC services. While small services are preferable, it’s important to remember that they are a means to an end and not the primary goal. The goal of microservices is to sufficiently decompose the application in order to facilitate agile application development and deployment.</p>
<p><strong>Another major drawback of microservices is the complexity that arises from the fact that a microservices application is a distributed system</strong>. Developers need to choose and implement an inter‑process communication mechanism based on either messaging or RPC. Moreover, they must also write code to handle partial failure since the destination of a request might be slow or unavailable. While none of this is rocket science, it’s much more complex than in a monolithic application where modules invoke one another via language‑level method/procedure calls.</p>
<p><strong>Another challenge with microservices is the partitioned database architecture</strong>. Business transactions that update multiple business entities are fairly common. These kinds of transactions are trivial to implement in a monolithic application because there is a single database. In a microservices‑based application, however, you need to update multiple databases owned by different services. Using distributed transactions is usually not an option, and not only because of the CAP theorem. They simply are not supported by many of today’s highly scalable NoSQL databases and messaging brokers. You end up having to use an eventual consistency based approach, which is more challenging for developers.</p>
<p><strong>Testing a microservices application is also much more complex</strong>. For example, with a modern framework such as Spring Boot it is trivial to write a test class that starts up a monolithic web application and tests its REST API. In contrast, a similar test class for a service would need to launch that service and any services that it depends upon (or at least configure stubs for those services). Once again, this is not rocket science but it’s important to not underestimate the complexity of doing this.</p>
<p><strong>Another major challenge with the Microservices Architecture pattern is implementing changes that span multiple services</strong>. For example, let’s imagine that you are implementing a story that requires changes to services A, B, and C, where A depends upon B and B depends upon C. In a monolithic application you could simply change the corresponding modules, integrate the changes, and deploy them in one go. In contrast, in a Microservices Architecture pattern you need to carefully plan and coordinate the rollout of changes to each of the services. For example, you would need to update service C, followed by service B, and then finally service A. Fortunately, most changes typically impact only one service and multi‑service changes that require coordination are relatively rare.</p>
<p><strong>Deploying a microservices‑based application is also much more complex</strong>. A monolithic application is simply deployed on a set of identical servers behind a traditional load balancer. Each application instance is configured with the locations (host and ports) of infrastructure services such as the database and a message broker. In contrast, a microservice application typically consists of a large number of services. For example, Hailo has 160 different services and Netflix has over 600 according to Adrian Cockcroft <em>[Editor – Hailo has been acquired by MyTaxi.]</em>. Each service will have multiple runtime instances. That’s many more moving parts that need to be configured, deployed, scaled, and monitored. In addition, you will also need to implement a service discovery mechanism (discussed in a later post) that enables a service to discover the locations (hosts and ports) of any other services it needs to communicate with. Traditional trouble ticket‑based and manual approaches to operations cannot scale to this level of complexity. Consequently, successfully deploying a microservices application requires greater control of deployment methods by developers, and a high level of automation.</p>
<p>One approach to automation is to use an off‑the‑shelf PaaS such as Cloud Foundry. A PaaS provides developers with an easy way to deploy and manage their microservices. It insulates them from concerns such as procuring and configuring IT resources. At the same time, the systems and network professionals who configure the PaaS can ensure compliance with best practices and with company policies. Another way to automate the deployment of microservices is to develop what is essentially your own PaaS. One typical starting point is to use a clustering solution, such as Kubernetes, in conjunction with a technology such as Docker. Later in this series we will look at how software‑based application delivery approaches like NGINX, which easily handles caching, access control, API metering, and monitoring at the microservice level, can help solve this problem.</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Building complex applications is inherently difficult. A Monolithic architecture only makes sense for simple, lightweight applications. You will end up in a world of pain if you use it for complex applications. <strong>The Microservices architecture pattern is the better choice for complex, evolving applications despite the drawbacks and implementation challenges</strong>.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E5%BE%AE%E6%9C%8D%E5%8A%A1/2018-05-19-introduction-to-microservices.html" target="_blank">Introduction to Microservices</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E5%BE%AE%E6%9C%8D%E5%8A%A1/2018-05-19-introduction-to-microservices.html]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>Introduction to Microservices</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Cloud(一)：大话Spring Cloud</title>
    <url>/spring/2018-07-01-simple-springcloud.html</url>
    <content><![CDATA[<blockquote>
<p>Reference: <a href="http://www.ityouknow.com/springcloud/2017/05/01/simple-springcloud.html">http://www.ityouknow.com/springcloud/2017/05/01/simple-springcloud.html</a></p>
</blockquote>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/spring/2018-07-01-simple-springcloud.html" target="_blank">Spring Cloud(一)：大话Spring Cloud</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/spring/2018-07-01-simple-springcloud.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Spring Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>How to disable Synology MariaDB password policy</title>
    <url>/mariadb/2019-05-08-disable-mariadb-password-policy-synology.html</url>
    <content><![CDATA[<p>With release 10.3.21 Synology added an annoying password policy plugin that loads with Maria DB.<br>If you’d like to change your complex password back to something for example without upper case characters, do the following:</p>
<h2 id="Stop-Maria-DB-service"><a href="#Stop-Maria-DB-service" class="headerlink" title="Stop Maria DB service"></a>Stop Maria DB service</h2><p>Either via Package Center or via command line:</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">synoservice <span class="comment">--stop pkgctl-MariaDB10</span></span><br></pre></td></tr></table></figure>

<h2 id="Edit-var-packages-MariaDB10-target-usr-local-mariadb10-etc-mysql-my-cnf"><a href="#Edit-var-packages-MariaDB10-target-usr-local-mariadb10-etc-mysql-my-cnf" class="headerlink" title="Edit /var/packages/MariaDB10/target/usr/local/mariadb10/etc/mysql/my.cnf"></a>Edit /var/packages/MariaDB10/target/usr/local/mariadb10/etc/mysql/my.cnf</h2><p>Comment out (add # sign) for:</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="comment">#synology_password_check = FORCE_PLUS_PERMANENT</span></span><br><span class="line"><span class="comment">#plugin_load_add = synology_password_check</span></span><br></pre></td></tr></table></figure>

<ul>
<li>The first line tells mysql that the plugin named <code>synology_password_check</code> must not be uninstalled.</li>
<li>The second line actually loads the plugin on sql startup.</li>
</ul>
<h2 id="Start-Maria-DB-service"><a href="#Start-Maria-DB-service" class="headerlink" title="Start Maria DB service"></a>Start Maria DB service</h2><p>Either via Package Center or via command line:</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">synoservice <span class="comment">--start pkgctl-MariaDB10</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/mariadb/2019-05-08-disable-mariadb-password-policy-synology.html" target="_blank">How to disable Synology MariaDB password policy</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/mariadb/2019-05-08-disable-mariadb-password-policy-synology.html]]></content>
      <categories>
        <category>MariaDB</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MariaDB</tag>
        <tag>Synology</tag>
      </tags>
  </entry>
  <entry>
    <title>上海电信桥接模式下使用IPTV</title>
    <url>/merlin/2021-07-02-enable-iptv-through-merlin.html</url>
    <content><![CDATA[<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>上海电信机顶盒本质是一个安卓盒子，通过获取DHCP地址的方式连接网络，和一台普通电脑或电视盒子基本一样。不同点在于电信机顶盒在连接网络时有一个认证过程。</p>
<p>本文即通过模拟上海电信光猫对机顶盒的认证过程，来让桥接的路由器可以顺利看IPTV。</p>
<h2 id="认证参数"><a href="#认证参数" class="headerlink" title="认证参数"></a>认证参数</h2><p>在电信机顶盒获取IP地址的时候，电信光猫会附带一系列<code>DHCP-Options</code>，连同IP地址一起发送至机顶盒。</p>
<blockquote>
<p>我家是ZTE机顶盒，获取到的<code>DHCP-Options</code>如下，其他品牌机顶盒可通过Wireshark或其他软件，监听DHCP包获取。</p>
</blockquote>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">dhcp</span>-option-force=<span class="number">125</span>,<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">00</span>:<span class="number">1</span>d:<span class="number">02</span>:<span class="number">06</span>:<span class="number">48</span>:<span class="number">47</span>:<span class="number">57</span>:<span class="number">2</span>d:<span class="number">43</span>:<span class="number">54</span>:<span class="number">03</span>:<span class="number">07</span>:<span class="number">48</span>:<span class="number">47</span>:<span class="number">32</span>:<span class="number">32</span>:<span class="number">30</span>:<span class="number">47</span>:<span class="number">53</span>:<span class="number">0</span>a:<span class="number">02</span>:<span class="number">20</span>:<span class="number">00</span>:<span class="number">0</span>b:<span class="number">02</span>:<span class="number">00</span>:<span class="number">55</span>:<span class="number">0</span>d:<span class="number">02</span>:<span class="number">00</span>:<span class="number">2</span>e</span><br></pre></td></tr></table></figure>

<h2 id="网络拓扑"><a href="#网络拓扑" class="headerlink" title="网络拓扑"></a>网络拓扑</h2><p>以下是我家的网络拓扑，路由器到光猫采用桥接的方式，路由器中拨号登录PPPoE。<br><img src="/images/0049.png"></p>
<h2 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h2><h3 id="配置光猫桥接（如果已配置请跳过）"><a href="#配置光猫桥接（如果已配置请跳过）" class="headerlink" title="配置光猫桥接（如果已配置请跳过）"></a>配置光猫桥接（如果已配置请跳过）</h3><p>首先将INTERNET设置为桥接模式，这里千万不要绑定任何端口，否则后面OTHER设置时候会无法绑定VLAN</p>
<p><img src="/images/0014.jpeg"></p>
<p>设置IPTV的连接，这里绑定端口的是传统IPTV无需B面认证的IPTV，没有就不用勾，主要是下面的绑定数据，在你路由器所用端口打钩，vlan_1填写85，如图</p>
<p><img src="/images/0015.jpeg"></p>
<p>进入应用-日常应用-IPTV 设置组播vlan为51，注意是OTHER的组播</p>
<p><img src="/images/0016.jpeg"></p>
<h3 id="配置DHCP服务器"><a href="#配置DHCP服务器" class="headerlink" title="配置DHCP服务器"></a>配置DHCP服务器</h3><p>我的AC88U路由器使用了梅林固件，并安装了<a href="https://github.com/hq450/fancyss">科学上网插件</a>，DHCP的参数由这个插件控制，故需要修改插件相关脚本。</p>
<h4 id="SSH登录路由器，修改dnsmasq-conf文件"><a href="#SSH登录路由器，修改dnsmasq-conf文件" class="headerlink" title="SSH登录路由器，修改dnsmasq.conf文件"></a>SSH登录路由器，修改dnsmasq.conf文件</h4><p>路由器中dnsmasq.conf文件位置为：/tmp/etc/dnsmasq.conf。但此文件是在路由器启动的时候动态生成的，故需要修改插件中相关脚本文件：</p>
<p>修改文件：/jffs/scripts/dnsmasq.postconf，增加以下内容到文件最后：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通过 pc_append把dhcp相关的设置append到 /tmp/etc/dnsmasq.conf 文件里</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">这样IPTV就能获取到VLAN的IP了</span></span><br><span class="line">pc_append &quot;dhcp-option-force=125,00:00:00:00:1d:02:06:48:47:57:2d:43:54:03:07:48:47:32:32:30:47:53:0a:02:20:00:0b:02:00:55:0d:02:00:2e&quot; /tmp/etc/dnsmasq.conf</span><br></pre></td></tr></table></figure>

<h4 id="重启路由器"><a href="#重启路由器" class="headerlink" title="重启路由器"></a>重启路由器</h4><p>重启路由器，在/tmp/etc/dnsmasq.conf文件中可以看到以上添加的<code>dhcp-options</code>。</p>
<blockquote>
<p><strong>特别注意：</strong>本文中的dnsmasq是通过<a href="https://github.com/hq450/fancyss">科学上网插件</a>控制的，故关闭<a href="https://github.com/hq450/fancyss">科学上网插件</a>后，该设置将失效。</p>
</blockquote>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>使用电脑连接路由器，并用wireshark抓DHCP包，能看到这个dhcp-options即可。</p>
<p>将IPTV机顶盒用网线接入到路由器上，打开即可享受IPTV了。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/merlin/2021-07-02-enable-iptv-through-merlin.html" target="_blank">上海电信桥接模式下使用IPTV</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/merlin/2021-07-02-enable-iptv-through-merlin.html]]></content>
      <categories>
        <category>Merlin</category>
      </categories>
      <tags>
        <tag>Merlin</tag>
        <tag>AC88U</tag>
        <tag>IPTV</tag>
      </tags>
  </entry>
  <entry>
    <title>安装MySQL并设置lower_case_table_names参数</title>
    <url>/mysql/2021-07-24-install-mysql-with_lowercasetablenames.html</url>
    <content><![CDATA[<p> I can get it to work with a workaround. By re-initializing MySQL with the new value for lower_case_table_names after its installation. The following steps apply to a new installation. If you have already data in a database, export it first to import it back later:</p>
<h2 id="Install-MySQL"><a href="#Install-MySQL" class="headerlink" title="Install MySQL:"></a>Install MySQL:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update    </span><br><span class="line">sudo apt-get install mysql-server -y</span><br></pre></td></tr></table></figure>

<h2 id="Stop-the-MySQL-service"><a href="#Stop-the-MySQL-service" class="headerlink" title="Stop the MySQL service:"></a>Stop the MySQL service:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service mysql stop</span><br></pre></td></tr></table></figure>

<h2 id="Delete-the-MySQL-data-directory"><a href="#Delete-the-MySQL-data-directory" class="headerlink" title="Delete the MySQL data directory:"></a>Delete the MySQL data directory:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">rm</span> -rf /var/lib/mysql</span><br></pre></td></tr></table></figure>

<h2 id="Recreate-the-MySQL-data-directory-yes-it-is-not-sufficient-to-just-delete-its-content"><a href="#Recreate-the-MySQL-data-directory-yes-it-is-not-sufficient-to-just-delete-its-content" class="headerlink" title="Recreate the MySQL data directory (yes, it is not sufficient to just delete its content):"></a>Recreate the MySQL data directory (yes, it is not sufficient to just delete its content):</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> /var/lib/mysql    </span><br><span class="line">sudo <span class="built_in">chown</span> mysql:mysql /var/lib/mysql</span><br><span class="line">sudo <span class="built_in">chmod</span> 700 /var/lib/mysql</span><br></pre></td></tr></table></figure>

<h2 id="Add-lower-case-table-names-1-to-the-mysqld-section-in-etc-mysql-mysql-conf-d-mysqld-cnf"><a href="#Add-lower-case-table-names-1-to-the-mysqld-section-in-etc-mysql-mysql-conf-d-mysqld-cnf" class="headerlink" title="Add lower_case_table_names = 1 to the [mysqld] section in /etc/mysql/mysql.conf.d/mysqld.cnf."></a>Add <code>lower_case_table_names = 1</code> to the <code>[mysqld]</code> section in <code>/etc/mysql/mysql.conf.d/mysqld.cnf</code>.</h2><h2 id="Re-initialize-MySQL-with-lower-case-table-names-1"><a href="#Re-initialize-MySQL-with-lower-case-table-names-1" class="headerlink" title="Re-initialize MySQL with --lower_case_table_names=1:"></a>Re-initialize MySQL with <code>--lower_case_table_names=1</code>:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo mysqld --defaults-file=/etc/mysql/my.cnf --initialize --lower_case_table_names=1 --user=mysql --console</span><br></pre></td></tr></table></figure>

<h2 id="Start-the-MySQL-service"><a href="#Start-the-MySQL-service" class="headerlink" title="Start the MySQL service:"></a>Start the MySQL service:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo service mysql start</span><br></pre></td></tr></table></figure>

<h2 id="Retrieve-the-new-generated-password-for-MySQL-user-root"><a href="#Retrieve-the-new-generated-password-for-MySQL-user-root" class="headerlink" title="Retrieve the new generated password for MySQL user root:"></a>Retrieve the new generated password for MySQL user root:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo grep <span class="string">&#x27;temporary password&#x27;</span> /var/log/mysql/error.log</span><br></pre></td></tr></table></figure>

<h2 id="Change-the-password-of-MySQL-user-root-either-by"><a href="#Change-the-password-of-MySQL-user-root-either-by" class="headerlink" title="Change the password of MySQL user root either by:"></a>Change the password of MySQL user root either by:</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo mysql -u root -p</span><br></pre></td></tr></table></figure>
<p>and executing:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ALTER USER <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;MyNewPa$$w0rd&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>afterwards, OR by calling the “hardening” script anyway:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo mysql_secure_installation</span><br></pre></td></tr></table></figure>

<p>After that, you can verify the lower_case_table_names setting by entering the MySQL shell:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo mysql -u root -p</span><br></pre></td></tr></table></figure>

<p>and executing:</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SHOW</span> VARIABLES <span class="keyword">LIKE</span> <span class="string">&#x27;lower_case_%&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>Expected output:</p>
<figure class="highlight asciidoc"><table><tr><td class="code"><pre><span class="line"><span class="code">+------------------------+</span>-------+</span><br><span class="line"><span class="section">| Variable_name          | Value |</span></span><br><span class="line"><span class="section">+------------------------+-------+</span></span><br><span class="line">| lower<span class="emphasis">_case_file_system | OFF   |</span></span><br><span class="line"><span class="emphasis">| lower_case_table_</span>names | 1     |</span><br><span class="line"><span class="code">+------------------------+</span>-------+</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/mysql/2021-07-24-install-mysql-with_lowercasetablenames.html" target="_blank">安装MySQL并设置lower_case_table_names参数</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/mysql/2021-07-24-install-mysql-with_lowercasetablenames.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>一文读懂电商产品架构</title>
    <url>/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/2022-02-17-product-structure-for-oneline-shop.html</url>
    <content><![CDATA[<p>大部分刚接触电商领域的产品经理，或多或少会体会到电商系统的模块多、流程长、逻辑复杂。电商系统中，除了前端APP和网站看得见摸得着外，更多的是看不见的底层逻辑和后端系统。</p>
<p>对于大部分同学而言，要找到同类后端系统的竞品进行研究借鉴是一件比较麻烦的事儿，因此长期以来便形成了一种电商产品的门槛比其他行业的产品门槛要更高的错觉。</p>
<p>虽然电商产品比较复杂，但是它有一个很重要的特征，那就是<strong>电商产品属于典型的业务驱动型产品</strong>。业务驱动型产品，其所有功能都服务于一个实体业务。因此想要弄清楚电商产品有哪些功能模块，可以从电商的业务入手，先了解一个完整的电商业务有哪些环节，基于每个环节再分析需要哪些功能来支撑，将所有功能穷举完以后，再按照一定的逻辑进行归纳总结即可窥探电商产品的全貌了。</p>
<p>本文将从电商的<strong>业务流程</strong>到电商的<strong>系统流程</strong>再到电商的<strong>系统架构</strong>这三个部分展开，分别通过三张图来深入浅出展示电商的世界。</p>
<h2 id="电商核心业务-采销仓配"><a href="#电商核心业务-采销仓配" class="headerlink" title="电商核心业务-采销仓配"></a>电商核心业务-采销仓配</h2><p>电商发展至今，出现了各种各样的叫法，有平台电商、自营电商、B2B、B2C、生鲜电商、社交电商、兴趣电商等等。不论电商的形式如何多样，其本质都是买卖双方围绕商品交易履约的过程。</p>
<p>在开始探讨之前，我们先圈定一下探讨的方向，<strong>本文主要以自营电商为探讨方向</strong>。因为与之相对的平台型电商的核心其实是流量生意，系统的责任更多的是将海量的商品和消费者做匹配，平台以此向商家收取交易佣金和广告费。</p>
<p>而自营电商除了需要具备平台电商的能力之外，由于自采自销的业务模式还涉及采购、仓储、履约等实体环节，其系统模块更多更长更复杂，基本上能覆盖平台型电商的核心系统模块，因此以自营电商为主要探讨方向可以了解的更为全面。而其他诸如B2B、B2C、生鲜电商等只是领域或表现形式不同，不属于同一个维度。</p>
<p>那么一个完整的自营电商业务是怎么样的？将一件商品交付给消费者需要经历哪些环节呢。</p>
<p><img src="/images/0017.jpeg" alt="电商业务流程"></p>
<p>通过以上业务场景图可以看出，一件商品卖给消费者需要经历的环节非常多，包括线下实体环节和线上系统环节，按照线下实体环节进一步抽象后，可以将自营电商业务划分为以下4个部分，分别是。</p>
<ol>
<li>从供应商处采购产品</li>
<li>采购产品入仓存储管理</li>
<li>商品上架到电商平台销售</li>
<li>根据销售订单进行履约配送</li>
</ol>
<p>用业务流程图表示如下。</p>
<p><img src="/images/0018.jpeg" alt="电商业务流程"></p>
<p>了解完业务流程后，基于业务流程再来梳理这些业务环节背后所需的系统就比较容易了。电商业务中所有的系统、功能都是基于以上业务流程所产生和演化的。</p>
<h2 id="电商·系统全流程"><a href="#电商·系统全流程" class="headerlink" title="电商·系统全流程"></a>电商·系统全流程</h2><p>基于上面的业务梳理结果，我们将业务流程和所需系统或功能结合起来，看看每个业务环节都有哪些系统或功能，同时，我们将整个系统流程按采销仓配的业务边界进行划分，再结合C端购买流程，就能得到一张完整的大型电商系统流程图，如下。</p>
<p><img src="/images/0001.jpg" alt="电商业务流程"></p>
<p>上图就是一个较为复杂的电商业务在系统中的流转逻辑（参考京东），从供应商/卖家入驻平台到采购商品到收货入库到上架销售再到配送履约，通过这张图就可以比较清晰的看出每个业务环节所对应的系统或功能大概有哪些了。为了便于初学者理解，有必要对流程图中的的部分节点进行解释说明（可结合流程图图对比阅读）。</p>
<h3 id="入驻-amp-采购流程"><a href="#入驻-amp-采购流程" class="headerlink" title="入驻&amp;采购流程"></a>入驻&amp;采购流程</h3><ol>
<li><strong>入驻：</strong>包括供应商入驻和卖家入驻，入驻动作主要包含选择入驻企业类型、基于类型提交相应材料（营业执照、资质等），签订合同，经过平台审核通过后，再开通企业账户钱包。</li>
<li><strong>开店：</strong>对于卖家而言，入驻成功后即可创建店铺，创建店铺主要是根据营业执照的经营范围选择主营类目、填写店铺基本信息、缴纳质保金等。</li>
<li>采购供应商入驻后，自营采销在采购系统中下<strong>采购订单</strong>，订单通过EDI或者线下的方式推送给供应商。</li>
<li><strong>供应商发货：</strong>供应商收到采购订单后，根据采购单中的信息（商品、收货仓库等）发货，发货后即产生采购在途库存。</li>
<li><strong>库存：</strong>无论是在途库存，还是实物入库后产生的实物库存，以及前端的可售库存等，均由库存中心控制。</li>
</ol>
<h3 id="销售流程"><a href="#销售流程" class="headerlink" title="销售流程"></a>销售流程</h3><ol>
<li><strong>发布商品。</strong>即创建商品sku，包括填写商品参数，商品详情介绍等信息，POP卖家会直接设置价格，自营因品类而异，创建商品时会调用主数据，即spu。</li>
<li><strong>定价。</strong>发布商品时会通过定价系统制定销售价格，销售价格与采购价、库存成本价、促销价等一系列价格组成复杂的价格模型，并一起记录在价格中心，形成完善的价格体系。</li>
<li><strong>上架。</strong>发品并定价完成后，可通过上下架功能控制商品上架销售。</li>
<li><strong>促销。</strong>即通过营销工具做促销活动，包括单品类、总价类、优惠券等，所有的促销规则均通过营销中心控制，包括活动准入规则、不同活动之间的叠加互斥规则、促销命中规则、优惠计算、促销风控等。</li>
<li><strong>活动页搭建。</strong>促销商品有时候会在特定的活动专题页面集中展示（满减专区、特价专区等），通过CMS系统可以随时随地的通过拖拽组件的方式搭建一个任意样式的专题页面，而不用临时开发。</li>
</ol>
<h3 id="黄金流程"><a href="#黄金流程" class="headerlink" title="黄金流程"></a>黄金流程</h3><p>指在用户视角下购买商品时所经历的页面，包括<strong>搜索—列表—商品详情页—购物车—提单页</strong>，很多公司内部也叫交易主流程或交易动线；</p>
<p>黄金流程是价格和促销的主要体现环节，因此在在黄金流程中，对于价格和促销的设计尤为重要，包括优惠价格的高亮突出，促销标识的设计，购物车的凑单分组等，对转化有直接的影响。</p>
<ol>
<li><strong>生成订单：</strong>生成订单在后端是一个非常复杂的过程，包括校验库存、价格、库存、用户信息、促销信息等，订单由订单中心负责创建生成。</li>
<li><strong>预占库存：</strong>生成订单的同时，会与库存中心交互预占库存。</li>
<li><strong>收银台：</strong>订单生成和支付是两个独立的环节，常见的支付方式有【在线支付】和【货到付款】，部分业务（B2B）会设置【对公转账】支付方式，后面两种支付方式以线下的形式完成。对于在线支付的订单，则可以将多种支付方式聚合到收银台页面，包括自由支付、网银支付和三方支付（微信支付、支付宝支付、京东支付等）。</li>
<li><strong>支付对账。</strong>对于先款后货订单，各类支付方式均设有支付额度限制，对公转账的方式也无法保证用户一定按照订单实收支付，因此存在实际支付金额不一定等于订单应收金额，所以需要经过对账系统完成对账。</li>
</ol>
<h3 id="订单寻源履约中心"><a href="#订单寻源履约中心" class="headerlink" title="订单寻源履约中心"></a>订单寻源履约中心</h3><p>介于交易流程和仓储流程之间的系统——将电商系统生成的数以万计的订单，按时下发给最适合的库房进行生产，就是订单寻源履约系统的职责。订单寻源履约中心由多个子系统或服务组成，包括拆分系统、分摊计算服务、转移系统、履约控制中心等。</p>
<ol>
<li><strong>订单拆分：</strong>对账成功后，订单会进入到寻源履约中心的第一个系统——拆分系统。拆分的场景主要有：生产维度（仓库不同、商家不同、配送方式不同···）、业务类型维度（实物订单、虚拟订单、生鲜订单···）等，该系统的职责是按照不同的规则将父订单拆分成多个子订单进行生产。拆分时会调用分摊计算服务计算每个新子订单的金额。</li>
<li><strong>订单转移。</strong>订单拆分完成之后会流转到转移流程，订单拆分完成之后会生成不同类型的订单，经过转移之后，不同的订单要执行不同的生产时机、不同的生产地点、不同的生产流程。<ol>
<li>针对<strong>虚拟订单</strong>，不用经由库房实际生产，直接由转移给订单中心或者虚拟业务对应的系统进行处理。</li>
<li>针对<strong>厂商直发订单和POP订单</strong>，因为这类订单都是由三方卖家发货或者工厂直接发货，转移系统会与对应的业务系统交互，生成供应商采购单或下传订单给POP对应的系统。</li>
<li>针对<strong>自营的订单</strong>，由于订单商品所属的仓库不同、配送时效不同、商品的类型不同（如生鲜如要走冷链库房生产）、用户指定送达时间等原因，转移系统会控制订单生产的时机（如一周后送达订单则需要控制不要立刻下传库房）、生产的流程，生产的仓库。</li>
</ol>
</li>
<li><strong>履约控制：</strong>履约控制系统负责控制订单生产的流程，将订单推送至对应的库房，并回传生产节点（拣货、复核、打包出库···）给前台系统；针对取消逆向订单，根据订单流转的不同节点做对应的控制：如订单未流转到仓库，则负责暂停订单下传，订单未出库则负责通知仓库终止生产、订单未派件则通知配送系统终止派件等。</li>
<li><strong>订单下传。</strong>订单经过拆分、转移、履约控制后，按时下传到对应的库房进行生产。</li>
</ol>
<p>以上就是电商全流程的介绍，全流程中的每个流程节点都是一个独立的、庞大的系统，本文只是介绍各个系统之间的流转关系和基本职责，详细的功能设计将在后续的系列文章中展开。</p>
<h2 id="大型电商产品架构"><a href="#大型电商产品架构" class="headerlink" title="大型电商产品架构"></a>大型电商产品架构</h2><p>我们通过电商业务流程得到了系统流程，有了系统流程就得到了电商系统的基本功能模块，我们基于上面梳理出来的基础功能模块，再从系统全局的角度进行扩展和做更细粒度的拆分，将最终拆分出的功能模块按照架构图的逻辑进行组织，就得到了一下产品架构图。</p>
<p><img src="/images/0002.jpg" alt="电商产品架构"></p>
<p>这张架构图的组织逻辑比较简单（可结合架构图对比查看）。</p>
<p>从上到下分别是：<strong>用户端系统&gt;运营系统&gt;履约系统&gt;生产系统&gt;基础平台&gt;BI系统</strong>。</p>
<ul>
<li><p><strong>用户端系统：</strong>主要负责用户选购商品的需求，核心系统包括注册/登录、黄金流程和个人中心等；用户端系统属于前台系统，在产品设计上更注重用户体验、数据分析等。</p>
</li>
<li><p><strong>运营系统：</strong>主要承载了内部运营的能力，核心系统包括用户管理、商品管理、价格管理以及营销管理等。</p>
</li>
<li><p><strong>交易履约系统：</strong>交易履约系统是一个中枢系统，向上承载订单交易，向下控制生产履约，核心系统有订单中心和寻源履约中心，属于电商系统中比较黑盒的部分，界面较少，更多的是底层逻辑。</p>
</li>
<li><p><strong>供应链与生产系统：</strong>供应链系统即进销存系统，在很多企业中统称ERP，主要负责商品的采购、库存的管理等、仓储管理（WMS）以及运输管理（TMS）。</p>
</li>
<li><p><strong>基础平台：</strong>基础平台是业务系统之外的系统，主要包括员工账号管理、主数据、财务系统、商家管理系统、以及服务市场和开放平台等。</p>
</li>
<li><p><strong>BI系统：</strong>平行于电商的其他系统，采集各个系统产生的数据，加工处理后反哺其他系统，提供各类数据分析能力。</p>
</li>
</ul>
<p>如果将电商系统比作一个大型超市。</p>
<ul>
<li><strong>用户端系统</strong>就是可以看见的超市本身，首页就是超市的入口，搜索就是导购牌，列表就是货架，购物车就是购物车，提单就是出口收银台，用户端系统负责承载消费者的选购下单需求；</li>
<li><strong>运营系统</strong>就是超市的营销导购人员，负责引导消费者购物、负责制定商品价格、发布促销活动，CMS系统就是超市的DM单、易拉宝，运营系统向上支撑各渠道、各终端的销售需求，向下对接订单系统和交易履约系统；</li>
<li><strong>交易履约系统</strong>就是超市的调度员，对消费者的订单负责，当超市缺货时，及时从附近仓库调货，或者向工厂订货，保证消费者的订单能按时履约；</li>
<li><strong>供应链与生产系统</strong>就是超市的幕后工作者，包括采购员、库管、配送员等。</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ol>
<li>一个完整的自营电商业务有4个核心板块：采购、销售、仓储、配送；</li>
<li>基于电商产品均服务实体业务的特性，根据业务流程可以梳理出每个环节对应所需的系统或功能，将这些功能按照业务流程串联起来就能得到完整的系统流程图；</li>
<li>将系统功能拆分成尽可能细的粒度，再按照一定的组织逻辑就能得到最终的架构图。</li>
</ol>
<p>就像前文说的，上述的每一个模块都是一个独立的、庞大的系统，在一个成熟的电商公司中，每一个系统往往都有一个或多个产品经理专门负责这个系统的设计、迭代和优化。</p>
<p>电商发展至今已经成为一个相对成熟的领域，很多系统和功能都能在网上找到对应的设计方案，可能只是行业、业务体量或者方向上有所差别。建议初学者在设计电商的核心系统时，不要凭借主观感觉盲目设计，应深入调研已有的成熟方案，避免踩坑。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/2022-02-17-product-structure-for-oneline-shop.html" target="_blank">一文读懂电商产品架构</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/2022-02-17-product-structure-for-oneline-shop.html]]></content>
      <categories>
        <category>产品经理</category>
      </categories>
      <tags>
        <tag>电商</tag>
        <tag>产品经理</tag>
        <tag>产品架构</tag>
      </tags>
  </entry>
  <entry>
    <title>使用为文章标题自动编号</title>
    <url>/hexo/2022-05-01-auto-numbering-in-hexo.html</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>我们都知道，MarkDown可以通过<code>#</code> <code>##</code> <code>###</code>等标记添加不同层次的标题，非常方便。但是问题来了：如何给标题加上编号呢？</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># Title</span></span><br><span class="line"><span class="section">## 1. sub-title</span></span><br><span class="line"><span class="section">### 1.1 sub-sub-title</span></span><br><span class="line"><span class="section">### 1.2 sub-sub-title</span></span><br><span class="line"><span class="section">## 2. sub-title</span></span><br><span class="line"><span class="section">## 3. sub-title</span></span><br></pre></td></tr></table></figure>

<p>为了给标题加上编号，手动加上11.11.223，很麻烦有没有？如果插入或删除章节，后面的编号都要重新修改一遍</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>CSS可以自动在某些元素前插入编号，而Hexo又支持自定义css样式。那么解决方法来了。</p>
<h3 id="开启Hexo自定义样式"><a href="#开启Hexo自定义样式" class="headerlink" title="开启Hexo自定义样式"></a>开启Hexo自定义样式</h3><p>我使用hexo的next主题，在根目录的<code>//_config.next.yml</code>文件中增加以下几行：</p>
<blockquote>
<p>Hexo的自定义样式参考：<a href="https://theme-next.js.org/docs/advanced-settings/custom-files">https://theme-next.js.org/docs/advanced-settings/custom-files</a></p>
</blockquote>
<blockquote>
<p><strong>注意：</strong>以下配置从主题目录配置文件中拷贝：//themes/next/_config.yml，不修改主题目录下的文件。</p>
</blockquote>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define custom file paths.</span></span><br><span class="line"><span class="comment"># Create your custom files in site directory `source/_data` and uncomment needed files below.</span></span><br><span class="line"><span class="attr">custom_file_path:</span></span><br><span class="line">  <span class="comment">#head: source/_data/head.swig</span></span><br><span class="line">  <span class="comment">#header: source/_data/header.swig</span></span><br><span class="line">  <span class="comment">#sidebar: source/_data/sidebar.swig</span></span><br><span class="line">  <span class="comment">#postMeta: source/_data/post-meta.swig</span></span><br><span class="line">  <span class="comment">#postBodyEnd: source/_data/post-body-end.swig</span></span><br><span class="line">  <span class="comment">#footer: source/_data/footer.swig</span></span><br><span class="line">  <span class="comment">#bodyEnd: source/_data/body-end.swig</span></span><br><span class="line">  <span class="comment">#variable: source/_data/variables.styl</span></span><br><span class="line">  <span class="comment">#mixin: source/_data/mixins.styl</span></span><br><span class="line">  <span class="attr">style:</span> <span class="string">source/_data/styles.styl</span></span><br></pre></td></tr></table></figure>

<h3 id="添加自定义css样式"><a href="#添加自定义css样式" class="headerlink" title="添加自定义css样式"></a>添加自定义css样式</h3><p>在<code>//source/_data/styles.styl</code>中添加以下内容：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span> &#123; <span class="attribute">counter-reset</span>: h2counter; &#125;</span><br><span class="line"><span class="selector-tag">h2</span> &#123; <span class="attribute">counter-reset</span>: h3counter; &#125;</span><br><span class="line"><span class="selector-tag">h3</span> &#123; <span class="attribute">counter-reset</span>: h4counter; &#125;</span><br><span class="line"><span class="selector-tag">h4</span> &#123; <span class="attribute">counter-reset</span>: h5counter; &#125;</span><br><span class="line"><span class="selector-tag">h5</span> &#123; <span class="attribute">counter-reset</span>: h6counter; &#125;</span><br><span class="line"><span class="selector-tag">h6</span> &#123; &#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">h2</span><span class="selector-pseudo">:before</span> &#123;</span><br><span class="line">  <span class="attribute">counter-increment</span>: h2counter;</span><br><span class="line">  <span class="attribute">content</span>: <span class="built_in">counter</span>(h2counter) <span class="string">&quot;.\0000a0\0000a0&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">h3</span><span class="selector-pseudo">:before</span> &#123;</span><br><span class="line">  <span class="attribute">counter-increment</span>: h3counter;</span><br><span class="line">  <span class="attribute">content</span>: <span class="built_in">counter</span>(h2counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h3counter) <span class="string">&quot;.\0000a0\0000a0&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">h4</span><span class="selector-pseudo">:before</span> &#123;</span><br><span class="line">  <span class="attribute">counter-increment</span>: h4counter;</span><br><span class="line">  <span class="attribute">content</span>: <span class="built_in">counter</span>(h2counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h3counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h4counter) <span class="string">&quot;.\0000a0\0000a0&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">h5</span><span class="selector-pseudo">:before</span> &#123;</span><br><span class="line">  <span class="attribute">counter-increment</span>: h5counter;</span><br><span class="line">  <span class="attribute">content</span>: <span class="built_in">counter</span>(h2counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h3counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h4counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h5counter) <span class="string">&quot;.\0000a0\0000a0&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">h6</span><span class="selector-pseudo">:before</span> &#123;</span><br><span class="line">  <span class="attribute">counter-increment</span>: h6counter;</span><br><span class="line">  <span class="attribute">content</span>: <span class="built_in">counter</span>(h2counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h3counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h4counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h5counter) <span class="string">&quot;.&quot;</span><span class="built_in">counter</span>(h6counter) <span class="string">&quot;.\0000a0\0000a0&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="其他说明"><a href="#其他说明" class="headerlink" title="其他说明"></a>其他说明</h2><p>个人不喜欢使用H1标题，觉得太大了，所以编号都是从2级标题开始的。如果有喜欢H1标题的，可以对应修改以上css文件。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/hexo/2022-05-01-auto-numbering-in-hexo.html" target="_blank">使用为文章标题自动编号</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/hexo/2022-05-01-auto-numbering-in-hexo.html]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>接连创造高估值、高增长神话的PLG SaaS</title>
    <url>/saas/2022-05-01-plg-in-saas.html</url>
    <content><![CDATA[<p><img src="/images/0013.jpeg"></p>
<p>不论是被Salesforce以277亿美元天价收购的Slack，还是因疫情市值暴涨至上千亿美元的Zoom，或是创下软件领域最大IPO的Snowflake，以及Canva、Figma、Notion、Miro等众多估值超百亿美金的独角兽，他们无一例外——均采用了PLG模式。</p>
<p><img src="/images/0026.png"></p>
<p>拥有获客成本更低、成本回收周期更短、付费转化率更高等诸多优势的PLG模式，<strong>造就了企业级SaaS行业一个又一个高估值、高增长的神话</strong>。</p>
<p>一时间，SaaS忙着贴上PLG的标签，资本忙着寻找PLG的标的。那么PLG，到底是概念的炒作？还是软件采购史上正迎来的、真正的变革？是否所有SaaS都适合？又该如何落地…..</p>
<p>本文近1.6万字，预计需要阅读15min，带你一文搞懂SaaS未来趋势——PLG。</p>
<h2 id="PLG模式为何受SaaS追捧？"><a href="#PLG模式为何受SaaS追捧？" class="headerlink" title="PLG模式为何受SaaS追捧？"></a>PLG模式为何受SaaS追捧？</h2><p>据Bessemer Venture Partners（以下简称BVP）统计，截至2021年，<strong>PLG SaaS的上市公司总市值已经超过9000亿美元</strong>。虽然2022年受全球股市震荡影响有一定的跌幅，但整体市值仍然在高速增长。</p>
<p><img src="/images/0027.png"></p>
<p>从2012年开始，只有少数SaaS上市公司采用了PLG模式，到如今，越来越多自成立就是PLG模式、由其他模式转为PLG模式的SaaS上市公司不断出现。贴上PLG模式的标签，似乎成为了SaaS公司的风潮。</p>
<p>为什么PLG模式能受SaaS如此追捧？</p>
<h3 id="增速快：“成年”时间明显缩短，更快迈向二级市场"><a href="#增速快：“成年”时间明显缩短，更快迈向二级市场" class="headerlink" title="增速快：“成年”时间明显缩短，更快迈向二级市场"></a>增速快：“成年”时间明显缩短，更快迈向二级市场</h3><p>ARR（Annual Recurring Revenue，年度经常性收入）超过1亿美元是美国企业级SaaS行业公认的“成年礼”，获得这个“成年礼”之后，ARR的增速也许会下降，但代表着SaaS的增长闭环基本成形，并具备了IPO上市的入场券。</p>
<p>据BVP统计，目前已上市的SaaS公司：</p>
<ul>
<li>前25％的公司，平均花费5.3年达到1亿美元ARR；</li>
<li>中间50%的公司，平均花费7.3年达到1亿美元的ARR；</li>
<li>后25％公司，平均花费10.6年达到1亿美元的ARR。</li>
</ul>
<p>PLG SaaS达到1亿美元ARR的时间，要明显短于其他模式的SaaS。以PLG模式的典型代表——Slack为例，仅用短短不到3年的时间便完成了这一“成年礼”，而Salesforce用了6.5年。</p>
<p>如下图所示，达到1亿美元ARR用时较短的大部分为PLG SaaS，较长的大部分为其他模式的SaaS。</p>
<p><img src="/images/0028.png"></p>
<h3 id="潜力大：颇有取代传统软件，成为新巨头之势"><a href="#潜力大：颇有取代传统软件，成为新巨头之势" class="headerlink" title="潜力大：颇有取代传统软件，成为新巨头之势"></a>潜力大：颇有取代传统软件，成为新巨头之势</h3><p><strong>“所有的传统软件，都值得用PLG模式重做一遍”</strong>，当然这句话可能有些夸张，但在某些传统软件领域正在悄然上演。</p>
<p>如在办公软件领域，Microsoft的Excel正在被Airtable挑战、Word正在被Notion挑战、PPT 正在被Figma挑战、Outlook正在被Superhuman挑战、Teams正在被Slack挑战……</p>
<p>近年来，尤其是在疫情反复的情况下，无法避免远程办公、协同办公，这就为<code>重视终端用户体验</code>的PLG SaaS创造了大量的机会。</p>
<p>如下图所示，邮件/短信、项目管理、日程安排、团队合作等模块都有越来越多卓越的、新兴的、重视用户体验的PLG SaaS出现，可以说整个办公软件的细分领域都正在被PLG SaaS拆分。</p>
<p><img src="/images/0029.png"></p>
<p><strong>“分久必合，合久必分”</strong>这些从不同细分领域切入的PLG SaaS，随着自身产品组建、产品生态的完善，很有可能取代传统软件，成长为新巨头。</p>
<p>刚完成2亿美元E轮融资的Figma，就正在快速抢食老牌软件厂商Adobe旗下Photoshop、AI以及Sketch的市场份额。</p>
<h3 id="估值高：SaaS投资热潮下，远超平均水平的市销率"><a href="#估值高：SaaS投资热潮下，远超平均水平的市销率" class="headerlink" title="估值高：SaaS投资热潮下，远超平均水平的市销率"></a>估值高：SaaS投资热潮下，远超平均水平的市销率</h3><p>由于拥有较高的投资回报率，在美国，近年来SaaS赛道一直备受投资者青睐，PLG SaaS更甚。</p>
<p>对于SaaS，美国企业普遍采用市销率（以下简称PS）的估值方法，即SaaS估值或市值＝SaaS全年营收×PS。两家企业在全年营收不相上下的情况下，如果一个PS等于10，一个PS等于0.1，估值或市值将是100倍的差距。</p>
<p><strong>目前软件领域的PS大致遵循：传统软件＜SaaS＜PLG SaaS</strong></p>
<p>PLG SaaS 的PS普遍较高，像Canva、Figma、Notion、Miro等暂未上市的明星PLG SaaS，估值时的PS基本按照10以上去估算。如年营收近10亿美元的Canva，最新估值已近400亿美金，PS高达近40。</p>
<p>再来看目前已上市的SaaS企业，下图统计了截至2022年3月，PS排名前15的SaaS企业，我们可以看到有73%的SaaS企业都采用了PLG模式，其中Snowflake的PS高达59.12。</p>
<p><img src="/images/0030.png"></p>
<h2 id="认识PLG模式"><a href="#认识PLG模式" class="headerlink" title="认识PLG模式"></a>认识PLG模式</h2><h3 id="什么是PLG模式"><a href="#什么是PLG模式" class="headerlink" title="什么是PLG模式"></a>什么是PLG模式</h3><p>话说回来，到底什么是PLG模式？</p>
<p>PLG全称<code>Product-Lead-Growth</code>，即产品主导增长。<strong>PLG模式是一种以终端用户为中心的增长模式，主要依赖于产品本身作为获取、激活、转化、留存、续约、推荐等客户全生命周期增长的主阵地。</strong></p>
<p>PLG SaaS主要有三大特征：</p>
<p><img src="/images/0031.png"></p>
<h4 id="特征一：提供免费试用或免费使用的产品"><a href="#特征一：提供免费试用或免费使用的产品" class="headerlink" title="特征一：提供免费试用或免费使用的产品"></a>特征一：提供免费试用或免费使用的产品</h4><p>PLG SaaS会为客户提供可以直接在线注册试用或使用的产品，并拥有十分流畅的产品Onboarding体验，帮助客户在短时间内上手产品并体验到产品的核心价值。</p>
<p><strong>免费试用</strong>很好理解，即使用者可以在有限的时间（通常为14天、30天）内获得完整的产品体验，达到该时间再选择是否付费。</p>
<p><strong>免费使用</strong>即为使用者提供不限时长的使用权限，但会通过其他的方式引导客户付费，如需要使用其他的功能模块、存储空间限制、团队人数限制、售后服务差异化等。如何逐步引导客户将免费版本逐步升级至付费、付更多费的版本，需要PLG SaaS提前就制定好商业化策略。</p>
<h4 id="特征二：能够自下而上的销售"><a href="#特征二：能够自下而上的销售" class="headerlink" title="特征二：能够自下而上的销售"></a>特征二：能够自下而上的销售</h4><p>B2B行业大多采用自上而下的销售，销售人员往往只需要负责说服高层决策者即可，<strong>PLG SaaS则正好相反</strong>。</p>
<p>以Slack为例，首先是罗大妹开始使用Slack。使用一段时间后，罗大妹觉得Slack对自己的日常工作效率提升非常有帮助，于是推荐给了自己的团队开始使用Slack。经过该团队的使用，Slack逐渐蔓延至企业的更多团队，最终促成企业采购Slack。</p>
<p><img src="/images/0032.png"></p>
<p>自下而上的销售，需要终端用户有一定的话语权，要么自身就能做出采购决策，要么能影响采购决策。</p>
<p>要能满足自上而下的销售，同时也要求PLG SaaS能让客户自行在线上流畅地完成整个采购全流程，这就需要有清晰明了的不同版本定价公示、自助付款、自助开票等细节支持。</p>
<h4 id="特征三：具备“病毒”传播效应"><a href="#特征三：具备“病毒”传播效应" class="headerlink" title="特征三：具备“病毒”传播效应"></a>特征三：具备“病毒”传播效应</h4><p>PLG SaaS通常具有“病毒”传播效应。“病毒”传播效应分为四种类型，口碑效应是PLG SaaS的必备特征，产品协作、产品推荐、产品版权机制是锦上添花，但PLG SaaS基本都具备了其中之一，或者更多。</p>
<p><strong>口碑效应。</strong>因为极致的用户体验、优秀的售后服务服务等，客户自发、无条件地正面传播产品，称之为口碑效应。PLG SaaS通常都能在某个群体内产生口碑效应。</p>
<p><strong>产品协同机制。</strong>具有协同机制的SaaS有天然的“病毒”传播效应，典型的有视频会议（如Zoom、腾讯会议）、文档协同（如Slack、飞书）、项目协同（如Worktile、Teambition）等。具备跨团队使用场景的SaaS，通常都具有协同机制，拥有极致产品体验的PLG SaaS便能借助这一机制，达到一传十、十传百的传播效果。</p>
<p><strong>产品推荐机制。</strong>产品推荐机制建立在双方互惠共赢的基础之上，以储存空间、数据时效、内容数量等为诱饵，引导用户自发传播产品。如PLG SaaS Drobox早期为扩大用户群，设置了250MB储存空间的诱饵，老用户分享给新用户注册成功后，双方均可获得250MB储存空间。</p>
<p><strong>产品版权机制。</strong>对外使用的SaaS通常都能设置产品版权机制，即客户使用SaaS时的版权露出能影响到客户的客户，随着客户数的增多，产品也借助客户如“病毒”般传播起来。如小鹅通的客户在进行直播时，直播间的最底部都会有版权——“由小鹅通提供技术支持”。这样的版权，每年都能为小鹅通带去大量的精准潜在客户。关于这一机制，我在《B2B运营实战；我如何带增长团队做私域获客》一书中的6.5也有详细拆解。</p>
<h3 id="PLG模式的两大误区"><a href="#PLG模式的两大误区" class="headerlink" title="PLG模式的两大误区"></a>PLG模式的两大误区</h3><h4 id="误区一：PLG模式就是产品经理主导增长"><a href="#误区一：PLG模式就是产品经理主导增长" class="headerlink" title="误区一：PLG模式就是产品经理主导增长"></a>误区一：PLG模式就是产品经理主导增长</h4><p>产品主导增长，听起来像是将增长掌控权交给了产品经理，但事实并不是这样。</p>
<p>PLG SaaS追求为终端用户提供极致的产品体验，<strong>要求从营销、销售、工程师到设计师、客户成功、产品经理等业务人员的工作，都围绕产品展开</strong>，集中力量为终端用户打造更易使用、更具粘性的产品。</p>
<p>而非PLG模式的SaaS，往往只有一部分业务人员参与到产品打磨。</p>
<h4 id="误区二：PLG模式不需要销售人员"><a href="#误区二：PLG模式不需要销售人员" class="headerlink" title="误区二：PLG模式不需要销售人员"></a>误区二：PLG模式不需要销售人员</h4><p>PLG模式往往会被误认为不需要销售人员，产品的采购就能实现自增长。面向个人用户、小微企业的客户、中大型企业中的某个团队，PLG模式的特有优势确实能够做到这一点。</p>
<p>但面向整个中大型企业，仍然需要有专业的销售人员去推进，但同时对销售人员的能力模型会有新的要求。<strong>PLG模式的SaaS企业倾向于更年轻的、能接受新鲜事物的、有过咨询经验的销售人员。</strong></p>
<p>综上，我们会发现，<strong>PLG模式不仅仅只是一种GTM（Go-To-Market，进入市场）战略，而是整个企业的商业战略——将PLG理念注入组织，调动整个组织围绕PLG开展跨部门协作，共同为终端用户打磨一款体验极佳的产品，让产品作为增长的基本驱动力。</strong></p>
<h3 id="PLG模式的两大优势"><a href="#PLG模式的两大优势" class="headerlink" title="PLG模式的两大优势"></a>PLG模式的两大优势</h3><h4 id="优势一：更低的获客成本，让成本回收周期明显缩短"><a href="#优势一：更低的获客成本，让成本回收周期明显缩短" class="headerlink" title="优势一：更低的获客成本，让成本回收周期明显缩短"></a>优势一：更低的获客成本，让成本回收周期明显缩短</h4><p><strong>SaaS企业的获客成本主要来源于营销费用和销售费用</strong>，由于主要依赖产品本身作为获客渠道、成交周期更短、销售人员的招聘往往放在产品打磨得非常成熟之后，PLG SaaS的获客成本往往更低。</p>
<p>如在首次公开募股时，Atlassian的获客成本仅占收入的19%，而这一数字，非PLG SaaS的Salesforce为49%、Marketo为60%、Box为80%。</p>
<p>获客成本低的同时，也让PLG SaaS拥有更短的获客成本回收周期。被称为“女版巴菲特”的Catherine Wood所执掌的ARK Invest在2020年8月发布的《SaaS：Could 2020-2030 be the Golden Age？》白皮书表明，自成立即PLG SaaS收回获客成本所需的时间平均仅为7个月，而其他SaaS则平均需要1.9年。</p>
<p><img src="/images/0033.png"></p>
<p>收回获客成本所需的时间缩短，意味着SaaS能将资金更快速地投入研发和运营，能为客户提供更好的产品和服务，以此又能获得更多的客户，形成良性发展的增长循环。</p>
<h4 id="优势二：更多的数据加持，能借B2C玩法降维打击"><a href="#优势二：更多的数据加持，能借B2C玩法降维打击" class="headerlink" title="优势二：更多的数据加持，能借B2C玩法降维打击"></a>优势二：更多的数据加持，能借B2C玩法降维打击</h4><p>正如我在《B2B运营实战：我如何带增长团队做私域获客》这本书内提到，<strong>任何一个成功的B2C运营玩法，如果能结合企业自身业务借鉴至B2B运营，都将是降维打击</strong>。</p>
<p>很多增长黑客的玩法都兴起于B2C，一个很重要的原因是B2C的数字化程度高，有很好的数据基础快速进行产品迭代、A/B测试、精细化运营等。</p>
<p>传统B2B企业的客户全生命周期，尤其是线下的部分是很难数字化的，但PLG SaaS几乎将所有业务团队的工作重心转移到产品上，<strong>客户全生命周期基本都借助产品进行数据监测、数据积累</strong>，这就能让PLG SaaS也能通过数据借鉴B2C玩法实现更高效的增长。</p>
<p><strong>用户行为数据是PLG模式下产品迭代的核心。</strong>借助不断扩大的免费试用或免费使用的用户基数，收集足够多的用户行为数据，将能够很方便地了解使用者在产品上的各种行为，进而对产品上手引导进行漏斗分析、对产品界面进行热图分析、对产品功能模块进行留存分析、对产品使用流程进行路径分析等。借助数据驱动产品功能的优化和需求优先级的决策。</p>
<h2 id="PLG模式的发展背景：软件采购时代的变迁"><a href="#PLG模式的发展背景：软件采购时代的变迁" class="headerlink" title="PLG模式的发展背景：软件采购时代的变迁"></a>PLG模式的发展背景：软件采购时代的变迁</h2><p>为了解PLG模式为什么会在美国兴起，我们可以从美国软件采购的发展史出发，一探究竟。</p>
<p>1940年，世界上第一款软件诞生，从软硬件一体到软件可单独销售，在政府、大型企业的需求推动下，美国的企业级软件开始登上历史的舞台。放眼全球，软件市场的发展离不开这4个驱动因素：</p>
<ul>
<li>驱动因素1，基础设施：软件在哪里？</li>
<li>驱动因素2，成本：部署和采购软件的成本是多少？</li>
<li>驱动因素3，买方：谁来评估和选择软件？</li>
<li>驱动因素4，推广：软件如何出现在客户面前？</li>
</ul>
<p>这4个驱动因素相互关联、相互影响。随着基础设施的发展，软件的部署和采购成本会变得更低，进而客户采购软件的价格也会变得更低。这二者又会共同推动买方决策权的下放，进而影响企业的推广方式。</p>
<p>结合这4个驱动因素，我们可以将美国的软件采购分为以下三个时代。</p>
<p><img src="/images/0034.png"></p>
<h3 id="时代一：CIO时代，SLG"><a href="#时代一：CIO时代，SLG" class="headerlink" title="时代一：CIO时代，SLG"></a>时代一：CIO时代，SLG</h3><p>2000年以前，软件的安装部署基本都在本地，部署和采购软件的费用十分高昂，这一时期的CIO掌握了最高话语权，CIO决定是否采购某企业级软件的标准通常是——IT兼容性，即该软件是否能在企业的环境中正常工作。</p>
<p><strong>这一时期主要是SLG（Sales-Lead-Growth）</strong>，销售主导增长。企业雇佣形象好、气质佳的销售，让西装革履的销售与CIO互动、交谈，甚至出入高端场所共进晚餐，是拿下单子的家常便饭。</p>
<h3 id="时代二：经理时代，MLG"><a href="#时代二：经理时代，MLG" class="headerlink" title="时代二：经理时代，MLG"></a>时代二：经理时代，MLG</h3><p>2000年以后，SaaS出现，企业采购软件的付费方式也从一次性的高昂付费，转变为事先仅需支付一小部分费用的订阅式付费。</p>
<p>这时，CIO走向了数据中心的道路，决策权下放到各部门的经理、管理者，他们的采购标准通常是——ROI/KPI，即该软件是否能够帮助我的团队实现目标。</p>
<p><strong>这一时期主要是MLG（Marketing-Lead-Growth）</strong>，营销主导增长。经典的从Leads、MQL、SQL到OPP的线索流转术语出现，SDR和MDR这类线索挖掘的岗位也开始出现。市场团队和销售团队如何紧密合作拿下客户，是这一时期的主旋律。</p>
<p><img src="/images/0035.png"></p>
<p>PS：我国的大部分SaaS企业可能还处在MLG的摸索阶段</p>
<h3 id="时代三：终端用户时代，PLG"><a href="#时代三：终端用户时代，PLG" class="headerlink" title="时代三：终端用户时代，PLG"></a>时代三：终端用户时代，PLG</h3><p>如今，尤其是疫情的催化下，我们已经加速进入到终端用户的时代。</p>
<p>这时的基础设施已经成为可以根据需要进行扩展的弹性实用程序，开发者可以从API、模块化的工具中更快捷地编写软件，软件数量爆发式增长，新软件试用/使用的门槛逐渐走低。</p>
<p><strong>这一时期主要是PLG</strong>，产品主导增长，决策权进一步下放到软件的真正使用者，他们的采购标准通常是——个人生产力，即该软件是否真的能帮助到我的日常工作？</p>
<p>与此同时，一个新的线索衡量指标——<code>PQL（Product Qualified Leads，产品合格线索）</code>出现。MQL通常依赖产品之外的公开课、白皮书、线下会议等方式获取，而PQL是用户真正体验产品后达到某些数据维度要求后的线索。有数据表明PQL的转化率通常为15%～30%，远高于MQL。</p>
<p><img src="/images/0036.png"></p>
<p>PLG模式之所以兴起，是美国企业的软件采购方式，正在发生巨大的变革。</p>
<h2 id="PLG模式下的组织协同会发生哪些变化？"><a href="#PLG模式下的组织协同会发生哪些变化？" class="headerlink" title="PLG模式下的组织协同会发生哪些变化？"></a>PLG模式下的组织协同会发生哪些变化？</h2><p>PLG SaaS表面上看起来只是为终端用户打磨了一款有着极致体验的产品，更深层次的其实是组织协同上的变化。</p>
<p><img src="/images/0037.png"></p>
<p><strong>任何一件增进跨部门协作的事情都有利于企业的整体增长。</strong>PLG模式下，各业务部门的工作重心都在数据驱动下围绕产品展开，并且围绕产品，在协同上联系得更加紧密。</p>
<p>这里以营销人员与产品经理、销售人员与营销人员的协同为例，具体展开。</p>
<h3 id="营销人员与产品经理的协同"><a href="#营销人员与产品经理的协同" class="headerlink" title="营销人员与产品经理的协同"></a>营销人员与产品经理的协同</h3><p>非PLG SaaS的营销人员很难对产品迭代起到实质性作用，大部分工作也都在产品之外，通过线上/线下活动、公开课、白皮书、SEM/SEO等方式为销售人员提供更精准的线索。</p>
<p><strong>PLG SaaS的营销人员，会将一部分工作重心转移到产品上</strong>，尽可能地通过各种营销方式吸引终端用户试用/使用产品，然后通过数据分析引导终端用户进行版本升级、在线上自助付费。这对营销人员来说将是一场全新的游戏。</p>
<p>在这个过程中，<strong>营销人员会与产品经理更好地协同，共同促进免费试用/使用产品的迭代</strong>，以及新手Onboarding、付费Onboarding的流程迭代。</p>
<h3 id="销售人员与营销人员的协同"><a href="#销售人员与营销人员的协同" class="headerlink" title="销售人员与营销人员的协同"></a>销售人员与营销人员的协同</h3><p>非PLG SaaS的销售人员，主要跟进的线索一部分是来源于营销团队，一部分是来源于自拓，还有一部分来源于生态合作。<strong>PLG SaaS的销售人员不再是这二者，而是PQL。</strong></p>
<p>由于有了终端用户使用产品的各种数据，营销人员会根据这些数据判断该企业的规模、是否有需求，及企业中具体有哪些角色在使用等，再将有中大型企业采购潜力的PQL转给销售人员。</p>
<p>过去，销售人员介入的时间基本都在客户还没有真正体验到产品的核心价值之前，毕竟传统软件是不提供免费试用的，更不用提免费使用。采购方往往只有在销售人员上门或远程演示产品时才能一睹产品的真容。</p>
<p>而PLG模式下，<strong>在销售人员未介入之前，使用者就已经体验到了产品的核心价值</strong>。销售人员将能更有针对性地把精力放在跟进中大客户上，提高投入产出比。</p>
<p>总而言之，<strong>践行PLG模式不只是产品团队的事情，而是整个企业的战略，需要高层的支持，以及集合各方力量共同为终端用户打磨一款好产品，用产品驱动增长。</strong></p>
<h2 id="PLG模式虽好，但需明辨"><a href="#PLG模式虽好，但需明辨" class="headerlink" title="PLG模式虽好，但需明辨"></a>PLG模式虽好，但需明辨</h2><h3 id="适合采用PLG模式的SaaS"><a href="#适合采用PLG模式的SaaS" class="headerlink" title="适合采用PLG模式的SaaS"></a>适合采用PLG模式的SaaS</h3><p>PLG模式虽然造就了很多高估值、高增长神话的SaaS，但相应地也会为SaaS的增长带来一定的阻碍，如免费版升级为付费版可能会更困难；也并不是每款SaaS都有必要立刻转向PLG模式，如还处在卖方市场的软件。</p>
<p>最重要的，<strong>并不是所有SaaS都具备采用PLG模式的条件。</strong></p>
<p>前文（可跳转至2.1）提到的PLG SaaS的三大特征，有些是我们可以后天去打造的，如Onboarding流程的优化、自助付费的线上通道等。那么在后天打造之前，我们如何判断自己的SaaS是否有采用PLG模式的先天条件呢？</p>
<ul>
<li><strong>产品使用门槛：</strong>对于终端用户来说，产品简单易用并且能够很快让其获得价值，是PLG SaaS所必须具备的。如果产品非常复杂，需要培训数月才能上手，终端用户的自学意愿不够，就不太适合PLG模式。</li>
<li><strong>采购决策权：</strong>因为企业采购往往会涉及到多角色的意见采纳，PLG SaaS主要围绕终端用户打磨产品，那么面向的终端用户最好有采购决策权，如果没有最好也是能对采购委员会有一定影响力的角色。否则，最终可能会竹篮打水一场空。</li>
<li><strong>边际成本：</strong>大量免费试用/使用的用户涌入后，如果会给企业相应地增加很多成本，如客户服务成本、数据储存成本等，即边际成本很高的SaaS，就不太适合采用PLG模式。PLG SaaS的边际成本最好非常低。</li>
<li><strong>目标组织：</strong>面向微型、小型、中型、大型企业都有实践PLG模式的可能性，但如果目标组织是面向政府、有严格采购政策的传统企业等强依赖关系型销售的，就不太适合采用PLG模式。因为产品做得再好，可能也比不上销售人员和决策者吃个饭。</li>
</ul>
<p>如果觉得还不够直观，我们可以直接对照OpenView有关PLG SaaS的统计，如果找到了和您企业同类型的SaaS，也一定程度上说明您企业的SaaS是适合采用PLG模式的。</p>
<p>如下图所示，根据OpenView的统计，适合采用PLG模式的SaaS可以主要分为四类：开发者和产品工具、后台支持和运维、客户体验/运营，以及生产力和协作工具。</p>
<p><img src="/images/0038.png"></p>
<p>有意思的是，<strong>该统计中面向程序员群体的PLG SaaS占据了大多数</strong>。程序员群体普遍比较内向，不太喜欢和销售人员打交道，而是喜欢自行研究各种文档。且面向程序员群体的产品大多专业门槛比较高，很多管理者可能自己并不懂技术，所以程序员大多拥有一定的采购决策权。</p>
<h3 id="判断真伪PLG-SaaS的指标"><a href="#判断真伪PLG-SaaS的指标" class="headerlink" title="判断真伪PLG SaaS的指标"></a>判断真伪PLG SaaS的指标</h3><p>随着PLG的火热，很多SaaS都在忙着从各种角度为自己贴上PLG的标签。为了更好地研究和学习PLG SaaS的增长案例，我们需要学会判断PLG SaaS的真伪。</p>
<p><strong>「研发支出：销售和营销支出」（以下简称R&amp;D：S&amp;M）</strong>这一指标可以帮助我们判断一家SaaS公司是否为PLG模式，毕竟数据很难说谎。</p>
<p>如Atlassian，Atlassian的<code>R&amp;D:S&amp;M</code>=2.9:1，Atlassian将高达47%的收入用于研发，销售和营销的支出仅占比16%。众所周知，Atlassian是典型的PLG SaaS，并一直致力于创新产品的研发。</p>
<p>我们再来看其他PLG SaaS的<code>R&amp;D:S&amp;M</code>，Dropbox为1.7、Datadog为1.1、Shopify为1.0，接着是Twilio为0.9、Slack为0.8。</p>
<p>根据OpenView对上市SaaS公司的统计，<strong>PLG SaaS的<code>R&amp;D:S&amp;M</code>平均为0.87，而非PLG SaaS的<code>R&amp;D:S&amp;M</code>平均为0.58</strong>。这一基准有助于帮助我们辨别真伪PLG SaaS。</p>
<h2 id="用户细分-关键行动：打造PLG-SaaS的增长飞轮"><a href="#用户细分-关键行动：打造PLG-SaaS的增长飞轮" class="headerlink" title="用户细分+关键行动：打造PLG SaaS的增长飞轮"></a>用户细分+关键行动：打造PLG SaaS的增长飞轮</h2><p>要想落地能带来高估值、高增长的PLG模式，<strong>1.首先需要有高层管理者从下至上的支持，2.然后需要有包含数据分析、自动化运营、跨部门协同等的工具箱支撑数据驱动增长，3.最后还需要有组织结构的调整以快速实践。</strong></p>
<p>这三点具备之后，我们即可开始打造PLG SaaS的增长飞轮，逐步开启产品驱动的客户全生命周期价值增长。</p>
<p>PLG SaaS增长飞轮的<strong>内轮</strong>由评估者、初学者、常用者、拥护者的用户细分组成，<strong>外轮</strong>由激活、采用、喜爱、倡导的关键行动组成，核心目标为终端用户打造极致体验的产品。</p>
<p><img src="/images/0039.png"></p>
<p>产品体验越好，越能促进用户更快进入到下一阶段，随着增长飞轮的旋转速度越来越快，将会有越来越多的用户成为拥护者，倡导更多新用户体验产品，让SaaS呈指数式增长。</p>
<h3 id="内轮1：评估者"><a href="#内轮1：评估者" class="headerlink" title="内轮1：评估者"></a>内轮1：评估者</h3><p><img src="/images/0040.png"></p>
<p>评估者通常都在寻找能帮助他们解决某种问题的解决方案，他们可能从各种途径，如广告投放、用户口碑等听闻哪些品牌能解决问题，继而开始对市面上能满足需求的品牌进行评估。</p>
<p>评估者通常是：</p>
<ul>
<li>处于免费试用或演示阶段，刚开始接触产品</li>
<li>没有开始真正地在工作流程中使用产品</li>
<li>仍在在为试图解决的问题寻找解决方案</li>
</ul>
<h4 id="评估者想从产品中得到什么"><a href="#评估者想从产品中得到什么" class="headerlink" title="评估者想从产品中得到什么"></a>评估者想从产品中得到什么</h4><p>评估者想知道<strong>你了解他们的问题，并能为他们提供一条能解决这个问题的明确途径</strong>。他们<em>不关心产品之间的细微差别，也不关心你的通用解决方案</em>，他们只关注你如何与他们最迫切的需求相联系。</p>
<p>评估者正在你的产品、你竞争对手的产品，以及内部提供的解决方案之间权衡。虽然评估者正在努力寻找解决方案，但他们不会深度使用产品，<strong>易用性、核心功能、独有特点是评估者的首要考虑因素</strong>。</p>
<h4 id="如何为评估者提供价值"><a href="#如何为评估者提供价值" class="headerlink" title="如何为评估者提供价值"></a>如何为评估者提供价值</h4><p>我们需要<strong>引导评估者找到重点价值，并激活他们</strong>，简而言之，就是引导评估者进入他们的“啊哈”时刻。</p>
<p>让评估者体验产品，但不要试图将评估者拖入每一个细节功能的体验中，而是要<strong>让评估者尽快对核心功能有所了解</strong>。我们可以通过Onboarding流程收集评估者的喜好，然后有选择性地引导评估者使用能帮助他们实现价值的功能。</p>
<p><strong>评估者需要的是一张通往成功的知识地图，而不是一本用户操作手册</strong>。如果评估者想了解某个功能的详细特性，记得提前准备好功能简介视频、功能介绍文档、社区问答等帮助他们。</p>
<h3 id="外轮1：激活"><a href="#外轮1：激活" class="headerlink" title="外轮1：激活"></a>外轮1：激活</h3><p><img src="/images/0041.png"></p>
<p>不同SaaS的激活方式肯定都是不一样的，但核心都是<strong>引导用户体验到一种感觉——当用户发现产品能很好地解决他们问题时的一种兴奋和愉悦</strong>。</p>
<p>需要注意的是，产品付费并不代表用户激活。事实上，有很多产品被采购后，由于终端用户没有体验到产品价值，没有被激活，最终面临的都是断约。</p>
<p>相反，即使用户还没有付费，但用户发现了产品的价值，体验到了“啊哈”时刻，激活就发生了。被激活的用户会想要了解更多，并愿意投入更多精力和时间进一步使用产品。</p>
<p>为激活评估者，我们可以通过数据分析，确定用户在产品中体验到的“啊哈”时刻，和触发激活的行为。一旦确定激活事件，我们的目标就是尽快帮助用户到达这里。</p>
<h4 id="谁负责激活？"><a href="#谁负责激活？" class="headerlink" title="谁负责激活？"></a>谁负责激活？</h4><p><strong>每个部门都会以某种方式为促进激活做出贡献。</strong></p>
<p><strong>营销团队和销售团队</strong>最常接触评估者，这两个团队需要专注于了解用户需求，尽可能地减少激活路上的摩擦。</p>
<p><strong>产品经理、设计师和工程师</strong>需要努力为新用户优化产品，并与营销团队或增长团队合作，提供产品内信息和优化Onboarding体验。</p>
<p><strong>客户成功团队、支持团队</strong>虽然负责增长飞轮更后期的客户，但也会通过与客户沟通以及对评估者的经验洞察，为激活引擎提供改进建议。</p>
<h3 id="内轮2：初学者"><a href="#内轮2：初学者" class="headerlink" title="内轮2：初学者"></a>内轮2：初学者</h3><p><img src="/images/0042.png"></p>
<p>初学者了解我们的产品如何满足他们的需求并提供价值，并会对此感到兴奋。由于这种兴奋，他们会花更多时间在产品上，更深入地探索产品的功能与特点。<strong>初学者可能不是付费用户，但已经做好了可能会付费的心理准备。</strong></p>
<p>初学者通常是：</p>
<ul>
<li>真正地开始在工作流程中使用产品</li>
<li>没有开始使用高级、复杂的功能</li>
<li>确信产品是最佳的问题解决方案</li>
</ul>
<h4 id="初学者想从产品中得到什么"><a href="#初学者想从产品中得到什么" class="headerlink" title="初学者想从产品中得到什么"></a>初学者想从产品中得到什么</h4><p><strong>初学者渴望了解更多</strong>，以发现产品可能提供的、超出最初带给他们的好处，并正在试图找出如何将产品整合到当前的工作流程和技术栈。过不了多久，初学者便会开始考虑结果和投资回报率。</p>
<p>初学者会对产品的最佳实践感兴趣，希望从一开始就学会如何有效和正确地使用产品。因此，<strong>他们很可能在这个阶段从额外的支持中受益。</strong></p>
<h4 id="如何为初学者提供价值"><a href="#如何为初学者提供价值" class="headerlink" title="如何为初学者提供价值"></a>如何为初学者提供价值</h4><p>初学者正在努力完成任务，给他们自由去完成他们需要做的事情。但要记住初学者还在学习，对障碍物很敏感。通过额外的指导，减少学习过程中的摩擦，能让初学者更易使用产品。</p>
<p>初学者应该以最小的摩擦成功完成关键任务并探索产品功能范围。在这个细分用户中，<strong>我们的重点应该是帮助用户在他们作为评估者所取得基础知识的基础上，发现解决次要问题、使工作流程更有效的额外功能，并将产品与他们的日常工作紧密联系起来。</strong></p>
<p>我们的目标是让初学者通过习惯性的、更高级的使用完全采用产品。</p>
<h3 id="外轮2：采用"><a href="#外轮2：采用" class="headerlink" title="外轮2：采用"></a>外轮2：采用</h3><p><img src="/images/0043.png"></p>
<p><strong>采用是指形成习惯，让用户将产品与特定的任务或解决方案联系起来。</strong>采用产品的用户在决定定期使用产品时不会花很多心思，只是在顺其自然地使用产品。</p>
<p>以Slack为例，如果你已经采用了Slack，并且你想和其他同事交流，你会自然而然地在Slack中给他们发信息，尽管你也通过电子邮件、电话与他们交流。在这种情况下，你只是在想“我需要给某某发一条信息”，而不是“我现在就想用Slack”。</p>
<p>产品采用意味着完全接受，<strong>这时的用户真正了解了产品的强大功能并经常依赖产品</strong>。</p>
<h4 id="谁负责采用？"><a href="#谁负责采用？" class="headerlink" title="谁负责采用？"></a>谁负责采用？</h4><p><strong>每个部门都会以某种方式为促进采用做出贡献。</strong></p>
<p><strong>产品团队、支持团队和客户成功团队</strong>通常会合力推动采用，一起帮助用户建立良好的使用习惯，致力于将产品尽快融入用户的工作流程，并实现更高级的产品价值。</p>
<p><strong>产品团队</strong>致力于消除使用摩擦，特别是经常重复的任务，并在用户体验中建立激励机制。</p>
<p>初学者往往有很多问题，<strong>支持团队</strong>应该考虑如何通过主动提供帮助和指导，抢在用户来找我们之前帮助他们。</p>
<p><strong>客户成功团队</strong>应该专注于帮助客户获得成功，用户在采用的体验对之后的旅程至关重要，为了确保初学者往正确的方向发展，客户成功团队也可以为其<em>提供最佳实践的建议</em>。</p>
<h3 id="内轮3：常用者"><a href="#内轮3：常用者" class="headerlink" title="内轮3：常用者"></a>内轮3：常用者</h3><p><img src="/images/0044.png"></p>
<p>常用者经常登录产品并用来处理日常工作中的多个事项。<strong>常用者可能并不总是对产品使用感到兴奋，但产品使用是他们实现目标的关键。</strong></p>
<p>常用者要切换至另一种解决方案的成本会很高，因为他们已经在你的产品中投入了时间、精力和数据。</p>
<p>常用者已经掌握了产品使用的核心方法，但对产品能解决的其他问题感到好奇。常用者对产品界面非常熟悉，不太需要经常性的支持。需要注意的是，<strong>产品的任何变化可能都会引起摩擦，扰乱他们的工作流程。</strong></p>
<p>常用者通常是：</p>
<ul>
<li>经常性登录和使用产品来完成工作</li>
<li>出现新问题时，默认将你的产品作为可能的解决方案</li>
<li>探索更深层次的产品体验，看看你的产品还能帮助他们做什么</li>
</ul>
<h4 id="常用者想从产品中得到什么"><a href="#常用者想从产品中得到什么" class="headerlink" title="常用者想从产品中得到什么"></a>常用者想从产品中得到什么</h4><p><strong>常用者希望享受使用产品</strong>，因为产品已经完全集成到用户的工作流中，如果产品出现问题会对常用者会有切实的业务影响、如果产品被重新设计也会影响常用者习以为常的使用流程。所以，虽然他们经常使用，但也很容易因为体验到摩擦感到不悦。</p>
<p>常用者通常会在产品中寻找获得价值的新方法，要么是通过尝试新功能，要么是通过提升效率来节省他们在现有任务上的时间。<strong>常用者对新功能、版本更新、持续教育感兴趣，他们大多喜欢学习先进的特性和功能，以及如何从产品中获得更多价值</strong>。</p>
<p>常用者也可能关注产品如何与他们一起成长，以满足他们不断变化的需求，所以<strong>他们可能对产品新方向有自己的看法，可以作为价值反馈的重要来源</strong>。</p>
<h4 id="如何为常用者提供价值"><a href="#如何为常用者提供价值" class="headerlink" title="如何为常用者提供价值"></a>如何为常用者提供价值</h4><p>对待常用者也要积极主动。虽然常用者经常使用产品，但也需要为他们随时提供产品基本操作上的支持。</p>
<p>为保持常用者的活跃率和留存率，我们要花足时间收集和了解常用者的反馈，让他们知道他们提供的反馈的重要性以及是如何用来改进产品的，并为常用者提供新产品功能的独家介绍。</p>
<p>教育性的内容对常用者十分有益，我们可以尝试为其提供客户专属网络研讨会、展示最佳实践和客户成功案例、甚至是对一个高级产品功能的深入研究等高价值内容。</p>
<p>不需要与常用者有太多的推送、太频繁的沟通，但可以通过用户行为数据分析，监测常用者的登录、使用情况，确保他们一直处在健康状态。</p>
<h3 id="外轮3：喜爱"><a href="#外轮3：喜爱" class="headerlink" title="外轮3：喜爱"></a>外轮3：喜爱</h3><p><img src="/images/0045.png"></p>
<p>喜爱产品的用户不仅仅是经常使用产品，而是真的期待通过使用产品完成任务，并真正渴望扩展新的使用场景。</p>
<p>一旦用户喜欢上了产品，就会把产品带到你意想不到的方向。<strong>这些用户很有激情，他们会挑战产品的极限，尝试发现新的使用场景和解决方案，并将产品进一步融入到他们的工作流中。同时，他们也热衷于提供反馈和见解，是制定产品路线图的强有力帮手。</strong></p>
<p>要让用户喜爱产品，需要为用户提供持续且愉快的产品体验，无论是对产品还是在他们使用产品过程中的任何人工触点。这就需要客户和公司之间建立一种双向的关系，让双方都能从对方那里获得价值。</p>
<h4 id="谁负责喜爱？"><a href="#谁负责喜爱？" class="headerlink" title="谁负责喜爱？"></a>谁负责喜爱？</h4><p>PLG SaaS的<strong>每一个团队都应该致力于打造一款让用户喜爱的产品，并与用户建立情感连接</strong>。</p>
<p><strong>产品团队</strong>应该继续专注于流程改善，消除使用摩擦点，并继续提供增值功能。并与营销团队合作，最大限度地提高对这些改进的认知，并确保用户保持参与。此外，还应借助各种与常用者交流的机会，让常用者感到自己建议受重视的同时，也让产品团队拥有了更多真实的宝贵观点。</p>
<p><strong>客户成功团队和支持团队</strong>应该继续专注于展示最佳实践，并通过抢先的服务将摩擦点降到最低。此外，支持团队还要准备好回答越来越高级的问题。</p>
<h3 id="内轮4：拥护者"><a href="#内轮4：拥护者" class="headerlink" title="内轮4：拥护者"></a>内轮4：拥护者</h3><p><img src="/images/0046.png"></p>
<p><strong>拥护者关注着产品的一举一动，希望从产品中获得更多的功能和权利</strong>——并不是因为拥护者一定需要这些，而是因为热爱你的产品，并积极投资于你的成功。如果哪天你的产品停止服务，拥护者可能会备受打击。</p>
<p>拥护者会向他们的同事、朋友和社交媒体粉丝上推荐你的产品，并已经和SaaS品牌形成了情感连接，在这种关系中，SaaS品牌能为拥护者提供工作之外的价值。</p>
<p>拥护者仍然需要帮助，但通常是因为他们已经将你的产品使用到了极限，或者正在思考更高级别的使用场景，他们的知识深度已经超过了大部分员工。</p>
<p>拥护者通常是：</p>
<ul>
<li>通过新的产品使用场景挑战产品的使用极限，积极参与产品的未来发展</li>
<li>产品的积极推广者，会主动向其他人“种草”产品</li>
<li>愿意使用SaaS品牌的周边，如T恤、水杯等</li>
</ul>
<h4 id="拥护者想从产品中得到什么"><a href="#拥护者想从产品中得到什么" class="headerlink" title="拥护者想从产品中得到什么"></a>拥护者想从产品中得到什么</h4><p>拥护者喜欢感觉自己是SaaS品牌的合作伙伴或朋友，<strong>希望积极参与你的未来，因为他们对你的未来进行了投资</strong>。</p>
<p>拥护者对使用产品所做的工作感到自豪，并感谢你对他们的成就和贡献的认可。<strong>他们希望成为第一个尝试新功能并提供反馈的群体，这能让拥护者感到兴奋。</strong></p>
<p>此外，拥护者还愿意且渴望参与到案例研究，并留下专业的评论，供其他用户参考。</p>
<h4 id="如何为拥护者提供价值"><a href="#如何为拥护者提供价值" class="headerlink" title="如何为拥护者提供价值"></a>如何为拥护者提供价值</h4><p>拥护者认为你的产品很特别，我们需要让他们知道这种感觉是相互的，可以为拥护者提供带有品牌Logo的礼品、新版本或新功能的优先使用权、更先进的知识指导等。</p>
<p>我们可以让拥护者积极参与产品评论、完成调研报告、合作客户案例、积极推荐产品等，他们会很乐意做这些事情。此外，我们还可以让这些拥护者，特别是专家级的拥护者加入到为你的客户提供的咨询服务中。</p>
<p><strong>我们需要与拥护者保持积极的联系，听取他们的成功经验，并询问他们是否愿意与他人分享。</strong>将拥护者纳入你公司的未来，让他们感到特别，让他们知道他们的反馈对你产品的持续成功至关重要。</p>
<h3 id="外轮4：倡导"><a href="#外轮4：倡导" class="headerlink" title="外轮4：倡导"></a>外轮4：倡导</h3><p><img src="/images/0047.png"></p>
<p>倡导让PLG SaaS的增长飞轮转得更快。主动邀请其他用户使用产品、积极在社交媒体传播产品正向评论等，这些都是倡导行为。</p>
<p>拥护者喜欢你的产品，并期望看到产品获得成功，他们渴望参与到产品的未来，但他们可能不会自己采取下一步行动，而是在等待你的邀请。</p>
<p>我们可以<strong>试着让拥护者参与到产品共建、案例共建等</strong>，或者主动向他们提出去第三方企业服务评价平台留下五星评价。第三方平台的产品评价和客户成功案例是最强大的倡导行为，能极大地推动新用户来体验产品。</p>
<h4 id="谁负责倡导？"><a href="#谁负责倡导？" class="headerlink" title="谁负责倡导？"></a>谁负责倡导？</h4><p><strong>每个部门都会以某种方式为促进倡导做出贡献。</strong></p>
<p><strong>客户成功团队</strong>应该专注于培养与拥护者的牢固关系，并利用他们的成功故事，构建强大的客户案例研究库。然后传递给市场团队进一步包装推向市场。</p>
<p><strong>市场团队</strong>应该确保那些想要宣传的用户能够有效地宣传，如为拥护者开设公开课，提供线下演讲的机会等，同时也是让拥护者找到影响潜在用户的机会。</p>
<p><strong>产品团队</strong>应该继续研究如何让用户感到兴奋和持续参与，同时也要让拥护者感到特别。如为拥护者提供测试版寻求反馈，咨询他们关于产品路线图的建议等，都是培养与拥护者关系的好方式。</p>
<p>PLG SaaS的增长飞轮，以为终端用户打造极致体验的产品为核心目标，需要产品、市场、客户成功、研发、设计、支持等团队互相协同，共同促进增长飞轮的旋转，来保持可持续的高增长。</p>
<h2 id="衡量PLG模式效果的关键指标"><a href="#衡量PLG模式效果的关键指标" class="headerlink" title="衡量PLG模式效果的关键指标"></a>衡量PLG模式效果的关键指标</h2><p>为了更好地落地PLG模式，除SaaS基本都会关注的<a href="https://baike.baidu.com/item/CAC/19777741?fr=aladdin">CAC</a>、<a href="https://baijiahao.baidu.com/s?id=1659854834286382839&wfr=spider&for=pc">MRR</a>、<a href="https://baike.baidu.com/item/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E6%80%BB%E4%BB%B7%E5%80%BC/50957024?fromtitle=LTV&fromid=10692626&fr=aladdin">LTV</a>等常规指标外，我们还需要更加关注以产品为导向的一些关键指标。</p>
<h3 id="TTV（Time-To-Value，价值实现时间）"><a href="#TTV（Time-To-Value，价值实现时间）" class="headerlink" title="TTV（Time To Value，价值实现时间）"></a>TTV（Time To Value，价值实现时间）</h3><p>TTV是指用户达到“啊哈”时刻，或触发激活事件所需要的时间。PLG SaaS需要尽可能地降低TTV，通过优化Onboarding流程、迭代与激活相关的关键操作等，让用户尽快达到“啊哈”时刻。</p>
<p>企业级SaaS行业的“啊哈”时刻分为四种：</p>
<ol>
<li>个人用户的“啊哈”时刻</li>
<li>团队的“啊哈”时刻</li>
<li>采购决策者的“啊哈”时刻</li>
<li>付费客户的“啊哈”时刻</li>
</ol>
<p>实现每个“啊哈”时刻的时间都应该尽可能地缩短。</p>
<h3 id="PQL（Product-Qualified-Leads，产品合格线索）"><a href="#PQL（Product-Qualified-Leads，产品合格线索）" class="headerlink" title="PQL（Product Qualified Leads，产品合格线索）"></a>PQL（Product Qualified Leads，产品合格线索）</h3><p>PQL通常是已经达到“啊哈”时刻被激活的用户，并且在产品中完成了一系列的关键操作，被判定为可能升级的、需要转给销售人员的企业线索。不同SaaS对PQL有着不同的定义，需要我们结合自身的业务通过用户访谈、数据分析等不断调优。</p>
<h3 id="NRG（Natural-Rate-Of-Growth，自然增长率）"><a href="#NRG（Natural-Rate-Of-Growth，自然增长率）" class="headerlink" title="NRG（Natural Rate Of Growth，自然增长率）"></a>NRG（Natural Rate Of Growth，自然增长率）</h3><p>NRG用于衡量除去付费营销、销售陌拜等非产品自然增长的方式后，SaaS的自然增长速度，PLG SaaS的NRG普遍较高，如Zoom的NRG高达89%。其计算公式为：</p>
<figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">NRG</span> <span class="operator">=</span> <span class="number">100</span> × ARR增长率 × 自然注册率 × 产品来源ARR率</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>ARR增长率。</strong>这个很好理解，即<code>ARR增长率 = (当年ARR-去年ARR) / 去年ARR</code></li>
<li><strong>自然注册率。</strong>自然注册数是指除去付费投放、活动、SDR引导等非自然注册方式，由用户推荐、品牌搜索、用户分享等自然注册方式带来的注册数。<code>自然注册率 = 自然注册数 / 总注册数</code></li>
<li><strong>产品来源ARR率。</strong>不论是免费试用、免费使用、开源产品，还是自助付费带来的ARR，都属于产品来源ARR。如果用户从来没有注册进入过产品，便联系销售，或申请产品演示的就不算产品来源ARR。<code>产品来源ARR率 = 产品来源ARR / 总ARR</code></li>
</ul>
<h3 id="K因子"><a href="#K因子" class="headerlink" title="K因子"></a>K因子</h3><p>PLG SaaS通常具有“病毒”传播效应，要实现“病毒”式传播，K因子必须大于1，也就是每个老用户可以带来超过1个新用户，这样SaaS就能很好地实现自增长。</p>
<p>计算方式为：<code>K因子 = 每个用户平均发送的邀请数量 × 每个邀请的平均转化率</code>。</p>
<h3 id="ER（Expansion-Revenue，扩张收入）"><a href="#ER（Expansion-Revenue，扩张收入）" class="headerlink" title="ER（Expansion Revenue，扩张收入）"></a>ER（Expansion Revenue，扩张收入）</h3><p>ER是指现有客户通过<strong>追加销售、附加产品、交叉销售</strong>等产生的收入，是衡量SaaS增长水平最重要的指标之一。由于PLG SaaS有更卓越的产品体验，应该对ER有更高的要求。</p>
<h3 id="ARPU（Average-Revenue-Per-User，每用户平均收入）"><a href="#ARPU（Average-Revenue-Per-User，每用户平均收入）" class="headerlink" title="ARPU（Average Revenue Per User，每用户平均收入）"></a>ARPU（Average Revenue Per User，每用户平均收入）</h3><p>ARPU是指从单个用户中获取的平均收入，计算方式为<code>MRR（Monthly Recurring Revenue，月度经常性收入）/用户总数</code>，能很好地反映SaaS业务的整体健康状况。</p>
<h3 id="CLV（Customer-Lifetime-Value，客户终身价值）"><a href="#CLV（Customer-Lifetime-Value，客户终身价值）" class="headerlink" title="CLV（Customer Lifetime Value，客户终身价值）"></a>CLV（Customer Lifetime Value，客户终身价值）</h3><p>CLV是指一个客户在与SaaS互动的全生命周期中带来的总收入，可以帮助我们识别更加有价值的客户群，并更透彻地了解合理的客户获取、客户留存成本。CLV的计算方式多样，主要有以下三种：</p>
<ul>
<li>CLV=（客户收入×客户生命周期）-客户维护成本</li>
<li>CLV=（平均采购价值/平均采购频率）×平均客户寿命</li>
<li>CLV=（每个账户的平均MRR×毛利率百分比）/收入流失率</li>
</ul>
<h3 id="NRC（Net-Revenue-Churn，净收入流失）"><a href="#NRC（Net-Revenue-Churn，净收入流失）" class="headerlink" title="NRC（Net Revenue Churn，净收入流失）"></a>NRC（Net Revenue Churn，净收入流失）</h3><p>NRC用于衡量现有客户因取消订阅、降级订阅带来的影响，<code>NRC=（流失的MRR+降级的MRR-扩展的MRR）/ 30天前的MRR</code>。</p>
<p>如果我们突然失去了低端市场的大部分用户，但在高端市场获得了少数用户，就能通过跟踪该指标的波动，及时地找出原因。</p>
<h2 id="PLG-SaaS的典型增长案例"><a href="#PLG-SaaS的典型增长案例" class="headerlink" title="PLG SaaS的典型增长案例"></a>PLG SaaS的典型增长案例</h2><p>随着国内外PLG模式的火热，越来越多自成立就是PLG模式、由其他模式转为PLG模式的SaaS不断涌现，并取得了不俗的增长成绩。这里分别各举一例，供所处不同现状的SaaS企业参考。</p>
<h3 id="市值千亿美元：自成立就是PLG模式的Atlassian"><a href="#市值千亿美元：自成立就是PLG模式的Atlassian" class="headerlink" title="市值千亿美元：自成立就是PLG模式的Atlassian"></a>市值千亿美元：自成立就是PLG模式的Atlassian</h3><p>2002年成立的Atlassian可以说是PLG SaaS的鼻祖级存在，刚成立时Atlassian的使命就是通过打造卓越的产品实现差异化。过早地就开始践行PLG模式，也让Atlassian在SaaS领域有些特立独行。</p>
<p>Atlassian刚成立时，并没有聚焦在一款产品，而是面向开发者推出了Jira和Confluence两款产品，并提供30天的免费试用；</p>
<ul>
<li>2005年，Atlassian成立的第3年，便通过卓越的产品轻松实现了盈利；</li>
<li>2010年，Atlassian成立的第8年，ARR突破5000万美元，这时才引入第一轮6000万美元的风险投资，随即开始战略性收购并进行产品融合；</li>
<li>2015年，Atlassian成立的第13年，IPO成功上市，开盘首日股价上涨32%，市值达57.8亿美元，而这时的Atlassian还没有雇佣自己的专职销售团队；</li>
<li>2019年，Atlassian成立的第17年，才成立自己的专职销售团队。在此之前，Atlassian的产品销售，不论是多大的客户，都是交由全球上百家的经销商来完成；</li>
<li>2021年，Atlassian成立的第19年，市值破千亿美元，不到六年时间市值翻了20多倍；</li>
<li>2022年，Atlassian成立的第20年，据2022财年Q2财报显示，ARR达到了惊人的30亿美元……</li>
</ul>
<p>Atlassian公司内部非常重视和强调飞轮这一概念，虽然初期可能需要花费很大的力气才能将飞轮转起来，但只要一开始转动就能保持，只要稍加推动便能让飞轮转得更快。如下图所示，为Atlassian的PLG飞轮。</p>
<p><img src="/images/0048.png"></p>
<ol>
<li><p>首先，开发一款好产品，Atlassian的两位创始人自身就是开发者出身，对于开发者真正需要什么样的产品解决工作上的问题，轻车熟路。</p>
</li>
<li><p>然后，让产品保持较低的价格，较低的价格是销量大的必要条件，销量大就意味着能几乎能销售给所有人，即目标客群广泛，既有个人用户、小微企业，也有中大型企业中的团队。</p>
</li>
<li><p>接着，要想销售给更广泛的目标客群，就需要解决线上销售的问题，要能满足线上销售便需要公开透明的定价、流畅的线上体验等支持。</p>
</li>
<li><p>最后，要想让用户能通过免费试用数日后就有采购产品的欲望，并做出采购决策，这就需要一款体验极佳真正能解决终端用户需求的产品。</p>
</li>
</ol>
<p>这就形成了Atlassian逐步将20多万客户收入囊中的PLG飞轮。</p>
<p>得益于PLG模式的各种优势，Atlassian每年都能将收入的35%以上投入到产品研发中，进一步推动PLG“飞轮”的加速旋转。</p>
<h3 id="市值百亿美元：由MLG模式转为PLG模式的HubSpot"><a href="#市值百亿美元：由MLG模式转为PLG模式的HubSpot" class="headerlink" title="市值百亿美元：由MLG模式转为PLG模式的HubSpot"></a>市值百亿美元：由MLG模式转为PLG模式的HubSpot</h3><p>B2B行业的营销人员应该都很熟悉“<a href="https://baike.baidu.com/item/Inbound%20marketing/4919909?fr=aladdin">Inbound Marketing（集客式营销）</a>”概念，提出这一概念的SaaS企业便是HubSpot。</p>
<p>由于自身处在营销自动化赛道，HubSpot的集客式营销能力，尤其是内容营销能力非常强。关于HubSpot在内容营销方面的详细拆解，可阅读<a href="https://book.douban.com/subject/35814337/">《B2B运营实战：我如何带增长团队做私域获客》</a>的4.5。所以，2006年成立的HubSpot一直都采用的是MLG模式。</p>
<p>虽然通过MLG模式，HubSpot每年也能取得30%～40%的增长，但HubSpot的管理层意识到，未来的SaaS一定是产品驱动增长的。</p>
<p>于是，在2014年，碰巧也是HubSpot的上市之年，HubSpot宣称将逐渐转向PLG模式。如今，8年过去，HubSpot的最高市值较上市时翻了近30倍。</p>
<p>为逐渐转向PLG模式，HubSpot在公司内部组建了一个PLG团队，就某个产品进行小范围的测试。PQL是PLG团队的核心指标，为给销售团队提供更精准的线索，HubSpot的PLG团队将PQL分为了三类：</p>
<ol>
<li><strong>手动升级PQL（Hand Raise PQLs）</strong>：PLG团队会对免费试用和免费使用的用户，针对性推送付费产品功能升级通知、部分付费功能的免费使用权限活动等消息，这类消息中都附带付费版本的CTA，这类来源被称之为手动升级PQL。</li>
<li><strong>使用升级PQL（Usage PQLs）</strong>：免费试用或免费使用的用户在使用产品的过程中，当用完了免费电话的分钟数、免费邮件的封数、团队人数达到上限等时，PLG团队都会在产品内设置一些自动触发的CTA引导用户付费，这类来源被称之为使用升级PQL。</li>
<li><strong>功能升级PQL（Upgrade PQLs）</strong>：当免费试用或免费使用的用户点击了某些需要付费的功能模块时，PLG团队会通过付费升级详情页引导付费，这类来源被称之为功能升级PQL。</li>
</ol>
<p>分类完毕后，PLG团队搭建了一个数据分析看板，实时监测这三类PQL的转化情况，并借助数据驱动不断地迭代增长策略。经过一年时间的测试，PLG团队取得了优异的增长成绩，PLG模式也逐步覆盖至HubSpot的全产品线。</p>
<p>目前，在HubSpot的全线产品中，Marketing Hub、Sales Hub、Service Hub提供免费使用版本，CMS Hub、Operations Hub提供免费试用14天。据统计，HubSpot大约有60%的客户都来自免费使用版本和免费试用版本。</p>
<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><p>从卖方市场到买方市场，从“一言堂”到决策权下放，拥有诸多优势并被验证可行的PLG模式，在国外SaaS领域已经成为业内公认的未来趋势。</p>
<p>下一个创造高估值、高增长神话的PLG SaaS会是谁呢？让我们拭目以待。</p>
<blockquote>
<p>作者：罗兰 易观内容增长总监，前GrowingIO内容营销负责人，深耕B2B企业的规模化获客，擅长内容驱动增长，<a href="https://book.douban.com/subject/35814337/">《B2B运营实战》</a>作者，分享在企业级SaaS运营路上的实操复盘、经验总结、职场心得等，及国内外明星B2B企业的增长案例拆解。</p>
</blockquote>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/saas/2022-05-01-plg-in-saas.html" target="_blank">接连创造高估值、高增长神话的PLG SaaS</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/saas/2022-05-01-plg-in-saas.html]]></content>
      <categories>
        <category>SaaS</category>
      </categories>
      <tags>
        <tag>PLG</tag>
        <tag>SaaS</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu安装php+nginx环境</title>
    <url>/ubuntu/2022-05-07-install-php-basis.html</url>
    <content><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>Ubuntu: 20.04</li>
<li>Nginx: 1.18.0</li>
<li>PHP: 7.4</li>
</ul>
<h2 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt install nginx -y</span><br></pre></td></tr></table></figure>

<h2 id="安装PHP"><a href="#安装PHP" class="headerlink" title="安装PHP"></a>安装PHP</h2><p>Ubuntu 20.04官方源自带的是PHP7.4，直接安装这个版本。</p>
<h3 id="安装php"><a href="#安装php" class="headerlink" title="安装php"></a>安装php</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt install php-fpm</span><br></pre></td></tr></table></figure>

<h3 id="启动php"><a href="#启动php" class="headerlink" title="启动php"></a>启动php</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/etc/init.d/php7.4-fpm start</span><br></pre></td></tr></table></figure>

<p>设置自动启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl enable php7.4-fpm</span><br></pre></td></tr></table></figure>

<h2 id="启用PHP"><a href="#启用PHP" class="headerlink" title="启用PHP"></a>启用PHP</h2><p>在nginx的server域增加以下代码（或者直接在default站点中取消注释掉以下代码）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Add index.php to the list if you are using PHP</span><br><span class="line">index index.html index.htm index.php;</span><br><span class="line"></span><br><span class="line">&lt;-- Hide serveral lines --&gt;</span><br><span class="line"></span><br><span class="line"># pass PHP scripts to FastCGI server</span><br><span class="line">#</span><br><span class="line">location ~ \.php$ &#123;</span><br><span class="line">        include snippets/fastcgi-php.conf;</span><br><span class="line"></span><br><span class="line">        # With php-fpm (or other unix sockets):</span><br><span class="line">        fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;</span><br><span class="line">        # With php-cgi (or other tcp sockets):</span><br><span class="line">        #fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="安装扩展"><a href="#安装扩展" class="headerlink" title="安装扩展"></a>安装扩展</h2><h3 id="安装：mysqli-connect"><a href="#安装：mysqli-connect" class="headerlink" title="安装：mysqli_connect"></a>安装：mysqli_connect</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-mysql</span><br></pre></td></tr></table></figure>

<p>修改<code>/etc/php/7.4/fpm/php.ini</code>，取消以下行的注释：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">extension</span>=mysqli</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>

<h3 id="安装：mb-strlen"><a href="#安装：mb-strlen" class="headerlink" title="安装：mb_strlen"></a>安装：mb_strlen</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-mbstring</span><br></pre></td></tr></table></figure>

<p>修改<code>/etc/php/7.4/fpm/php.ini</code>，取消以下行的注释：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">extension</span>=mbstring</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>

<h3 id="安装：bcmath（含bccomp）"><a href="#安装：bcmath（含bccomp）" class="headerlink" title="安装：bcmath（含bccomp）"></a>安装：bcmath（含bccomp）</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-bcmath</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>

<h3 id="安装：curl"><a href="#安装：curl" class="headerlink" title="安装：curl"></a>安装：curl</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-curl</span><br></pre></td></tr></table></figure>

<p>修改<code>/etc/php/7.4/fpm/php.ini</code>，取消以下行的注释：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">extension</span>=curl</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>

<h3 id="安装：zip"><a href="#安装：zip" class="headerlink" title="安装：zip"></a>安装：zip</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-zip</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>

<h3 id="安装：gd"><a href="#安装：gd" class="headerlink" title="安装：gd"></a>安装：gd</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-gd</span><br></pre></td></tr></table></figure>

<p>修改<code>/etc/php/7.4/fpm/php.ini</code>，取消以下行的注释：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">extension</span>=gd2</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>

<h3 id="安装：dom"><a href="#安装：dom" class="headerlink" title="安装：dom"></a>安装：dom</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">sudo apt <span class="keyword">install</span> php-xml</span><br></pre></td></tr></table></figure>

<p>重启php：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">sudo <span class="regexp">/etc/i</span>nit.d/php7.<span class="number">4</span>-fpm restart</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/ubuntu/2022-05-07-install-php-basis.html" target="_blank">Ubuntu安装php+nginx环境</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/ubuntu/2022-05-07-install-php-basis.html]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Ubuntu</tag>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>十分钟快速入门 Pandas</title>
    <url>/python/2022-05-22-introduction-to-pandas.html</url>
    <content><![CDATA[<blockquote>
<p>Source: <a href="https://zhuanlan.zhihu.com/p/21933466">十分钟快速入门 Pandas</a></p>
</blockquote>
<p>Pandas 是我最喜爱的库之一。通过带有标签的列和索引，Pandas 使我们可以以一种所有人都能理解的方式来处理数据。它可以让我们毫不费力地从诸如 csv 类型的文件中导入数据。我们可以用它快速地对数据进行复杂的转换和过滤等操作。Pandas 真是超级棒。</p>
<p>我觉得<strong>它和 Numpy、Matplotlib 一起构成了一个 Python 数据探索和分析的强大基础</strong>。Scipy （将会在下一篇推文里介绍）当然也是一大主力并且是一个绝对赞的库，但是我觉得前三者才是 Python 科学计算真正的顶梁柱。</p>
<p>那么，赶紧看看 python 科学计算系列的第三篇推文，一窥 Pandas 的芳容吧。如果你还没看其它几篇文章的话，别忘了去看看。</p>
<h2 id="导入-Pandas"><a href="#导入-Pandas" class="headerlink" title="导入 Pandas"></a>导入 Pandas</h2><p>第一件事当然是请出我们的明星 —— Pandas。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># This is the standard</span></span><br></pre></td></tr></table></figure>

<p>这是导入 pandas 的标准方法。我们不想一直写 pandas 的全名，但是保证代码的简洁和避免命名冲突都很重要，所以折中使用 pd 。如果你去看别人使用 pandas 的代码，就会看到这种导入方式。</p>
<h2 id="Pandas-中的数据类型"><a href="#Pandas-中的数据类型" class="headerlink" title="Pandas 中的数据类型"></a>Pandas 中的数据类型</h2><p>Pandas 基于两种数据类型，<code>series</code>和<code>dataframe</code>。</p>
<ul>
<li><p><strong>series</strong> 是一种一维的数据类型，其中的每个元素都有各自的标签。如果你之前看过这个系列关于Numpy 的推文，你可以把它当作一个由带标签的元素组成的 numpy 数组。标签可以是数字或者字符。</p>
</li>
<li><p><strong>dataframe</strong> 是一个二维的、表格型的数据结构。Pandas 的 dataframe 可以储存许多不同类型的数据，并且每个轴都有标签。你可以把它当作一个 series 的字典。</p>
</li>
</ul>
<h2 id="将数据导入-Pandas"><a href="#将数据导入-Pandas" class="headerlink" title="将数据导入 Pandas"></a>将数据导入 Pandas</h2><p>在对数据进行修改、探索和分析之前，我们得先导入数据。多亏了 Pandas ，这比在 Numpy 中还要容易。</p>
<p>这里我鼓励你去找到自己感兴趣的数据并用来练习。你的（或者别的）国家的网站就是不错的数据源。如果要举例的话，首推<a href="https://data.gov.uk/data/search">英国政府数据</a>和<a href="http://catalog.data.gov/dataset">美国政府数据</a>。<a href="https://www.kaggle.com/">Kaggle</a>也是个很好的数据源。</p>
<p>我将使用英国降雨数据，这个数据集可以很容易地从英国政府网站上下载到。此外，我还下载了一些日本降雨量的数据。</p>
<blockquote>
<p>英国降雨数据：<a href="https://data.gov.uk/dataset/3f952707-b04e-4a32-a807-a53b6fa0ee58/average-temperature-and-total-rainfall-in-england-and-wales/datafile/3fea0f7b-5304-4f11-a809-159f4558e7da/preview">下载地址</a></p>
</blockquote>
<h3 id="read-csv"><a href="#read-csv" class="headerlink" title="read_csv"></a>read_csv</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Reading a csv into Pandas.</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;uk_rain_2014.csv&#x27;</span>, header=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>译者注：如果你的数据集中有中文的话，最好在里面加上 encoding = ‘gbk’ ，以避免乱码问题。后面的导出数据的时候也一样。</p>
</blockquote>
<p>这里我们从 csv 文件里导入了数据，并储存在 dataframe 中。这一步非常简单，你只需要调用read_csv 然后将文件的路径传进去就行了。header 关键字告诉 Pandas 哪些是数据的列名。如果没有列名的话就将它设定为 None 。Pandas 非常聪明，所以这个经常可以省略。</p>
<h2 id="准备好要进行探索和分析的数据"><a href="#准备好要进行探索和分析的数据" class="headerlink" title="准备好要进行探索和分析的数据"></a>准备好要进行探索和分析的数据</h2><p>现在数据已经导入到 Pandas 了，我们也许想看一眼数据来得到一些基本信息，以便在真正开始探索之前找到一些方向。</p>
<h3 id="head"><a href="#head" class="headerlink" title="head"></a>head</h3><p>查看前 x 行的数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting first x rows.</span></span><br><span class="line">df.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>我们只需要调用 head() 函数并且将想要查看的行数传入。</p>
<p>得到的结果如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df.head(5)</span></span><br><span class="line">  <span class="string">Water</span> <span class="string">Year</span>  <span class="string">Rain</span> <span class="string">(mm)</span> <span class="string">Oct-Sep</span>  <span class="string">...</span>  <span class="string">Rain</span> <span class="string">(mm)</span> <span class="string">Jun-Aug</span>  <span class="string">Outflow</span> <span class="string">(m3/s)</span> <span class="string">Jun-Aug</span></span><br><span class="line"><span class="number">0</span>    <span class="number">1980</span><span class="string">/81</span>               <span class="number">1182</span>  <span class="string">...</span>                <span class="number">174</span>                    <span class="number">2212</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1981</span><span class="string">/82</span>               <span class="number">1098</span>  <span class="string">...</span>                <span class="number">242</span>                    <span class="number">1936</span></span><br><span class="line"><span class="number">2</span>    <span class="number">1982</span><span class="string">/83</span>               <span class="number">1156</span>  <span class="string">...</span>                <span class="number">124</span>                    <span class="number">1802</span></span><br><span class="line"><span class="number">3</span>    <span class="number">1983</span><span class="string">/84</span>                <span class="number">993</span>  <span class="string">...</span>                <span class="number">141</span>                    <span class="number">1078</span></span><br><span class="line"><span class="number">4</span>    <span class="number">1984</span><span class="string">/85</span>               <span class="number">1182</span>  <span class="string">...</span>                <span class="number">343</span>                    <span class="number">4313</span></span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> <span class="string">rows</span> <span class="string">x</span> <span class="number">7</span> <span class="string">columns</span>]</span><br></pre></td></tr></table></figure>

<h3 id="tail"><a href="#tail" class="headerlink" title="tail"></a>tail</h3><p>你可能还想看看最后几行：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting last x rows.</span></span><br><span class="line"><span class="attribute">df</span>.tail(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>跟 head 一样，我们只需要调用 tail 并且传入想要查看的行数即可。注意，它并不是从最后一行倒着显示的，而是按照数据原来的顺序显示。</p>
<p>得到的结果如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df.tail(5)</span></span><br><span class="line">   <span class="string">Water</span> <span class="string">Year</span>  <span class="string">Rain</span> <span class="string">(mm)</span> <span class="string">Oct-Sep</span>  <span class="string">...</span>  <span class="string">Rain</span> <span class="string">(mm)</span> <span class="string">Jun-Aug</span>  <span class="string">Outflow</span> <span class="string">(m3/s)</span> <span class="string">Jun-Aug</span></span><br><span class="line"><span class="number">28</span>    <span class="number">2008</span><span class="string">/09</span>               <span class="number">1139</span>  <span class="string">...</span>                <span class="number">323</span>                    <span class="number">3189</span></span><br><span class="line"><span class="number">29</span>    <span class="number">2009</span><span class="string">/10</span>               <span class="number">1103</span>  <span class="string">...</span>                <span class="number">244</span>                    <span class="number">1958</span></span><br><span class="line"><span class="number">30</span>    <span class="number">2010</span><span class="string">/11</span>               <span class="number">1053</span>  <span class="string">...</span>                <span class="number">267</span>                    <span class="number">2885</span></span><br><span class="line"><span class="number">31</span>    <span class="number">2011</span><span class="string">/12</span>               <span class="number">1285</span>  <span class="string">...</span>                <span class="number">379</span>                    <span class="number">5261</span></span><br><span class="line"><span class="number">32</span>    <span class="number">2012</span><span class="string">/13</span>               <span class="number">1090</span>  <span class="string">...</span>                <span class="number">187</span>                    <span class="number">1797</span></span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> <span class="string">rows</span> <span class="string">x</span> <span class="number">7</span> <span class="string">columns</span>]</span><br></pre></td></tr></table></figure>

<h3 id="columns"><a href="#columns" class="headerlink" title="columns"></a>columns</h3><p>你通常使用列的名字来在 Pandas 中查找列。这一点很好而且易于使用，但是有时列名太长，比如调查问卷的一整个问题。不过你把列名缩短之后一切就好说了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Changing column labels.</span></span><br><span class="line">df.columns = [<span class="string">&#x27;water_year&#x27;</span>,<span class="string">&#x27;rain_octsep&#x27;</span>, <span class="string">&#x27;outflow_octsep&#x27;</span>,</span><br><span class="line">              <span class="string">&#x27;rain_decfeb&#x27;</span>, <span class="string">&#x27;outflow_decfeb&#x27;</span>, <span class="string">&#x27;rain_junaug&#x27;</span>, <span class="string">&#x27;outflow_junaug&#x27;</span>]</span><br><span class="line"></span><br><span class="line">df.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>需要注意的一点是，我故意没有在每列的标签中使用空格和破折号。之后你会看到这样为变量命名可以使我们少打一些字符。</p>
<p>你得到的数据与之前的一样，只是换了列的名字：</p>
<figure class="highlight tap"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.head(5)</span><br><span class="line">  water_year  rain_octsep  outflow_octsep  rain_decfeb  outflow_decfeb  rain_junaug  outflow_junaug</span><br><span class="line">0    1980/81        <span class="number"> 1182 </span>          <span class="number"> 5408 </span>        <span class="number"> 292 </span>          <span class="number"> 7248 </span>        <span class="number"> 174 </span>           2212</span><br><span class="line">1    1981/82        <span class="number"> 1098 </span>          <span class="number"> 5112 </span>        <span class="number"> 257 </span>          <span class="number"> 7316 </span>        <span class="number"> 242 </span>           1936</span><br><span class="line">2    1982/83        <span class="number"> 1156 </span>          <span class="number"> 5701 </span>        <span class="number"> 330 </span>          <span class="number"> 8567 </span>        <span class="number"> 124 </span>           1802</span><br><span class="line">3    1983/84         <span class="number"> 993 </span>          <span class="number"> 4265 </span>        <span class="number"> 391 </span>          <span class="number"> 8905 </span>        <span class="number"> 141 </span>           1078</span><br><span class="line">4    1984/85        <span class="number"> 1182 </span>          <span class="number"> 5364 </span>        <span class="number"> 217 </span>          <span class="number"> 5813 </span>        <span class="number"> 343 </span>           4313</span><br></pre></td></tr></table></figure>

<h3 id="len"><a href="#len" class="headerlink" title="len"></a>len</h3><p>你通常会想知道数据的另一个特征——它有多少条记录。在 Pandas 中，一条记录对应着一行，所以我们可以对数据集调用 len 方法，它将返回数据集的总行数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Finding out how many rows dataset has.</span></span><br><span class="line"><span class="built_in">len</span>(df)</span><br></pre></td></tr></table></figure>

<p>上面的代码返回一个表示数据行数的整数，在我的数据集中，这个值是 33 。</p>
<h3 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h3><p>你可能还想知道数据集的一些基本的统计数据，在 Pandas 中，这个操作简单到哭：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Finding out basic statistical information on your dataset.</span></span><br><span class="line">pd.options.display.float_format = <span class="string">&#x27;&#123;:,.3f&#125;&#x27;</span>.<span class="built_in">format</span> <span class="comment"># Limit output to 3 decimal places.</span></span><br><span class="line">df.describe()</span><br></pre></td></tr></table></figure>

<p>这将返回一张表，其中有诸如总数、均值、标准差之类的统计数据：</p>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df.describe()</span><br><span class="line">       rain_octsep  outflow_octsep  rain_decfeb  outflow_decfeb  rain_junaug  outflow_junaug</span><br><span class="line">count       <span class="number">33</span>.<span class="number">000</span>          <span class="number">33</span>.<span class="number">000</span>       <span class="number">33</span>.<span class="number">000</span>          <span class="number">33</span>.<span class="number">000</span>       <span class="number">33</span>.<span class="number">000</span>          <span class="number">33</span>.<span class="number">000</span></span><br><span class="line">mean     <span class="number">1,129.000</span>       <span class="number">5,019.182</span>      <span class="number">325.364</span>       <span class="number">7</span>,<span class="number">926.545</span>      <span class="number">237.485</span>       <span class="number">2</span>,<span class="number">439.758</span></span><br><span class="line">std        <span class="number">101.900</span>         <span class="number">658.588</span>       <span class="number">69</span>.<span class="number">995</span>       <span class="number">1</span>,<span class="number">692.800</span>       <span class="number">66</span>.<span class="number">168</span>       <span class="number">1</span>,<span class="number">025.914</span></span><br><span class="line">min        <span class="number">856.000</span>       <span class="number">3</span>,<span class="number">479.000</span>      <span class="number">206.000</span>       <span class="number">4</span>,<span class="number">578.000</span>      <span class="number">103.000</span>       <span class="number">1</span>,<span class="number">078.000</span></span><br><span class="line"><span class="number">25</span>%      <span class="number">1</span>,<span class="number">053.000</span>       <span class="number">4</span>,<span class="number">506.000</span>      <span class="number">268.000</span>       <span class="number">6</span>,<span class="number">690.000</span>      <span class="number">193.000</span>       <span class="number">1</span>,<span class="number">797.000</span></span><br><span class="line"><span class="number">50</span>%      <span class="number">1,139.000</span>       <span class="number">5,112.000</span>      <span class="number">309.000</span>       <span class="number">7</span>,<span class="number">630.000</span>      <span class="number">229.000</span>       <span class="number">2,142.000</span></span><br><span class="line"><span class="number">75</span>%      <span class="number">1,182.000</span>       <span class="number">5</span>,<span class="number">497.000</span>      <span class="number">360.000</span>       <span class="number">8</span>,<span class="number">905.000</span>      <span class="number">280.000</span>       <span class="number">2</span>,<span class="number">959.000</span></span><br><span class="line">max      <span class="number">1</span>,<span class="number">387.000</span>       <span class="number">6</span>,<span class="number">391.000</span>      <span class="number">484.000</span>      <span class="number">11</span>,<span class="number">486.000</span>      <span class="number">379.000</span>       <span class="number">5</span>,<span class="number">261.000</span></span><br></pre></td></tr></table></figure>

<h2 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h2><p>在探索数据的时候，你可能经常想要抽取数据中特定的样本，比如你有一个关于工作满意度的调查表，你可能就想要提取特定行业或者年龄的人的数据。</p>
<p>在 Pandas 中有多种方法可以实现提取我们想要的信息。</p>
<p>有时你想提取一整列，使用列的标签可以非常简单地做到：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting a column by label</span></span><br><span class="line">df[<span class="string">&#x27;rain_octsep&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>注意，当我们提取列的时候，会得到一个 <code>series</code> ，而不是 <code>dataframe</code> 。记得我们前面提到过，你可以把 <code>dataframe</code> 看作是一个 <code>series</code> 的字典，所以在抽取列的时候，我们就会得到一个 <code>series</code>。</p>
<p>还记得我在命名列标签的时候特意指出的吗？不用空格、破折号之类的符号，这样我们就可以像访问对象属性一样访问数据集的列——只用一个点号。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting a column by label using .</span></span><br><span class="line">df.rain_octsep</span><br></pre></td></tr></table></figure>

<p>这句代码返回的结果与前一个例子完全一样——是我们选择的那列数据。</p>
<p>如果你读过这个系列关于 Numpy 的推文，你可能还记得一个叫做 <code>布尔过滤（boolean masking）</code>的技术，通过在一个数组上运行条件来得到一个布林数组。在 Pandas 里也可以做到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Creating a series of booleans based on a conditional</span></span><br><span class="line">df.rain_octsep &lt; <span class="number">1000</span> <span class="comment"># Or df[&#x27;rain_octsep] &lt; 1000</span></span><br></pre></td></tr></table></figure>

<p>上面的代码将会返回一个由布尔值构成的 dataframe。True 表示在十月-九月降雨量小于 1000 mm，False 表示大于等于 1000 mm。</p>
<p>我们可以用这些条件表达式来过滤现有的 dataframe。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Using a series of booleans to filter</span></span><br><span class="line">df[df.rain_octsep &lt; <span class="number">1000</span>]</span><br></pre></td></tr></table></figure>

<p>这条代码只返回十月-九月降雨量小于 1000 mm 的记录：</p>
<figure class="highlight tap"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df[df.rain_octsep &lt; 1000]</span><br><span class="line">   water_year  rain_octsep  outflow_octsep  rain_decfeb  outflow_decfeb  rain_junaug  outflow_junaug</span><br><span class="line">3     1983/84         <span class="number"> 993 </span>          <span class="number"> 4265 </span>        <span class="number"> 391 </span>          <span class="number"> 8905 </span>        <span class="number"> 141 </span>           1078</span><br><span class="line">8     1988/89         <span class="number"> 976 </span>          <span class="number"> 4330 </span>        <span class="number"> 309 </span>          <span class="number"> 6465 </span>        <span class="number"> 200 </span>           1440</span><br><span class="line">15    1995/96         <span class="number"> 856 </span>          <span class="number"> 3479 </span>        <span class="number"> 245 </span>          <span class="number"> 5515 </span>        <span class="number"> 172 </span>           1439</span><br></pre></td></tr></table></figure>

<p>也可以通过复合条件表达式来进行过滤：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Filtering by multiple conditionals</span></span><br><span class="line">df[(df.rain_octsep &lt; <span class="number">1000</span>) &amp; (df.outflow_octsep &lt; <span class="number">4000</span>)] <span class="comment"># Can&#x27;t use the keyword &#x27;and&#x27;</span></span><br></pre></td></tr></table></figure>

<p>这条代码只会返回 rain_octsep 中小于 1000 的和 outflow_octsep 中小于 4000 的记录：</p>
<p>注意重要的一点：这里不能用 and 关键字，因为会引发操作顺序的问题。必须用 &amp; 和圆括号。</p>
<p>如果你的数据中字符串，你也可以使用字符串方法来进行过滤：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Filtering by string methods</span></span><br><span class="line">df[df.water_year.<span class="built_in">str</span>.startswith(<span class="string">&#x27;199&#x27;</span>)]</span><br></pre></td></tr></table></figure>

<p>注意，你必须用 .str.[string method] ，而不能直接在字符串上调用字符方法。上面的代码返回所有 90 年代的记录：</p>
<figure class="highlight tap"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; df[df.water_year.str.startswith(&#x27;199&#x27;)]</span><br><span class="line">   water_year  rain_octsep  outflow_octsep  rain_decfeb  outflow_decfeb  rain_junaug  outflow_junaug</span><br><span class="line">10    1990/91        <span class="number"> 1022 </span>          <span class="number"> 4418 </span>        <span class="number"> 305 </span>          <span class="number"> 7120 </span>        <span class="number"> 216 </span>           1923</span><br><span class="line">11    1991/92        <span class="number"> 1151 </span>          <span class="number"> 4506 </span>        <span class="number"> 246 </span>          <span class="number"> 5493 </span>        <span class="number"> 280 </span>           2118</span><br><span class="line">12    1992/93        <span class="number"> 1130 </span>          <span class="number"> 5246 </span>        <span class="number"> 308 </span>          <span class="number"> 8751 </span>        <span class="number"> 219 </span>           2551</span><br><span class="line">13    1993/94        <span class="number"> 1162 </span>          <span class="number"> 5583 </span>        <span class="number"> 422 </span>         <span class="number"> 10109 </span>        <span class="number"> 193 </span>           1638</span><br><span class="line">14    1994/95        <span class="number"> 1110 </span>          <span class="number"> 5370 </span>        <span class="number"> 484 </span>         <span class="number"> 11486 </span>        <span class="number"> 103 </span>           1231</span><br><span class="line">15    1995/96         <span class="number"> 856 </span>          <span class="number"> 3479 </span>        <span class="number"> 245 </span>          <span class="number"> 5515 </span>        <span class="number"> 172 </span>           1439</span><br><span class="line">16    1996/97        <span class="number"> 1047 </span>          <span class="number"> 4019 </span>        <span class="number"> 258 </span>          <span class="number"> 5770 </span>        <span class="number"> 256 </span>           2102</span><br><span class="line">17    1997/98        <span class="number"> 1169 </span>          <span class="number"> 4953 </span>        <span class="number"> 341 </span>          <span class="number"> 7747 </span>        <span class="number"> 285 </span>           3206</span><br><span class="line">18    1998/99        <span class="number"> 1268 </span>          <span class="number"> 5824 </span>        <span class="number"> 360 </span>          <span class="number"> 8771 </span>        <span class="number"> 225 </span>           2240</span><br><span class="line">19    1999/00        <span class="number"> 1204 </span>          <span class="number"> 5665 </span>        <span class="number"> 417 </span>         <span class="number"> 10021 </span>        <span class="number"> 197 </span>           2166</span><br></pre></td></tr></table></figure>

<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>之前的部分展示了如何通过列操作来得到数据，但是 Pandas 的行也有标签。行标签可以是基于数字的或者是标签，而且获取行数据的方法也根据标签的类型各有不同。</p>
<h3 id="iloc"><a href="#iloc" class="headerlink" title="iloc"></a>iloc</h3><p>如果你的行标签是数字型的，你可以通过 <code>iloc</code> 来引用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting a row via a numerical index</span></span><br><span class="line">df.iloc[<span class="number">30</span>]</span><br></pre></td></tr></table></figure>

<p>iloc 只对数字型的标签有用。它会返回给定行的 <code>series</code>，行中的每一列都是返回 <code>series</code> 的一个元素。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df.iloc[30]</span></span><br><span class="line"><span class="string">water_year</span>        <span class="number">2010</span><span class="string">/11</span></span><br><span class="line"><span class="string">rain_octsep</span>          <span class="number">1053</span></span><br><span class="line"><span class="string">outflow_octsep</span>       <span class="number">4521</span></span><br><span class="line"><span class="string">rain_decfeb</span>           <span class="number">265</span></span><br><span class="line"><span class="string">outflow_decfeb</span>       <span class="number">6593</span></span><br><span class="line"><span class="string">rain_junaug</span>           <span class="number">267</span></span><br><span class="line"><span class="string">outflow_junaug</span>       <span class="number">2885</span></span><br><span class="line"><span class="attr">Name:</span> <span class="number">30</span><span class="string">,</span> <span class="attr">dtype:</span> <span class="string">object</span></span><br></pre></td></tr></table></figure>

<h3 id="set-index"><a href="#set-index" class="headerlink" title="set_index"></a>set_index</h3><p>也许你的数据集中有年份或者年龄的列，你可能想通过这些年份或者年龄来引用行，这个时候我们就可以设置一个（或者多个）新的索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Setting a new index from an existing column</span></span><br><span class="line">df = df.set_index([<span class="string">&#x27;water_year&#x27;</span>])</span><br><span class="line">df.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>上面的代码将 water_year 列设置为索引。注意，列的名字实际上是一个列表，虽然上面的例子中只有一个元素。如果你想设置多个索引，只需要在列表中加入列的名字即可。</p>
<h3 id="loc"><a href="#loc" class="headerlink" title="loc"></a>loc</h3><p>上例中我们设置的索引列中都是字符型数据，这意味着我们不能继续使用 iloc 来引用，那我们用什么呢？用 <code>loc</code> 。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting a row via a label-based index</span></span><br><span class="line">df.loc[<span class="string">&#x27;2000/01&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>和 <code>iloc</code> 一样，<code>loc</code> 会返回你引用的行的 <code>series</code>，唯一一点不同就是此时你使用的是基于字符串的引用，而不是基于数字的。</p>
<h3 id="ix"><a href="#ix" class="headerlink" title="ix"></a>ix</h3><p>还有一个引用列的常用常用方法—— <code>ix</code> 。如果 <code>loc</code> 是基于标签的，而 <code>iloc</code> 是基于数字的，那 <code>ix</code> 是基于什么的？事实上，<code>ix</code> 是基于标签的查询方法，但它同时也支持数字型索引作为备选。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Getting a row via a label-based or numerical index</span></span><br><span class="line">df.ix[<span class="string">&#x27;1999/00&#x27;</span>] <span class="comment"># Label based with numerical index fallback *Not recommended</span></span><br></pre></td></tr></table></figure>

<p>与 <code>iloc</code>、<code>loc</code> 一样，它也会返回你查询的行。</p>
<p>如果 <code>ix</code> 可以同时起到 <code>loc</code> 和 <code>iloc</code> 的作用，那为什么还要用后两个？一大原因就是 <code>ix</code> 具有轻微的不可预测性。还记得我说过它所支持的数字型索引只是备选吗？这一特性可能会导致 <code>ix</code> 产生一些奇怪的结果，比如讲一个数字解释为一个位置。而使用 <code>iloc</code> 和 <code>loc</code> 会很安全、可预测并且让人放心。但是我要指出的是，<code>ix</code> 比 <code>iloc</code> 和 <code>loc</code> 要快一些。</p>
<h3 id="sort-index"><a href="#sort-index" class="headerlink" title="sort_index"></a>sort_index</h3><p>将索引排序通常会很有用，在 Pandas 中，我们可以对 dataframe 调用 sort_index 方法进行排序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sort_index(ascending=<span class="literal">False</span>).head(<span class="number">5</span>) <span class="comment">#inplace=True to apple the sorting in place</span></span><br></pre></td></tr></table></figure>

<p>我的索引本来就是有序的，为了演示，我将参数 <code>ascending</code> 设置为 <code>false</code>，这样我的数据就会呈降序排列。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df.sort_index(ascending=False).head(5)</span></span><br><span class="line">            <span class="string">rain_octsep</span>  <span class="string">outflow_octsep</span>  <span class="string">rain_decfeb</span>  <span class="string">outflow_decfeb</span>  <span class="string">rain_junaug</span>  <span class="string">outflow_junaug</span></span><br><span class="line"><span class="string">water_year</span></span><br><span class="line"><span class="number">2012</span><span class="string">/13</span>            <span class="number">1090            </span><span class="number">5329          </span><span class="number">350</span>            <span class="number">9615          </span><span class="number">187</span>            <span class="number">1797</span></span><br><span class="line"><span class="number">2011</span><span class="string">/12</span>            <span class="number">1285            </span><span class="number">5500          </span><span class="number">339</span>            <span class="number">7630          </span><span class="number">379</span>            <span class="number">5261</span></span><br><span class="line"><span class="number">2010</span><span class="string">/11</span>            <span class="number">1053            </span><span class="number">4521          </span><span class="number">265</span>            <span class="number">6593          </span><span class="number">267</span>            <span class="number">2885</span></span><br><span class="line"><span class="number">2009</span><span class="string">/10</span>            <span class="number">1103            </span><span class="number">4738          </span><span class="number">255</span>            <span class="number">6435          </span><span class="number">244</span>            <span class="number">1958</span></span><br><span class="line"><span class="number">2008</span><span class="string">/09</span>            <span class="number">1139            </span><span class="number">4941          </span><span class="number">268</span>            <span class="number">6690          </span><span class="number">323</span>            <span class="number">3189</span></span><br></pre></td></tr></table></figure>

<h3 id="reset-index"><a href="#reset-index" class="headerlink" title="reset_index"></a>reset_index</h3><p>当你将一列设置为索引的时候，它就不再是数据的一部分了。如果你想将索引恢复为数据，调用 <code>set_index</code> 相反的方法 <code>reset_index</code> 即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Returning an index to data</span></span><br><span class="line">df = df.reset_index(<span class="string">&#x27;water_year&#x27;</span>)</span><br><span class="line">df.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>这一语句会将索引恢复成数据形式。</p>
<h2 id="对数据集应用函数"><a href="#对数据集应用函数" class="headerlink" title="对数据集应用函数"></a>对数据集应用函数</h2><h3 id="apply-amp-applymap"><a href="#apply-amp-applymap" class="headerlink" title="apply &amp; applymap"></a>apply &amp; applymap</h3><p>有时你想对数据集中的数据进行改变或者某种操作。比方说，你有一列年份的数据，你需要新的一列来表示这些年份对应的年代。Pandas 中有两个非常有用的函数，apply 和 applymap。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Applying a function to a column</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">base_year</span>(<span class="params">year</span>):</span><br><span class="line">    base_year = year[:<span class="number">4</span>]</span><br><span class="line">    base_year= pd.to_datetime(base_year).year</span><br><span class="line">    <span class="keyword">return</span> base_year</span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;year&#x27;</span>] = df.water_year.apply(base_year)</span><br><span class="line">df.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>上面的代码创建了一个叫做 year 的列，它只将 water_year 列中的年提取了出来。这就是 apply的用法，即对一列数据应用函数。如果你想对整个数据集应用函数，就要使用 applymap 。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">def</span> <span class="string">base_year(year):</span></span><br><span class="line"><span class="string">...</span>     <span class="string">base_year</span> <span class="string">=</span> <span class="string">year[:4]</span></span><br><span class="line"><span class="string">...</span>     <span class="string">base_year</span> <span class="string">=</span> <span class="string">pd.to_datetime(base_year).year</span></span><br><span class="line"><span class="string">...</span>     <span class="string">return</span> <span class="string">base_year</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df[&#x27;year&#x27;]</span> <span class="string">=</span> <span class="string">df.water_year.apply(base_year)</span></span><br><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df.head(5)</span></span><br><span class="line">  <span class="string">water_year</span>  <span class="string">rain_octsep</span>  <span class="string">outflow_octsep</span>  <span class="string">...</span>  <span class="string">rain_junaug</span>  <span class="string">outflow_junaug</span>  <span class="string">year</span></span><br><span class="line"><span class="number">0</span>    <span class="number">1980</span><span class="string">/81</span>         <span class="number">1182            </span><span class="number">5408</span>  <span class="string">...</span>          <span class="number">174</span>            <span class="number">2212  </span><span class="number">1980</span></span><br><span class="line"><span class="number">1</span>    <span class="number">1981</span><span class="string">/82</span>         <span class="number">1098            </span><span class="number">5112</span>  <span class="string">...</span>          <span class="number">242</span>            <span class="number">1936  </span><span class="number">1981</span></span><br><span class="line"><span class="number">2</span>    <span class="number">1982</span><span class="string">/83</span>         <span class="number">1156            </span><span class="number">5701</span>  <span class="string">...</span>          <span class="number">124</span>            <span class="number">1802  </span><span class="number">1982</span></span><br><span class="line"><span class="number">3</span>    <span class="number">1983</span><span class="string">/84</span>          <span class="number">993</span>            <span class="number">4265</span>  <span class="string">...</span>          <span class="number">141</span>            <span class="number">1078  </span><span class="number">1983</span></span><br><span class="line"><span class="number">4</span>    <span class="number">1984</span><span class="string">/85</span>         <span class="number">1182            </span><span class="number">5364</span>  <span class="string">...</span>          <span class="number">343</span>            <span class="number">4313  </span><span class="number">1984</span></span><br><span class="line"></span><br><span class="line">[<span class="number">5</span> <span class="string">rows</span> <span class="string">x</span> <span class="number">8</span> <span class="string">columns</span>]</span><br></pre></td></tr></table></figure>

<h2 id="操作数据集的结构"><a href="#操作数据集的结构" class="headerlink" title="操作数据集的结构"></a>操作数据集的结构</h2><p>另一常见的做法是重新建立数据结构，使得数据集呈现出一种更方便并且（或者）有用的形式。</p>
<p>掌握这些转换最简单的方法就是观察转换的过程。比起这篇文章的其他部分，接下来的操作需要你跟着练习以便能掌握它们。</p>
<h3 id="groupby"><a href="#groupby" class="headerlink" title="groupby"></a>groupby</h3><p>首先，是 groupby ：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Manipulating structure (groupby, unstack, pivot)</span></span><br><span class="line"><span class="comment"># Grouby</span></span><br><span class="line">df.groupby(df.year // <span class="number">10</span> *<span class="number">10</span>).<span class="built_in">max</span>()</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">df.groupby(df.year</span> <span class="string">//</span> <span class="number">10</span> <span class="string">*10).max()</span></span><br><span class="line">     <span class="string">water_year</span>  <span class="string">rain_octsep</span>  <span class="string">outflow_octsep</span>  <span class="string">...</span>  <span class="string">rain_junaug</span>  <span class="string">outflow_junaug</span>  <span class="string">year</span></span><br><span class="line"><span class="string">year</span>                                          <span class="string">...</span></span><br><span class="line"><span class="number">1980    </span><span class="number">1989</span><span class="string">/90</span>         <span class="number">1210            </span><span class="number">5701</span>  <span class="string">...</span>          <span class="number">343</span>            <span class="number">4313  </span><span class="number">1989</span></span><br><span class="line"><span class="number">1990    </span><span class="number">1999</span><span class="string">/00</span>         <span class="number">1268            </span><span class="number">5824</span>  <span class="string">...</span>          <span class="number">285</span>            <span class="number">3206  </span><span class="number">1999</span></span><br><span class="line"><span class="number">2000    </span><span class="number">2009</span><span class="string">/10</span>         <span class="number">1387            </span><span class="number">6391</span>  <span class="string">...</span>          <span class="number">357</span>            <span class="number">5168  </span><span class="number">2009</span></span><br><span class="line"><span class="number">2010    </span><span class="number">2012</span><span class="string">/13</span>         <span class="number">1285            </span><span class="number">5500</span>  <span class="string">...</span>          <span class="number">379</span>            <span class="number">5261  </span><span class="number">2012</span></span><br><span class="line"></span><br><span class="line">[<span class="number">4</span> <span class="string">rows</span> <span class="string">x</span> <span class="number">8</span> <span class="string">columns</span>]</span><br></pre></td></tr></table></figure>

<p>groupby 会按照你选择的列对数据集进行分组。上例是按照年代分组。不过仅仅这样做并没有什么用，我们必须对其调用函数，比如 max 、 min 、mean 等等。例中，我们可以得到 90 年代的均值。</p>
<p>你也可以按照多列进行分组：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Grouping by multiple columns</span></span><br><span class="line">decade_rain = df.groupby([df.year // <span class="number">10</span> * <span class="number">10</span>, df.rain_octsep // <span class="number">1000</span> * <span class="number">1000</span>])[[<span class="string">&#x27;outflow_octsep&#x27;</span>,                                                              <span class="string">&#x27;outflow_decfeb&#x27;</span>, <span class="string">&#x27;outflow_junaug&#x27;</span>]].mean()</span><br><span class="line">decade_rain</span><br></pre></td></tr></table></figure>

<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; decade_rain = df.groupby([df.year // <span class="number">10</span> * <span class="number">10</span>, df.rain_octsep // <span class="number">1000</span> * <span class="number">1000</span>])[[&#x27;outflow_octsep&#x27;,                                                              &#x27;outflow_decfeb&#x27;, &#x27;outflow_junaug&#x27;]].mean()</span><br><span class="line">&gt;&gt;&gt; decade_rain</span><br><span class="line">                  outflow_octsep  outflow_decfeb  outflow_junaug</span><br><span class="line">year rain_octsep</span><br><span class="line"><span class="number">1980</span> <span class="number">0</span>                 <span class="number">4</span>,<span class="number">297.500</span>       <span class="number">7</span>,<span class="number">685.000</span>       <span class="number">1</span>,<span class="number">259.000</span></span><br><span class="line">     <span class="number">1000</span>              <span class="number">5</span>,<span class="number">289.625</span>       <span class="number">7</span>,<span class="number">933.000</span>       <span class="number">2,572.250</span></span><br><span class="line"><span class="number">1990</span> <span class="number">0</span>                 <span class="number">3</span>,<span class="number">479.000</span>       <span class="number">5</span>,<span class="number">515.000</span>       <span class="number">1</span>,<span class="number">439.000</span></span><br><span class="line">     <span class="number">1000</span>              <span class="number">5</span>,<span class="number">064.889</span>       <span class="number">8,363.111</span>       <span class="number">2,130.556</span></span><br><span class="line"><span class="number">2000 1000</span>              <span class="number">5</span>,<span class="number">030.800</span>       <span class="number">7,812.100</span>       <span class="number">2</span>,<span class="number">685.900</span></span><br><span class="line"><span class="number">2010 1000</span>              <span class="number">5,116.667</span>       <span class="number">7</span>,<span class="number">946.000</span>       <span class="number">3</span>,<span class="number">314.333</span></span><br></pre></td></tr></table></figure>

<h3 id="unstack"><a href="#unstack" class="headerlink" title="unstack"></a>unstack</h3><p>接下来是 <code>unstack</code> ，最开始可能有一些困惑，它可以将一列数据设置为列标签。最好还是看看实际的操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Unstacking</span></span><br><span class="line">decade_rain.unstack(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>这条语句将上例中的 dataframe 转换为下面的形式。它将第 0 列，也就是 year 列设置为列的标签。</p>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; decade_rain.unstack(<span class="number">0</span>)</span><br><span class="line">            outflow_octsep                               outflow_decfeb                               outflow_junaug</span><br><span class="line">year                  <span class="number">1980</span>      <span class="number">1990</span>      <span class="number">2000</span>      <span class="number">2010</span>           <span class="number">1980</span>      <span class="number">1990</span>      <span class="number">2000</span>      <span class="number">2010</span>           <span class="number">1980</span>      <span class="number">1990</span>      <span class="number">2000</span>      <span class="number">2010</span></span><br><span class="line">rain_octsep</span><br><span class="line"><span class="number">0</span>                <span class="number">4</span>,<span class="number">297.500</span> <span class="number">3</span>,<span class="number">479.000</span>       NaN       NaN      <span class="number">7</span>,<span class="number">685.000</span> <span class="number">5</span>,<span class="number">515.000</span>       NaN       NaN      <span class="number">1</span>,<span class="number">259.000</span> <span class="number">1</span>,<span class="number">439.000</span>       NaN       NaN</span><br><span class="line"><span class="number">1000</span>             <span class="number">5</span>,<span class="number">289.625</span> <span class="number">5</span>,<span class="number">064.889</span> <span class="number">5</span>,<span class="number">030.800</span> <span class="number">5,116.667</span>      <span class="number">7</span>,<span class="number">933.000</span> <span class="number">8,363.111</span> <span class="number">7,812.100</span> <span class="number">7</span>,<span class="number">946.000</span>      <span class="number">2,572.250</span> <span class="number">2,130.556</span> <span class="number">2</span>,<span class="number">685.900</span> <span class="number">3</span>,<span class="number">314.333</span></span><br></pre></td></tr></table></figure>

<p>让我们再操作一次。这次使用第 1 列，也就是 <code>rain_octsep</code> 列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># More unstacking</span></span><br><span class="line">decade_rain.unstack(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; decade_rain.unstack(<span class="number">1</span>)</span><br><span class="line">            outflow_octsep           outflow_decfeb           outflow_junaug</span><br><span class="line">rain_octsep           <span class="number">0</span>         <span class="number">1000</span>           <span class="number">0</span>         <span class="number">1000</span>           <span class="number">0</span>         <span class="number">1000</span></span><br><span class="line">year</span><br><span class="line"><span class="number">1980</span>             <span class="number">4</span>,<span class="number">297.500</span> <span class="number">5</span>,<span class="number">289.625</span>      <span class="number">7</span>,<span class="number">685.000</span> <span class="number">7</span>,<span class="number">933.000</span>      <span class="number">1</span>,<span class="number">259.000</span> <span class="number">2,572.250</span></span><br><span class="line"><span class="number">1990</span>             <span class="number">3</span>,<span class="number">479.000</span> <span class="number">5</span>,<span class="number">064.889</span>      <span class="number">5</span>,<span class="number">515.000</span> <span class="number">8,363.111</span>      <span class="number">1</span>,<span class="number">439.000</span> <span class="number">2,130.556</span></span><br><span class="line"><span class="number">2000</span>                   NaN <span class="number">5</span>,<span class="number">030.800</span>            NaN <span class="number">7,812.100</span>            NaN <span class="number">2</span>,<span class="number">685.900</span></span><br><span class="line"><span class="number">2010</span>                   NaN <span class="number">5,116.667</span>            NaN <span class="number">7</span>,<span class="number">946.000</span>            NaN <span class="number">3</span>,<span class="number">314.333</span></span><br></pre></td></tr></table></figure>

<p>在进行下次操作之前，我们先创建一个用于演示的 dataframe :</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Create a new dataframe containing entries which</span></span><br><span class="line"><span class="comment"># has rain_octsep values of greater than 1250</span></span><br><span class="line">high_rain = df[df.rain_octsep &gt; <span class="number">1250</span>]</span><br><span class="line">high_rain</span><br></pre></td></tr></table></figure>
<figure class="highlight tap"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; high_rain</span><br><span class="line">   water_year  rain_octsep  outflow_octsep  rain_decfeb  outflow_decfeb  rain_junaug  outflow_junaug  year</span><br><span class="line">18    1998/99        <span class="number"> 1268 </span>          <span class="number"> 5824 </span>        <span class="number"> 360 </span>          <span class="number"> 8771 </span>        <span class="number"> 225 </span>          <span class="number"> 2240 </span> 1998</span><br><span class="line">26    2006/07        <span class="number"> 1387 </span>          <span class="number"> 6391 </span>        <span class="number"> 437 </span>         <span class="number"> 10926 </span>        <span class="number"> 357 </span>          <span class="number"> 5168 </span> 2006</span><br><span class="line">31    2011/12        <span class="number"> 1285 </span>          <span class="number"> 5500 </span>        <span class="number"> 339 </span>          <span class="number"> 7630 </span>        <span class="number"> 379 </span>          <span class="number"> 5261 </span> 2011</span><br></pre></td></tr></table></figure>

<h3 id="pivot"><a href="#pivot" class="headerlink" title="pivot"></a>pivot</h3><p>上面的代码将会产生如下的 dataframe ，我们将会在上面演示轴向旋转（pivoting）。</p>
<p>轴旋转其实就是我们之前已经看到的那些操作的一个集合。首先，它会设置一个新的索引（set_index()），然后对索引排序（sort_index()），最后调用 unstack 。以上的步骤合在一起就是pivot 。接下来看看你能不能搞清楚下面的代码在干什么：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Pivoting</span></span><br><span class="line"><span class="comment">#does set_index, sort_index and unstack in a row</span></span><br><span class="line">high_rain.pivot(<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;rain_octsep&#x27;</span>)[[<span class="string">&#x27;outflow_octsep&#x27;</span>, <span class="string">&#x27;outflow_decfeb&#x27;</span>, <span class="string">&#x27;outflow_junaug&#x27;</span>]].fillna(<span class="string">&#x27;&#x27;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&gt;&gt;&gt;</span> <span class="string">high_rain.pivot(&#x27;year&#x27;,</span> <span class="string">&#x27;rain_octsep&#x27;</span><span class="string">)[[&#x27;outflow_octsep&#x27;,</span> <span class="string">&#x27;outflow_decfeb&#x27;</span><span class="string">,</span> <span class="string">&#x27;outflow_junaug&#x27;</span><span class="string">]].fillna(&#x27;&#x27;)</span></span><br><span class="line">            <span class="string">outflow_octsep</span>                     <span class="string">outflow_decfeb</span>                      <span class="string">outflow_junaug</span></span><br><span class="line"><span class="string">rain_octsep</span>           <span class="number">1268      </span><span class="number">1285      </span><span class="number">1387           </span><span class="number">1268      </span><span class="number">1285       </span><span class="number">1387           </span><span class="number">1268      </span><span class="number">1285      </span><span class="number">1387</span></span><br><span class="line"><span class="string">year</span></span><br><span class="line"><span class="number">1998             </span><span class="number">5</span><span class="string">,824.000</span>                          <span class="number">8</span><span class="string">,771.000</span>                           <span class="number">2</span><span class="string">,240.000</span></span><br><span class="line"><span class="number">2006                                 </span><span class="number">6</span><span class="string">,391.000</span>                          <span class="number">10</span><span class="string">,926.000</span>                          <span class="number">5</span><span class="string">,168.000</span></span><br><span class="line"><span class="number">2011                       </span><span class="number">5</span><span class="string">,500.000</span>                          <span class="number">7</span><span class="string">,630.000</span>                           <span class="number">5</span><span class="string">,261.000</span></span><br></pre></td></tr></table></figure>

<p>注意，最后有一个 .fillna(‘’) 。pivot 产生了很多空的记录，也就是值为 NaN 的记录。我个人觉得数据集里面有很多 NaN 会很烦，所以使用了 fillna(‘’) 。你也可以用别的别的东西，比方说 0 。我们也可以使用 dropna(how = ‘any’) 来删除有 NaN 的行，不过这样就把所有的数据都删掉了，所以不这样做。</p>
<p>上面的 dataframe 展示了所有降雨超过 1250 的 outflow 。诚然，这并不是讲解 pivot 实际应用最好的例子，但希望你能明白它的意思。看看你能在你的数据集上得到什么结果。</p>
<h2 id="合并数据集"><a href="#合并数据集" class="headerlink" title="合并数据集"></a>合并数据集</h2><h3 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h3><p>有时你有两个相关联的数据集，你想将它们放在一起比较或者合并它们。好的，没问题，在 Pandas 里很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Merging two datasets together</span></span><br><span class="line">rain_jpn = pd.read_csv(<span class="string">&#x27;jpn_rain.csv&#x27;</span>)</span><br><span class="line">rain_jpn.columns = [<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;jpn_rainfall&#x27;</span>]</span><br><span class="line"></span><br><span class="line">uk_jpn_rain = df.merge(rain_jpn, on=<span class="string">&#x27;year&#x27;</span>)</span><br><span class="line">uk_jpn_rain.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p>首先你需要通过 on 关键字来指定需要合并的列。通常你可以省略这个参数，Pandas 将会自动选择要合并的列。</p>
<p>如下图所示，两个数据集在年份这一类上合并了。jpn_rain 数据集只有年份和降雨量两列，通过年份列合并之后，jpn_rain 中只有降雨量那一列合并到了 UK_rain 数据集中。</p>
<h2 id="使用-Pandas-快速作图"><a href="#使用-Pandas-快速作图" class="headerlink" title="使用 Pandas 快速作图"></a>使用 Pandas 快速作图</h2><h3 id="plot"><a href="#plot" class="headerlink" title="plot"></a>plot</h3><p>Matplotlib 很棒，但是想要绘制出还算不错的图表却要写不少代码，而有时你只是想粗略的做个图来探索下数据，搞清楚数据的含义。Pandas 通过 plot 来解决这个问题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Using pandas to quickly plot graphs</span></span><br><span class="line">uk_jpn_rain.plot(x=<span class="string">&#x27;year&#x27;</span>, y=[<span class="string">&#x27;rain_octsep&#x27;</span>, <span class="string">&#x27;jpn_rainfall&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>这会调用 Matplotlib 快速轻松地绘出了你的数据图。通过这个图你就可以在视觉上分析数据，而且它能在探索数据的时候给你一些方向。比如，看到我的数据图，你会发现在 1995 年的英国好像有一场干旱。</p>
<p>你会发现英国的降雨明显少于日本，但人们却说英国总是下雨。</p>
<h2 id="保存你的数据集"><a href="#保存你的数据集" class="headerlink" title="保存你的数据集"></a>保存你的数据集</h2><h3 id="to-csv"><a href="#to-csv" class="headerlink" title="to_csv"></a>to_csv</h3><p>在清洗、重塑、探索完数据之后，你最后的数据集可能会发生很大改变，并且比最开始的时候更有用。你应该保存原始的数据集，但是你同样应该保存处理之后的数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Saving your data to a csv</span></span><br><span class="line">df.to_csv(<span class="string">&#x27;uk_rain.csv&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>上面的代码将会保存你的数据到 csv 文件以便下次使用。</p>
<p>我们对 Pandas 的介绍就到此为止了。就像我之前所说的， Pandas 非常强大，我们只是领略到了一点皮毛而已，不过你现在知道的应该足够你开始清洗和探索数据了。</p>
<p>像以前一样，我建议你用自己感兴趣的数据集做一下练习，坐下来，一杯啤酒配数据。这确实是你唯一熟悉 Pandas 以及这个系列其他库的方式。而且你也许会发现一些有趣的东西。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/python/2022-05-22-introduction-to-pandas.html" target="_blank">十分钟快速入门 Pandas</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/python/2022-05-22-introduction-to-pandas.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title>（英文版）Windows 10 WSL 2中文乱码问题解决</title>
    <url>/windows/2022-05-28-chinese-in-wsl-windows.html</url>
    <content><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>Windows 10</li>
<li>WSL 2</li>
<li>Ubuntu: 20.04</li>
</ul>
<h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>如图：终端中所有中文都变成了豆腐。</p>
<p><img src="/images/0050.png"></p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><p>进入Windows设置（<code>Settings</code>）</p>
<p><img src="/images/0055.png"></p>
<p>选择时间和语言（<code>Time &amp; Language</code>），并选择语言（<code>Language</code>）</p>
<p><img src="/images/0051.png"></p>
<p>点击右上角：<code>Administratative language settings</code></p>
<p><img src="/images/0052.png"></p>
<p>选择<code>Administrative</code></p>
<p><img src="/images/0053.png"></p>
<p>将<code>Current system locales</code>调整为<code>Chinese(Simplified, China)</code></p>
<p><strong>不要勾选：<code>Beta: Use Unicode UTF-8 for worldwide language support</code></strong></p>
<p><img src="/images/0054.png"></p>
<p>重启系统即可。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/windows/2022-05-28-chinese-in-wsl-windows.html" target="_blank">（英文版）Windows 10 WSL 2中文乱码问题解决</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/windows/2022-05-28-chinese-in-wsl-windows.html]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Windows</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Desktop WSL 2 backend</title>
    <url>/docker/2022-06-11-docker-install-on-windows-wsl.html</url>
    <content><![CDATA[<p>Windows Subsystem for Linux (WSL) 2 introduces a significant architectural change as it is a full Linux kernel built by Microsoft, allowing Linux distributions to run without having to manage Virtual Machines. With Docker Desktop running on WSL 2, users can leverage Linux workspaces and avoid having to maintain both Linux and Windows build scripts. In addition, WSL 2 provides improvements to file system sharing, boot time, and allows access to some cool new features for Docker Desktop users.</p>
<p>Docker Desktop uses the dynamic memory allocation feature in WSL 2 to greatly improve the resource consumption. This means, Docker Desktop only uses the required amount of CPU and memory resources it needs, while enabling CPU and memory-intensive tasks such as building a container to run much faster.</p>
<p>Additionally, with WSL 2, the time required to start a Docker daemon after a cold start is significantly faster. It takes less than 10 seconds to start the Docker daemon when compared to almost a minute in the previous version of Docker Desktop.</p>
<h2 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h2><p>Before you install the Docker Desktop WSL 2 backend, you must complete the following steps:</p>
<ol>
<li>Install Windows 10, version 1903 or higher or Windows 11.</li>
<li>Enable WSL 2 feature on Windows. For detailed instructions, refer to the <a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">Microsoft documentation</a>.</li>
<li>Download and install the <a href="https://docs.microsoft.com/windows/wsl/wsl2-kernel">Linux kernel update package</a>.</li>
</ol>
<h2 id="Download"><a href="#Download" class="headerlink" title="Download"></a>Download</h2><p>Download <a href="https://desktop.docker.com/win/main/amd64/Docker%20Desktop%20Installer.exe">Docker Desktop for Windows</a>.</p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>Ensure you have completed the steps described in the Prerequisites section <strong>before</strong> installing the Docker Desktop release.</p>
<ol>
<li>Follow the usual installation instructions to install Docker Desktop. If you are running a supported system, Docker Desktop prompts you to enable WSL 2 during installation. Read the information displayed on the screen and enable WSL 2 to continue.</li>
<li>Start Docker Desktop from the Windows Start menu.</li>
<li>From the Docker menu, select <strong>Settings</strong> &gt; <strong>General</strong>.<br><img src="/images/0056.png"></li>
<li>Select the <code>Use WSL 2 based engine</code> check box.<br> If you have installed Docker Desktop on a system that supports WSL 2, this option will be enabled by default.</li>
<li>Click Apply &amp; Restart.</li>
</ol>
<p>That’s it! Now <code>docker</code> commands will work from Windows using the new WSL 2 engine.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/docker/2022-06-11-docker-install-on-windows-wsl.html" target="_blank">Docker Desktop WSL 2 backend</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/docker/2022-06-11-docker-install-on-windows-wsl.html]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Windows</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>GreenPlum单节点版安装</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-06-11-introduction-to-greenplum.html</url>
    <content><![CDATA[<h2 id="GPDB简介"><a href="#GPDB简介" class="headerlink" title="GPDB简介"></a>GPDB简介</h2><blockquote>
<p>Pivotal Greenplum Database is a MPP (massively parallel processing) database built on open source <a href="https://en.wikipedia.org/wiki/PostgreSQL?spm=a2c6h.12873639.article-detail.4.1bcc51349E2X2H">PostgreSQL</a>.The system consists of a master node, standby master node, and segment nodes.</p>
</blockquote>
<blockquote>
<p>All of the data resides on the segment nodes and the catalog information is stored in the master nodes. Segment nodes run one or more segments, which are modified PostgreSQL database instances and are assigned a content identifier.</p>
</blockquote>
<blockquote>
<p>For each table the data is divided among the segment nodes based on the distribution column keys specified by the user in the DDL statement.</p>
</blockquote>
<blockquote>
<p>For each segment content identifier there is both a primary segment and mirror segment which are not running on the same physical host.</p>
</blockquote>
<blockquote>
<p>When a SQL query enters the master node, it is parsed, optimized and dispatched to all of the segments to execute the query plan and either return the requested data or insert the result of the query into a database table.</p>
</blockquote>
<h2 id="安装GreenPlum"><a href="#安装GreenPlum" class="headerlink" title="安装GreenPlum"></a>安装GreenPlum</h2><h3 id="Ubuntu-16-04-amp-18-04"><a href="#Ubuntu-16-04-amp-18-04" class="headerlink" title="Ubuntu 16.04 &amp; 18.04"></a>Ubuntu 16.04 &amp; 18.04</h3><h4 id="安装GreenPlum-1"><a href="#安装GreenPlum-1" class="headerlink" title="安装GreenPlum"></a>安装GreenPlum</h4><p>如果是Ubuntu 16.04或Ubuntu 18.04，执行以下命令安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install software-properties-common</span><br><span class="line">sudo add-apt-repository ppa:greenplum/db</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install greenplum-db-6</span><br></pre></td></tr></table></figure>

<p>安装之后可以看到目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ubuntu@8837967a36f4:~$ <span class="built_in">ls</span> /opt</span><br><span class="line">greenplum-db-6.20.5</span><br></pre></td></tr></table></figure>

<h4 id="将安装的可执行文件加载至环境变量"><a href="#将安装的可执行文件加载至环境变量" class="headerlink" title="将安装的可执行文件加载至环境变量"></a>将安装的可执行文件加载至环境变量</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ubuntu@8837967a36f4:~$ <span class="built_in">source</span> /opt/greenplum-db-6.20.5/greenplum_path.sh</span><br><span class="line">ubuntu@8837967a36f4:~$ <span class="built_in">which</span> gpssh</span><br><span class="line">/opt/greenplum-db-6.20.5/bin/gpssh</span><br></pre></td></tr></table></figure>

<h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><p>首先复制一个样例配置文件到目录中：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">ubuntu@<span class="number">8837967</span>a36f4:~$ cp <span class="variable">$GPHOME</span><span class="regexp">/docs/</span>cli_help<span class="regexp">/gpconfigs/</span></span><br><span class="line">gpinitsystem_singlenode .</span><br></pre></td></tr></table></figure>

<p>创建hostlist文件，只包含本机名称：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> `hostname` &gt; hostlist_singlenode</span><br></pre></td></tr></table></figure>

<p>设置数据目录：</p>
<p>创建目录：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="regexp">/home/u</span>buntu<span class="regexp">/gpdb/</span>primary</span><br></pre></td></tr></table></figure>

<p>修改配置文件：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">declare -a DATA_DIRECTORY=(<span class="regexp">/home/u</span>buntu<span class="regexp">/gpdb/</span>primary <span class="regexp">/home/u</span>buntu<span class="regexp">/gpdb/</span>primary)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>括号中重复的次数，代表了分片的次数。</p>
</blockquote>
<p>修改HOSTNAME参数为本地hostname</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">MASTER_HOSTNAME</span>=<span class="number">8837967</span>a36f4</span><br></pre></td></tr></table></figure>

<p>修改Master数据地址：</p>
<p>创建目录：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="regexp">/home/u</span>buntu<span class="regexp">/gpdb/m</span>aster</span><br></pre></td></tr></table></figure>

<p>修改配置文件：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">MASTER_DIRECTORY=<span class="regexp">/home/u</span>buntu<span class="regexp">/gpdb/m</span>aster</span><br></pre></td></tr></table></figure>

<h4 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h4><p>执行下以下命令，交换下ssh指纹（其实就是在known_hosts里边增加了localhost的记录）：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">ssh localhost</span></span><br></pre></td></tr></table></figure>

<p>登录之后再退出就可以了。</p>
<p>设置非密码登录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="built_in">cp</span> .ssh/id_rsa.pub .ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>执行以下命令，确认Key没有问题：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gpssh-exkeys -h localhost</span><br></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">ubuntu@<span class="number">8837967</span>a36f4:~$ gpssh-exkeys -h localhost</span><br><span class="line">[<span class="keyword">STEP</span> <span class="number">1</span> of <span class="number">5</span>] create local ID and authorize on local host</span><br><span class="line">  ... <span class="regexp">/home/u</span>buntu<span class="regexp">/.ssh/i</span>d_rsa <span class="keyword">file</span> exists ... key generation skipped</span><br><span class="line"></span><br><span class="line">[<span class="keyword">STEP</span> <span class="number">2</span> of <span class="number">5</span>] keyscan all hosts and update known_hosts <span class="keyword">file</span></span><br><span class="line"></span><br><span class="line">[<span class="keyword">STEP</span> <span class="number">3</span> of <span class="number">5</span>] retrieving credentials <span class="keyword">from</span> remote hosts</span><br><span class="line">  ... send to localhost</span><br><span class="line"></span><br><span class="line">[<span class="keyword">STEP</span> <span class="number">4</span> of <span class="number">5</span>] determine common authentication <span class="keyword">file</span> content</span><br><span class="line"></span><br><span class="line">[<span class="keyword">STEP</span> <span class="number">5</span> of <span class="number">5</span>] <span class="keyword">copy</span> authentication files to all remote hosts</span><br><span class="line">  ... finished key exchange with localhost</span><br><span class="line"></span><br><span class="line">[INFO] completed successfully</span><br></pre></td></tr></table></figure>

<p>安装en_US.UTF-8编码，执行以下命令，按提示选择即可：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">sudo dpkg-reconfigure locales</span></span><br></pre></td></tr></table></figure>

<p>执行以下命令执行数据库初始化：</p>
<figure class="highlight nsis"><table><tr><td class="code"><pre><span class="line">gpinit<span class="params">system</span> -c gpinit<span class="params">system</span>_singlenode</span><br></pre></td></tr></table></figure>

<p>输出如下：</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">ubuntu<span class="variable">@8837967a36f4</span><span class="symbol">:~/gpdb</span><span class="variable">$ </span>gpinitsystem -c gpinitsystem_singlenode</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_CTYPE</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_MESSAGES</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_COLLATE</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">16</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Checking</span> configuration parameters, please wait...</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">16</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Reading</span> <span class="title class_">Greenplum</span> configuration file gpinitsystem_singlenode</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">16</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Locale</span> has <span class="keyword">not</span> been set <span class="keyword">in</span> gpinitsystem_singlenode, will set to default value</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_CTYPE</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_MESSAGES</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_COLLATE</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Locale</span> set to en_US.utf8</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_CTYPE</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_MESSAGES</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line">/usr/bin/<span class="symbol">locale:</span> <span class="title class_">Cannot</span> set <span class="title class_">LC_ALL</span> to default <span class="symbol">locale:</span> <span class="title class_">No</span> such file <span class="keyword">or</span> directory</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-No</span> <span class="title class_">DATABASE_NAME</span> set, will exit following template1 updates</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-MASTER_MAX_CONNECT</span> <span class="keyword">not</span> set, will set to default value <span class="number">250</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Detected</span> a single host <span class="title class_">GPDB</span> array build, reducing value of <span class="title class_">BATCH_DEFAULT</span> from <span class="number">60</span> to <span class="number">4</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">WARN</span>]<span class="symbol">:-Master</span> open file limit is <span class="number">1024</span> should be &gt;= <span class="number">65535</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Checking</span> configuration parameters, <span class="title class_">Completed</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Commencing</span> multi-home checks, please wait...</span><br><span class="line">.</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Configuring</span> build <span class="keyword">for</span> standard array</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Commencing</span> multi-home checks, <span class="title class_">Completed</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Building</span> primary segment instance array, please wait...</span><br><span class="line">..</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Checking</span> <span class="title class_">Master</span> host</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">17</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Checking</span> new segment hosts, please wait...</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">18</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">WARN</span>]<span class="symbol">:-Host</span> <span class="number">8837967</span>a36f4 open files limit is <span class="number">1024</span> should be &gt;= <span class="number">65535</span></span><br><span class="line">..</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Checking</span> new segment hosts, <span class="title class_">Completed</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Greenplum</span> <span class="title class_">Database</span> <span class="title class_">Creation</span> <span class="title class_">Parameters</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:---------------------------------------</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> <span class="title class_">Configuration</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:---------------------------------------</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> instance name       = <span class="title class_">GPDB</span> <span class="title class_">SINGLENODE</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> hostname            = <span class="number">8837967</span>a36f4</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> port                = <span class="number">5432</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> instance dir        = /home/ubuntu/gpdb/master/gpsne<span class="number">-1</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> <span class="title class_">LOCALE</span>              = en_US.utf8</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Greenplum</span> segment prefix   = gpsne</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> <span class="title class_">Database</span>            =</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> connections         = <span class="number">250</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> buffers             = <span class="number">128000</span>kB</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Segment</span> connections        = <span class="number">750</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Segment</span> buffers            = <span class="number">128000</span>kB</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Checkpoint</span> segments        = <span class="number">8</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Encoding</span>                   = <span class="title class_">UNICODE</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Postgres</span> param file        = <span class="title class_">Off</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Initdb</span> to be used          = /opt/greenplum-db<span class="number">-6.20</span>.<span class="number">5</span>/bin/initdb</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-GP_LIBRARY_PATH</span> is         = /opt/greenplum-db<span class="number">-6.20</span>.<span class="number">5</span>/lib</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-HEAP_CHECKSUM</span> is           = on</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-HBA_HOSTNAMES</span> is           = <span class="number">0</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">WARN</span>]<span class="symbol">:-Ulimit</span> check               = <span class="title class_">Warnings</span> generated, see log file &lt;&lt;&lt;&lt;&lt;</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Array</span> host connect type    = <span class="title class_">Single</span> hostname per node</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Master</span> <span class="title class_">IP</span> address [<span class="number">1</span>]      = <span class="number">172.17</span>.<span class="number">0.2</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Standby</span> <span class="title class_">Master</span>             = <span class="title class_">Not</span> <span class="title class_">Configured</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Number</span> of primary segments = <span class="number">2</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Total</span> <span class="title class_">Database</span> segments    = <span class="number">2</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Trusted</span> shell              = ssh</span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Number</span> segment hosts       = <span class="number">1</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Mirroring</span> config           = <span class="title class_">OFF</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:----------------------------------------</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-Greenplum</span> <span class="title class_">Primary</span> <span class="title class_">Segment</span> <span class="title class_">Configuration</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:----------------------------------------</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-</span><span class="number">8837967</span>a36f4 	<span class="number">6000</span> 	<span class="number">8837967</span>a36f4 	/home/ubuntu/gpdb/primary/gpsne0 	<span class="number">2</span></span><br><span class="line"><span class="number">20220611</span><span class="symbol">:</span><span class="number">12</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">19</span><span class="symbol">:</span><span class="number">005363</span> <span class="symbol">gpinitsystem:</span><span class="number">8837967</span><span class="symbol">a36f4:</span>ubuntu-[<span class="title class_">INFO</span>]<span class="symbol">:-</span><span class="number">8837967</span>a36f4 	<span class="number">6001</span> 	<span class="number">8837967</span>a36f4 	/home/ubuntu/gpdb/primary/gpsne1 	<span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>输入“y”就可以继续安装了。</p>
<p>完成之后就可以开心的使用了。</p>
<h3 id="Ubuntu-20-04-或其他Linux版本"><a href="#Ubuntu-20-04-或其他Linux版本" class="headerlink" title="Ubuntu 20.04 或其他Linux版本"></a>Ubuntu 20.04 或其他Linux版本</h3><h4 id="下载源代码"><a href="#下载源代码" class="headerlink" title="下载源代码"></a>下载源代码</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:greenplum-db/gpdb.git</span><br></pre></td></tr></table></figure>

<h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><p>在下载的源码目录下执行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> DEBIAN_FRONTEND=noninteractive <span class="comment"># 跳过测试用的一些参数</span></span><br><span class="line">sudo ./README.Ubuntu.bash</span><br></pre></td></tr></table></figure>

<h4 id="编译源码"><a href="#编译源码" class="headerlink" title="编译源码"></a>编译源码</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Configure build environment to install at /usr/local/gpdb</span></span><br><span class="line">./configure --with-perl --with-python --with-libxml --with-gssapi --prefix=/usr/local/gpdb</span><br><span class="line"></span><br><span class="line"><span class="comment"># Compile and install</span></span><br><span class="line">make -j3</span><br><span class="line">make -j3 install</span><br><span class="line"></span><br><span class="line"><span class="comment"># Bring in greenplum environment into your running shell</span></span><br><span class="line"><span class="built_in">source</span> /usr/local/gpdb/greenplum_path.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start demo cluster</span></span><br><span class="line">make create-demo-cluster</span><br><span class="line"><span class="comment"># (gpdemo-env.sh contains __PGPORT__ and __MASTER_DATA_DIRECTORY__ values)</span></span><br><span class="line"><span class="built_in">source</span> gpAux/gpdemo/gpdemo-env.sh</span><br></pre></td></tr></table></figure>

<h4 id="修改参数"><a href="#修改参数" class="headerlink" title="修改参数"></a>修改参数</h4><p>数据目录和TCP端口都可以在运行过程中修改，执行以下命令即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DATADIRS=/tmp/gpdb-cluster PORT_BASE=5555 make cluster</span><br></pre></td></tr></table></figure>

<p>回归测试也可以在运行中修改参数：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PGPORT=5555 make installcheck-world</span><br></pre></td></tr></table></figure>

<p>如果要关闭<code>GPORCA</code>，GP就会使用<code>Postgres Planner</code>来做查询优化。调整参数执行一下命令即可：</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> <span class="attribute">optimizer</span>=off;</span><br></pre></td></tr></table></figure>

<h4 id="执行测试"><a href="#执行测试" class="headerlink" title="执行测试"></a>执行测试</h4><figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">make installcheck-world</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-06-11-introduction-to-greenplum.html" target="_blank">GreenPlum单节点版安装</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-06-11-introduction-to-greenplum.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>GreenPlum</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【三】：基本概念</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-basic-concepts.html</url>
    <content><![CDATA[<p>众所周知，做数据分析、BI建设，都离不开数据仓库建设，数仓建设的本质目的是支撑分析决策。今天跟着我来学学数据仓库的基础知识，通过本文的阅读，你将获得以下方面的认知：</p>
<ol>
<li>什么是数仓</li>
<li>数仓的核心概念</li>
<li>数仓的分层架构</li>
</ol>
<h2 id="数据仓库概述"><a href="#数据仓库概述" class="headerlink" title="数据仓库概述"></a>数据仓库概述</h2><p>数据仓库，顾名思义，就是存储数据的仓库。</p>
<p>现实中的仓库会有不同的分区和归类，分区下有多个货架，货架上堆放着各种各样的商品。对于数据仓库来说，分区归类就类似于数据仓库的基础架构，数据仓库的数据存储结构（如表）就是仓库的货架，而商品则是对应数据仓库实际存储的各种数据。无论是什么样的仓库，无论仓库大小，其目的都是为了实现物品的集中管理、有序存取，数据仓库也是一样，它管理存储的是数据以及数据结构。</p>
<p>其实业界对于数据仓库早已有了广泛认可的定义，即：<strong>数据仓库是一个面向主题的(Subject Oriented)、集成的(Integrated)、相对稳定的(Non-Volatile)、反映历史变化(Time Variant)的数据集合，用于支持管理决策</strong>。</p>
<p>数据仓库本质上是一种特殊的数据组织形式：</p>
<ol>
<li>面向主题，即数据仓库中表的设计是按照一个个主题进行组织的而非按照业务流程设计；</li>
<li>集成性，是指将企业中各大业务系统进行数据集中、整合、加工从而形成全局统一的数据视图；</li>
<li>相对稳定，则是指数据仓库中的数据不会做频繁的增删改操作，相对于业务系统中频繁的事务处理，其数据变化相对稳定；</li>
<li>反应历史变化，表明数据仓库通常会保存数据的历史备份，因此就可以从中获取数据历史变化情况。</li>
</ol>
<p>数据仓库的这些特性满足了分析型应用的需求，可以更好的帮助企业制定管理决策。</p>
<h2 id="数据仓库核心概念"><a href="#数据仓库核心概念" class="headerlink" title="数据仓库核心概念"></a>数据仓库核心概念</h2><p>理解完数据仓库基本概念和特性，接着我们来学习下数据仓库的核心概念。</p>
<h3 id="维度"><a href="#维度" class="headerlink" title="维度"></a>维度</h3><p>维度是一个<strong>与业务相关的观察角度</strong>，比如我们从地区角度观察哪个地区的销售额最多，那么地区就是一个维度。在数据仓库中我们将这些维度信息存储成一张张数据库表，我们称之为维表。</p>
<p>维表主要分为：单级维、层级维、变化维。</p>
<ul>
<li><strong>单级维</strong>是指一对一的代码表，不存在层级关系，最主要的作用是<strong>将事实表中的代码显示为标题（名称）</strong>。</li>
<li><strong>层级维</strong>是具有分层结构的维度表，比如地区维，层级往上可以到区、市、省、国家等。</li>
<li><strong>缓慢变化维</strong>是随着时间属性变化的，如机构维，机构名称会随时间而改变。</li>
</ul>
<p>维表通常由维主键编码和维度名称以及其他属性字段组成。</p>
<h3 id="度量"><a href="#度量" class="headerlink" title="度量"></a>度量</h3><p>度量是<strong>反映企业运行情况或状态的一些数值指标，是业务量化的表示，可以用来监测业务的成效</strong>，比如销售额、利润来反应企业业绩。</p>
<h3 id="事实表"><a href="#事实表" class="headerlink" title="事实表"></a>事实表</h3><p>事实表<strong>也被称为主题表，它是由若干维度和度量组合而成，表达期望分析的主题</strong>。事实表中的多个维度的组合决定了事实表的数据详细程度，这种详细程度我们称之为颗粒度。以颗粒度来划分主题表的话，通常会有三种事实表：<strong>事务粒度事实表</strong>、<strong>周期快照粒度事实表</strong>、<strong>累积快照粒度事实表</strong>。</p>
<p>以一个例子来说明，比如某个商品的一笔销售记录，我们用表记录下来，这条记录已经是<strong>最小的数据记录单元，不可再分，因此它是一个事务粒度的事实表</strong>，我们将这张表按自然月进行汇总得到该商品月度销售情况，那么这张表就是<strong>按一定周期记录事实，我们称之为周期快照粒度事实表</strong>。最后一种<strong>累积快照事实表，则记录覆盖整个生命周期过程中的不同阶段的关键信息</strong>，如订单累积快照事实表，包括下单时间、付款时间、发货时间、收货时间等，通过多个时间字段记录订单从产生到业务完结的关键节点，在订单的不同阶段，这些时间字段逐步被填充。</p>
<p>在数据仓库中，维度表和事实表的设计需要遵循一些重要原则，即<strong>一致性维度</strong>和<strong>一致性事实</strong>。</p>
<p>所谓<strong>一致性维度</strong>是指在同一个集市内，两个维度如果有关系，要么就是完全一样的，要么就是一个维度在数学意义上是另一个维度的子集，例如，如果建立月维度话，月维度的各种描述必须与日期维度中的完全一致，最常用的做法就是在日期维度上建立视图生成月维度。这样月维度就可以是日期维度的子集，在后续钻取等操作时可以保持一致；</p>
<p>所谓<strong>一致性事实</strong>，即是指表达相同业务含义的度量（或称为指标）需要在描述定义和计算口径、度量单位等保持一致，杜绝系统间同词不同义或同义不同词的问题。</p>
<h2 id="数据仓库分层架构"><a href="#数据仓库分层架构" class="headerlink" title="数据仓库分层架构"></a>数据仓库分层架构</h2><p>数据仓库有分层结构，每个分层结构都有各自的作用，大抵上分层结构分为：<strong>贴源层、整合层、集市层、汇总层</strong>。</p>
<ul>
<li>贴源层，就是将所有涉及业务系统的数据抽取到这一层集中存放，同时也会保留历史数据，这一层基本<strong>保留了与源系统一样的结构和数据</strong>。</li>
<li>整合层，会保留最细颗粒的所有历史数据，它面向主题、规范化建模，站在全局的视角上规划主题、整合业务模型，在数据模型维度上完成重大的转变。</li>
<li>集市层，面向某个业务主题的多维模型集合。通过预计算、预连接、维度规范化等方式进一步将业务系统的范式模型转变成面向主题的多维模型。</li>
<li>汇总层，它应技术或业务需要而建，直面需求，方便展现，同时提高数据的存储性能。</li>
</ul>
<p>数据仓库分层架构从整体上来看，是将数据从分散到集中、从细粒度到高度汇总、从业务模型到分析型模型转变的过程，从而更好的为分析型系统提供后台数据支撑。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-basic-concepts.html" target="_blank">数据仓库【三】：基本概念</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-basic-concepts.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【五】：通用的数据仓库分层方法</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-common-layers.html</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>数据分层是数据仓库设计中十分重要的一个环节，优秀的分层设计能够让整个数据体系更易理解和使用。而目前网络中大部分可以被检索到相关文章只是简单地提及数据分层的设计，或缺少明确而详细的说明，或缺少可落地实施的方案，或缺少具体的示例说明。</p>
<h3 id="数据分层？"><a href="#数据分层？" class="headerlink" title="数据分层？"></a>数据分层？</h3><blockquote>
<p>“为什么要设计数据分层？”</p>
</blockquote>
<p>这应该是数据仓库同学在设计数据分层时首先要被挑战的问题，类似的问题可能会有很多，比如说“为什么要做数据仓库？”、“为什么要做元数据管理？”、“为什么要做数据质量管理？”。当然，这里我们只聊一下为什么要做设计数据分层。</p>
<p>作为一名数据的规划者，我们肯定希望自己的数据能够有秩序地流转，数据的整个生命周期能够清晰明确被设计者和使用者感知到。直观来讲就是如下的左图这般层次清晰、依赖关系直观。</p>
<p>但是，大多数情况下，我们完成的数据体系却是依赖复杂、层级混乱的。如下的右图，在不知不觉的情况下，我们可能会做出一套表依赖结构混乱，甚至出现循环依赖的数据体系。</p>
<p><img src="/images/0068.png"></p>
<p>因此，我们需要一套行之有效的数据组织和管理方法来让我们的数据体系更有序，这就是谈到的数据分层。数据分层并不能解决所有的数据问题，但是，数据分层却可以给我们带来如下的好处：</p>
<ul>
<li><p>清晰数据结构：每一个数据分层都有它的作用域和职责，在使用表的时候能更方便地定位和理解</p>
</li>
<li><p>减少重复开发：规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算</p>
</li>
<li><p>统一数据口径：通过数据分层，提供统一的数据出口，统一对外输出的数据口径</p>
</li>
<li><p>复杂问题简单化：将一个复杂的任务分解成多个步骤来完成，每一层解决特定的问题</p>
</li>
</ul>
<h2 id="一种通用的数据分层设计"><a href="#一种通用的数据分层设计" class="headerlink" title="一种通用的数据分层设计"></a>一种通用的数据分层设计</h2><p>为了满足前面提到数据分层带来的好处，我们将数据模型分为三层：数据运营层（ ODS ）、数据仓库层（DW）和数据应用层（APP）。如下图所示。简单来讲，我们可以理解为：<strong>ODS层存放的是接入的原始数据，DW层是存放我们要重点设计的数据仓库中间层数据，APP是面向业务定制的应用数据。</strong> 下面详细介绍这三层的设计。</p>
<p><img src="/images/0069.png"></p>
<h3 id="数据运营层：ODS（Operational-Data-Store）"><a href="#数据运营层：ODS（Operational-Data-Store）" class="headerlink" title="数据运营层：ODS（Operational Data Store）"></a>数据运营层：ODS（Operational Data Store）</h3><p>“面向主题的”数据运营层，也叫ODS层，是最接近数据源中数据的一层，数据源中的数据，经过抽取、洗净、传输，也就说传说中的 ETL 之后，装入本层。本层的数据，总体上大多是按照源头业务系统的分类方式而分类的。</p>
<p>一般来讲，为了考虑后续可能需要追溯数据问题，因此对于这一层就不建议做过多的数据清洗工作，原封不动地接入原始数据即可，至于数据的去噪、去重、异常值处理等过程可以放在后面的DWD层来做。</p>
<h3 id="数据仓库层：DW（Data-Warehouse）"><a href="#数据仓库层：DW（Data-Warehouse）" class="headerlink" title="数据仓库层：DW（Data Warehouse）"></a>数据仓库层：DW（Data Warehouse）</h3><p>数据仓库层是我们在做数据仓库时要核心设计的一层，在这里，从 ODS 层中获得的数据按照主题建立各种数据模型。</p>
<p>DW层又细分为 DWD（Data Warehouse Detail）层、DWM（Data WareHouse Middle）层和DWS（Data WareHouse Servce）层。</p>
<h4 id="数据明细层：DWD（Data-Warehouse-Detail）"><a href="#数据明细层：DWD（Data-Warehouse-Detail）" class="headerlink" title="数据明细层：DWD（Data Warehouse Detail）"></a>数据明细层：DWD（Data Warehouse Detail）</h4><p>该层一般保持和ODS层一样的数据粒度，并且提供一定的数据质量保证。同时，为了提高数据明细层的易用性，该层会采用一些维度退化手法，将维度退化至事实表中，减少事实表和维表的关联。</p>
<p>另外，在该层也会做一部分的数据聚合，将相同主题的数据汇集到一张表中，提高数据的可用性，后文会举例说明。</p>
<h4 id="数据中间层：DWM（Data-WareHouse-Middle）"><a href="#数据中间层：DWM（Data-WareHouse-Middle）" class="headerlink" title="数据中间层：DWM（Data WareHouse Middle）"></a>数据中间层：DWM（Data WareHouse Middle）</h4><p>该层会在DWD层的数据基础上，对数据做轻度的聚合操作，生成一系列的中间表，提升公共指标的复用性，减少重复加工。</p>
<p>直观来讲，就是对通用的核心维度进行聚合操作，算出相应的统计指标。</p>
<h4 id="数据服务层：DWS（Data-WareHouse-Servce）"><a href="#数据服务层：DWS（Data-WareHouse-Servce）" class="headerlink" title="数据服务层：DWS（Data WareHouse Servce）"></a>数据服务层：DWS（Data WareHouse Servce）</h4><p>又称数据集市或宽表。按照业务划分，如流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。</p>
<p>一般来讲，该层的数据表会相对比较少，一张表会涵盖比较多的业务内容，由于其字段较多，因此一般也会称该层的表为宽表。</p>
<p>在实际计算中，如果直接从DWD或者ODS计算出宽表的统计指标，会存在计算量太大并且维度太少的问题，因此一般的做法是，在DWM层先计算出多个小的中间表，然后再拼接成一张DWS的宽表。由于宽和窄的界限不易界定，也可以去掉DWM这一层，只留DWS层，将所有的数据在放在DWS亦可。</p>
<h3 id="数据应用层：APP（Application）"><a href="#数据应用层：APP（Application）" class="headerlink" title="数据应用层：APP（Application）"></a>数据应用层：APP（Application）</h3><p>在这里，主要是提供给数据产品和数据分析使用的数据，一般会存放在 ES、PostgreSql、Redis等系统中供线上系统使用，也可能会存在 Hive 或者 Druid 中供数据分析和数据挖掘使用。比如我们经常说的报表数据，一般就放在这里。</p>
<h3 id="维表层（Dimension）"><a href="#维表层（Dimension）" class="headerlink" title="维表层（Dimension）"></a>维表层（Dimension）</h3><p>最后补充一个维表层，维表层主要包含两部分数据：</p>
<ul>
<li><p>高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。</p>
</li>
<li><p>低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。数据量可能是个位数或者几千几万。</p>
</li>
</ul>
<p>至此，我们讲完了数据分层设计中每一层的含义，这里做一个总结便于理解，如下图。</p>
<p><img src="/images/0065.png"></p>
<h2 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h2><p>趁热打铁，举个栗子说明一下，如下图，可以认为是一个电商网站的数据体系设计。我们暂且只关注用户访问日志这一部分数据。</p>
<p><img src="/images/0066.png"></p>
<ol>
<li><p>在ODS层中，由于各端的开发团队不同或者各种其它问题，用户的访问日志被分成了好几张表上报到了我们的ODS层。</p>
</li>
<li><p>为了方便大家的使用，我们在DWD层做了一张用户访问行为天表，在这里，我们将PC网页、H5、小程序和原生APP访问日志汇聚到一张表里面，统一字段名，提升数据质量，这样就有了一张可供大家方便使用的明细表了。</p>
</li>
<li><p>在DWM层，我们会从DWD层中选取业务关注的核心维度来做聚合操作，比如只保留人、商品、设备和页面区域维度。类似的，我们这样做了很多个DWM的中间表</p>
</li>
<li><p>然后在DWS层，我们将一个人在整个网站中的行为数据放到一张表中，这就是我们的宽表了，有了这张表，就可以快速满足大部分的通用型业务需求了。</p>
</li>
<li><p>最后，在APP应用层，根据需求从DWS层的一张或者多张表取出数据拼接成一张应用表即可。</p>
</li>
</ol>
<p>备注：例子只是为了简单地说明每一层的作用，并不是最合理的解决方案，大家辩证地看待即可。</p>
<h2 id="技术实践"><a href="#技术实践" class="headerlink" title="技术实践"></a>技术实践</h2><p>既然谈到了数据分层，那不同的层次中会用到什么计算引擎和存储系统呢，本节来简单分享一下。</p>
<p>数据层的存储一般如下：</p>
<ul>
<li>Data Source：数据源一般是业务库和埋点，当然也会有第三方购买数据等多种数据来源方式。业务库的存储一般是Mysql 和 PostgreSql。</li>
<li>ODS 层：ODS 的数据量一般非常大，所以大多数公司会选择存在HDFS上，即Hive或者Hbase，Hive居多。</li>
<li>DW 层：一般和 ODS 的存储一致，但是为了满足更多的需求，也会有存放在 PG 和 ES 中的情况。</li>
<li>APP 层：应用层的数据，一般都要求比较快的响应速度，因此一般是放在 Mysql、PG、Redis中。</li>
</ul>
<p>计算引擎的话，可以简单参考图中所列就行。目前大数据相关的技术更新迭代比较快，本节所列仅为简单参考。</p>
<p><img src="/images/0067.png"></p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-common-layers.html" target="_blank">数据仓库【五】：通用的数据仓库分层方法</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-common-layers.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【二】：数据库、数据仓库、数据平台、数据中台、数据湖到底是什么？</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-concepts-comparsion.html</url>
    <content><![CDATA[<p>层出不穷的新技术、新概念、新应用往往会对初学者造成很大的困扰，有时候很难理清楚它们之间的区别与联系。本文将以数据研发相关领域为例，对比分析我们工作中高频出现的几个名词，主要包括以下几个方面：</p>
<p>数据</p>
<ul>
<li>什么是大数据</li>
<li>数据分析与数据挖掘的区别是什么</li>
</ul>
<p>数据库</p>
<ul>
<li>什么是数据库</li>
<li>数据库中的分布式事务理论</li>
</ul>
<p>数据仓库</p>
<ul>
<li>什么是数据仓库</li>
<li>什么是数据集市</li>
<li>数据库与数据仓库的区别是什么</li>
</ul>
<p>大数据平台</p>
<ul>
<li>什么是大数据平台</li>
<li>什么是大数据开发平台</li>
</ul>
<p>数据中台</p>
<ul>
<li>什么是数据中台</li>
<li>数据仓库与数据中台的区别与联系</li>
</ul>
<p>数据湖</p>
<ul>
<li>什么是数据湖</li>
<li>数据仓库与数据湖有什么区别与联系</li>
</ul>
<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><h3 id="什么是大数据"><a href="#什么是大数据" class="headerlink" title="什么是大数据"></a>什么是大数据</h3><p>麦肯锡全球研究所给出的定义是：一种规模大到在获取、存储、管理、分析方面大大超出了传统数据库软件工具能力范围的数据集合，具有<strong>海量的数据规模</strong>、<strong>快速的数据流转</strong>、<strong>多样的数据类型</strong>和<strong>价值密度低</strong>四大特征。</p>
<p>我们再往深处思考一下，为什么会有大数据(大数据技术)？其实大数据就是在这个数据爆炸增长的时代，业务需求增长促进技术迭代，技术满足需求后又形成闭环促进业务持续增长，从而形成一个闭环。</p>
<h3 id="数据分析与数据挖掘的区别是什么"><a href="#数据分析与数据挖掘的区别是什么" class="headerlink" title="数据分析与数据挖掘的区别是什么"></a>数据分析与数据挖掘的区别是什么</h3><p>数据分析可以分为<strong>广义的数据分析</strong>和<strong>狭义的数据分析</strong>。广义的数据分析就包括<strong>狭义的数据分析和数据挖掘</strong>。我们在工作中经常常说的数据分析指的是狭义的数据分析。</p>
<table>
<thead>
<tr>
<th></th>
<th>数据分析（狭义）Data Analysis</th>
<th>数据挖掘  Data Mining</th>
</tr>
</thead>
<tbody><tr>
<td>定义</td>
<td>根据分析目的，用适当的<strong>统计分析方法及工具</strong>，对收集来的数据进行处理与分析，提取有价值的信息，发挥数据的作用。</td>
<td>数据挖掘是指从大量的数据中，通过<strong>统计学、人工智能、机器学习等</strong>方法，挖掘出<strong>未知的、且有价值的</strong>信息和知识的过程。</td>
</tr>
<tr>
<td>作用</td>
<td>主要实现三大作用：<strong>现状分析、原因分析、预测分析（定量）</strong>。数据分析的<strong>目标明确</strong>，先做假设，然后通过数据分析来验证假设是否正确，从而得到相应的结论。</td>
<td>数据挖掘主要侧重解决四类问题：<strong>分类、聚类、关联和预测（定量、定性）</strong>，数据挖掘的重点在寻找<strong>未知的模式与规律</strong>；如我们常说的数据挖掘案例：啤酒与尿布等，这就是事先未知的，但又是非常有价值的信息。</td>
</tr>
<tr>
<td>方法</td>
<td>主要采用<strong>对比分析、分组分析、交叉分析、回归分析</strong>等常用分析方法。</td>
<td>主要采用<strong>决策树、神经网络、关联规则、聚类分析等统计学、人工智能、机器学习等方法</strong>进行挖掘。</td>
</tr>
<tr>
<td>结果</td>
<td>数据分析一般都是得到<strong>一个指标统计量结果</strong>，如总和、平均值等，这些指标数据都需要与业务结合进行解读，才能发挥出数据的价值与作用。</td>
<td>输出模型或规则，并且可相应得到模型得分或标签，模型得分如流失概率值、总和得分、相似度、预测值等，标签如高中低价值用户、流失与非流失、信用优良中差等。</td>
</tr>
</tbody></table>
<h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><h3 id="什么是数据库"><a href="#什么是数据库" class="headerlink" title="什么是数据库"></a>什么是数据库</h3><p>数据库是<strong>按照数据结构来组织、存储和管理数据的仓库</strong>。是一个<strong>长期存储在计算机内的、有组织的、可共享的、统一管理</strong>的大量数据的集合。</p>
<p>一般而言，我们所说的数据库指的是数据库管理系统，并不单指一个数据库实例。</p>
<p>根据数据存储的方式不同，可以将数据库分为三类：分别为<strong>行存储、列存储、行列混合存储</strong>，其中：</p>
<ul>
<li>行存储的数据库代表产品有Oracle、MySQL、PostgresSQL等</li>
<li>列存储的数据代表产品有Greenplum、HBASE、Teradata等</li>
<li>行列混合存储的数据库代表产品有TiDB，ADB for Mysql等</li>
</ul>
<h3 id="数据库中的分布式事务理论"><a href="#数据库中的分布式事务理论" class="headerlink" title="数据库中的分布式事务理论"></a>数据库中的分布式事务理论</h3><h4 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h4><p>传统关系型数据库事务设计原则，以下四点必须全部满足：</p>
<ul>
<li>原子性Atomicity：事务中操作要么都发生，要么都不发生；</li>
<li>一致性Consistency：事务前后数据完整性保持一致；</li>
<li>隔离性Isolation：多个用户并发事务相互隔离；</li>
<li>持久性Durability：事务被提交后数据的改变就是永久性的。</li>
</ul>
<p>举例说明：A账号有200元，B账号有100元，现在A给B账户进行转账操作：</p>
<ul>
<li>A减少100元，同时B增加100元，两个操作要么都成功要么都失败,满足原子性；</li>
<li>A减少的金额，和B增加的金额要一致，按照一致性；</li>
<li>假如A给B转账的同一时刻，B又给C转账，这两笔交易是相互隔离，满足隔离性；</li>
<li>A给B转账100元，事务提交之后，在查询账号，A减少100元，B增加100元，满足持久性；</li>
</ul>
<h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><p>2000年，Berkerly大学有位Eric Brewer教授提出了一个CAP理论，在2002年，麻省理工学院的Seth Gilbert(赛斯·吉尔伯特)和Nancy Lynch(南希·林奇)发表了布鲁尔猜想的证明，证明了CAP理论的正确性。</p>
<p>所谓CAP理论，是指<strong>对于一个分布式计算系统来说，不可能同时满足以下三点</strong>：</p>
<ul>
<li>一致性（Consistency） 等同于所有节点访问同一份最新的数据副本。即任何一个读操作总是能够读到之前完成的写操作的结果，也就是说，在分布式环境中，不同节点访问的数据是一致的。</li>
<li>可用性（Availability） 每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据。即快速获取数据，可以在确定的时间内返回操作结果。</li>
<li>分区容错性（Partition tolerance） 以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。即指当出现网络分区时(系统中的一部分节点无法与其他的节点进行通信)，分离的系统也能够正常运行，即可靠性。</li>
</ul>
<p>一个分布式的系统不可能同时满足一致性、可用性和分区容错性，最多同时满足两个。当处理CAP的问题时，可以有一下几个选择：</p>
<ul>
<li><p>满足CA，不满足P。将所有与事务相关的内容都放在同一个机器上，这样会影响系统的可扩展性。传统的关系型数据库。如<code>MySQL</code>、<code>SQL Server</code> 、<code>PostgresSQL</code>等都采用了此种设计原则。</p>
</li>
<li><p>满足AP，不满足C。不满足一致性(C)，即允许系统返回不一致的数据。其实，对于WEB2.0的网站而言，更加关注的是服务是否可用，而不是一致性。比如你发了一篇博客或者写一篇微博，你的一部分朋友立马看到了这篇文章或者微博，另一部分朋友却要等一段时间之后才能刷出这篇文章或者微博。虽然有延时，但是对于一个娱乐性质的Web 2.0网站而言，这几分钟的延时并不重要，不会影响用户体验。相反，当发布一篇文章或微博时，不能够立即发布(不满足可用性)，用户对此肯定不爽。所以呢，对于WEB2.0的网站而言，可用性和分区容错性的优先级要高于数据一致性，当然，**并没有完全放弃一致性，而是最终的一致性(有延时)**。如<code>Dynamo</code>、<code>Cassandra</code>、<code>CouchDB</code>等NoSQL数据库采用了此原则。</p>
</li>
<li><p>满足CP，不满足A。强调一致性性(C)和分区容错性(P)，放弃可用性性(A)。当出现网络分区时，受影响的服务需要等待数据一致，在等待期间无法对外提供服务。如<code>Neo4J</code>、<code>HBase</code>、<code>MongoDB</code>、<code>Redis</code>等采用了此种设计原则。</p>
</li>
</ul>
<h2 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h2><h3 id="什么是数据仓库"><a href="#什么是数据仓库" class="headerlink" title="什么是数据仓库"></a>什么是数据仓库</h3><p>数据仓库（Data Warehouse）是一个**面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策(Decision Making Support)**。</p>
<ul>
<li>面向主题的：根据使用者的需求，将来自不同数据源的数据围绕着各种主题进行分类整合。</li>
<li>集成的：来自各种数据源的数据按照统一的标准集成于数据仓库中。</li>
<li>相对稳定的：数据仓库中的数据是一系列的历史快照，不允许修改或删除，只涉及数据查询。</li>
<li>反映历史变化的：数据仓库会定期接收新的集成数据，从而反映出最新的数据变化。</li>
</ul>
<h3 id="数据库与数据仓库有什么区别"><a href="#数据库与数据仓库有什么区别" class="headerlink" title="数据库与数据仓库有什么区别"></a>数据库与数据仓库有什么区别</h3><p>严格来讲<strong>数据仓库不是一门技术，也不是一个产品</strong>。像前文提到的关系型数据库<code>MySQL</code>和<code>Oracle</code>都属于一种产品。那么是什么数据仓库的，见名知意，其实就是存储数据的仓库，数据的来源有很多种，可以统一在数据仓库中进行汇合，然后通过统一的建模，加工成服务与数据分析的数据模型，辅助企业分析决策。</p>
<p>那么，数据仓库该怎么构建呢，目前使用Hive构建数据仓库的比较多，本文不会过多分析这些大数据技术。总之一句话，数据仓库涉及数据建模，数据抽取ETL，数据可视化等一系列的流程，是一种数据解决方案，通常需要多种技术进行组合使用。</p>
<p><strong>数据仓库的本质是OLAP，即是做在线分析处理，这是与数据库的本质区别。</strong>还有一点既然是数据仓库，肯定是要加工数据，那么加工数据肯定耗时间，所以加工数据在实际的应用中又分为批处理和实时处理。</p>
<p><strong>数据库是为了解决OLTP而存在的，而数据仓库是为了分析数据而存在的。</strong>数据库的数据是数据仓库的数据源，即将数据库的数据加载至数据仓库，所以说，数据仓库不生产数据，只做数据的搬运工。</p>
<p>还有一点就是，<strong>数据仓库并不是必须的，但是对于一个业务系统而言，数据库是必须的</strong>。只有在业务稳定运转的情况下，才会去构建企业级数据仓库，通过数据分析，数据挖掘来辅助业务决策，实现锦上添花。</p>
<table>
<thead>
<tr>
<th></th>
<th>数据库</th>
<th>数据仓库</th>
</tr>
</thead>
<tbody><tr>
<td>数据处理类型</td>
<td>OLTP</td>
<td>OLAP</td>
</tr>
<tr>
<td>使用人员</td>
<td>业务开发人员</td>
<td>分析决策人员</td>
</tr>
<tr>
<td>核心功能</td>
<td>日常事务处理</td>
<td>面向分析决策</td>
</tr>
<tr>
<td>数据模型</td>
<td>关系模型（ER）</td>
<td>多维模型（雪花、星型）</td>
</tr>
<tr>
<td>数据量</td>
<td>相对较小</td>
<td>相对较大</td>
</tr>
<tr>
<td>存储内容</td>
<td>存储当前数据</td>
<td>存储历史数据</td>
</tr>
<tr>
<td>操作类型</td>
<td>查询、插入、更新、删除</td>
<td>查询为主：只读操作、复杂查询</td>
</tr>
</tbody></table>
<h3 id="什么是数据集市"><a href="#什么是数据集市" class="headerlink" title="什么是数据集市"></a>什么是数据集市</h3><p>数据集市（Data Mart），也叫数据市场，就是满足特定的部门或者用户的需求，<strong>按照多维的方式进行存储，包括定义维度、需要计算的指标、维度的层次等，生成面向决策分析需求的数据立方体</strong>。</p>
<p>从范围上来说，数据集市的数据是从数据库，或者是更加专业的数据仓库中抽取出来的。数据集市分为<strong>从属的数据集市</strong>与<strong>独立的数据集市</strong>：</p>
<ul>
<li><p>独立型数据集市的数据来自于操作型数据库，是为了满足特殊用户而建立的一种分析型环境。这种数据集市的开发周期一般较短，具有灵活性，但是因为脱离了数据仓库，独立建立的数据集市可能会导致信息孤岛的存在，不能以全局的视角去分析数据。</p>
</li>
<li><p>从属型数据集市的数据来自于企业的数据仓库，这样会导致开发周期的延长，但是从属型数据集市在体系结构上比独立型数据集市更稳定，可以提高数据分析的质量，保证数据的一致性。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>指标</th>
<th>数据仓库</th>
<th>数据集市</th>
</tr>
</thead>
<tbody><tr>
<td>数据来源</td>
<td>OLTP系统、外部数据</td>
<td>数据仓库</td>
</tr>
<tr>
<td>范围</td>
<td>企业级</td>
<td>部门级或工作组级</td>
</tr>
<tr>
<td>主题</td>
<td>企业主题</td>
<td>部门或特殊的分析主题</td>
</tr>
<tr>
<td>数据粒度</td>
<td>最细的粒度</td>
<td>较粗的粒度</td>
</tr>
<tr>
<td>历史数据</td>
<td>大量的历史数据</td>
<td>适度的历史数据</td>
</tr>
<tr>
<td>目的</td>
<td>处理海量数据，数据探索</td>
<td>便于某个维度数据访问和分析，快速查询</td>
</tr>
</tbody></table>
<h2 id="大数据平台"><a href="#大数据平台" class="headerlink" title="大数据平台"></a>大数据平台</h2><h3 id="什么是大数据平台"><a href="#什么是大数据平台" class="headerlink" title="什么是大数据平台"></a>什么是大数据平台</h3><p>大数据平台是一个<strong>集数据接入、数据处理、数据存储、查询检索、分析挖掘等、应用接口等功能为一体的平台</strong>。通俗的理解包括Hadoop生态的相关产品，比如Spark、Flink、Flume、Kafka、Hive、HBase等等等经典开源产品。</p>
<p>提到Hadoop生态技术，不得不提的是Apache和Cloudera。国内绝大部分公司的大数据平台都是基于这两个分支的产品进行商业化包装和改进。例如：阿里云EMR、腾讯TBDS、华为FusionInsight、新华三DataEngine、浪潮Insight HD、中兴DAP等产品。</p>
<p>其实，对于大数据平台，业内并无一个固定的能力范围。当前比较权威的是全国信标委今年发布了大数据平台的国标 《GB/T 38673-2020 信息技术 大数据 大数据系统基本要求》，将大数据系统划分为<strong>数据收集、数据存储、数据预处理、数据处理、数据分析、数据访问、资源管理、系统管理</strong>8个部分，分别对各部分提出技术要求。所以会发现每个厂家推出的大数据平台都包含很多功能、甚至组合的产品，属于大数据的产品种类非常多。</p>
<h3 id="什么是大数据开发平台"><a href="#什么是大数据开发平台" class="headerlink" title="什么是大数据开发平台"></a>什么是大数据开发平台</h3><p>由于大数据技术很多，单独使用的学习成本很高，为了提升数据开发的效率，也就出现了大数据开发平台。简单讲，<strong>数据开发平台就是集成了大数据平台的一个开发套件</strong>，比如阿里云的DataWorks就是一个代表，DataWorks（数据工场，原大数据开发套件）是阿里云重要的PaaS（Platform-as-a-Service）平台产品，提供数据集成、数据开发、数据地图、数据质量和数据服务等全方位的产品服务，一站式开发管理的界面，帮助企业专注于数据价值的挖掘和探索。</p>
<h2 id="数据中台"><a href="#数据中台" class="headerlink" title="数据中台"></a>数据中台</h2><h3 id="什么是数据中台"><a href="#什么是数据中台" class="headerlink" title="什么是数据中台"></a>什么是数据中台</h3><p>阿里巴巴于2017年云栖大会正式对外提出数据中台概念，数据中台的出现，就是为了弥补数据开发和应用开发之间，由于开发速度不匹配，出现的响应力跟不上的问题。<strong>中台不是一个产品！</strong>与业务强相关。</p>
<p><img src="/images/0057.png"></p>
<p>数据中台的一些定义：</p>
<table>
<thead>
<tr>
<th>#</th>
<th>定义</th>
<th>出处</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>中台就是“企业级能力复用平台”。</td>
<td>《白话中台战略-3：中台的定义》</td>
</tr>
<tr>
<td>2</td>
<td>中台通过集合整个集团的运营数据能力、产品技术能力，来对各前台业务形成强力支撑。</td>
<td>《大型集团性企业的中台战略—阿里的中台战略其实是个伪命题》</td>
</tr>
<tr>
<td>3</td>
<td>中台是一种需求分析的方法论，一套能力接入标准，一套运作机制，集中配置、分布执行的控制台。</td>
<td>《中台如何助力标准化业务？中台关键要快！》</td>
</tr>
<tr>
<td>4</td>
<td>“中台”是强调资源整合、能力沉淀的平台体系，为“前台”的业务开展提供底层的技术、数据等资源和能力的支持。</td>
<td>《大中台 小前台》</td>
</tr>
<tr>
<td>5</td>
<td>中台是居于前台和后台之间、位于基础架构和各产品线间的业务架构。</td>
<td>《关于架构的思考-评《阿里巴巴中台战略思想与架构实践》》</td>
</tr>
<tr>
<td>6</td>
<td>数据中台是将各个业务板块多年来积累的数据，按业务特征进行横向关联和统一，按数据用途进行纵向分层，最终沉淀为公共的数据服务能力。</td>
<td>《传统企业数据中台的建设与思考》</td>
</tr>
<tr>
<td>7</td>
<td>数据中台的实质还是组件化，模块化，是设计模式与业务端的应用。</td>
<td>袋鼠云数据中台专栏（一）：浅析数据中台策略与建设实践</td>
</tr>
<tr>
<td>8</td>
<td>中台是一个用技术链接大数据技术能力，用业务链接数据应用场景的能力平台。</td>
<td>《阿里中台建设全解密：包含哪些内容？如何发挥作用？》</td>
</tr>
</tbody></table>
<h3 id="数据仓库与数据中台的区别与联系"><a href="#数据仓库与数据中台的区别与联系" class="headerlink" title="数据仓库与数据中台的区别与联系"></a>数据仓库与数据中台的区别与联系</h3><table>
<thead>
<tr>
<th></th>
<th>数据仓库</th>
<th>数据中台</th>
</tr>
</thead>
<tbody><tr>
<td>计算存储</td>
<td>基于OLAP类型的数据库构建一套数据存储体系</td>
<td>混合架构，随需搭配，满足各类数据的计算要求</td>
</tr>
<tr>
<td>技术体系</td>
<td>传统的ETL开发和报表开发为主</td>
<td>数仓建设、数据开发IDE、任务调度、数据集成、数据治理、统一数据服务、数据资产管理、元数据管理、数据质量管理、流批计算、敏捷BI报表开发等多个功能</td>
</tr>
<tr>
<td>应用场景</td>
<td>报表为主</td>
<td>多元化场景：除了传统报表，还支持商品推荐、精准推送、客满评价等非确定场景的业务，数据服务业务、业务与数据互补，形成闭环</td>
</tr>
<tr>
<td>价值体现</td>
<td>面向管理层和业务人员的辅助决策</td>
<td>除了完成传统的业务人员辅助决策，还能面向业务系统推动优化升级、数据变现等，把数据资产变成数据服务能力。</td>
</tr>
</tbody></table>
<h2 id="数据湖"><a href="#数据湖" class="headerlink" title="数据湖"></a>数据湖</h2><h3 id="什么是数据湖"><a href="#什么是数据湖" class="headerlink" title="什么是数据湖"></a>什么是数据湖</h3><p>Pentaho的CTO James Dixon 在2011年提出了“Data Lake”的概念。在面对大数据挑战时，他声称：不要想着数据的“仓库”概念，想想数据 的“湖”概念。数据“仓库”概念和数据湖概念的重大区别是：<strong>数据仓库中数据在进入仓库之前需要是事先归类，以便于未来的分析</strong>。这在OLAP时代很常见，但是对于离线分析却没有任何意义，不如<strong>把大量的原始数据保存下来</strong>，而现在廉价的存储提供了这个可能。</p>
<p><img src="/images/0058.png"></p>
<ul>
<li>数据仓库是高度结构化的架构，数据在转换之前是无法加载到数据仓库的，用户可以直接获得分析数据。</li>
<li>数据湖中，数据直接加载到数据湖中，然后根据分析的需要再转换数据</li>
</ul>
<h3 id="数据湖产品-—-是一套产品组合的解决方案"><a href="#数据湖产品-—-是一套产品组合的解决方案" class="headerlink" title="数据湖产品 — 是一套产品组合的解决方案"></a>数据湖产品 — 是一套产品组合的解决方案</h3><p><img src="/images/0059.png"></p>
<h3 id="数据仓库与数据湖有什么区别与联系"><a href="#数据仓库与数据湖有什么区别与联系" class="headerlink" title="数据仓库与数据湖有什么区别与联系"></a>数据仓库与数据湖有什么区别与联系</h3><table>
<thead>
<tr>
<th>特性</th>
<th>数据仓库</th>
<th>数据湖</th>
</tr>
</thead>
<tbody><tr>
<td>数据</td>
<td>来自事务系统、运营数据库和业务线应用程序的关系数据</td>
<td>来自IoT 设备、网站、移动应用程序、社交媒体和企业应用程序的非关系和关系数据</td>
</tr>
<tr>
<td>Schema</td>
<td>写入型Schema，数据存储之前需要定义Schema，数据集成之前需要完成大量清洗工作，数据的价值需要提前明确</td>
<td>读取型Schema，数据存储之后才需要定义Schema 提供敏捷、简单的数据集成，数据的价值尚未明确</td>
</tr>
<tr>
<td>扩展性</td>
<td>中等开销获得较大的容量扩展</td>
<td>低成本开销获得极大容量扩展</td>
</tr>
<tr>
<td>性价比</td>
<td>更快查询结果会带来较高存储成本</td>
<td>更快查询结果只需较低存储成本</td>
</tr>
<tr>
<td>连接方式</td>
<td>标准的SQL接口或者BI接口、ANSI SQL</td>
<td>应用程序、类SQL程序、其它方法</td>
</tr>
<tr>
<td>数据质量</td>
<td>可作为重要事实依据的高度监管数据</td>
<td>任何可以或无法进行监管的数据（例如原始数据）</td>
</tr>
<tr>
<td>复杂性</td>
<td>复杂的SQL链接</td>
<td>复杂的大数据处理</td>
</tr>
<tr>
<td>用户</td>
<td>业务分析师</td>
<td>数据科学家、数据开发人员和业务分析师（使用监管数据）</td>
</tr>
<tr>
<td>分析</td>
<td>批处理报告、BI和可视化</td>
<td>机器学习、预测分析、数据发现和分析</td>
</tr>
<tr>
<td>优势</td>
<td>高并发、快速响应、干净安全的数据、数据一次转换多次使用</td>
<td>无限扩展性、支持编程框架、数据存储成本低</td>
</tr>
</tbody></table>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-concepts-comparsion.html" target="_blank">数据仓库【二】：数据库、数据仓库、数据平台、数据中台、数据湖到底是什么？</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-concepts-comparsion.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【一】：数据仓库的8个发展阶段</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-history.html</url>
    <content><![CDATA[<h2 id="概念阶段（1978-1988）"><a href="#概念阶段（1978-1988）" class="headerlink" title="概念阶段（1978-1988）"></a>概念阶段（1978-1988）</h2><p>数据仓库最早的概念可以追溯到20世纪70年代MIT的一项研究，该研究致力于开发一种优化的技术架构并提出这些架构的指导性意见。</p>
<p>第一次，MIT的研究员<strong>将业务系统和分析系统分开</strong>，<strong>将业务处理和分析处理分成不同的层次</strong>，并采用单独的数据存储和完全不同的设计准则。同时，MIT的研究成果与80年代提出的信息中心（InformationCenter）相吻合：即把那些新出现的、不可以预测的、但是大量存在的分析型的负载从业务处理系统中剥离出来。</p>
<p>但是限于当时的信息处理和数据存储能力，该研究只是确立了一个论点：这两种信息处理的方式差别如此之大，以至于它们只能采用完全不同的架构和设计方法。</p>
<h2 id="萌芽阶段"><a href="#萌芽阶段" class="headerlink" title="萌芽阶段"></a>萌芽阶段</h2><p>在80年代中后期，作为当时技术最先进的公司，DEC已经开始采用分布式网络架构来支持其业务应用，并且DEC公司首先将业务系统移植到其自身的RDBMS产品：RdB。并且，DEC公司从工程部、销售部、财务部以及信息技术部抽调了不同的人员组建了新的小组，不仅研究新的分析系统架构，并要求将其应用到其全球的财务系统中。该小组结合MIT的研究结论，建立了TA2（TechnicalArchitecture2）规范，该规范定义了分析系统的四个组成部分：</p>
<ol>
<li>数据获取</li>
<li>数据访问</li>
<li>目录</li>
<li>用户服务</li>
</ol>
<p>其中的数据获取和数据访问目前大家都很清楚，而目录服务是用于帮助用户在网络中找到他们想要的信息，类似于业务元数据管理；用户服务用以支持对数据的直接交互，包含了其他服务的所有人机交互界面，这是系统架构的一个非常大的转变，<strong>第一次将交互界面作为单独的组件提出来</strong>。</p>
<h2 id="集成阶段"><a href="#集成阶段" class="headerlink" title="集成阶段"></a>集成阶段</h2><p>全企业集成（EnterpriseIntergration，1988）同时，IBM也在处理信息管理不同方面的问题，其最烦人的问题是不断增加的信息孤岛，IBM的很多客户要面对很多分立系统的数据集成问题，而这些系统有不同的编码方式和数据格式。</p>
<p>1988年，为解决全企业集成问题，IBM爱尔兰公司的BarryDevlin和PaulMurphy第一次提出了“信息仓库（InformationWarehouse）”的概念，将其定义为：</p>
<blockquote>
<p>一个结构化的环境，能支持最终用户管理其全部的业务，并支持信息技术部门保证数据质量”</p>
</blockquote>
<p>，并在1991年在DECTA2的基础上把信息仓库的概念包含进去，并称之为VITAL规范，将PC、图形化界面、面向对象的组件以及局域网都包含在VITAL里，并定义了85种信息仓库的组件，包括数据抽取、转换、有效性验证、加载、Cube开发和图形化查询工具等。但是IBM只是将这种领先的概念用于市场宣传，而没有付诸实际的架构设计。这是IBM有一个领域上创新后停止不前导致丧失其领先地位。因此，在90年代初期，数据仓库的基本原理、框架架构，以及分析系统的主要原则都已经确定，主要的技术，包括关系型数据存取、网络、C/S架构和图形化界面均已具备，只欠东风了。</p>
<p>同时，在1988年－1991年，一些前沿的公司已经开始建立数据仓库。</p>
<h2 id="确立阶段（1991）"><a href="#确立阶段（1991）" class="headerlink" title="确立阶段（1991）"></a>确立阶段（1991）</h2><p>企业级数据仓库（EDW，1991）1991年，BillInmon出版了其有关数据仓库的第一本书，这本书不仅仅说明为什么要建数据仓库、数据仓库能给你带来什么，更重要的是，Inmon第一次提供了如何建设数据仓库的指导性意见，该书<strong>定义了数据仓库非常具体的原则</strong>，包括：</p>
<ul>
<li>数据仓库是面向主题的（Subject-Oriented）</li>
<li>集成的（Integrated）</li>
<li>包含历史的（Time-variant）</li>
<li>相对稳定的（Nonvolatile）</li>
<li>面向决策支持的（DecisionSupport）</li>
<li>面向全企业的（EnterpriseScope）</li>
<li>最明细的数据存（AtomicDetail）</li>
<li>数据快照式的数据获取（SnapShotCapture）</li>
</ul>
<p>这些原则到现在仍然是指导数据仓库建设的最基本原则，虽然中间的一些原则引发一些争论，并导致一些分歧和数据仓库变体的产生。</p>
<p>BillInmon凭借其这本书奠定了其在数据仓库建设的位置，被称之为<strong>“数据仓库之父”</strong>。</p>
<h2 id="数据集市（1994－1996）"><a href="#数据集市（1994－1996）" class="headerlink" title="数据集市（1994－1996）"></a>数据集市（1994－1996）</h2><p>数据仓库发展的第一明显分歧是数据集市概念的产生。由于企业级数据仓库的设计、实施很困难，使得最早吃数据仓库螃蟹的公司遭到大面积的失败，因此数据仓库的建设者和分析师开始考虑只建设企业级数据仓库的一部分，然后再逐步添加，但是这有背于BillInmon的原则：<strong>各个实施部分的数据抽取、清洗、转换和加载是独立，导致了数据的混乱与不一致性</strong>。而且部分实施的项目也有很多失败，除了常见的业务需求定义不清、项目执行不力之外，很重要的原因是因为其数据模型设计，在企业级数据仓库中，Inmon推荐采用3范式进行数据建模，但是不排除其他的方法，但是Inmon的追随者固守OLTP系统的3范式设计，从而无法支持DSS系统的性能和数据易访问性的要求。</p>
<p>这时，Ralph Kimball出现了，他的第一本书<em>The Data Warehouse Toolkit</em>掀起了数据集市的狂潮，这本书<strong>提供了如何为分析进行数据模型优化详细指导意见</strong>，从<code>Dimensional Modeling</code>大行其道，也为传统的关系型数据模型和多维OLAP之间建立了很好的桥梁。从此，数据集市在很多地方冒了出来，并获得很大成功，而企业级数据仓库已逐渐被人所淡忘。</p>
<h2 id="争吵与混乱（1996-1997）"><a href="#争吵与混乱（1996-1997）" class="headerlink" title="争吵与混乱（1996-1997）"></a>争吵与混乱（1996-1997）</h2><p>企业级数据仓库还是部门级数据集市？关系型还是多维？BillInmon和RalphKimball一开始就争论不休，其各自的追随者也唇舌相向，形成相对立的两派：Inmon派和Kimball派（有点象少林和武当，呵呵）。</p>
<p>在初期，数据集市的快速实施和较高的成功率让Kimball派占了上风，但是很快，他们也发现自己陷入了某种困境：企业中存在6－7个不同的数据集市，分别有不同的ETL，相互之间的数据也不完全一致。同时，各个项目实施中也任意侵犯了Inmon开始定下的准则：把数据集市当成众多OLTP系统之后的又一个系统，而不是一个基础性的集成性的东西，为保证数据的准确性和实时性，有的甚至可以由OLTP系统直接修改数据集市里面的数据，为了保证系统的性能，有的数据集市删除了历史数据。等等，不一而足。</p>
<p>当然，这导致了一些新的应用的出现，例如ODS，但是人们对<code>DataWarehouse</code>、<code>DataMart</code>、<code>ODS</code>的概念非常的模糊，经常混为一谈。有人说OLAP就是数据仓库，也有人说我要ODS和DataMart，不要Datawarehouse，也有人说，我DataMart建多了，自然就有DataWarehouse了。但是BillInmon一直很旗帜鲜明：<strong>“你可以打到几万吨的小鱼小虾，但是这些小鱼小虾加起来不是大鲸鱼”</strong>。</p>
<h2 id="合并（1998－2001）"><a href="#合并（1998－2001）" class="headerlink" title="合并（1998－2001）"></a>合并（1998－2001）</h2><p>经过多翻争吵，证明one-size-fits-all是不可能的，你需要不同的BI架构来满足不同的业务需求。BillInmon也推出了新的BI架构CIF（Corporation information factory），把Kimball的数据集市也包容进来了，第一次，Kimball承认了Inmon，但是仍然还有很多人在争论是自顶向下，还是自底向上。</p>
<h2 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h2><p>未来几个方向：</p>
<ul>
<li>时效性方向的实时数仓；</li>
<li>数据质量方向的数据治理；</li>
<li>数据中台、数据湖</li>
</ul>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-history.html" target="_blank">数据仓库【一】：数据仓库的8个发展阶段</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-history.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【四】：四种常见数据模型</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-models.html</url>
    <content><![CDATA[<p>大数据时代，维度建模已成为各大厂的主流方式。</p>
<p>维度建模从分析决策的需求出发构建模型，为分析需求服务。重点关注<strong>用户如何快速的完成数据分析，可以直观的反应业务模型中的业务问题，需要大量的数据预处理、数据冗余，有较好的大规模复杂查询的响应性能</strong>。</p>
<h2 id="为什么要进行数据仓库建模"><a href="#为什么要进行数据仓库建模" class="headerlink" title="为什么要进行数据仓库建模"></a>为什么要进行数据仓库建模</h2><ul>
<li>性能：良好的模型能帮我们快速查询需要的数据，减少数据的IO吞吐</li>
<li>成本：减少数据冗余、计算结果复用、从而降低存储和计算成本</li>
<li>效率：改善用户使用数据的体验，提高使用数据的效率</li>
<li>改善统计口径的不一致性，减少数据计算错误的可能性</li>
</ul>
<h2 id="四种常见模型"><a href="#四种常见模型" class="headerlink" title="四种常见模型"></a>四种常见模型</h2><h3 id="维度模型"><a href="#维度模型" class="headerlink" title="维度模型"></a>维度模型</h3><p><strong>维度建模</strong>按数据组织类型划分可分为<strong>星型模型、雪花模型、星座模型</strong>。Kimball老爷爷维度建模四部曲：</p>
<p>选择业务处理过程 &gt; 定义粒度 &gt; 选择维度 &gt; 确定事实</p>
<h4 id="星型模型"><a href="#星型模型" class="headerlink" title="星型模型"></a>星型模型</h4><p>星型模型主要是维表和事实表，<strong>以事实表为中心，所有维度直接关联在事实表上</strong>，呈星型分布。</p>
<p><img src="/images/0060.png"></p>
<h4 id="雪花模型"><a href="#雪花模型" class="headerlink" title="雪花模型"></a>雪花模型</h4><p>雪花模型，在星型模型的基础上，<strong>维度表上又关联了其他维度表</strong>。这种模型维护成本高，性能方面也较差，所以一般不建议使用。尤其是基于hadoop体系构建数仓，减少join就是减少shuffle，性能差距会很大。</p>
<p>星型模型可以理解为，一个事实表关联多个维度表，雪花模型可以理解为一个事实表关联多个维度表，维度表再关联维度表。</p>
<p><img src="/images/0061.png"></p>
<h4 id="星座模型"><a href="#星座模型" class="headerlink" title="星座模型"></a>星座模型</h4><p>星座模型，是对星型模型的扩展延伸，<strong>多张事实表共享维度表</strong>。</p>
<p>星座模型是很多数据仓库的常态，因为很多数据仓库都是多个事实表的。所以星座模型只反映是否有多个事实表，他们之间是否共享一些维度表。</p>
<p><img src="/images/0062.png"></p>
<h3 id="范式模型"><a href="#范式模型" class="headerlink" title="范式模型"></a>范式模型</h3><p>即实体关系（ER）模型，数据仓库之父Immon提出的，从全企业的高度设计一个3NF模型，用实体加关系描述的数据模型描述企业业务架构，在范式理论上符合3NF。此建模方法，对建模人员的能力要求非常高。</p>
<p>特点：设计思路自上而下，适合上游基础数据存储，<strong>同一份数据只存储一份，没有数据冗余</strong>，方便解耦，易维护，缺点是开发周期一般比较长，维护成本高。</p>
<h3 id="Data-Vault模型"><a href="#Data-Vault模型" class="headerlink" title="Data Vault模型"></a>Data Vault模型</h3><p>DataVault由 **Hub（关键核心业务实体）、Link（关系）、Satellite（实体属性） ** 三部分组成 ，是Dan Linstedt发起创建的一种模型方法论，它是在ER关系模型上的衍生，同时设计的出发点也是为了实现数据的整合，并非为数据决策分析直接使用。</p>
<h3 id="Anchor模型"><a href="#Anchor模型" class="headerlink" title="Anchor模型"></a>Anchor模型</h3><p>高度可扩展的模型，所有的扩展只是添加而不是修改，因此它将模型规范到6NF，基本变成了K-V结构模型。企业很少使用。</p>
<h2 id="数据模型的评价标准"><a href="#数据模型的评价标准" class="headerlink" title="数据模型的评价标准"></a>数据模型的评价标准</h2><p>数据模型建设的怎么样，极度依赖规范设计，如果代码风格是“千人千面”，那么恐怕半年下来，业务系统就没法看了。<strong>没有什么比“数据系统”更看重“法制”了</strong>，规范体系不仅能保障数据建设的一致性，也能够应对业务交接的情况，更能够为自动化奠定基础。</p>
<ul>
<li>业务过程清晰：ODS就是原始信息，不修改；DWD面向基础业务过程；DIM描述维度信息；DWS针对最小场景做指标计算；ADS也要分层，面向跨域的建设，和面向应用的建设；</li>
<li>指标可理解：按照一定业务事务过程进行业务划分，明细层粒度明确、历史数据可获取，汇总层维度和指标同名同义，能客观反映业务不同角度下的量化程度；</li>
<li>核心模型相对稳定：如果业务过程运行的比较久，过程相对固定，就要尽快下沉到公共层，形成可复用的核心模型；</li>
<li>高内聚低耦合：各主题内数据模型要业务高内聚，避免在一个模型耦合其他业务的指标，造成该模型主题不清晰和性价比低。</li>
</ul>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-models.html" target="_blank">数据仓库【四】：四种常见数据模型</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-models.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【六】：事实表</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-06-dw-fact-table.html</url>
    <content><![CDATA[<p>事实表作为数据仓库维度建模的核心，紧紧围绕着业务过程来设 计，通过获取描述业务过程的度量来表达业务过程，包含了引用的维度 和与业务过程有关的度量。</p>
<h2 id="三种事实表概述"><a href="#三种事实表概述" class="headerlink" title="三种事实表概述"></a>三种事实表概述</h2><p>事实表有三种类型 : <strong>事务事实表</strong>、<strong>周期快照事实表</strong>和<strong>累积快照事实表</strong>。</p>
<h3 id="事务事实表"><a href="#事务事实表" class="headerlink" title="事务事实表"></a>事务事实表</h3><p>也称原子事实表，描述业务过程，跟踪控件或时间上某点的度量事件，保存的是最原子的数据；</p>
<blockquote>
<p>个人理解：类似于mysql binlog日志，每一次相关的 change 都记录下来，生成一行新的数据</p>
</blockquote>
<h3 id="周期快照事实表"><a href="#周期快照事实表" class="headerlink" title="周期快照事实表"></a>周期快照事实表</h3><p>以一个周期为时间间隔，来记录事实，一般周期可以是每天、每周、每月、每年等；</p>
<blockquote>
<p>个人理解：只看某个业务过程，比如订单收货，数据按订单收货时间来切分，周期可以为每天、每月等。</p>
</blockquote>
<h3 id="累积快照事实"><a href="#累积快照事实" class="headerlink" title="累积快照事实"></a>累积快照事实</h3><p>用来描述过程开始和结束之间的关键步骤事件，覆盖过程的整个生命周期，通常具有多个日期字段来记录关键时间点；当过程随着生命周期不断变化时，记录也会随着过程的变化而被修改；</p>
<blockquote>
<p>个人理解：要看整个生命周期的多个业务过程，比如：创建订单 → 买家付款 → 卖家发货 → 买家确认收货。粒度是一个订单一行数据，创建订单时间，付款时间，发货时间，收货时间，分别作为一个字段，便于计算不同业务过程的时间间隔。</p>
</blockquote>
<h2 id="三种事实表对比"><a href="#三种事实表对比" class="headerlink" title="三种事实表对比"></a>三种事实表对比</h2><table>
<thead>
<tr>
<th></th>
<th>事务事实表</th>
<th>周期快照事实表</th>
<th>累积快照事实表</th>
</tr>
</thead>
<tbody><tr>
<td>时期/时间</td>
<td>离散事务时间点</td>
<td>以有规律的、可预测的</td>
<td>用于时间跨度不确定的不断变化的工作流</td>
</tr>
<tr>
<td>日期维度</td>
<td>事务日期</td>
<td>快照日期</td>
<td>相关业务过程涉及的多个日期</td>
</tr>
<tr>
<td>粒度</td>
<td>每行代表实体的一个事务</td>
<td>每行代表某时间周期的一个实体</td>
<td>每行代表一个实体的生命周期</td>
</tr>
<tr>
<td>事实</td>
<td>事务事实</td>
<td>累积事实</td>
<td>相关业务过程事实和时间间隔事实</td>
</tr>
<tr>
<td>事实表加载</td>
<td>插入</td>
<td>插入</td>
<td>插入与更新</td>
</tr>
<tr>
<td>事实表更新</td>
<td>不更新</td>
<td>不更新</td>
<td>业务过程变更时更新</td>
</tr>
</tbody></table>
<h2 id="事实表设计-8-大原则"><a href="#事实表设计-8-大原则" class="headerlink" title="事实表设计 8 大原则"></a>事实表设计 8 大原则</h2><h3 id="尽可能包含所有与业务过程相关的事实"><a href="#尽可能包含所有与业务过程相关的事实" class="headerlink" title="尽可能包含所有与业务过程相关的事实"></a>尽可能包含所有与业务过程相关的事实</h3><p>分析哪些事实与业务过程相关，是设计过程中非常重要的关注点；<br>在事实表中，尽量包含所有与业务过程相关的事实，即使存在冗余，由于事实通常是数字型，存储开销不会太大；</p>
<h3 id="只选择与业务过程相关的事实"><a href="#只选择与业务过程相关的事实" class="headerlink" title="只选择与业务过程相关的事实"></a>只选择与业务过程相关的事实</h3><p>如，订单的下单这个业务过程，事实表中不应该存在支付金额这个表示支付业务过程的事实；</p>
<h3 id="分解不可加性事实为可加的组件"><a href="#分解不可加性事实为可加的组件" class="headerlink" title="分解不可加性事实为可加的组件"></a>分解不可加性事实为可加的组件</h3><p>如，订单的优惠率，应分解为订单原价金额与订单优惠金额两个事实存储在事实表中；</p>
<h3 id="在选择维度和事实之前必须先声明粒度"><a href="#在选择维度和事实之前必须先声明粒度" class="headerlink" title="在选择维度和事实之前必须先声明粒度"></a>在选择维度和事实之前必须先声明粒度</h3><ul>
<li>因为原子粒度提供了最大限度的灵活性，可以支持无法预期的各种细节层次的用户需求；</li>
<li>粒度用于确定事实表中一行所表示业务的细节层次，决定了维度模型的扩展性；</li>
<li>每个维度和事实必须与所定义的粒度保持一致；</li>
<li>设计事实表时，粒度定义越细越好，一般从最低级别的原子粒度开始；</li>
</ul>
<h3 id="在同一个事实表中不能有多种不同粒度的事实"><a href="#在同一个事实表中不能有多种不同粒度的事实" class="headerlink" title="在同一个事实表中不能有多种不同粒度的事实"></a>在同一个事实表中不能有多种不同粒度的事实</h3><ul>
<li>粒度为票一级；（实际业务中，一个订单可以同时支付多张票）</li>
<li>票支付金额和票折扣金额，两个事实的粒度为 “票级”，与定义的粒度一致；</li>
<li>订单支付金额和订单票数，两个事实的粒度为 “订单级”，属于上一层订单级数据，与 “票级” 事实表的粒度不一致，且不能进行汇总；</li>
<li>如果，以订单金额和订单票数这两个维度汇总总金额和总票数，会造成大量的重复计算；</li>
</ul>
<h3 id="事实的单位要保持一致"><a href="#事实的单位要保持一致" class="headerlink" title="事实的单位要保持一致"></a>事实的单位要保持一致</h3><p>如，订单金额、订单优惠金额、订单运费这 3 个事实，应该采用统一的计量单位，统一为元或者分，以方便使用；</p>
<h3 id="对事实的-null-值要处理"><a href="#对事实的-null-值要处理" class="headerlink" title="对事实的 null 值要处理"></a>对事实的 null 值要处理</h3><ul>
<li>原因：在数据库中，null 值对常用数字型字段的 SQL 过滤条件都不生效；如，大于、小于、等于、大于或等于、小于或等于；</li>
<li>处理：用 0 代替 null ；</li>
</ul>
<h3 id="使用退化维度提高事实表的易用性"><a href="#使用退化维度提高事实表的易用性" class="headerlink" title="使用退化维度提高事实表的易用性"></a>使用退化维度提高事实表的易用性</h3><p>易用性：对事实表，更较少关联操作、过滤查询、控制聚合层次、排序数据、定义主从关系等；</p>
<p>事实表中存储各种类型的常用维度信息，较少下游用户使用时关联多个表的操作；<br>通过退化维度，可以实现对事实表的过滤查询、控制聚合层次、排序数据、定义主从关系等；</p>
<p>在 Kimball 的维度建模中，通常按照星形模型的方式设计，通过事实表的外键关联专门的维表，这种方式来获取维度，谨慎使用退化维表；这与大数据领域的事实表设计不一样；</p>
<p>思路：通过增加冗余存储，减少计算开销，提高使用效率；</p>
<h2 id="事实表设计方法"><a href="#事实表设计方法" class="headerlink" title="事实表设计方法"></a>事实表设计方法</h2><p>Kimball 的维度模型设计 4 步法：</p>
<ol>
<li>选择业务过程</li>
<li>声明粒度</li>
<li>确定维度</li>
<li>确定事实；</li>
</ol>
<p>当前的互联网大数据环境，维度模型的设计，是基于 Kimball 的四步维度建模方法进行了更进一步的改进：</p>
<h3 id="第一步：选择业务过程及确定事实表类型"><a href="#第一步：选择业务过程及确定事实表类型" class="headerlink" title="第一步：选择业务过程及确定事实表类型"></a>第一步：选择业务过程及确定事实表类型</h3><ul>
<li>如淘宝的一个交易订单，选择 “买家付款” 这个业务过程，则事实表类型应为只包含买家付款这一个业务过程的 “单事务事实表”；</li>
<li>如选择了所有 4 个业务过程，并且需要分享各业务过程的时间间隔，则事实表类型应为包含了所有 4 个业务过程的 “累积快照事实表”；</li>
<li>如是选择 “买家付款” 这个业务过程，还是选择 “创建订单” 和 “买家付款” 这两个业务过程，具体根据业务情况来定；</li>
</ul>
<p>思路：详细分析需求，对业务的整个生命周期进行分析，明确关键的业务步骤，从而选择与需求有关的业务过程；</p>
<p>  实例说明：</p>
<ol>
<li>分析业务的生命周期，业务过程通常使用行为动词表示业务执行的活动；</li>
<li>明确关键的业务步骤：该订单流转的业务过程有 4 个：创建订单 → 买家付款 → 卖家发货 → 买家确认收货；</li>
<li>根据业务需求，选择与维度建模有关的业务过程；</li>
<li>根据所选的业务过程确定事实表类型；</li>
</ol>
<h3 id="第二步：声明粒度"><a href="#第二步：声明粒度" class="headerlink" title="第二步：声明粒度"></a>第二步：声明粒度</h3><p>粒度的选择：尽量选择最细级别的原子粒度，以确保事实表的应用具有最大的灵活性；</p>
<ul>
<li>灵活性：支持无法预期的各种细节层次的用户需求；</li>
<li>对于订单级别，粒度可以定义为最细的订单级别；（如，父子订单，事实表的粒度可以定 “子订单级别” ；）</li>
<li>粒度的声明，意味着精确定义事实表的每一行所表示的业务含义；</li>
</ul>
<p>明确的粒度能够确保对实表中行的意思的理解不会产生混淆，保证所有的事实按照同样的细节层次记录；</p>
<h3 id="第三步：确定维度"><a href="#第三步：确定维度" class="headerlink" title="第三步：确定维度"></a>第三步：确定维度</h3><p>如，淘宝订单 “付款事务事实表” 中，粒度为 “子订单”，相关的维度有买家、卖家、商品、收货人信息、业务类型、订单时间等；</p>
<p>完成了粒度声明，就意味着确定了主键，对应的维度组合以及相关的维度字段也可以确定了；</p>
<p>选择维度的原则：应该选择能够描述清楚业务过程所处的环境的维度信息；</p>
<h3 id="第四步：确定事实"><a href="#第四步：确定事实" class="headerlink" title="第四步：确定事实"></a>第四步：确定事实</h3><p>确定原则：选择与业务过程有关的所有事实，且事实的粒度要与所声明的事实表的粒度一致；</p>
<p>思路：可以通过回答 “过程的度量是什么” 来确定；</p>
<p>注意：将不可加性事实分解为可加的组件；（分解的原则：可以通过分解后的可加的属性值，计算得到不可加性事实）</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-06-dw-fact-table.html" target="_blank">数据仓库【六】：事实表</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-06-dw-fact-table.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【七】：维度表</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-07-dw-dim-table.html</url>
    <content><![CDATA[<h2 id="什么是维度表"><a href="#什么是维度表" class="headerlink" title="什么是维度表"></a>什么是维度表</h2><p>维度是维度建模的基础和灵魂。在维度建模中，将度量称为“事实” ， 将环境描述为“维度”。</p>
<p>维度表包含了事实表中指定属性的相关详细信息，最常用的维度表有日期维度、城市维度等。</p>
<p><strong>日期维表：</strong></p>
<table>
<thead>
<tr>
<th>num</th>
<th>字段名</th>
<th>字段中文名</th>
<th>描述</th>
<th>数据类型</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>date</td>
<td>日期</td>
<td>日期 yyyMMdd格式</td>
<td>bigint</td>
</tr>
<tr>
<td>2</td>
<td>week</td>
<td>星期，数字型</td>
<td>星期，数字型 0-6</td>
<td>bigint</td>
</tr>
<tr>
<td>3</td>
<td>week_cn</td>
<td>星期中文名</td>
<td>星期中文名 星期一……</td>
<td>string</td>
</tr>
<tr>
<td>4</td>
<td>year_weeks</td>
<td>一年中的第几周</td>
<td>一年中的第几周 1 2 3……</td>
<td>bigint</td>
</tr>
<tr>
<td>5</td>
<td>mon_dt</td>
<td>本周周一日期</td>
<td>本周周一日期</td>
<td>bigint</td>
</tr>
<tr>
<td>6</td>
<td>sun_dt</td>
<td>本周周日日期</td>
<td>本周周日日期</td>
<td>bigint</td>
</tr>
<tr>
<td>7</td>
<td>month</td>
<td>年月</td>
<td>年月，yyyyMM格式</td>
<td>bigint</td>
</tr>
<tr>
<td>8</td>
<td>month_short</td>
<td>月份简写</td>
<td>月份简写，MM格式1~12</td>
<td>bigint</td>
</tr>
<tr>
<td>9</td>
<td>month_cn</td>
<td>月份中文名</td>
<td>月份中文名 一月……</td>
<td>string</td>
</tr>
<tr>
<td>10</td>
<td>quarter</td>
<td>季度</td>
<td>季度，yyyyQ1\2\3\4</td>
<td>string</td>
</tr>
<tr>
<td>11</td>
<td>quarter_short</td>
<td>季度 数字型</td>
<td>季度 数字型 1-4</td>
<td>bigint</td>
</tr>
<tr>
<td>12</td>
<td>quarter_cn</td>
<td>季度中文名</td>
<td>季度中文名 第一季度……</td>
<td>string</td>
</tr>
<tr>
<td>13</td>
<td>year</td>
<td>年份</td>
<td>年份，yyyy格式</td>
<td>bigint</td>
</tr>
</tbody></table>
<h2 id="维度表设计原则"><a href="#维度表设计原则" class="headerlink" title="维度表设计原则"></a>维度表设计原则</h2><p>维度的作用一般是查询约束、分类汇总以及排序等，我们在进行维度表设计时，应当提前考虑：</p>
<h3 id="维度属性尽量丰富，为数据使用打下基础"><a href="#维度属性尽量丰富，为数据使用打下基础" class="headerlink" title="维度属性尽量丰富，为数据使用打下基础"></a>维度属性尽量丰富，为数据使用打下基础</h3><p>比如淘宝商品维度有近百个维度属性，为下游的数据统计、分析、探查提供了良好的基础。</p>
<h3 id="给出详实的、富有意义的文字描述"><a href="#给出详实的、富有意义的文字描述" class="headerlink" title="给出详实的、富有意义的文字描述"></a>给出详实的、富有意义的文字描述</h3><p>属性不应该是编码，而应该是真正的文字。在间里巴巴维度建模中， 一般是编码和文字同时存在，比如商品维度中的商品 ID 和商品标题、 类目 ID 和 类目名称等。ID 一 般用于不同表之间的关联，而名称一般用 于报表标签</p>
<h3 id="区分数值型属性和事实"><a href="#区分数值型属性和事实" class="headerlink" title="区分数值型属性和事实"></a>区分数值型属性和事实</h3><p>数值型字段是作为事实还是维度属性，可以参考字段的一般用途。如果通常<strong>用于查询约束条件或分组统计，则是作为维度属性</strong>；如果通常<strong>用于参与度量的计算，则是作为事实</strong>。</p>
<p>比如商品价格，可以用于查询约束条件或统计价格区间的商品数量，此时是作为维度属性使用的；也可以用于统计某类目下商品的平均价格，此时是作为事实使用的。另外，如果数值型字段是离散值，则作为维度属性存在的可能性较大；如果数值型宇段是连续值，则作为度量存在的可能性较大，但并不绝对，需要同时参考宇段的具体用途。</p>
<h3 id="沉淀出通用的维度属性，为建立一致性维度做好铺垫"><a href="#沉淀出通用的维度属性，为建立一致性维度做好铺垫" class="headerlink" title="沉淀出通用的维度属性，为建立一致性维度做好铺垫"></a>沉淀出通用的维度属性，为建立一致性维度做好铺垫</h3><p>有些维度属性获取需要进行比较复杂的逻辑处理，有些需要通过多表关联得到，或者通过单表的不同字段混合处理得到，或者通过对单表的某个字段进行解析得到。此时，需要将尽可能多的通用的维度属性进行沉淀。一方面，可以提高下游使用的方便性，减少复杂度；另一方面，可以避免下游使用解析时由于各自逻辑不同而导致口径不一致。</p>
<h3 id="退化维度（Degenerate-Dimension）"><a href="#退化维度（Degenerate-Dimension）" class="headerlink" title="退化维度（Degenerate Dimension）"></a>退化维度（Degenerate Dimension）</h3><p>在维度类型中，有一种重要的维度称作为退化维度。这种维度指的是直接<strong>把一些简单的维度放在事实表中</strong>。退化维度是维度建模领域中的一个非常重要的概念，它对理解维度建模有着非常重要的作用，退化维度一般在分析中可以用来做分组使用。</p>
<h3 id="缓慢变化维（Slowly-Changing-Dimensions）"><a href="#缓慢变化维（Slowly-Changing-Dimensions）" class="headerlink" title="缓慢变化维（Slowly Changing Dimensions）"></a>缓慢变化维（Slowly Changing Dimensions）</h3><p>维度的属性并不是始终不变的，它会随着时间的流逝发生缓慢的变化，这种随时间发生变化的维度我们一般称之为缓慢变化维（SCD），<strong>缓慢变化维一般使用代理健作为维度表的主健</strong>。</p>
<blockquote>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzkxNTI2MzMyMA==&mid=2247505768&idx=1&sn=6773b4930448625671fb87446db576fe&chksm=c1634d5ff614c449f560f6139df2a7a40f9684ad5613fbbe635c3bbcc3feeca681c29ab782b5&scene=21#wechat_redirect">缓慢变化维度的10种处理方式</a></p>
</blockquote>
<h2 id="维度表设计方法"><a href="#维度表设计方法" class="headerlink" title="维度表设计方法"></a>维度表设计方法</h2><h3 id="第一步：选择维度或新建维度。"><a href="#第一步：选择维度或新建维度。" class="headerlink" title="第一步：选择维度或新建维度。"></a>第一步：选择维度或新建维度。</h3><p>作为维度建模的核心，在企业级数据仓库中必须保证维度的唯一性。以淘宝商品维度为例，有且只允许有一个维度定义。</p>
<h3 id="第二步：确定主维表。"><a href="#第二步：确定主维表。" class="headerlink" title="第二步：确定主维表。"></a>第二步：确定主维表。</h3><p>此处的主维表一般是ODS表，直接与业务系统同步。以淘宝商品维度为例，s_auction_auctions是与前台商品中心系统同步的商品表，此表即是主维表。</p>
<h3 id="第三步：确定相关维表。"><a href="#第三步：确定相关维表。" class="headerlink" title="第三步：确定相关维表。"></a>第三步：确定相关维表。</h3><p>数据仓库是业务源系统的数据整合，不同业务系统或者同一业务系统中的表之间存在关联性。根据对业务的梳理，确定哪些表和主维表存在关联关系，并选择其中的某些表用于生成维度属性。</p>
<h3 id="第四步：确定维度属性。"><a href="#第四步：确定维度属性。" class="headerlink" title="第四步：确定维度属性。"></a>第四步：确定维度属性。</h3><p>本步骤主要包括两个阶段，其中第一个阶段是从主维表中选择维度属性或生成新的维度属性；第二个阶段是从相关维表中选择维度属性或生成新的维度属性。以淘宝商品维度为例，从主维表(s_auction_auctions)和类目、SPU、卖家、店铺等相关维表中选择维度属性或生成新的维度属性。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-07-dw-dim-table.html" target="_blank">数据仓库【七】：维度表</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-07-dw-dim-table.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【八】：三范式与反范式</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-08-dw-nf.html</url>
    <content><![CDATA[<p><strong>范式是符合某一种级别的关系模式的集合。</strong>构造数据库必须遵循一定的规则。在关系数据库中，这种规则就是范式。</p>
<p>关系数据库中的关系必须满足一定的要求，即满足不同的范式。大数据生态中，各类强大的查询引擎层出不穷，相对廉价的磁盘和分布式技术，也让数据冗余变得可接受甚至更加方便。</p>
<p>在创建一个数据库的过程中，范化是将其转化为一些表的过程，这种方法可以使从数据库得到的结果更加明确。这样可能使数据库产生重复数据，从而导致创建多余的表。范化是在识别数据库中的数据元素、关系以及定义所需的表和各表中的项目等这些初始工作之后的一个细化的过程。</p>
<h2 id="三范式与反范式"><a href="#三范式与反范式" class="headerlink" title="三范式与反范式"></a>三范式与反范式</h2><h3 id="第一范式"><a href="#第一范式" class="headerlink" title="第一范式"></a>第一范式</h3><blockquote>
<p><strong>1NF要求属性具有原子性，即列不可再分解。</strong></p>
</blockquote>
<figure class="highlight lasso"><table><tr><td class="code"><pre><span class="line">表：字段<span class="number">1</span>、 字段<span class="number">2</span>(字段<span class="number">2.1</span>、字段<span class="number">2.2</span>)、字段<span class="number">3</span> <span class="params">...</span><span class="params">...</span></span><br></pre></td></tr></table></figure>

<p>如</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">学生（学号，姓名，性别，出生年月日）</span><br></pre></td></tr></table></figure>

<p>有些钢筋可能要问了，姓名可以拆成姓、名两列， “出生年月日” 也可以拆成年、月、日三个字段。所以就不满足第一范式了！！！这里再强调一下原子性，原子性是根据使用方便来自定义的最小单位。中国人一般姓名一起用，美国就习惯姓名分别存两字段。</p>
<h3 id="第二范式"><a href="#第二范式" class="headerlink" title="第二范式"></a>第二范式</h3><blockquote>
<p><strong>2NF要求记录有惟一标识，即不存在部分依赖；</strong></p>
</blockquote>
<p>简单来说就是拆表，以人为粒度做一张明细表，以课程号为粒度做一张维度表，两表关联使用，消除了数据冗余</p>
<figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line">表：学号、课程号、姓名、学分<span class="comment">;</span></span><br></pre></td></tr></table></figure>

<p>这个表明显说明了两个事务：学生信息，课程信息；由于非主键字段必须依赖主键，这里学分依赖课程号，姓名依赖与学号，所以不符合二范式。</p>
<p>可能会存在问题：</p>
<ul>
<li>数据冗余：每条记录都含有相同信息；</li>
<li>删除异常：删除所有学生成绩，就把课程信息全删除了；</li>
<li>插入异常：学生未选课，无法记录进数据库；</li>
<li>更新异常：调整课程学分，所有行都调整。</li>
</ul>
<p>正确做法:</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line">学生：<span class="built_in">Student</span>(学号, 姓名)；</span><br><span class="line">课程：<span class="built_in">Course</span>(课程号, 学分)；</span><br><span class="line">选课关系：<span class="built_in">StudentCourse</span>(学号, 课程号, 成绩)。</span><br></pre></td></tr></table></figure>

<h3 id="第三范式"><a href="#第三范式" class="headerlink" title="第三范式"></a>第三范式</h3><p>3NF是对字段的<strong>冗余性</strong>，要求任何字段不能由其他字段派生出来，它要求字段没有冗余，即不存在传递依赖；</p>
<figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="section">表: 学号, 姓名, 年龄, 学院名称, 学院电话</span></span><br></pre></td></tr></table></figure>

<p>因为存在依赖传递: (学号) → (学生)→(所在学院) → (学院电话) 。</p>
<p>可能会存在问题：</p>
<ul>
<li>数据冗余：有重复值；</li>
<li>更新异常：有重复的冗余信息，修改时需要同时修改多条记录，否则会出现数据不一致的情况 。</li>
</ul>
<p>正确做法：</p>
<figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">学生：<span class="comment">(学号, 姓名, 年龄, 所在学院)</span>；</span><br><span class="line">学院：<span class="comment">(学院, 电话)</span>。</span><br></pre></td></tr></table></figure>

<h3 id="反范式化"><a href="#反范式化" class="headerlink" title="反范式化"></a>反范式化</h3><p><strong>一般说来，数据库只需满足第三范式（3NF）就行了。</strong></p>
<p>没有冗余的数据库设计可以做到。但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，<strong>降低范式标准的工作放到物理数据模型设计时考虑</strong>。降低范式就是增加字段，允许冗余，达到以空间换时间的目的。</p>
<blockquote>
<p>  〖例〗：有一张存放商品的基本表，如表1所示。“金额”这个字段的存在，表明该表的设计不满足第三范式，因为“金额”可以由“单价”乘以“数量”得到，说明“金额”是冗余字段。但是，增加“金额”这个冗余字段，可以提高查询统计的速度，这就是以空间换时间的作法。</p>
</blockquote>
<p>在Rose 2002中，规定列有两种类型：<strong>数据列和计算列</strong>。“金额”这样的列被称为“计算列”，而“单价”和“数量”这样的列被称为“数据列”。</p>
<h2 id="范式化设计和反范式化设计的优缺点"><a href="#范式化设计和反范式化设计的优缺点" class="headerlink" title="范式化设计和反范式化设计的优缺点"></a>范式化设计和反范式化设计的优缺点</h2><h3 id="范式化-（时间换空间）"><a href="#范式化-（时间换空间）" class="headerlink" title="范式化 （时间换空间）"></a>范式化 （时间换空间）</h3><p>优点：</p>
<ul>
<li>范式化的表减少了数据冗余，数据表更新操作快、占用存储空间少。</li>
</ul>
<p>缺点：</p>
<ul>
<li>查询时需要对多个表进行关联，查询性能降低。</li>
<li>更难进行索引优化</li>
</ul>
<h3 id="反范式化（空间换时间）"><a href="#反范式化（空间换时间）" class="headerlink" title="反范式化（空间换时间）"></a>反范式化（空间换时间）</h3><p>反范式的过程就是通过冗余数据来提高查询性能，但冗余数据会牺牲数据一致性</p>
<p>优点：</p>
<ul>
<li>可以减少表关联</li>
<li>可以更好进行索引优化</li>
</ul>
<p>缺点：</p>
<ul>
<li>存在大量冗余数据</li>
<li>数据维护成本更高（删除异常，插入异常，更新异常）</li>
</ul>
<h2 id="OLAP和OLTP中范式设计"><a href="#OLAP和OLTP中范式设计" class="headerlink" title="OLAP和OLTP中范式设计"></a>OLAP和OLTP中范式设计</h2><p>OLAP 一般冗余比较多，以查询分析为主，这种一般都是采用反范式设计，以提高查询效率。更新一般是定时大批量数据插入。</p>
<p>OLTP 则是尽可能消除冗余，以提高变更的效率。因为这种应用无时无刻不在频繁变化。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-08-dw-nf.html" target="_blank">数据仓库【八】：三范式与反范式</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-08-dw-nf.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【九】：数据治理（目的、方法、流程）</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-09-dw-data-governance.html</url>
    <content><![CDATA[<h2 id="什么是数据治理"><a href="#什么是数据治理" class="headerlink" title="什么是数据治理"></a>什么是数据治理</h2><p>数据治理（Data Governance）是组织中涉及数据使用的一整套管理行为。由企业数据治理部门发起并推行，关于如何制定和实施针对整个企业内部数据的商业应用和技术管理的一系列政策和流程。</p>
<p>数据的质量直接影响着数据的价值，并且直接影响着数据分析的结果以及我们以此做出的决策的质量。</p>
<p>我们常说，用数据说话，用数据支撑决策管理，但低质量的数据、甚至存在错误的数据，必然会”说假话”！！！数据治理即提高数据的质量，发挥数据资产价值。</p>
<h2 id="数据治理的目的"><a href="#数据治理的目的" class="headerlink" title="数据治理的目的"></a>数据治理的目的</h2><ul>
<li>降低风险</li>
<li>建立数据使用内部规则</li>
<li>实施合规要求</li>
<li>改善内部和外部沟通</li>
<li>增加数据价值</li>
<li>方便数据管理</li>
<li>降低成本</li>
<li>通过风险管理和优化来帮助确保公司的持续生存</li>
</ul>
<h2 id="数据治理的方法"><a href="#数据治理的方法" class="headerlink" title="数据治理的方法"></a>数据治理的方法</h2><p>从技术实施角度看，数据治理包含 <strong>“理”“采”“存”“管”“用”</strong> 这五个步骤，即<strong>业务和数据资源梳理、数据采集清洗、数据库设计和存储、数据管理、数据使用</strong>。</p>
<h3 id="数据资源梳理"><a href="#数据资源梳理" class="headerlink" title="数据资源梳理"></a>数据资源梳理</h3><p>数据治理的第一个步骤是从业务的视角厘清组织的数据资源环境和数据资源清单，包含组织机构、业务事项、信息系统，以及以数据库、网页、文件和 API 接口形式存在的数据项资源，本步骤的输出物为分门别类的数据资源清单。</p>
<h3 id="数据采集清洗"><a href="#数据采集清洗" class="headerlink" title="数据采集清洗"></a>数据采集清洗</h3><p>通过可视化的 ETL 工具（例如阿里的 DataX，Pentaho Data Integration）将数据从来源端经过 <strong>抽取 (extract)、转换 (transform)、加载 (load)</strong> 至目的端的过程，目的是将散落和零乱的数据集中存储起来。</p>
<h3 id="基础库主题库建设"><a href="#基础库主题库建设" class="headerlink" title="基础库主题库建设"></a>基础库主题库建设</h3><p>一般情况下，可以将数据分为<strong>基础数据、业务主题数据和分析数据</strong>。</p>
<p>基础数据一般指的是核心实体数据，或称主数据，例如智慧城市中的人口、法人、地理信息、信用、电子证照等数据。</p>
<p>主题数据一般指的是某个业务主题数据，例如市场监督管理局的食品监管、质量监督检查、企业综合监管等数据。</p>
<p>而分析数据指的是基于业务主题数据综合分析而得的分析结果数据，例如市场监督管理局的企业综合评价、产业区域分布、高危企业分布等。</p>
<p>那么基础库和主题库的建设就是在对业务理解的基础上，基于易存储、易管理、易使用的原则抽像数据存储结构，说白了，就是基于一定的原则设计数据库表结构，然后再根据数据资源清单设计数据采集清洗流程，将整洁干净的数据存储到数据库或数据仓库中。</p>
<h3 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h3><p>元数据管理是对基础库和主题库中的<strong>数据项属性的管理</strong>，同时，将数据项的业务含义与数据项进行了关联，便于业务人员也能够理解数据库中的数据字段含义。并且，元数据是后面提到的自动化数据共享、数据交换和商业智能（BI）的基础。需要注意的是， <strong>元数据管理</strong>一般是对基础库和主题库中（即核心数据资产）的数据项属性的管理，而<strong>数据资源清单</strong>是对各类数据来源的数据项的管理。</p>
<h3 id="血缘追踪"><a href="#血缘追踪" class="headerlink" title="血缘追踪"></a>血缘追踪</h3><p>数据被业务场景使用时，发现数据错误，数据治理团队需要快速定位数据来源，修复数据错误。那么数据治理团队需要知道业务团队的数据来自于哪个核心库，核心库的数据又来自于哪个数据源头。我们的实践是在元数据和数据资源清单之间建立关联关系，且业务团队使用的数据项由元数据组合配置而来，这样，就建立了数据使用场景与数据源头之间的血缘关系。</p>
<h3 id="数据资源目录"><a href="#数据资源目录" class="headerlink" title="数据资源目录"></a>数据资源目录</h3><p>数据资源目录一般应用于数据共享的场景，例如政府部门之间的数据共享，数据资源目录是基于业务场景和行业规范而创建，同时依托于元数据和基础库主题而实现自动化的数据申请和使用。</p>
<h3 id="质量管理"><a href="#质量管理" class="headerlink" title="质量管理"></a>质量管理</h3><p>数据价值的成功发掘必须依托于高质量的数据，唯有<strong>准确、完整、一致</strong>的数据才有使用价值。因此，需要从多维度来分析数据的质量，例如：<strong>偏移量、非空检查、值域检查、规范性检查、重复性检查、关联关系检查、离群值检查、波动检查等等</strong>。需要注意的是，优秀的数据质量模型的设计必须依赖于对业务的深刻理解，在技术上也推荐使用大数据相关技术来保障检测性能和降低对业务系统的性能影响，例如 Hadoop，MapReduce，HBase 等。</p>
<h3 id="商业智能（BI）"><a href="#商业智能（BI）" class="headerlink" title="商业智能（BI）"></a>商业智能（BI）</h3><p>数据治理的目的是使用，对于一个大型的数据仓库来说，数据使用的场景和需求是多变的，那么可以使用 BI 类的产品快速获取需要的数据，并分析形成报表，比较知名的产品有 Microsoft Power BI，QlikView，Tableau，帆软等。</p>
<h3 id="数据共享交换"><a href="#数据共享交换" class="headerlink" title="数据共享交换"></a>数据共享交换</h3><p>数据共享包括组织内部和组织之间的数据共享，共享方式也分为<strong>库表、文件和 API 接口</strong>三种共享方式，库表共享比较直接粗暴，文件共享方式通过 ETL 工具做一个反向的数据交换也就可以实现。我们比较推荐的是 API 接口共享方式，在这种方式下，能够让中心数据仓库保留数据所有权，把数据使用权通过 API 接口的形式进行了转移。API 接口共享可以使用 API 网关实现，常见的功能是自动化的<strong>接口生成、申请审核、限流、限并发、多用户隔离、调用统计、调用审计、黑白名单、调用监控、质量监控等等</strong>。</p>
<h2 id="数据质量8个衡量标准"><a href="#数据质量8个衡量标准" class="headerlink" title="数据质量8个衡量标准"></a>数据质量8个衡量标准</h2><h3 id="数据的准确性"><a href="#数据的准确性" class="headerlink" title="数据的准确性"></a>数据的准确性</h3><p>数据采集值或者观测值和真实值之间的接近程度，也叫做误差值，误差越大，准确度越低。</p>
<h3 id="数据的精确性"><a href="#数据的精确性" class="headerlink" title="数据的精确性"></a>数据的精确性</h3><p>指对同一对象的观测数据在重复测量时所得到不同数据间的接近程度。</p>
<h3 id="数据的真实性"><a href="#数据的真实性" class="headerlink" title="数据的真实性"></a>数据的真实性</h3><h3 id="数据的及时性"><a href="#数据的及时性" class="headerlink" title="数据的及时性"></a>数据的及时性</h3><p>数据能否在需要的时候得到保证，比如月初的财务对账，能不能在月初就完成</p>
<h3 id="数据的即时性"><a href="#数据的即时性" class="headerlink" title="数据的即时性"></a>数据的即时性</h3><p>指数据采集时间节点和数据传输的时间节点，一个数据在数据源头采集后立即存储，并立即加工呈现，就是即时数据，而经过一段时间之后再传输到信息系统中，则数据即时性就稍差。</p>
<h3 id="数据的完整性"><a href="#数据的完整性" class="headerlink" title="数据的完整性"></a>数据的完整性</h3><p>应采集和实际采集到数据之间的比例。</p>
<h3 id="数据的全面性"><a href="#数据的全面性" class="headerlink" title="数据的全面性"></a>数据的全面性</h3><p>完整性衡量的是应采集和实际采集的差异。而全面性指的是数据采集点的遗漏情况。</p>
<h3 id="数据的关联性"><a href="#数据的关联性" class="headerlink" title="数据的关联性"></a>数据的关联性</h3><p>指各个数据集之间的关联关系。比如员工工资数据和员工绩效考核数据是通过员工这个资源关联在一起来的。</p>
<h2 id="数据治理流程"><a href="#数据治理流程" class="headerlink" title="数据治理流程"></a>数据治理流程</h2><p><img src="/images/0070.png"></p>
<p>基本流程：发现数据质量问题 &gt; 定义数据质量规则 &gt; 质量控制 &gt; 质量评估 &gt; 质量优化</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-09-dw-data-governance.html" target="_blank">数据仓库【九】：数据治理（目的、方法、流程）</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-09-dw-data-governance.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【十】：ETL</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-10-dw-etl.html</url>
    <content><![CDATA[<h2 id="什么是ETL"><a href="#什么是ETL" class="headerlink" title="什么是ETL"></a>什么是ETL</h2><p>ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程，是数据仓库的生命线。</p>
<h3 id="抽取（Extract）"><a href="#抽取（Extract）" class="headerlink" title="抽取（Extract）"></a>抽取（Extract）</h3><p>主要是针对各个业务系统及不同服务器的分散数据，充分理解数据定义后，规划需要的数据源及数据定义，制定可操作的数据源，制定增量抽取和缓慢渐变的规则。</p>
<h3 id="转换（transform）"><a href="#转换（transform）" class="headerlink" title="转换（transform）"></a>转换（transform）</h3><p>主要是针对数据仓库建立的模型，通过一系列的转换来实现将数据从业务模型到分析模型，通过ETL工具可视化拖拽操作可以直接使用标准的内置代码片段功能、自定义脚本、函数、存储过程以及其他的扩展方式，实现了各种复杂的转换，并且支持自动分析日志，清楚的监控数据转换的状态并优化分析模型。</p>
<h3 id="装载（Load）"><a href="#装载（Load）" class="headerlink" title="装载（Load）"></a>装载（Load）</h3><p>主要是将经过转换的数据装载到数据仓库里面，可以通过直连数据库的方式来进行数据装载，可以充分体现高效性。在应用的时候可以随时调整数据抽取工作的运行方式，可以灵活的集成到其他管理系统中。</p>
<h2 id="ETL-amp-ELT"><a href="#ETL-amp-ELT" class="headerlink" title="ETL &amp; ELT"></a>ETL &amp; ELT</h2><p>伴随着数据仓库的发展（传送门：<a href="/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-02-dw-history.html">数据仓库的八个发展阶段</a>），数据量从小到大，数据实时性从T+1到准实时、实时，ETL也在不断演进。</p>
<p><strong>在传统数仓中</strong>，数据量小，计算逻辑相对简单，我们可以直接用ETL工具实现数据转换（T），转换之后再加载到目标库，即（Extract-Transform-Load）。但<strong>在大数据场景下</strong>，数据量越大越大，计算逻辑愈发复杂，数据清洗需放在运算能力更强的分布式计算引擎中完成，ETL也就变成了ELT（Extract-Load-Transform）。</p>
<p>即：</p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Extract</span>-Transform-<span class="keyword">Load</span>  &gt;&gt;  <span class="keyword">Extract</span>-<span class="keyword">Load</span>-Transform</span><br></pre></td></tr></table></figure>

<p>通常我们所说的ETL，已经泛指数据同步、数据清洗全过程，而不仅限于数据的抽取-转换-加载。</p>
<h2 id="常用的ETL工具"><a href="#常用的ETL工具" class="headerlink" title="常用的ETL工具"></a>常用的ETL工具</h2><p>下面将介绍几类ETL工具（sqoop，DataX，Kettle，canal，StreamSets）。</p>
<h3 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h3><ul>
<li>是Apache开源的一款在Hadoop和关系数据库服务器之间传输数据的工具。</li>
<li>可以将一个关系型数据库（MySQL ,Oracle等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导出到关系型数据库中。</li>
<li>sqoop命令的本质是转化为MapReduce程序。</li>
<li>sqoop分为导入（import）和导出（export），</li>
<li>策略分为table和query</li>
<li>模式分为增量和全量。</li>
</ul>
<p><img src="/images/0071.png"></p>
<p><img src="/images/0001.jfif"></p>
<h3 id="DataX"><a href="#DataX" class="headerlink" title="DataX"></a>DataX</h3><p>DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、Oracle、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、DRDS 等各种异构数据源之间高效的数据同步功能。</p>
<p><img src="/images/0072.png"></p>
<h3 id="Kettle"><a href="#Kettle" class="headerlink" title="Kettle"></a>Kettle</h3><p>一款国外免费开源的、可视化的、功能强大的ETL工具，纯java编写，可以在Windows、Linux、Unix上运行，数据抽取高效稳定。</p>
<h3 id="canal"><a href="#canal" class="headerlink" title="canal"></a>canal</h3><p>canal是阿里巴巴旗下的一款开源项目，纯Java开发。基于数据库增量日志解析，提供增量数据实时订阅和消费，目前主要支持了MySQL，也支持mariaDB。</p>
<p><img src="/images/0073.png"></p>
<h3 id="StreamSets"><a href="#StreamSets" class="headerlink" title="StreamSets"></a>StreamSets</h3><p>是大数据实时采集ETL工具，可以实现不写一行代码完成数据的采集和流转。通过拖拽式的可视化界面，实现数据管道(Pipelines)的设计和定时任务调度。</p>
<p>创建一个Pipelines管道需要配置数据源(Origins)、操作(Processors)、目的地(Destinations)三部分。</p>
<h2 id="ETL加载策略"><a href="#ETL加载策略" class="headerlink" title="ETL加载策略"></a>ETL加载策略</h2><h3 id="增量"><a href="#增量" class="headerlink" title="增量"></a>增量</h3><p>有些表巨大，我们需要选择增量策略，新增delta数据需要和存量数据merge合并。</p>
<p>只有新增（full join。能拿更新表就拿更新表）</p>
<p><img src="/images/0074.png"></p>
<h3 id="新增-删除"><a href="#新增-删除" class="headerlink" title="新增+删除"></a>新增+删除</h3><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">history-<span class="keyword">table</span> <span class="keyword">Left join</span> delet-<span class="keyword">table</span> <span class="keyword">where</span> delta-<span class="keyword">table</span>.<span class="keyword">value</span> <span class="keyword">is</span> <span class="keyword">null</span> == 表a</span><br></pre></td></tr></table></figure>
<p>表a full join update-table (能拿update就拿update)</p>
<h3 id="全量"><a href="#全量" class="headerlink" title="全量"></a>全量</h3><p>每天一个全量表，也可一个hive天分区一个全量。</p>
<h3 id="流式"><a href="#流式" class="headerlink" title="流式"></a>流式</h3><p>使用kafka，消费mysql binlog日志到目标库，源表和目标库是1：1的镜像。</p>
<p>无论是全量还是增量的方式，都会浪费多余的存储或通过计算去重，得到最新的全量数据。为解决这一问题，西红柿墙裂建议kafka的数据同步方案，源表变化一条，目标表消费一条，目标表数据始终是一份最新全量数据，且为实时同步的。</p>
<p>ps.极端情况下可能会丢数，需要写几个监控脚本（详见上文数据质量部分）和补数脚本即可~</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-10-dw-etl.html" target="_blank">数据仓库【十】：ETL</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-10-dw-etl.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【十一】：OLAP</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-11-dw-olap.html</url>
    <content><![CDATA[<h2 id="OLAP和OLTP的区别"><a href="#OLAP和OLTP的区别" class="headerlink" title="OLAP和OLTP的区别"></a>OLAP和OLTP的区别</h2><table>
<thead>
<tr>
<th></th>
<th>OLTP</th>
<th>OLAP</th>
</tr>
</thead>
<tbody><tr>
<td>对象</td>
<td>业务开发人员</td>
<td>分析决策人员</td>
</tr>
<tr>
<td>功能</td>
<td>日常事务处理</td>
<td>面向分析决策</td>
</tr>
<tr>
<td>模型</td>
<td>关系模型</td>
<td>多维模型</td>
</tr>
<tr>
<td>数据量</td>
<td>几条或几十条记录</td>
<td>＞百万于万条记录</td>
</tr>
<tr>
<td>操作类型</td>
<td>增、删、查、改(CRUD)</td>
<td>查询为主</td>
</tr>
<tr>
<td>总体概括</td>
<td>联机事务处理</td>
<td>在线分析处理</td>
</tr>
</tbody></table>
<h2 id="OLAP分类"><a href="#OLAP分类" class="headerlink" title="OLAP分类"></a>OLAP分类</h2><h3 id="MOLAP：基于多维数组的存储模型"><a href="#MOLAP：基于多维数组的存储模型" class="headerlink" title="MOLAP：基于多维数组的存储模型"></a>MOLAP：基于多维数组的存储模型</h3><p>基于多维数组的存储模型，也是OLAP最初的形态，特点是对数据进行预计算，以空间换效率，明细和聚合数据都保存在cube中。但生成cube需要大量时间和空间。</p>
<h3 id="ROLAP：基于关系模型进行存储数据"><a href="#ROLAP：基于关系模型进行存储数据" class="headerlink" title="ROLAP：基于关系模型进行存储数据"></a>ROLAP：基于关系模型进行存储数据</h3><p>ROLAP，基于关系模型进行存储数据，不需要预计算，按需即时查询。明细和汇总数据都保存在关系型数据库事实表中。其特点是与事务实体对应，关系清晰；但一般需要较为复杂的数据准备。在响应前端需求时，一般较快，但取决于计算引擎能力。</p>
<h3 id="HOLAP：混合模型"><a href="#HOLAP：混合模型" class="headerlink" title="HOLAP：混合模型"></a>HOLAP：混合模型</h3><p>HOLAP，混合模型，<strong>细节数据以ROLAP存放，聚合数据以MOLAP存放</strong>。这种方式相对灵活，且更加高效。可按企业业务场景和数据粒度进行取舍，没有最好，只有最适合。</p>
<p><img src="/images/0002.jfif"></p>
<h2 id="OLAP基本操作"><a href="#OLAP基本操作" class="headerlink" title="OLAP基本操作"></a>OLAP基本操作</h2><h3 id="★钻取"><a href="#★钻取" class="headerlink" title="★钻取"></a>★钻取</h3><p>维的层次变化，从粗粒度到细粒度，汇总数据下钻到明细数据。如通过季度销售数据钻取每个月的销售数据。</p>
<h3 id="★上卷"><a href="#★上卷" class="headerlink" title="★上卷"></a>★上卷</h3><p>钻取的逆，向上钻取。从细粒度到粗粒度，细粒度数据到不同维层级的汇总。eg. 通过每个月的销售数据汇总季度、年销售数据。</p>
<h3 id="★切片"><a href="#★切片" class="headerlink" title="★切片"></a>★切片</h3><p>特定维数据（剩余维两个）。eg. 只选电子产品销售数据。</p>
<h3 id="★切块"><a href="#★切块" class="headerlink" title="★切块"></a>★切块</h3><p>维区间数据（剩余维三个）。eg. 第一季度到第二季度销售数据。</p>
<h3 id="★旋转"><a href="#★旋转" class="headerlink" title="★旋转"></a>★旋转</h3><p>维位置互换（数据行列互换），通过旋转可以得到不同视角的数据。</p>
<p><img src="/images/0075.png"></p>
<h2 id="OLAP选型"><a href="#OLAP选型" class="headerlink" title="OLAP选型"></a>OLAP选型</h2><h3 id="druid"><a href="#druid" class="headerlink" title="druid"></a>druid</h3><ul>
<li>实时查询和分析的高容错、高性能开源分布式系统，用于解决如何在大规模数据集下进行快速的、交互式的查询和分析。</li>
<li>实时的数据消费，真正做到数据摄入实时、查询结果实时。</li>
<li>扩展性强，支持 PB 级数据</li>
<li>极高的高可用保障，支持滚动升级。</li>
<li>druid属于时间存储，删除操作比较繁琐，且不支持查询条件删除数据，只能根据时间范围删除数据。Druid能接受的数据的格式相对简单，比如不能处理嵌套结构的数据。</li>
</ul>
<h3 id="kylin"><a href="#kylin" class="headerlink" title="kylin"></a>kylin</h3><ul>
<li>可扩展超快olap引擎，Hadoop/Spark上百亿数据规模</li>
<li>提供 Hadoop ANSI SQL 接口</li>
<li>交互式查询能力，用户可以与Hadoop数据进行亚秒级交互</li>
<li>百亿以上数据集构建多维立方体（MOLAP CUBE）</li>
<li>与BI工具无缝整合，如Tableau，PowerBI/Excel，MSTR，QlikSense，Hue和SuperSet</li>
</ul>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-11-dw-olap.html" target="_blank">数据仓库【十一】：OLAP</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-11-dw-olap.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>数据仓库【十二】：星型模型设计实例</title>
    <url>/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-12-dw-dim-fact-example.html</url>
    <content><![CDATA[<p>假设有一个连锁店的销售数据仓库，记录销售相关的日期、商店和产品，其星型模式如下所示：</p>
<p><img src="/images/0076.png"></p>
<p>Fact_Sales是唯一的事实表，Dim_Date、Dim_Store和Dim_Product是三个维度表。每个维度表的Id字段是它们的主键。事实表的Date_Id、Store_Id、Product_Id三个字段构成了事实表的联合主键，同时这个三个字段也是外键，分别引用对应的三个维度表的主键。Units_Sold是事实表的唯一一个非主键列，代表销售量，是用于计算和分析的度量值。维度表的非主键列表示维度的附加属性。</p>
<p>下面的查询可以回答2015年各个城市的手机销量是多少。</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> s.city <span class="keyword">as</span> city, <span class="built_in">sum</span>(f.units_sold)</span><br><span class="line">    <span class="keyword">from</span> fact_sales f</span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">join</span> dim_date d <span class="keyword">on</span> (f.date_id <span class="operator">=</span> d.id)</span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">join</span> dim_store s <span class="keyword">on</span> (f.store_id <span class="operator">=</span> s.id)</span><br><span class="line">    <span class="keyword">inner</span> <span class="keyword">join</span> dim_product p <span class="keyword">on</span> (f.product_id <span class="operator">=</span> p.id)</span><br><span class="line">    <span class="keyword">where</span> d.year <span class="operator">=</span> <span class="number">2015</span> <span class="keyword">and</span> p.product_category <span class="operator">=</span> <span class="string">&#x27;mobile&#x27;</span></span><br><span class="line">    <span class="keyword">group</span> <span class="keyword">by</span> s.city;</span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-12-dw-dim-fact-example.html" target="_blank">数据仓库【十二】：星型模型设计实例</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/2022-07-12-dw-dim-fact-example.html]]></content>
      <categories>
        <category>数据仓库</category>
      </categories>
      <tags>
        <tag>Data Warehouse</tag>
        <tag>数据仓库</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible常用命令</title>
    <url>/%E8%BF%90%E7%BB%B4/ansible-commands.html</url>
    <content><![CDATA[<h2 id="Host匹配方式"><a href="#Host匹配方式" class="headerlink" title="Host匹配方式"></a>Host匹配方式</h2><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line">web_server:!http1:&amp;http2</span><br><span class="line">http*:web_server</span><br><span class="line">web_server<span class="section">[0]</span></span><br><span class="line">web_server<span class="section">[0:3]</span></span><br><span class="line">&#x27;~(web|http)*&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="用户名密码验证方式"><a href="#用户名密码验证方式" class="headerlink" title="用户名密码验证方式"></a>用户名密码验证方式</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web_server -a <span class="string">&quot;shell命令&quot;</span> -k</span><br><span class="line">ansible web_server -a <span class="string">&quot;shell命令&quot;</span> -u username -k</span><br><span class="line">ansible web_server -a <span class="string">&quot;shell命令&quot;</span> -u username --sudo [--ask-sudo-pass]</span><br></pre></td></tr></table></figure>

<h2 id="多进程并发执行"><a href="#多进程并发执行" class="headerlink" title="多进程并发执行"></a>多进程并发执行</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web_server -a <span class="string">&quot;/sbin/reboot&quot;</span> -f 10</span><br></pre></td></tr></table></figure>

<h2 id="Ansible模块"><a href="#Ansible模块" class="headerlink" title="Ansible模块"></a>Ansible模块</h2><p>Shell操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web_server -m shell -a <span class="string">&quot;grep &#x27;/sbin/nologin&#x27; /etc/passwd | wc -l&quot;</span></span><br><span class="line">ansible web_server -m shell -a <span class="string">&#x27;echo $PATH&#x27;</span></span><br></pre></td></tr></table></figure>

<p>文件操作</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web_server -m copy -a <span class="string">&quot;src=/etc/hosts dest=/tmp/&quot;</span></span><br><span class="line">ansible web_server -m file -a <span class="string">&quot;dest=/tmp/hosts mode=600 owner=xuad group=xuad&quot;</span> <span class="comment"># chmod chown</span></span><br><span class="line">ansible web_server -m file -a <span class="string">&quot;dest=/tmp/test mode=755 owner=xuad group=xuad state=directory&quot;</span> <span class="comment"># mkdir -p /tmp/test</span></span><br><span class="line">ansible web_server -m file -a <span class="string">&quot;dest=/tmp/test.txt mode=755 owner=xuad group=xuad state=touch&quot;</span> <span class="comment"># touch /tmp/test.txt</span></span><br><span class="line">ansible web_server -m file -a <span class="string">&quot;src=/root/test.txt dest=/tmp/test.txt state=link&quot;</span> <span class="comment"># ln -s</span></span><br><span class="line">ansible web_server -m file -a <span class="string">&quot;dest=/tmp/test.txt state=absent&quot;</span> <span class="comment"># rm -rf</span></span><br></pre></td></tr></table></figure>

<p>软件安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web_server -m yum -a <span class="string">&quot;name=wget state=present&quot;</span> <span class="comment"># check if exist</span></span><br><span class="line">ansible web_server -m yum -a <span class="string">&quot;name=wget state=latest&quot;</span> <span class="comment"># upgrade</span></span><br><span class="line">ansible web_server -m yum -a <span class="string">&quot;name=wget state=removed&quot;</span> <span class="comment"># remove</span></span><br><span class="line">ansible web_server -m yum -a <span class="string">&quot;name=wget state=absent&quot;</span> <span class="comment"># check if nonexist</span></span><br><span class="line">ansible web_server -m yum -a <span class="string">&quot;name=wget state=installed&quot;</span> <span class="comment"># install</span></span><br></pre></td></tr></table></figure>

<p>用户名密码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible web_server -m user -a <span class="string">&quot;name=andy state=absent&quot;</span> <span class="comment"># remove user</span></span><br><span class="line">ansible web_server -m user -a <span class="string">&quot;name=andy state=present&quot;</span> <span class="comment"># create on absence</span></span><br><span class="line">ansible web_server -m user -a <span class="string">&#x27;name=andy password=&quot;&amp;lt;crypted password here&amp;gt;&quot;&#x27;</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/ansible-commands.html" target="_blank">Ansible常用命令</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E8%BF%90%E7%BB%B4/ansible-commands.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Controlling Nginx with Supervisor</title>
    <url>/linux/control-nginx-with-supervisor.html</url>
    <content><![CDATA[<h2 id="Important"><a href="#Important" class="headerlink" title="Important"></a>Important</h2><p>Supervisor uses <code>daemon off;</code> to start Nginx. The <code>daemon off;</code> directive tells Nginx to stay in the foreground. The <code>sudo service nginx stop/start/restart</code> commands won’t work. For more information read <a href="https://stackoverflow.com/questions/25970711/what-is-the-difference-between-nginx-daemon-on-off-option/34821579#34821579">Stack Overflow</a> answer.</p>
<h2 id="Current-nginx-process"><a href="#Current-nginx-process" class="headerlink" title="Current nginx process"></a>Current nginx process</h2><p>As you can see below, Nginx is running in “daemon on” mode.</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">root</span>@us:~# ps aux | grep nginx</span><br><span class="line"><span class="attribute">root</span>       <span class="number">12527</span>  <span class="number">0</span>.<span class="number">0</span>  <span class="number">0</span>.<span class="number">2</span> <span class="number">132576</span>  <span class="number">1064</span> ?        Ss   <span class="number">09</span>:<span class="number">52</span>   <span class="number">0</span>:<span class="number">00</span> nginx: master process /usr/sbin/nginx -g daemon <span class="literal">on</span>; master_process <span class="literal">on</span>;</span><br><span class="line"><span class="attribute">www</span>-data   <span class="number">12529</span>  <span class="number">0</span>.<span class="number">2</span>  <span class="number">1</span>.<span class="number">6</span> <span class="number">134176</span>  <span class="number">8092</span> ?        S    <span class="number">09</span>:<span class="number">52</span>   <span class="number">0</span>:<span class="number">07</span> nginx: worker process</span><br><span class="line"><span class="attribute">www</span>-data   <span class="number">12530</span>  <span class="number">0</span>.<span class="number">0</span>  <span class="number">0</span>.<span class="number">7</span> <span class="number">132808</span>  <span class="number">3800</span> ?        S    <span class="number">09</span>:<span class="number">52</span>   <span class="number">0</span>:<span class="number">00</span> nginx: cache manager process</span><br><span class="line"><span class="attribute">root</span>       <span class="number">13154</span>  <span class="number">0</span>.<span class="number">0</span>  <span class="number">0</span>.<span class="number">1</span>   <span class="number">8900</span>   <span class="number">660</span> pts/<span class="number">0</span>    S+   <span class="number">10</span>:<span class="number">38</span>   <span class="number">0</span>:<span class="number">00</span> grep --color=auto nginx</span><br></pre></td></tr></table></figure>

<h2 id="Install-amp-Setup-supervisor"><a href="#Install-amp-Setup-supervisor" class="headerlink" title="Install &amp; Setup supervisor"></a>Install &amp; Setup supervisor</h2><h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install supervisor</span><br></pre></td></tr></table></figure>

<h3 id="Setup-configuration-for-Nignx"><a href="#Setup-configuration-for-Nignx" class="headerlink" title="Setup configuration for Nignx"></a>Setup configuration for Nignx</h3><p>Add <code>nginx.conf</code> file: <code>/etc/supervisor/conf.d/nginx.conf</code></p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[program:nginx]</span></span><br><span class="line"><span class="attr">command</span>=/usr/sbin/nginx -g <span class="string">&quot;daemon off;&quot;</span></span><br><span class="line"><span class="attr">autostart</span>=<span class="literal">true</span></span><br><span class="line"><span class="attr">autorestart</span>=<span class="literal">true</span></span><br><span class="line"><span class="attr">startretries</span>=<span class="number">5</span></span><br><span class="line"><span class="attr">numprocs</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">startsecs</span>=<span class="number">0</span></span><br><span class="line"><span class="attr">process_name</span>=%(program_name)s_%(process_num)<span class="number">02</span>d</span><br><span class="line"><span class="attr">stderr_logfile</span>=/var/log/supervisor/%(program_name)s_stderr.log</span><br><span class="line"><span class="attr">stderr_logfile_maxbytes</span>=<span class="number">10</span>MB</span><br><span class="line"><span class="attr">stdout_logfile</span>=/var/log/supervisor/%(program_name)s_stdout.log</span><br><span class="line"><span class="attr">stdout_logfile_maxbytes</span>=<span class="number">10</span>MB</span><br></pre></td></tr></table></figure>

<p>Let supervisor know about new config.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo supervisorctl reread</span><br><span class="line">nginx: available</span><br></pre></td></tr></table></figure>

<p>Stop and disable the Nginx service</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo systemctl stop nginx</span><br><span class="line">sudo systemctl <span class="built_in">disable</span> nginx</span><br></pre></td></tr></table></figure>

<p>Let supervisor start nginx service.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo supervisorctl update</span><br><span class="line">nginx: added process group</span><br></pre></td></tr></table></figure>

<p>Verify if supervisor started nginx service.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo supervisorctl</span></span><br><span class="line">nginx:nginx_00                   RUNNING   pid 18429, uptime 0:01:47</span><br><span class="line"><span class="meta prompt_">supervisor&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="Check"><a href="#Check" class="headerlink" title="Check"></a>Check</h2><p>As you can see below, Nginx is running in “daemon off” mode.</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">root</span>@us:~# ps aux | grep nginx</span><br><span class="line"><span class="attribute">root</span>         <span class="number">692</span>  <span class="number">0</span>.<span class="number">3</span>  <span class="number">1</span>.<span class="number">5</span> <span class="number">132576</span>  <span class="number">7768</span> ?        S    <span class="number">10</span>:<span class="number">56</span>   <span class="number">0</span>:<span class="number">00</span> nginx: master process /usr/sbin/nginx -g daemon <span class="literal">off</span>;</span><br><span class="line"><span class="attribute">www</span>-data     <span class="number">703</span>  <span class="number">1</span>.<span class="number">1</span>  <span class="number">1</span>.<span class="number">4</span> <span class="number">133140</span>  <span class="number">6884</span> ?        S    <span class="number">10</span>:<span class="number">56</span>   <span class="number">0</span>:<span class="number">00</span> nginx: worker process</span><br><span class="line"><span class="attribute">www</span>-data     <span class="number">704</span>  <span class="number">0</span>.<span class="number">0</span>  <span class="number">0</span>.<span class="number">7</span> <span class="number">132808</span>  <span class="number">3620</span> ?        S    <span class="number">10</span>:<span class="number">56</span>   <span class="number">0</span>:<span class="number">00</span> nginx: cache manager process</span><br><span class="line"><span class="attribute">www</span>-data     <span class="number">708</span>  <span class="number">0</span>.<span class="number">0</span>  <span class="number">0</span>.<span class="number">7</span> <span class="number">132808</span>  <span class="number">3620</span> ?        S    <span class="number">10</span>:<span class="number">56</span>   <span class="number">0</span>:<span class="number">00</span> nginx: cache loader process</span><br><span class="line"><span class="attribute">root</span>         <span class="number">800</span>  <span class="number">0</span>.<span class="number">0</span>  <span class="number">0</span>.<span class="number">1</span>   <span class="number">8900</span>   <span class="number">736</span> pts/<span class="number">0</span>    S+   <span class="number">10</span>:<span class="number">57</span>   <span class="number">0</span>:<span class="number">00</span> grep --color=auto nginx</span><br></pre></td></tr></table></figure>

<h2 id="Restart-nginx-with-supervisor"><a href="#Restart-nginx-with-supervisor" class="headerlink" title="Restart nginx with supervisor"></a>Restart nginx with supervisor</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">sudo supervisorctl</span></span><br><span class="line">nginx:nginx_00                   RUNNING   pid 18429, uptime 0:01:47</span><br><span class="line"><span class="meta prompt_">supervisor&gt; </span><span class="language-bash">restart nginx:nginx_00</span></span><br></pre></td></tr></table></figure>


<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/control-nginx-with-supervisor.html" target="_blank">Controlling Nginx with Supervisor</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/control-nginx-with-supervisor.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Nginx</tag>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中的DelayQueue</title>
    <url>/java/delayqueue-in-java.html</url>
    <content><![CDATA[<p><strong>面试官：好久不见啊，上次我们聊完了<code>PriorityBlockingQueue</code>，今天我们再来聊聊和它相关的<code>DelayQueue</code>吧？</strong></p>
<p>Hydra：就知道你前面肯定给我挖了坑，<code>DelayQueue</code>也是一个无界阻塞队列，但是和之前我们聊的其他队列不同，不是所有类型的元素都能够放进去，只有实现了<code>Delayed</code>接口的对象才能放进队列。<code>Delayed</code>对象具有一个过期时间，只有在到达这个到期时间后才能从队列中取出。</p>
<p><strong>面试官：有点意思，那么它有什么使用场景呢？</strong></p>
<p>Hydra：不得不说，由于<code>DelayQueue</code>的精妙设计，使用场景还是蛮多的。例如在电商系统中，如果有一笔订单在下单30分钟内没有完成支付，那么就需要自动取消这笔订单。还有，如果我们缓存了一些数据，并希望这些缓存在一定时间后失效的话，也可以使用延迟队列将它从缓存中删除。</p>
<p>以电商系统为例，可以简单看一下这个流程：</p>
<p><img src="/images/0006.jpeg"></p>
<p><strong>面试官：看起来和任务调度有点类似啊，它们之间有什么区别吗？</strong></p>
<p>Hydra：任务调度更多的偏向于定时的特性，是在指定的<em>时间点</em>或<em>时间间隔</em>执行特定的任务，而延迟队列更多偏向于在指定的延迟时间后执行任务。相对任务调度来说，<strong>上面举的例子中的延迟队列场景都具有高频率的特性，使用定时任务来实现它们的话会显得有些过于笨重了</strong>。</p>
<p><strong>面试官：好了，你也白话了半天了，能动手就别吵吵，还是先给我写个例子吧。</strong></p>
<p>Hydra：好嘞，前面说过存入队列的元素要实现Delayed接口，所以我们先定义这么一个类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Task</span> <span class="keyword">implements</span> <span class="title class_">Delayed</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> delay,expire;</span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Task</span><span class="params">(String name, <span class="type">long</span> delay)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.name = name;</span><br><span class="line">        <span class="built_in">this</span>.delay = delay;</span><br><span class="line">        <span class="built_in">this</span>.expire=System.currentTimeMillis()+delay;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDelay</span><span class="params">(TimeUnit unit)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> unit.convert(<span class="built_in">this</span>.expire - System.currentTimeMillis(), TimeUnit.MILLISECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(Delayed o)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="type">int</span>)(<span class="built_in">this</span>.getDelay(TimeUnit.MILLISECONDS) - o.getDelay(TimeUnit.MILLISECONDS));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实现了<code>Delayed</code>接口的类必须要实现下面的两个方法：</p>
<ul>
<li><code>getDelay</code>方法用于计算对象的剩余延迟时间，判断对象是否到期，计算方法一般使用过期时间减当前时间。如果是0或负数，表示延迟时间已经用完，否则说明还没有到期</li>
<li><code>compareTo</code>方法用于延迟队列的内部排序比较，这里使用当前对象的延迟时间减去被比较对象的延迟时间</li>
</ul>
<p>在完成队列中元素的定义后，向队列中加入5个不同延迟时间的对象，并等待从队列中取出：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">delay</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    DelayQueue&lt;Task&gt; queue=<span class="keyword">new</span> <span class="title class_">DelayQueue</span>&lt;&gt;();</span><br><span class="line">    queue.offer(<span class="keyword">new</span> <span class="title class_">Task</span>(<span class="string">&quot;task1&quot;</span>,<span class="number">5000</span>));</span><br><span class="line">    queue.offer(<span class="keyword">new</span> <span class="title class_">Task</span>(<span class="string">&quot;task2&quot;</span>,<span class="number">1000</span>));</span><br><span class="line">    queue.offer(<span class="keyword">new</span> <span class="title class_">Task</span>(<span class="string">&quot;task3&quot;</span>,<span class="number">6000</span>));</span><br><span class="line">    queue.offer(<span class="keyword">new</span> <span class="title class_">Task</span>(<span class="string">&quot;task4&quot;</span>,<span class="number">100</span>));</span><br><span class="line">    queue.offer(<span class="keyword">new</span> <span class="title class_">Task</span>(<span class="string">&quot;task5&quot;</span>,<span class="number">3000</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">        <span class="type">Task</span> <span class="variable">task</span> <span class="operator">=</span> queue.take();</span><br><span class="line">        System.out.println(task);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行结果如下，可以看到按照延迟时间从短到长的顺序，元素被依次从队列中取出。</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">Task&#123;<span class="attribute">name</span>=<span class="string">&#x27;task4&#x27;</span>, <span class="attribute">delay</span>=100&#125;</span><br><span class="line">Task&#123;<span class="attribute">name</span>=<span class="string">&#x27;task2&#x27;</span>, <span class="attribute">delay</span>=1000&#125;</span><br><span class="line">Task&#123;<span class="attribute">name</span>=<span class="string">&#x27;task5&#x27;</span>, <span class="attribute">delay</span>=3000&#125;</span><br><span class="line">Task&#123;<span class="attribute">name</span>=<span class="string">&#x27;task1&#x27;</span>, <span class="attribute">delay</span>=5000&#125;</span><br><span class="line">Task&#123;<span class="attribute">name</span>=<span class="string">&#x27;task3&#x27;</span>, <span class="attribute">delay</span>=6000&#125;</span><br></pre></td></tr></table></figure>

<p><strong>面试官：看起来应用还是挺简单的，但今天也不能这么草草了事吧，还是说说原理吧。</strong></p>
<p>Hydra：开始的时候你自己不都说了吗，今天咱们聊的<code>DelayQueue</code>和前几天聊过的<code>PriorityBlockingQueue</code>多少有点关系。<code>DelayQueue</code>的底层是<code>PriorityQueue</code>，而<code>PriorityBlockingQueue</code>和它的差别也没有多少，只是在<code>PriorityQueue</code>的基础上加上锁和条件等待，入队和出队用的都是二叉堆的那一套逻辑。底层使用的有这些：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">transient</span> <span class="type">ReentrantLock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantLock</span>();</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> PriorityQueue&lt;E&gt; q = <span class="keyword">new</span> <span class="title class_">PriorityQueue</span>&lt;E&gt;();</span><br><span class="line"><span class="keyword">private</span> <span class="type">Thread</span> <span class="variable">leader</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">Condition</span> <span class="variable">available</span> <span class="operator">=</span> lock.newCondition();</span><br></pre></td></tr></table></figure>

<p><strong>面试官：你这样也有点太糊弄我了吧，这就把我敷衍过去了？</strong></p>
<p>Hydra：还没完呢，还是先看入队的offer方法，它的源码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">offer</span><span class="params">(E e)</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">ReentrantLock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="built_in">this</span>.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        q.offer(e);</span><br><span class="line">        <span class="keyword">if</span> (q.peek() == e) &#123;</span><br><span class="line">            leader = <span class="literal">null</span>;</span><br><span class="line">            available.signal();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>DelayQueue</code>每次向优先级队列<code>PriorityQueue</code>中添加元素时，会以元素的剩余延迟时间<code>delay</code>作为排序的因素，来实现使最先过期的元素排在队首，以此达到在之后从队列中取出的元素都是先取出最先到达过期的元素。</p>
<p>二叉堆的构造过程我们上次讲过了，就不再重复了。向队列中添加完5个元素后，二叉堆和队列中的结构是这样的：</p>
<p><img src="/images/0021.png"></p>
<p>当每个元素在按照二叉堆的顺序插入队列后，会查看堆顶元素是否刚插入的元素，如果是的话那么设置<code>leader</code>线程为空，并唤醒在<code>available</code>上阻塞的线程。</p>
<p>这里先简单的介绍一下<code>leader</code>线程的作用，<code>leader</code>是等待获取元素的线程，它的作用主要是用于减少不必要的等待，具体的使用在后面介绍<code>take</code>方法的时候我们细说。</p>
<p><strong>面试官：也别一会了，趁热打铁直接讲队列的出队方法吧。</strong></p>
<p>Hydra：这还真没法着急，在看阻塞方法take前还得先看看非阻塞的poll方法是如何实现的：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> E <span class="title function_">poll</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">ReentrantLock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="built_in">this</span>.lock;</span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">E</span> <span class="variable">first</span> <span class="operator">=</span> q.peek();</span><br><span class="line">        <span class="keyword">if</span> (first == <span class="literal">null</span> || first.getDelay(NANOSECONDS) &gt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> q.poll();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码非常短，理解起来非常简单，在加锁后首先检查堆顶元素，如果堆顶元素为空或没有到期，那么直接返回空，否则返回堆顶元素，然后解锁。</p>
<p><strong>面试官：好了，铺垫完了吧，该讲阻塞方法的过程了吧？</strong></p>
<p>Hydra：阻塞的take方法理解起来会比上面稍微困难一点，我们还是直接看它的源码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> E <span class="title function_">take</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">ReentrantLock</span> <span class="variable">lock</span> <span class="operator">=</span> <span class="built_in">this</span>.lock;</span><br><span class="line">    lock.lockInterruptibly();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">            <span class="type">E</span> <span class="variable">first</span> <span class="operator">=</span> q.peek();</span><br><span class="line">            <span class="keyword">if</span> (first == <span class="literal">null</span>)</span><br><span class="line">                available.await();</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="type">long</span> <span class="variable">delay</span> <span class="operator">=</span> first.getDelay(NANOSECONDS);</span><br><span class="line">                <span class="keyword">if</span> (delay &lt;= <span class="number">0</span>)</span><br><span class="line">                    <span class="keyword">return</span> q.poll();</span><br><span class="line">                first = <span class="literal">null</span>; <span class="comment">// don&#x27;t retain ref while waiting</span></span><br><span class="line">                <span class="keyword">if</span> (leader != <span class="literal">null</span>)</span><br><span class="line">                    available.await();</span><br><span class="line">                <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="type">Thread</span> <span class="variable">thisThread</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">                    leader = thisThread;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        available.awaitNanos(delay);</span><br><span class="line">                    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                        <span class="keyword">if</span> (leader == thisThread)</span><br><span class="line">                            leader = <span class="literal">null</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (leader == <span class="literal">null</span> &amp;&amp; q.peek() != <span class="literal">null</span>)</span><br><span class="line">            available.signal();</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>阻塞过程中分支条件比较复杂，我们一个一个看：</p>
<ol>
<li>首先获取堆顶元素，如果为空，那么说明队列中还没有元素，让当前线程在<code>available</code>上进行阻塞等待</li>
<li>如果堆顶元素不为空，那么查看它的过期时间，如果已到期，那么直接弹出堆顶元素</li>
<li>如果堆顶元素还没有到期，那么查看<code>leader</code>线程是否为空，如果<code>leader</code>线程不为空的话，表示已经有其他线程在等待获取队列的元素，直接阻塞当前线程。</li>
<li>如果<code>leader</code>为空，那么把当前线程赋值给它，并调用<code>awaitNanos</code>方法，在阻塞<code>delay</code>时间后自动醒来。唤醒后，如果<code>leader</code>还是当前线程那么把它置为空，重新进入循环，再次判断堆顶元素是否到期。</li>
<li>当有队列中的元素完成出队后，如果<code>leader</code>线程为空，并且堆中还有元素，就唤醒阻塞在<code>available</code>上的其他线程，并释放持有的锁。</li>
</ol>
<p><strong>面试官：我注意到一个问题，在上面的代码中，为什么要设置first = null呢？</strong></p>
<p>Hydra：假设有多个线程在执行<code>take</code>方法，当第一个线程进入时，堆顶元素还没有到期，那么会将<code>leader</code>指向自己，然后阻塞自己一段时间。如果在这期间有其他线程到达，会因为<code>leader</code>不为空阻塞自己。</p>
<p>当第一个线程阻塞结束后，如果将堆顶元素弹出成功，那么<code>first</code>指向的元素应该被gc回收掉。但是如果还被其他线程持有的话，它就不会被回收掉，所以将<code>first</code>置为空可以帮助完成垃圾回收。</p>
<p><strong>面试官：我突然有一个发散性的疑问，定时任务线程池ScheduledThreadPoolExecutor，底层使用的也是DelayQueue吗？</strong></p>
<p>Hydra：问题很不错，但很遗憾并不是，<code>ScheduledThreadPoolExecutor</code>在类中自己定义了一个<code>DelayedWorkQueue</code>内部类，并没有直接使用<code>DelayQueue</code>。不过如果你看一下源码，就会看到它们实现的逻辑基本一致，同样是基于二叉堆的上浮、下沉、扩容，也同样基于<code>leader</code>、锁、条件等待等操作，只不过自己用数组又实现了一遍而已。说白了，看看两个类的作者，都是<code>Doug Lea</code>大神，所以差异根本没有多大。</p>
<p><strong>面试官：好了，今天先到这吧，能最后再总结一下吗？</strong></p>
<p>Hydra：<code>DelayQueue</code>整体理解起来也没有什么困难的点，难的地方在前面聊优先级队列的时候基本已经扫清了，新加的东西也就是一个对于<code>leader</code>线程的操作，使用了<code>leader</code>线程来减少不必要的线程等待时间。</p>
<p><strong>面试官：今天的面试有点短啊，总是有点意犹未尽的感觉，看来下次得给你加点料了。</strong></p>
<p>Hydra：…</p>
<hr>
<blockquote>
<p>原文链接：<a href="https://mp.weixin.qq.com/s/XOToC0CUI4H6AFTSwKZMRw">https://mp.weixin.qq.com/s/XOToC0CUI4H6AFTSwKZMRw</a></p>
</blockquote>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/java/delayqueue-in-java.html" target="_blank">Java中的DelayQueue</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/java/delayqueue-in-java.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>DelayQueue</tag>
      </tags>
  </entry>
  <entry>
    <title>自动为Hexo博客添加文章链接</title>
    <url>/hexo/hexo-add-post-links.html</url>
    <content><![CDATA[<p>文章链接是写博客时一个非常常用的东西，因为如果每次写博客都需要在文章前后加上一个几乎格式一模一样的东西，还是很烦人的，特别如果你突然决定改变文章的永久链接，那么就更加烦人了，因为默认在Hexo里面，我们需要一篇文章一篇文章的把所有的文章链接改了（虽然这种情况我们需要尽量避免）。</p>
<p>这里我们介绍一个插件，可以自动为博客添加文章链接：</p>
<blockquote>
<p>hexo-tag-post-link</p>
</blockquote>
<p>项目地址：<a href="https://github.com/r12f/hexo-tag-post-link">https://github.com/r12f/hexo-tag-post-link</a></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>和其他的hexo插件一样，hexo-tag-post-link安装起来十分简单，只需要在博客目录下执行如下命令即可：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-tag-post-link --save</span><br></pre></td></tr></table></figure>

<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><h3 id="配置模板"><a href="#配置模板" class="headerlink" title="配置模板"></a>配置模板</h3><h4 id="添加模板文件：post-link-yml"><a href="#添加模板文件：post-link-yml" class="headerlink" title="添加模板文件：post_link.yml"></a>添加模板文件：post_link.yml</h4><ol>
<li>首先我们需要在<code>source</code>目录下创建一个<code>_data</code>目录，如果没有的话。<code>source/_data</code>这个目录是Hexo的数据目录，用来存放一些公用的全局数据，所以的模板文件也放在这里。</li>
<li>现在在<code>_data</code>目录下创建一个名为<code>post_link.yml</code>的文件，这个文件就是我们的配置文件了。</li>
<li>现在我们可以来添加模板了！模板的格式非常简单，如下：</li>
</ol>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">format</span></span><br></pre></td></tr></table></figure>

<p>比如我的博客使用的配置如下，而最后的效果就如本文最上方显示的那样。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">footer: <span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">hr</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>转载请注明出处：<span class="tag">&lt;/<span class="name">b</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;&lt;%= post_permalink %&gt;&quot;</span> <span class="attr">target</span>=<span class="string">&quot;_blank&quot;</span>&gt;</span>&lt;%= post_title %&gt;<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;<span class="name">br</span>&gt;</span><span class="tag">&lt;<span class="name">b</span>&gt;</span>原文地址：<span class="tag">&lt;/<span class="name">b</span>&gt;</span>&lt;%= post_permalink %&gt;</span><br></pre></td></tr></table></figure>

<h4 id="可用模板变量"><a href="#可用模板变量" class="headerlink" title="可用模板变量"></a>可用模板变量</h4><ul>
<li>site_title</li>
<li>site_subtitle</li>
<li>site_description</li>
<li>site_author</li>
<li>site_url</li>
<li>post_title</li>
<li>post_slug</li>
<li>post_created</li>
<li>post_created_date</li>
<li>post_created_time</li>
<li>post_updated</li>
<li>post_updated_date</li>
<li>post_updated_time</li>
<li>post_relative_url</li>
<li>post_permalink</li>
</ul>
<h3 id="增加全局配置"><a href="#增加全局配置" class="headerlink" title="增加全局配置"></a>增加全局配置</h3><p>在配置文件_config.yml中添加如下配置：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">post_link:</span></span><br><span class="line">  <span class="comment">#insert_before_post: header</span></span><br><span class="line">  <span class="attr">insert_after_post:</span> <span class="string">footer</span></span><br></pre></td></tr></table></figure>

<p>以上配置完成，即可在文章末尾看到文章声明和原文地址。</p>
<h2 id="更多使用方法"><a href="#更多使用方法" class="headerlink" title="更多使用方法"></a>更多使用方法</h2><p>可参考Github中的项目说明：<a href="https://github.com/r12f/hexo-tag-post-link">https://github.com/r12f/hexo-tag-post-link</a></p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/hexo/hexo-add-post-links.html" target="_blank">自动为Hexo博客添加文章链接</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/hexo/hexo-add-post-links.html]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Post Links</tag>
        <tag>Github Pages</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Let&#39;s Encrypt免费证书让你的网站SSL化</title>
    <url>/nginx/letsencrypt-for-free-ssl-cert.html</url>
    <content><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p><a href="https://letsencrypt.org/">Let’s Encrypt</a>是一个免费颁发SSL证书的非盈利组织，其颁布的证书已被Chrome等主流浏览器认可。GitHub Pages站点默认使用的SSL证书也是<a href="https://letsencrypt.org/">Let’s Encrypt</a>提供的。</p>
<p>此文主要解决：</p>
<ol>
<li>如何使用<a href="https://letsencrypt.org/">Let’s Encrypt</a>为我们的域名颁发证书</li>
<li>颁发的证书如何自动更新有效时间</li>
</ol>
<h2 id="About-certbot"><a href="#About-certbot" class="headerlink" title="About certbot"></a>About certbot</h2><p>本文使用Certbot完成HTTPS的自动颁发和续期。其<a href="https://certbot.eff.org/about/">官方介绍</a>如下：</p>
<blockquote>
<p>Certbot is a free, open source software tool for automatically using Let’s Encrypt certificates on manually-administrated websites to enable HTTPS.<br>Certbot is made by the Electronic Frontier Foundation (EFF), a 501(c)3 nonprofit based in San Francisco, CA, that defends digital privacy, free speech, and innovation.  </p>
</blockquote>
<h2 id="使用环境"><a href="#使用环境" class="headerlink" title="使用环境"></a>使用环境</h2><ul>
<li>Web服务器：Nginx 1.18.0</li>
<li>宿主服务器：Ubuntu 20.04</li>
</ul>
<p>说明：如果不是使用的以上两个服务器或版本，可使用Certbot官网选择对应服务器和版本。</p>
<h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><h3 id="SSH-into-the-server"><a href="#SSH-into-the-server" class="headerlink" title="SSH into the server"></a>SSH into the server</h3><p>SSH into the server running your HTTP website as a user with sudo privileges.</p>
<h3 id="Install-snapd"><a href="#Install-snapd" class="headerlink" title="Install snapd"></a>Install snapd</h3><p>You’ll need to install snapd and make sure you follow any instructions to enable classic snap support.<br>Follow these <a href="https://snapcraft.io/docs/installing-snapd">instructions on snapcraft’s site to install snapd</a>.</p>
<blockquote>
<p>If you’re running Ubuntu 16.04 LTS (Xenial Xerus) or later, including Ubuntu 18.04 LTS (Bionic Beaver), Ubuntu 18.10 (Cosmic Cuttlefish) and Ubuntu 19.10 (Eoan Ermine), you don’t need to do anything. Snap is already installed and ready to go.</p>
</blockquote>
<h3 id="Ensure-that-your-version-of-snapd-is-up-to-date"><a href="#Ensure-that-your-version-of-snapd-is-up-to-date" class="headerlink" title="Ensure that your version of snapd is up to date"></a>Ensure that your version of snapd is up to date</h3><p>Execute the following instructions on the command line on the machine to ensure that you have the latest version of snapd.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo snap install core; sudo snap refresh core</span><br></pre></td></tr></table></figure>

<h3 id="Remove-certbot-auto-and-any-Certbot-OS-packages"><a href="#Remove-certbot-auto-and-any-Certbot-OS-packages" class="headerlink" title="Remove certbot-auto and any Certbot OS packages"></a>Remove certbot-auto and any Certbot OS packages</h3><p>If you have any Certbot packages installed using an OS package manager like apt, dnf, or yum, you should remove them before installing the Certbot snap to ensure that when you run the command certbot the snap is used rather than the installation from your OS package manager.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get remove certbot, sudo dnf remove certbot</span><br></pre></td></tr></table></figure>

<p>If you previously used Certbot through the certbot-auto script, you should also remove its installation by following the instructions <a href="https://certbot.eff.org/docs/uninstall.html">here</a>.</p>
<h3 id="Install-Certbot"><a href="#Install-Certbot" class="headerlink" title="Install Certbot"></a>Install Certbot</h3><p>Run this command on the command line on the machine to install Certbot.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo snap install --classic certbot</span><br></pre></td></tr></table></figure>

<h3 id="Prepare-the-Certbot-command"><a href="#Prepare-the-Certbot-command" class="headerlink" title="Prepare the Certbot command"></a>Prepare the Certbot command</h3><p>Execute the following instruction on the command line on the machine to ensure that the <code>certbot</code> command can be run.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo ln -s /snap/bin/certbot /usr/bin/certbot</span><br></pre></td></tr></table></figure>

<h3 id="Get-certificates-and-or-install-certificates"><a href="#Get-certificates-and-or-install-certificates" class="headerlink" title="Get certificates and/or install certificates"></a>Get certificates and/or install certificates</h3><h4 id="Get-and-Install"><a href="#Get-and-Install" class="headerlink" title="Get and Install"></a>Get and Install</h4><p>Run this command to get a certificate and have Certbot edit your Nginx configuration automatically to serve it, turning on HTTPS access in a single step.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo certbot --nginx</span><br></pre></td></tr></table></figure>

<h4 id="Just-get-a-certificate"><a href="#Just-get-a-certificate" class="headerlink" title="Just get a certificate"></a>Just get a certificate</h4><p>If you’re feeling more conservative and would like to make the changes to your Nginx configuration by hand, run this command.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo certbot certonly --nginx</span><br></pre></td></tr></table></figure>

<h3 id="Test-automatic-renewal"><a href="#Test-automatic-renewal" class="headerlink" title="Test automatic renewal"></a>Test automatic renewal</h3><p>The Certbot packages on your system come with a cron job or systemd timer that will renew your certificates automatically before they expire. You will not need to run Certbot again, unless you change your configuration. You can test automatic renewal for your certificates by running this command:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo certbot renew --dry-run</span><br></pre></td></tr></table></figure>

<p>The command to renew certbot is installed in one of the following locations:</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/etc/</span>crontab/</span><br><span class="line"><span class="regexp">/etc/</span>cron.*/*</span><br><span class="line">systemctl list-timers</span><br></pre></td></tr></table></figure>

<p>My timers would be:</p>
<figure class="highlight elixir"><table><tr><td class="code"><pre><span class="line">root<span class="variable">@us</span><span class="symbol">:/var/log/nginx</span><span class="comment"># systemctl list-timers</span></span><br><span class="line"><span class="title class_">NEXT</span>                        <span class="title class_">LEFT</span>          <span class="title class_">LAST</span>                        <span class="title class_">PASSED</span>      <span class="title class_">UNIT</span>                         <span class="title class_">ACTIVATES</span></span><br><span class="line"><span class="title class_">Sun</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-09</span> <span class="number">13</span><span class="symbol">:</span><span class="number">20</span><span class="symbol">:</span><span class="number">00</span> <span class="title class_">CST</span> <span class="number">1</span>h <span class="number">57</span>min left <span class="title class_">Sun</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-09</span> <span class="number">01</span><span class="symbol">:</span><span class="number">22</span><span class="symbol">:</span><span class="number">05</span> <span class="title class_">CST</span> <span class="number">10</span>h ago     snap.certbot.renew.timer     snap.certbot.renew.service</span><br><span class="line">...</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="Confirm-that-Certbot-worked"><a href="#Confirm-that-Certbot-worked" class="headerlink" title="Confirm that Certbot worked"></a>Confirm that Certbot worked</h3><p>To confirm that your site is set up properly, visit <a href="https://yourwebsite.com/">https://yourwebsite.com/</a> in your browser and look for the lock icon in the URL bar.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/nginx/letsencrypt-for-free-ssl-cert.html" target="_blank">使用Let's Encrypt免费证书让你的网站SSL化</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/nginx/letsencrypt-for-free-ssl-cert.html]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Github Pages</tag>
        <tag>Ubuntu 20.04</tag>
        <tag>Nignx</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux find命令高阶用法</title>
    <url>/linux/linux-command-find-howtos.html</url>
    <content><![CDATA[<blockquote>
<p>linux 下一切皆文件。</p>
</blockquote>
<p>Find命令是程序员每天都会使用的命令，是一个无处不在是命令，是linux中最有用的命令之一。你可以使用它在任意一个目录（及子目录）中搜索文件，你也可以定义一些特定的条件，如按文件名、文件类型、用户甚至是时间节点去查找文件。</p>
<p>毋庸置疑的是在强大的功能背后，它的使用对比其他的命令会复杂的多，比较难。下面就跟大家分享几个 find 命令的简单却又高级的用法。</p>
<h2 id="根据访问-修改-更改时间查找文件"><a href="#根据访问-修改-更改时间查找文件" class="headerlink" title="根据访问/修改/更改时间查找文件"></a>根据访问/修改/更改时间查找文件</h2><p>如果服务器被入侵，你可以利用find 查询到近期被访问、修改、更改的文件</p>
<blockquote>
<p>备注：min=分钟 time=天 修改注重于对内容的修改，更改注重于对权限的更改</p>
</blockquote>
<p>查找1个小时内被访问过的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -amin -60</span><br></pre></td></tr></table></figure>

<p>查找1天内被访问过的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find / -atime -1</span><br></pre></td></tr></table></figure>

<p>查找在1个小时内被修改的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -mmin -60</span><br></pre></td></tr></table></figure>

<p>查找在1天内被修改的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find / -mtime -1</span><br></pre></td></tr></table></figure>

<p>查找1小时内状态被改变的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -cmin -60</span><br></pre></td></tr></table></figure>

<p>查找1天内状态被改变的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find / -ctime -1</span><br></pre></td></tr></table></figure>

<h2 id="查找比某文件新或某文件旧的文件"><a href="#查找比某文件新或某文件旧的文件" class="headerlink" title="查找比某文件新或某文件旧的文件"></a>查找比某文件新或某文件旧的文件</h2><p>环境上日志文件数不胜数，想删除某个时间之前的文件，该怎么处理？</p>
<blockquote>
<p>备注：newer（修改时间）、anewer（访问时间）、ctime（修改时间，包括权限属性的修改）<br>列出比1.log更旧的文件</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find ./ ! -newer 1.log |xargs ls -al</span><br></pre></td></tr></table></figure>

<p>列出比1.log更新的文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find ./ -newer 1.log |xargs ls -al</span><br></pre></td></tr></table></figure>

<h2 id="多条件组合查找"><a href="#多条件组合查找" class="headerlink" title="多条件组合查找"></a>多条件组合查找</h2><p>有时我们要查找的文件并不止一个类目这个时候我们可以使用多条件组合的方式去查找，常用的条件组合参数有<code>-a(and)</code>,<code>-o(or)</code>,<code>!(not)</code>。</p>
<p>查找普通文档和符号链接文档：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find ./ -type f -o -type l</span><br></pre></td></tr></table></figure>

<p>查找名称为skill的符号链接文档</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find ./ -name &quot;*skill&quot; -a -type l</span><br></pre></td></tr></table></figure>

<p>查找log文档以外的其他文档：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find ./ ! -name &quot;*.log&quot;</span><br></pre></td></tr></table></figure>

<h2 id="对所查找到的文件进行操作"><a href="#对所查找到的文件进行操作" class="headerlink" title="对所查找到的文件进行操作"></a>对所查找到的文件进行操作</h2><p>文件我们已经查找到了，如何对它们做些什么呢？</p>
<p>对于以查找到的文件，进行操作万能公式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*something*&quot; -exec action &#123;&#125; somearguments \\;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>命令解释：</p>
<ul>
<li>find . -name “something” 找出所有名字包含something的文件;</li>
<li>-exec 执行后面的命令， action 任意命令名; {}是find的结果集合</li>
<li>somearguments ， 命令需要的参数，就是例子中的-r; \; 结束命令</li>
</ul>
</blockquote>
<p><strong>举例:</strong></p>
<p>利用Find命令对文件进行备份</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*something*&quot; –exec cp &#123;&#125; /backup/&#123;&#125;.backup /;</span><br></pre></td></tr></table></figure>

<p>利用Find命令对文件进行删除</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . -name &quot;*something*&quot; –exec rm –I &#123;&#125; /;</span><br></pre></td></tr></table></figure>

<p>下面列一些比较常用的：</p>
<ul>
<li>rm 命令，用于删除find查找出来的文件</li>
<li>mv 命令，用于重命名查找出的文件</li>
<li>ls -l 命令，显示查找出的文件的详细信息</li>
<li>md5sum， 对查找出的文件进行md5sum运算，可以获得一个字符串，用于检测文件内容的合法性</li>
<li>wc 命令，用于统计计算文件的单词数量，文件大小等</li>
</ul>
<p>执行任何Unix的shell命令<br>执行你自己写的shell脚本，参数就是每个查找出来的文件名</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/linux/linux-command-find-howtos.html" target="_blank">Linux find命令高阶用法</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/linux/linux-command-find-howtos.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOS常见操作</title>
    <url>/macos/macos-howtos.html</url>
    <content><![CDATA[<h2 id="常见配置"><a href="#常见配置" class="headerlink" title="常见配置"></a>常见配置</h2><h3 id="屏幕截图的默认存储位置调整"><a href="#屏幕截图的默认存储位置调整" class="headerlink" title="屏幕截图的默认存储位置调整"></a>屏幕截图的默认存储位置调整</h3><p>在mac终端执行命令：</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">defaults <span class="keyword">write</span> com.apple.screencapture <span class="keyword">location</span> <span class="title">~/Desktop</span>/idolaoxuPic</span><br></pre></td></tr></table></figure>

<p>执行完后，需执行如下命令生效（当然，重启也是可以的）</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">killall SystemUIServer</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>MacOS截屏快捷键</p>
<ol>
<li>Command + Shift + 3：拍摄截屏</li>
<li>Command + Shift + 4：捕捉屏幕上的某一部分</li>
<li>Command + Shift + 5</li>
</ol>
<p>Reference：<a href="https://support.apple.com/zh-cn/HT201361">https://support.apple.com/zh-cn/HT201361</a></p>
</blockquote>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/macos/macos-howtos.html" target="_blank">MacOS常见操作</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/macos/macos-howtos.html]]></content>
      <categories>
        <category>MacOS</category>
      </categories>
      <tags>
        <tag>MacOS</tag>
        <tag>MacBook</tag>
      </tags>
  </entry>
  <entry>
    <title>千亿数据扛不住，三思后还是从MySQL迁走了……</title>
    <url>/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-mongodb-migration.html</url>
    <content><![CDATA[<p>作者介绍</p>
<blockquote>
<p>杨亚洲，前滴滴出行专家工程师，现任OPPO文档数据库MongoDB负责人，负责数万亿级数据量文档数据库MongoDB内核研发、性能优化及运维工作，一直专注于分布式缓存、高性能服务端、数据库、中间件等相关研发。后续持续分享《MongoDB内核源码设计、性能优化、最佳运维实践》。</p>
</blockquote>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>线上某IOT核心业务集群之前采用MySQL作为主存储数据库，随着业务规模的不断增加，MySQL已无法满足海量数据存储需求，业务面临着容量痛点、成本痛点问题、数据不均衡问题等。</p>
<p>400亿该业务迁移MongoDB后，同样的数据节省了极大的内存、CPU、磁盘成本，同时完美解决了容量痛点、数据不均衡痛点，并且实现了一定的性能提升。</p>
<p>此外，迁移时候的MySQL数据为400亿，3个月后的现在对应MongoDB集群数据已增长到1000亿，如果以1000亿数据规模等比例计算成本，实际成本节省比例会更高。迁移MongoDB后，除了解决业务痛点问题，同时也促进了业务的快速迭代开发，业务不在关心数据库容量痛点、数据不均衡痛点、成本痛点等问题。</p>
<p>当前国内很多mongod文档资料、性能数据等还停留在早期的MMAP_V1存储引擎，实际上从MongoDB-3.x版本开始，MongoDB默认存储引擎已经采用高性能、高压缩比、更小锁粒度的wiredtiger存储引擎，因此其性能、成本等优势相比之前的MMAP_V1存储引擎更加明显。</p>
<h2 id="一、业务迁移背景"><a href="#一、业务迁移背景" class="headerlink" title="一、业务迁移背景"></a>一、业务迁移背景</h2><p>该业务在迁移MongoDB前已有约400亿数据，申请了64套MySQL集群，由业务通过shardingjdbc做分库分表，提前拆分为64个库，每个库100张表。主从高可用选举通过依赖开源orchestrator组建，MySQL架构图如下图所示：</p>
<p><img src="/images/0011.png"></p>
<p><strong>说明：</strong>上图中红色代表磁盘告警，磁盘使用水位即将100%。如上图所示，业务一年多前一次性申请了64套MySQL集群，单个集群节点数一主三从，每个节点规格如下：</p>
<ul>
<li>cpu：4</li>
<li>mem：16G</li>
<li>磁盘：500G</li>
<li>总节点数：64*4=256</li>
<li>SSD服务器</li>
</ul>
<p>该业务运行一年多时间后，总集群数据量达到了400亿，并以每月200亿速度增长，由于数据不均衡等原因，造成部分集群数据量大，持续性耗光磁盘问题。由于节点众多，越来越多的集群节点磁盘突破瓶颈，为了解决磁盘瓶颈，DBA不停的提升节点磁盘容量。业务和DBA都面临严重痛点，主要如下：</p>
<ul>
<li>数据不均衡问题</li>
<li>节点容量问题</li>
<li>成本持续性增加</li>
<li>DBA工作量剧增(部分磁盘提升不了需要迁移数据到新节点)，业务也提心吊胆</li>
</ul>
<h2 id="二、为何选择MongoDB-附十大核心优势总结"><a href="#二、为何选择MongoDB-附十大核心优势总结" class="headerlink" title="二、为何选择MongoDB-附十大核心优势总结"></a>二、为何选择MongoDB-附十大核心优势总结</h2><p>业务遇到瓶颈后，基于MongoDB在公司已有的影响力，业务开始调研MongoDB，通过和业务接触了解到，业务使用场景都是普通的增、删、改、查、排序等操作，同时查询条件都比较固定，用MongoDB完全没任何问题。</p>
<p>此外，MongoDB相比传统开源数据库拥有如下核心优索：</p>
<h3 id="优势一：模式自由"><a href="#优势一：模式自由" class="headerlink" title="优势一：模式自由"></a>优势一：模式自由</h3><p>MongoDB为schema-free结构，数据格式没有严格限制。业务数据结构比较固定，该功能业务不用，但是并不影响业务使用MongoDB存储结构化的数据。</p>
<h3 id="优势二：天然高可用支持"><a href="#优势二：天然高可用支持" class="headerlink" title="优势二：天然高可用支持"></a>优势二：天然高可用支持</h3><p>MySQL高可用依赖第三方组件来实现高可用，MongoDB副本集内部多副本通过raft协议天然支持高可用，相比MySQL减少了对第三方组件的依赖。</p>
<h3 id="优势三：分布式-解决分库分表及海量数据存储痛点"><a href="#优势三：分布式-解决分库分表及海量数据存储痛点" class="headerlink" title="优势三：分布式-解决分库分表及海量数据存储痛点"></a>优势三：分布式-解决分库分表及海量数据存储痛点</h3><p>MongoDB是分布式数据库，完美解决MySQL分库分表及海量数据存储痛点，业务无需在使用数据库前评估需要提前拆多少个库多少个表，MongoDB对业务来说就是一个无限大的表(当前我司最大的表存储数千亿数据，查询性能无任何影响)。</p>
<p>此外，业务在早期的时候一般数据都比较少，可以只申请一个分片MongoDB集群。而如果采用MySQL，就和本次迁移的IOT业务一样，需要提前申请最大容量的集群，早期数据量少的时候严重浪费资源。</p>
<h3 id="优势四：完善的数据均衡机制、不同分片策略、多种片建类型支持"><a href="#优势四：完善的数据均衡机制、不同分片策略、多种片建类型支持" class="headerlink" title="优势四：完善的数据均衡机制、不同分片策略、多种片建类型支持"></a>优势四：完善的数据均衡机制、不同分片策略、多种片建类型支持</h3><ul>
<li>关于balance：支持自动balance、手动balance、时间段任意配置balance.</li>
<li>关于分片策略：支持范围分片、hash分片，同时支持预分片。</li>
<li>关于片建类型：支持单自动片建、多字段片建</li>
</ul>
<h3 id="优势五：不同等级的数据一致性及安全性保证"><a href="#优势五：不同等级的数据一致性及安全性保证" class="headerlink" title="优势五：不同等级的数据一致性及安全性保证"></a>优势五：不同等级的数据一致性及安全性保证</h3><p>MongoDB在设计上根据不同一致性等级需求，支持不同类型的<code>Read Concern</code>、<code>Write Concern</code>读写相关配置，客户端可以根据实际情况设置。此外，MongoDB内核设计拥有完善的rollback机制来保证数据安全性和一致性。</p>
<h3 id="优势六：高并发、高性能"><a href="#优势六：高并发、高性能" class="headerlink" title="优势六：高并发、高性能"></a>优势六：高并发、高性能</h3><p>为了适应大规模高并发业务读写，MongoDB在线程模型设计、并发控制、高性能存储引擎等方面做了很多细致化优化。</p>
<h3 id="优势七：wiredtiger高性能存储引擎设计"><a href="#优势七：wiredtiger高性能存储引擎设计" class="headerlink" title="优势七：wiredtiger高性能存储引擎设计"></a>优势七：wiredtiger高性能存储引擎设计</h3><p>网上很多评论还停留在早期MMAPv1存储引擎，相比MMAPv1，wiredtiger引擎性能更好，压缩比更高，锁粒度更小，具体如下：</p>
<ul>
<li>WiredTiger提供了低延迟和高吞吐量</li>
<li>处理比内存大得多的数据，而不会降低性能或资源</li>
<li>系统故障后可快速恢复到最近一个checkpoint</li>
<li>支持PB级数据存储</li>
<li>多线程架构，尽力利用乐观锁并发控制算法减少锁操作</li>
<li>具有hot-caches能力</li>
<li>磁盘IO最大化利用，提升磁盘IO能力</li>
<li>其他</li>
</ul>
<blockquote>
<p>更多WT存储引擎设计细节可以参考：<br><a href="http://source.wiredtiger.com/3.2.1/architecture.html">http://source.wiredtiger.com/3.2.1/architecture.html</a></p>
</blockquote>
<h3 id="优势八：成本节省-WT引擎高压缩比支持"><a href="#优势八：成本节省-WT引擎高压缩比支持" class="headerlink" title="优势八：成本节省-WT引擎高压缩比支持"></a>优势八：成本节省-WT引擎高压缩比支持</h3><p>MongoDB对数据的压缩支持snappy、zlib算法，在以往线上真实的数据空间大小与真实磁盘空间消耗进行对比，可以得出以下结论：</p>
<ul>
<li>MongoDB默认的snappy压缩算法压缩比约为2.2-4.5倍</li>
<li>zlib压缩算法压缩比约为4.5-7.5倍(本次迁移采用zlib高压缩算法)</li>
</ul>
<p><img src="/images/0001.jpeg"></p>
<p>此外，以线上已有的从MySQL、Es迁移到MongoDB的真实业务磁盘消耗统计对比，同样的数据，存储在MongoDB、MySQL、Es的磁盘占比≈1：3.5：6。</p>
<p>后续会有数千亿hbase数据迁移MongoDB，到时候总结同样数据MongoDB和Hbase的磁盘消耗比。</p>
<h3 id="优势九：天然N机房-不管同城还是异地-多活容灾支持"><a href="#优势九：天然N机房-不管同城还是异地-多活容灾支持" class="headerlink" title="优势九：天然N机房(不管同城还是异地)多活容灾支持"></a>优势九：天然N机房(不管同城还是异地)多活容灾支持</h3><p>MongoDB天然高可用机制及代理标签自动识别转发功能的支持，可以通过节点不同机房部署来满足同城和异地N机房多活容灾需求，从而实现成本、性能、一致性的“三丰收”。</p>
<h3 id="优势十：完善的客户端均衡访问策略"><a href="#优势十：完善的客户端均衡访问策略" class="headerlink" title="优势十：完善的客户端均衡访问策略"></a>优势十：完善的客户端均衡访问策略</h3><p>MongoDB客户端访问路由策略由客户端自己指定，该功能通过Read Preference实现，支持primary 、primaryPreferred 、secondary 、secondaryPreferred 、nearest 五种客户端均衡访问策略。</p>
<h3 id="补充：分布式事务支持"><a href="#补充：分布式事务支持" class="headerlink" title="补充：分布式事务支持"></a>补充：分布式事务支持</h3><p>MongoDB-4.2 版本开始已经支持分布式事务功能，当前对外文档版本已经迭代到 version-4.2.11，分布式事务功能也进一步增强。此外，从 MongoDB-4.4 版本产品规划路线图可以看出，MongoDB 官方将会持续投入开发查询能力和易用性增强功能，例如 union 多表联合查询、索引隐藏等。</p>
<blockquote>
<p>更多MongoDB核心优势细节详见我分享的一篇文章，也欢迎各位参加讨论：</p>
<p>mongodb源码分析、更多实践案例细节：<br><a href="https://github.com/y123456yz/reading-and-annotate-mongodb-3.6">https://github.com/y123456yz/reading-and-annotate-mongodb-3.6</a></p>
<p>话题讨论 | MongoDB 拥有十大核心优势，为何国内知名度远不如 MySQL 高？<br><a href="https://xie.infoq.cn/article/180d98535bfa0c3e71aff1662">https://xie.infoq.cn/article/180d98535bfa0c3e71aff1662</a></p>
</blockquote>
<h2 id="三、MongoDB资源评估及部署架构"><a href="#三、MongoDB资源评估及部署架构" class="headerlink" title="三、MongoDB资源评估及部署架构"></a>三、MongoDB资源评估及部署架构</h2><p>业务开始迁移MongoDB的时候，通过和业务对接梳理，该集群规模及业务需求总结如下：</p>
<ul>
<li>已有数据量400亿左右</li>
<li>数据磁盘消耗总和30T左右</li>
<li>读写峰值流量4-5W/s左右，流量很小</li>
<li>同城两机房多活容灾</li>
<li>读写分离</li>
<li>每月预计增加200亿数据</li>
<li>满足几个月内1500亿新增数据需求</li>
</ul>
<p><strong>说明：</strong>数据规模和磁盘消耗按照单副本计算，例如MySQL 64个分片，256个副本，数据规模和磁盘消耗计算方式为：64个主节点数据量之和、64个分片主节点磁盘消耗之和。</p>
<h3 id="1、MongoDB资源评估"><a href="#1、MongoDB资源评估" class="headerlink" title="1、MongoDB资源评估"></a>1、MongoDB资源评估</h3><p>分片数及存储节点套餐规格选定评估过程如下：</p>
<h4 id="内存评估"><a href="#内存评估" class="headerlink" title="内存评估"></a>内存评估</h4><p>我司都是容器化部署，以往经验来看，MongoDB对内存消耗不高，历史百亿级以上MongoDB集群单个容器最大内存基本上都是64Gb，因此内存规格确定为64G。</p>
<h4 id="分片评估"><a href="#分片评估" class="headerlink" title="分片评估"></a>分片评估</h4><p>业务流量峰值3-5W/s，考虑到可能后期有更大峰值流量，因此按照峰值10W/s写，5w/s读，也就是峰值15W/s评估，预计需要4个分片。</p>
<h4 id="磁盘评估"><a href="#磁盘评估" class="headerlink" title="磁盘评估"></a>磁盘评估</h4><p>MySQL中已有数据400亿，磁盘消耗30T。按照以网线上迁移经验，MongoDB默认配置磁盘消耗约为mysql的1/3-1/5，400亿数据对应MongoDB磁盘消耗预计8T。考虑到1500亿数据，预计4个分片，按照每个分片400亿规模，预计每个分片磁盘消耗8T。</p>
<p>线上单台物理机10多T磁盘，几百G内存，几十个CPU，为了最大化利用服务器资源，我们需要预留一部分磁盘给其他容器使用。另外，因为容器组套餐化限制，最终确定确定单个节点磁盘在7T。预计使用7T的节点，4个分片存储约1500亿数据。</p>
<h4 id="CPU规格评估"><a href="#CPU规格评估" class="headerlink" title="CPU规格评估"></a>CPU规格评估</h4><p>由于容器调度套餐化限制，因此CPU只能限定为16CPU(实际上用不了这么多CPU)。</p>
<h4 id="mongos代理及config-server规格评估"><a href="#mongos代理及config-server规格评估" class="headerlink" title="mongos代理及config server规格评估"></a>mongos代理及config server规格评估</h4><p>此外，由于分片集群还有mongos代理和config server复制集，因此还需要评估mongos代理和config server节点规格。由于config server只主要存储路由相关元数据，因此对磁盘、CUP、MEM消耗都很低；mongos代理只做路由转发只消耗CPU，因此对内存和磁盘消耗都不高。最终，为了最大化节省成本，我们决定让一个代理和一个config server复用同一个容器，容器规格如下：</p>
<p>8CPU/8G内存/50G磁盘，一个代理和一个config server节点复用同一个容器。</p>
<ul>
<li>分片及存储节点规格总结：4分片/16CPU、64G内存、7T磁盘。</li>
<li>mongos及config server规格总结：8CPU/8G内存/50G磁盘</li>
</ul>
<p><img src="/images/0002.jpeg"></p>
<h3 id="2、集群部署架构"><a href="#2、集群部署架构" class="headerlink" title="2、集群部署架构"></a>2、集群部署架构</h3><p>由于该业务所在城市只有两个机房，因此我们采用2+2+1(2mongod+2mongod+1arbiter模式)，在A机房部署2个mongod节点，B机房部署2个mongod节点，C机房部署一个最低规格的选举节点，如下图所示：</p>
<p><img src="/images/0012.png"></p>
<p><strong>说明：</strong></p>
<ul>
<li>每个机房代理部署2个mongos代理，保证业务访问代理高可用，任一代理挂掉，对应机房业务不受影响；</li>
<li>如果机房A挂掉，则机房B和机房C剩余2mongod+1arbiter，则会在B机房mongod中从新选举一个主节点。arbiter选举节点不消耗资源；</li>
<li>客户端配置nearest ，实现就近读，确保请求通过代理转发的时候，转发到最近网络时延节点，也就是同机房对应存储节点读取数据；</li>
<li>弊端：如果是异地机房，B机房和C机房写存在跨机房写场景。如果A、B、C为同城机房，则没用该弊端，同城机房时延可以忽略。</li>
</ul>
<h2 id="四、业务全量-增量迁移方式"><a href="#四、业务全量-增量迁移方式" class="headerlink" title="四、业务全量+增量迁移方式"></a>四、业务全量+增量迁移方式</h2><p><img src="/images/0003.jpeg"></p>
<blockquote>
<p>迁移过程由业务自己完成，通过阿里开源的datax工具实现，该迁移工具的更多细节可以参考：<br><a href="https://github.com/alibaba/DataX">https://github.com/alibaba/DataX</a></p>
</blockquote>
<h2 id="五、性能优化过程"><a href="#五、性能优化过程" class="headerlink" title="五、性能优化过程"></a>五、性能优化过程</h2><p>该集群优化过程按照如下两个步骤优化：数据迁移开始前的提前预优化、迁移过程中瓶颈分析及优化、迁移完成后性能优化。</p>
<h3 id="1、数据迁移开始前的提前预操作"><a href="#1、数据迁移开始前的提前预操作" class="headerlink" title="1、数据迁移开始前的提前预操作"></a>1、数据迁移开始前的提前预操作</h3><p>和业务沟通确定，业务每条数据都携带有一个设备标识ssoid，同时业务查询更新等都是根据ssoid维度查询该设备下面的单条或者一批数据，因此片建选择ssoid。</p>
<h4 id="分片方式"><a href="#分片方式" class="headerlink" title="分片方式"></a>分片方式</h4><p>为了充分散列数据到4个分片，因此选择hash分片方式，这样数据可以最大化散列，同时可以满足同一个ssoid数据落到同一个分片，保证查询效率。</p>
<h4 id="预分片"><a href="#预分片" class="headerlink" title="预分片"></a>预分片</h4><p>MongoDB如果分片片建为hashed分片，则可以提前做预分片，这样就可以保证数据写进来的时候比较均衡的写入多个分片。预分片的好处可以规避非预分片情况下的chunk迁移问题，最大化提升写入性能。</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">sh.<span class="title function_">shardCollection</span>(<span class="string">&quot;xxx.xxx&quot;</span>, &#123;<span class="attr">ssoid</span>:<span class="string">&quot;hashed&quot;</span>&#125;, <span class="literal">false</span>, &#123; <span class="attr">numInitialChunks</span>: <span class="number">8192</span>&#125; )</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意事项：切记提前对ssoid创建hashed索引，否则对后续分片扩容有影响。</p>
</blockquote>
<h4 id="就近读"><a href="#就近读" class="headerlink" title="就近读"></a>就近读</h4><p>客户端增加nearest 配置，从离自己最近的节点读，保证了读的性能。</p>
<h4 id="mongos代理配置"><a href="#mongos代理配置" class="headerlink" title="mongos代理配置"></a>mongos代理配置</h4><p>A机房业务只配置A机房的代理，B机房业务只配置B机房代理，同时带上nearest配置，最大化的实现本机房就近读，同时避免客户端跨机房访问代理。</p>
<h4 id="禁用enableMajorityReadConcern"><a href="#禁用enableMajorityReadConcern" class="headerlink" title="禁用enableMajorityReadConcern"></a>禁用<code>enableMajorityReadConcern</code></h4><p>禁用该功能后ReadConcern majority将会报错，ReadConcern majority功能主要是避免脏读，和业务沟通业务没该需求，因此可以直接关闭。</p>
<p>MongoDB默认使能了<code>enableMajorityReadConcern</code>，该功能开启对性能有一定影响，参考：</p>
<blockquote>
<p>MongoDB readConcern 原理解析<br><a href="https://developer.aliyun.com/article/60553">https://developer.aliyun.com/article/60553</a></p>
</blockquote>
<blockquote>
<p>OPPO百万级高并发MongoDB集群性能数十倍提升优化实践<br><a href="https://mongoing.com/archives/29934">https://mongoing.com/archives/29934</a></p>
</blockquote>
<h4 id="存储引擎cacheSize规格选择"><a href="#存储引擎cacheSize规格选择" class="headerlink" title="存储引擎cacheSize规格选择"></a>存储引擎cacheSize规格选择</h4><p>单个容器规格：16CPU、64G内存、7T磁盘，考虑到全量迁移过程中对内存压力，内存碎片等压力会比较大，为了避免OOM，设置cacheSize=42G。</p>
<h3 id="2、数据全量迁移过程中优化过程"><a href="#2、数据全量迁移过程中优化过程" class="headerlink" title="2、数据全量迁移过程中优化过程"></a>2、数据全量迁移过程中优化过程</h3><p><img src="/images/0013.png"></p>
<p>全量数据迁移过程中，迁移速度较块，内存脏数据较多，当脏数据比例达到一定比例后用户读写请求对应线程将会阻塞，用户线程也会去淘汰内存中的脏数据page，最终写性能下降明显。</p>
<p>wiredtiger存储引擎cache淘汰策略相关的几个配置如下:</p>
<p><img src="/images/0014.png"></p>
<p>由于业务全量迁移数据是持续性的大流量写，而不是突发性的大流量写，因此eviction_target、eviction_trigger、eviction_dirty_target、eviction_dirty_trigger几个配置用处不大，这几个参数阀值只是在短时间突发流量情况下调整才有用。</p>
<p>但是，在持续性长时间大流量写的情况下，我们可以通过提高wiredtiger存储引擎后台线程数来解决脏数据比例过高引起的用户请求阻塞问题，淘汰脏数据的任务最终交由evict模块后台线程来完成。</p>
<p>全量大流量持续性写存储引擎优化如下：</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">db.<span class="title function_">adminCommand</span>( &#123; setParameter : <span class="number">1</span>, <span class="string">&quot;wiredTigerEngineRuntimeConfig&quot;</span> : <span class="string">&quot;eviction=(threads_min=4, threads_max=20)&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>

<h3 id="3、全量迁移完成后，业务流量读写优化"><a href="#3、全量迁移完成后，业务流量读写优化" class="headerlink" title="3、全量迁移完成后，业务流量读写优化"></a>3、全量迁移完成后，业务流量读写优化</h3><p><img src="/images/0015.png"></p>
<p>前面章节我们提到，在容器资源评估的时候，我们最终确定选择单个容器套餐规格为如下：</p>
<blockquote>
<p>16CPU、64G内存、7T磁盘。</p>
</blockquote>
<p>全量迁移过程中为了避免OOM，预留了约1/3内存给MongoDB server层、操作系统开销等，当全量数据迁移完后，业务写流量相比全量迁移过程小了很多，峰值读写OPS约2-4W/s。</p>
<p>也就是说，前量迁移完成后，cache中脏数据比例几乎很少，基本上不会达到20%阀值，业务读流量相比之前多了很多(数据迁移过程中读流量走原MySQL集群)。为了提升读性能，因此做了如下性能调整(提前建好索引)：</p>
<ul>
<li>节点cacheSize从之前的42G调整到55G，尽量多的缓存热点数据到内存，供业务读，最大化提升读性能；</li>
<li>每天凌晨低峰期做一次cache内存加速释放，避免OOM。</li>
</ul>
<p>上面的内核优后后，业务测时延监控曲线变化，时延更加平稳，平均时延也有25%左右的性能优后，如下图所示：</p>
<p><img src="/images/0016.png"></p>
<h2 id="六、迁移前后，业务测时延统计对比：-MySQL-vs-MongoDB"><a href="#六、迁移前后，业务测时延统计对比：-MySQL-vs-MongoDB" class="headerlink" title="六、迁移前后，业务测时延统计对比：(MySQL vs MongoDB)"></a>六、迁移前后，业务测时延统计对比：(MySQL vs MongoDB)</h2><p>迁移前业务测时延监控曲线(平均时延7ms, 2月1日数据，此时mysql集群只有300亿数据)：</p>
<p><img src="/images/0017.png"></p>
<p>迁移MongoDB后并且业务流量全部切到MongoDB后业务测时延监控曲线(平均6ms, 3月6日数据，此时MongoDB集群已有约500亿数据))</p>
<p><img src="/images/0016.png"></p>
<p>总结：</p>
<ul>
<li>MySQL(300亿数据)时延：7ms</li>
<li>MongoDB(500亿数据)时延：6ms</li>
</ul>
<h2 id="七、迁移成本收益对比"><a href="#七、迁移成本收益对比" class="headerlink" title="七、迁移成本收益对比"></a>七、迁移成本收益对比</h2><h3 id="1、MySQL集群规格及存储数据最大量"><a href="#1、MySQL集群规格及存储数据最大量" class="headerlink" title="1、MySQL集群规格及存储数据最大量"></a>1、MySQL集群规格及存储数据最大量</h3><p><img src="/images/0019.png"></p>
<p>原mysql集群一共64套，每套集群4副本，每个副本容器规格：4CPU、16G mem、500G磁盘，总共可以存储400亿数据，这时候大部分节点已经开始磁盘90%水位告警，DBA对部分节点做了磁盘容量提升。</p>
<p>总结如下：</p>
<ul>
<li>集群总套数：64</li>
<li>单套集群副本数：4</li>
<li>每个节点规格：4CPU、16G mem、500G磁盘</li>
<li>该64套集群最大存储数据量：400亿</li>
</ul>
<h3 id="2、MongoDB集群规格及存储数据最大量"><a href="#2、MongoDB集群规格及存储数据最大量" class="headerlink" title="2、MongoDB集群规格及存储数据最大量"></a>2、MongoDB集群规格及存储数据最大量</h3><p><img src="/images/0020.png"></p>
<p>MongoDB从MySQL迁移过来后，数据量已从400亿增加到1000亿，并以每个月增加200亿数据。</p>
<p>MongoDB集群规格及存储数据量总结如下：</p>
<ul>
<li>分片数：4</li>
<li>单分片副本数：4</li>
<li>每个节点规格：16CPU、64G mem、7T磁盘</li>
<li>四个分片存储数据量：当前已存1000亿，最大可存1500亿数据。</li>
</ul>
<h3 id="3、成本对比计算过程"><a href="#3、成本对比计算过程" class="headerlink" title="3、成本对比计算过程"></a>3、成本对比计算过程</h3><p><strong>说明：</strong>由于MySQL迁移MongoDB后，数据不再往MySQL中写入，流量切到MongoDB时候MySQL中大约存储有400亿数据，因此我们以这个时间点做为对比时间点。以400亿数据为基准，资源消耗对比如下表(每个分片只计算主节点资源消耗，因为MySQL和MongoDB都是4副本)：</p>
<p><img src="/images/0004.jpeg"></p>
<p>由于MongoDB四个分片还有很多磁盘冗余，该四个分片相比400亿数据，还可以写1100亿数据。如果按照1500亿数据计算，如果还是按照MySQL之前套餐规格，则MySQL集群数需要再增加三倍，也就是总集群套数需要64*4=256套，资源占用对比如下：</p>
<p><img src="/images/0005.jpeg"></p>
<h3 id="4、收益总结-客观性对比"><a href="#4、收益总结-客观性对比" class="headerlink" title="4、收益总结(客观性对比)"></a>4、收益总结(客观性对比)</h3><p>从上面的内容可以看出，该业务迁移MongoDB后，除了解决了业务容量痛点、促进业务快速迭代开发、性能提升外，成本还节省了数倍。成本节省总结如下：</p>
<p>400亿维度计算(mysql和MongoDB都存储相同的400亿数据)：</p>
<ul>
<li>CPU和内存成本比例：4:1</li>
<li>磁盘成本比例：3.3:1</li>
</ul>
<p>1500亿维度计算(假设mysql集群都采用之前规格等比例换算)：</p>
<ul>
<li>CPU和内存成本比例：16:1</li>
<li>磁盘成本比例：3.3:1</li>
</ul>
<p>从上面的分析可以看出，数据量越大，按照等比例换算原则，MongoDB存储成本会更低，原因如下：</p>
<h4 id="CPU-内存节省原因："><a href="#CPU-内存节省原因：" class="headerlink" title="CPU/内存节省原因："></a>CPU/内存节省原因：</h4><p>主要是因为MongoDB海量数据存储及高性能原因，索引建好后，单实例单表即使几百亿数据，读写也是ms级返回(注意：切记查询更新建好索引)。</p>
<p>此外，由于MongoDB分布式功能，对容量评估更加方便，就无需提前一次性申请很多套mysql，而是根据实际需要可以随时加分片。</p>
<h4 id="磁盘节省原因："><a href="#磁盘节省原因：" class="headerlink" title="磁盘节省原因："></a>磁盘节省原因：</h4><p>MongoDB存储引擎wiredtiger默认高压缩、高性能。</p>
<p>最后，鉴于客观性成本评价，CPU/内存成本部分可能会有争议，比如mysql内存和CPU是否申请的时候就申请过大。MongoDB对应CPU也同样存在该问题，例如申请的单个容器是16CPU，实际上真实只消耗了几个CPU。</p>
<p>但是，磁盘节省是实实在在的，是相同数据情况下mysql和MongoDB的真实磁盘消耗对比。</p>
<p>当前该集群总数据量已经达到近千亿，并以每个月200亿规模增加，单从容器计费层面上换算，1000亿数据按照等比例换算，预计节省成本10倍。</p>
<h2 id="八、最后：千亿级中等规模MongoDB集群注意事项"><a href="#八、最后：千亿级中等规模MongoDB集群注意事项" class="headerlink" title="八、最后：千亿级中等规模MongoDB集群注意事项"></a>八、最后：千亿级中等规模MongoDB集群注意事项</h2><p>MongoDB无需分库分表，单表可以无限大，但是单表随着数据量的增多会引起以下问题：</p>
<ul>
<li>切记提前建好索引，否则影响查询更新性能(数据越多，无索引查询扫描会越慢)。</li>
<li>切记提前评估好业务需要那些索引，单节点单个表数百亿数据，加索引执行时间较长。</li>
<li>服务器异常情况下节点替换时间相比会更长。</li>
<li>切记数据备份不要采用mongodump/mongorestore方式，而是采用热备或者文件拷贝方式备份。</li>
<li>节点替换尽量从备份中拷贝数据加载方式恢复，而不是通过主从全量同步方式，全量同步过程较长。</li>
</ul>
<h2 id="九、未来挑战-该集群未来万亿级实时数据规模挑战"><a href="#九、未来挑战-该集群未来万亿级实时数据规模挑战" class="headerlink" title="九、未来挑战(该集群未来万亿级实时数据规模挑战)"></a>九、未来挑战(该集群未来万亿级实时数据规模挑战)</h2><p>随着时间推移，业务数据增长也会越来越多，单月数据量增长曲线预计会直线增加(当前每月数据量增加200亿左右)，预计未来2-3年该集群总数据量会达到万亿级，分片数也会达到20个分片左右，可能会遇到各自各样的问题。</p>
<p>但是，IOT业务数据存在明显的冷数问题，一年前的数据用户基本上不会访问，因此我们考虑做如下优后来满足性能、成本的进一步提升：</p>
<ul>
<li>冷数据归档到低成本SATA盘</li>
<li>冷数据提升压缩比，最大化减少磁盘消耗</li>
</ul>
<blockquote>
<p>如何解决冷数据归档sata盘过程中的性能问题<br>冷热归档存储可以参考之前在dbaplus分享的另一篇文章：<br>1.《用最少人力玩转万亿级数据，我用的就是MongoDB！》<br>2.MongoDB源码分析、更多实践案例细节<br><a href="https://github.com/y123456yz/reading-and-annotate-mongodb-3.6">https://github.com/y123456yz/reading-and-annotate-mongodb-3.6</a></p>
</blockquote>
<h2 id="十、最后说明-业务场景"><a href="#十、最后说明-业务场景" class="headerlink" title="十、最后说明(业务场景)"></a>十、最后说明(业务场景)</h2><p>本千亿级IOT业务使用场景总结如下：</p>
<ul>
<li>业务数据读、更新、排序等都可以走索引，包括单字段索引、多字段索引、数组索引，所有查询和更新都能确定走具体的某个最优索引。</li>
<li>查询都是单表查询，不涉及多表联合查询。</li>
</ul>
<p>数据库场景非常重要，脱离业务场景谈数据库优劣无任何意义。例如本文的业务场景，业务能确定需要建那些索引，同时所有的更新、查询、排序都可以对应具体的最优索引，因此该场景就非常适合MongoDB。</p>
<p>每种数据库都有其适合的业务场景，没有万能的数据库。此外，不能因为某种场景不适合而全盘否定没数据库，主流数据库都有其存在的意义，千万不能因为某种场景下的不合适而全盘否定某个数据库。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-mongodb-migration.html" target="_blank">千亿数据扛不住，三思后还是从MySQL迁走了……</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql-mongodb-migration.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>PowerBI常见操作</title>
    <url>/powerbi/powerbi-howtos.html</url>
    <content><![CDATA[<h2 id="分析方法"><a href="#分析方法" class="headerlink" title="分析方法"></a>分析方法</h2><h3 id="按周进行数据分析"><a href="#按周进行数据分析" class="headerlink" title="按周进行数据分析"></a>按周进行数据分析</h3><p>Source：<a href="https://zhuanlan.zhihu.com/p/58948031">https://zhuanlan.zhihu.com/p/58948031</a></p>
<h3 id="按条件统计数量（DAX）"><a href="#按条件统计数量（DAX）" class="headerlink" title="按条件统计数量（DAX）"></a>按条件统计数量（DAX）</h3><p>增加一个统计列，此列统计了符合<code>FILTER</code>条件的数据数量：</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">不足<span class="number">8</span>小时数量 = <span class="constructor">COUNTROWS(FILTER(<span class="params">sheet1</span>, <span class="params">sheet1</span>[Group] = <span class="string">&quot;招聘管理&quot;</span> <span class="operator">&amp;&amp;</span> <span class="params">sheet1</span>[出勤时长]&lt;7.5 <span class="operator">&amp;&amp;</span> <span class="params">sheet1</span>[出勤时长] &gt; 0 <span class="operator">||</span> <span class="params">sheet1</span>[Group] &lt;&gt; <span class="string">&quot;招聘管理&quot;</span> <span class="operator">&amp;&amp;</span> <span class="params">sheet1</span>[出勤时长] &lt; 8 <span class="operator">&amp;&amp;</span>  <span class="params">sheet1</span>[出勤时长] &gt; 0)</span>)</span><br></pre></td></tr></table></figure>

<h2 id="类Excel的计算"><a href="#类Excel的计算" class="headerlink" title="类Excel的计算"></a>类Excel的计算</h2><h3 id="VLOOKUP-DAX"><a href="#VLOOKUP-DAX" class="headerlink" title="VLOOKUP (DAX)"></a>VLOOKUP (DAX)</h3><p>Document: <a href="https://docs.microsoft.com/en-us/dax/lookupvalue-function-dax">https://docs.microsoft.com/en-us/dax/lookupvalue-function-dax</a><br>Example: <a href="https://www.wallstreetmojo.com/vlookup-in-power-bi/">https://www.wallstreetmojo.com/vlookup-in-power-bi/</a></p>
<h4 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h4><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">LOOKUPVALUE(</span><br><span class="line">    <span class="tag">&lt;<span class="name">result_columnName</span>&gt;</span>,</span><br><span class="line">    <span class="tag">&lt;<span class="name">search_columnName</span>&gt;</span>,</span><br><span class="line">    <span class="tag">&lt;<span class="name">search_value</span>&gt;</span></span><br><span class="line">    [, <span class="tag">&lt;<span class="name">search2_columnName</span>&gt;</span>, <span class="tag">&lt;<span class="name">search2_value</span>&gt;</span>]…</span><br><span class="line">    [, <span class="tag">&lt;<span class="name">alternateResult</span>&gt;</span>]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters"></a>Parameters</h4><table>
<thead>
<tr>
<th>Term</th>
<th>Definition</th>
</tr>
</thead>
<tbody><tr>
<td>result_columnName</td>
<td>The name of an existing column that contains the value you want to return. It cannot be an expression.</td>
</tr>
<tr>
<td>search_columnName</td>
<td>The name of an existing column. It can be in the same table as result_columnName or in a related table. It cannot be an expression.</td>
</tr>
<tr>
<td>search_value</td>
<td>The value to search for in search_columnName.</td>
</tr>
<tr>
<td>alternateResult</td>
<td>(Optional) The value returned when the context for result_columnName has been filtered down to zero or more than one distinct value. When not provided, the function returns BLANK when result_columnName is filtered down to zero value or an error when more than one distinct value.</td>
</tr>
</tbody></table>
<h4 id="Return-value"><a href="#Return-value" class="headerlink" title="Return value"></a>Return value</h4><p>The value of result_column at the row where all pairs of search_column and search_value have an exact match.</p>
<p>If there’s no match that satisfies all the search values, BLANK or alternateResult (if supplied) is returned. In other words, the function won’t return a lookup value if only some of the criteria match.</p>
<p>If multiple rows match the search values and in all cases result_column values are identical, then that value is returned. However, if result_column returns different values, an error or alternateResult (if supplied) is returned.</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/powerbi/powerbi-howtos.html" target="_blank">PowerBI常见操作</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/powerbi/powerbi-howtos.html]]></content>
      <categories>
        <category>PowerBI</category>
      </categories>
      <tags>
        <tag>PowerBI</tag>
        <tag>BI</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis常见的CPU和内存性能问题</title>
    <url>/redis/redis-performance-issues-cpu.html</url>
    <content><![CDATA[<blockquote>
<p>Reference: <a href="https://www.infoq.cn/article/yqUuS2qNRybILGrQUliv">https://www.infoq.cn/article/yqUuS2qNRybILGrQUliv</a></p>
</blockquote>
<p>我们在使用 Redis 时，总会碰到一些 redis-server 端 CPU 及内存占用比较高的问题。下面以几个实际案例为例，来讨论一下在使用 Redis 时容易忽视的几种情形。</p>
<h2 id="短连接导致-CPU-高"><a href="#短连接导致-CPU-高" class="headerlink" title="短连接导致 CPU 高"></a>短连接导致 CPU 高</h2><p>某用户反映 QPS 不高，从监控看 CPU 确实偏高。既然 QPS 不高，那么 redis-server 自身很可能在做某些清理工作或者用户在执行复杂度较高的命令，经排查无没有进行 key 过期删除操作，没有执行复杂度高的命令。</p>
<p>上机器对 redis-server 进行 perf 分析，发现函数 listSearchKey 占用 CPU 比较高，分析调用栈发现在释放连接时会频繁调用 listSearchKey，且用户反馈说是使用的短连接，所以推断是频繁释放连接导致 CPU 占用有所升高。</p>
<h3 id="对比实验"><a href="#对比实验" class="headerlink" title="对比实验"></a>对比实验</h3><p>下面使用 redis-benchmark 工具分别使用长连接和短连接做一个对比实验，redis-server 为社区版 4.0.10。</p>
<h4 id="长连接测试"><a href="#长连接测试" class="headerlink" title="长连接测试"></a>长连接测试</h4><p>使用 10000 个长连接向 redis-server 发送 50w 次 ping 命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./redis-benchmark -h host -p port -t ping -c 10000 -n 500000 -k 1（k=1表示使用长连接，k=0表示使用短连接)</span><br></pre></td></tr></table></figure>
<p>最终 QPS：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">PING_INLINE</span>: <span class="number">92902</span>.<span class="number">27</span> requests per second</span><br><span class="line"><span class="attribute">PING_BULK</span>: <span class="number">93580</span>.<span class="number">38</span> requests per second</span><br></pre></td></tr></table></figure>
<p>对 redis-server 分析，发现占用 CPU 最高的是 readQueryFromClient，即主要是在处理来自用户端的请求。</p>
<p><img src="/images/0001.png" alt="占用 CPU 最高的是 readQueryFromClient"></p>
<h4 id="短连接测试"><a href="#短连接测试" class="headerlink" title="短连接测试"></a>短连接测试</h4><p>使用 10000 个短连接向 redis-server 发送 50w 次 ping 命令：</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">./redis-benchmark -h host -p port -<span class="built_in">t</span> ping -c <span class="number">10000</span> -<span class="built_in">n</span> <span class="number">500000</span> -k <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>最终 QPS：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">PING_INLINE</span>: <span class="number">15187</span>.<span class="number">18</span> requests per second</span><br><span class="line"><span class="attribute">PING_BULK</span>: <span class="number">16471</span>.<span class="number">75</span> requests per second</span><br></pre></td></tr></table></figure>
<p>对 redis-server 分析，发现占用 CPU 最高的确实是 listSearchKey，而 readQueryFromClient 所占 CPU 的比例比 listSearchKey 要低得多，也就是说 CPU 有点“不务正业”了，处理用户请求变成了副业，而搜索 list 却成为了主业。所以在同样的业务请求量下，使用短连接会增加 CPU 的负担。</p>
<p><img src="/images/0002.png" alt="使用短连接会增加 CPU 的负担"></p>
<p>从 QPS 上看，短连接与长连接差距比较大，原因来自两方面：</p>
<ul>
<li>每次重新建连接引入的网络开销。</li>
<li>释放连接时，redis-server 需消耗额外的 CPU 周期做清理工作。（这一点可以尝试从 redis-server 端做优化）</li>
</ul>
<h3 id="Redis-连接释放"><a href="#Redis-连接释放" class="headerlink" title="Redis 连接释放"></a>Redis 连接释放</h3><p>我们从代码层面来看下 redis-server 在用户端发起连接释放后都会做哪些事情，redis-server 在收到用户端的断连请求时会直接进入到 freeClient。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">freeClient</span><span class="params">(client *c)</span> &#123;</span><br><span class="line">    listNode *ln;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* .........*/</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Free the query buffer */</span></span><br><span class="line">    sdsfree(c-&gt;querybuf);</span><br><span class="line">    sdsfree(c-&gt;pending_querybuf);</span><br><span class="line">    c-&gt;querybuf = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Deallocate structures used to block on blocking ops. */</span></span><br><span class="line">    <span class="keyword">if</span> (c-&gt;flags &amp; CLIENT_BLOCKED) unblockClient(c);</span><br><span class="line">    dictRelease(c-&gt;bpop.keys);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* UNWATCH all the keys */</span></span><br><span class="line">    unwatchAllKeys(c);</span><br><span class="line">    listRelease(c-&gt;watched_keys);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Unsubscribe from all the pubsub channels */</span></span><br><span class="line">    pubsubUnsubscribeAllChannels(c,<span class="number">0</span>);</span><br><span class="line">    pubsubUnsubscribeAllPatterns(c,<span class="number">0</span>);</span><br><span class="line">    dictRelease(c-&gt;pubsub_channels);</span><br><span class="line">    listRelease(c-&gt;pubsub_patterns);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Free data structures. */</span></span><br><span class="line">    listRelease(c-&gt;reply);</span><br><span class="line">    freeClientArgv(c);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Unlink the client: this will close the socket, remove the I/O</span></span><br><span class="line"><span class="comment">     * handlers, and remove references of the client from different</span></span><br><span class="line"><span class="comment">     * places where active clients may be referenced. */</span></span><br><span class="line">    <span class="comment">/*  redis-server维护了一个server.clients链表，当用户端建立连接后，新建一个client对象并追加到server.clients上，</span></span><br><span class="line"><span class="comment">        当连接释放时，需求从server.clients上删除client对象 */</span></span><br><span class="line">    unlinkClient(c);</span><br><span class="line"></span><br><span class="line">   <span class="comment">/* ...........*/</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlinkClient</span><span class="params">(client *c)</span> &#123;</span><br><span class="line">    listNode *ln;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If this is marked as current client unset it. */</span></span><br><span class="line">    <span class="keyword">if</span> (server.current_client == c) server.current_client = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Certain operations must be done only if the client has an active socket.</span></span><br><span class="line"><span class="comment">     * If the client was already unlinked or if it&#x27;s a &quot;fake client&quot; the</span></span><br><span class="line"><span class="comment">     * fd is already set to -1. */</span></span><br><span class="line">    <span class="keyword">if</span> (c-&gt;fd != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="comment">/* 搜索server.clients链表，然后删除client节点对象，这里复杂为O(N) */</span></span><br><span class="line">        ln = listSearchKey(server.clients,c);</span><br><span class="line">        serverAssert(ln != <span class="literal">NULL</span>);</span><br><span class="line">        listDelNode(server.clients,ln);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Unregister async I/O handlers and close the socket. */</span></span><br><span class="line">        aeDeleteFileEvent(server.el,c-&gt;fd,AE_READABLE);</span><br><span class="line">        aeDeleteFileEvent(server.el,c-&gt;fd,AE_WRITABLE);</span><br><span class="line">        close(c-&gt;fd);</span><br><span class="line">        c-&gt;fd = <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/*   ......... */</span></span><br></pre></td></tr></table></figure>

<p>所以在每次连接断开时，都存在一个 O(N)的运算。对于 redis 这样的内存数据库，我们应该尽量避开 O(N)运算，特别是在连接数比较大的场景下，对性能影响比较明显。虽然用户只要不使用短连接就能避免，但在实际的场景中，用户端连接池被打满后，用户也可能会建立一些短连接。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>从上面的分析看，每次连接释放时都会进行 O(N)的运算，那能不能降复杂度降到 O(1)呢？</p>
<p>这个问题非常简单，server.clients 是个双向链表，只要当 client 对象在创建时记住自己的内存地址，释放时就不需要遍历 server.clients。接下来尝试优化下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">client *<span class="title function_">createClient</span><span class="params">(<span class="type">int</span> fd)</span> &#123;</span><br><span class="line">    client *c = zmalloc(<span class="keyword">sizeof</span>(client));</span><br><span class="line">   <span class="comment">/*  ........  */</span></span><br><span class="line">    listSetFreeMethod(c-&gt;pubsub_patterns,decrRefCountVoid);</span><br><span class="line">    listSetMatchMethod(c-&gt;pubsub_patterns,listMatchObjects);</span><br><span class="line">    <span class="keyword">if</span> (fd != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="comment">/*  client记录自身所在list的listNode地址 */</span></span><br><span class="line">        c-&gt;client_list_node = listAddNodeTailEx(server.clients,c);</span><br><span class="line">    &#125;</span><br><span class="line">    initClientMultiState(c);</span><br><span class="line">    <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">unlinkClient</span><span class="params">(client *c)</span> &#123;</span><br><span class="line">    listNode *ln;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If this is marked as current client unset it. */</span></span><br><span class="line">    <span class="keyword">if</span> (server.current_client == c) server.current_client = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Certain operations must be done only if the client has an active socket.</span></span><br><span class="line"><span class="comment">     * If the client was already unlinked or if it&#x27;s a &quot;fake client&quot; the</span></span><br><span class="line"><span class="comment">     * fd is already set to -1. */</span></span><br><span class="line">    <span class="keyword">if</span> (c-&gt;fd != <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="comment">/* 这时不再需求搜索server.clients链表 */</span></span><br><span class="line">        <span class="comment">//ln = listSearchKey(server.clients,c);</span></span><br><span class="line">        <span class="comment">//serverAssert(ln != NULL);</span></span><br><span class="line">        <span class="comment">//listDelNode(server.clients,ln);</span></span><br><span class="line">        listDelNode(server.clients, c-&gt;client_list_node);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Unregister async I/O handlers and close the socket. */</span></span><br><span class="line">        aeDeleteFileEvent(server.el,c-&gt;fd,AE_READABLE);</span><br><span class="line">        aeDeleteFileEvent(server.el,c-&gt;fd,AE_WRITABLE);</span><br><span class="line">        close(c-&gt;fd);</span><br><span class="line">        c-&gt;fd = <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">/*   ......... */</span></span><br></pre></td></tr></table></figure>

<h4 id="优化后短连接测试"><a href="#优化后短连接测试" class="headerlink" title="优化后短连接测试"></a>优化后短连接测试</h4><p>使用 10000 个短连接向 redis-server 发送 50w 次 ping 命令：</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">./redis-benchmark -h host -p port -<span class="built_in">t</span> ping -c <span class="number">10000</span> -<span class="built_in">n</span> <span class="number">500000</span> -k <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>最终 QPS：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">PING_INLINE</span>: <span class="number">21884</span>.<span class="number">23</span> requests per second</span><br><span class="line"><span class="attribute">PING_BULK</span>: <span class="number">21454</span>.<span class="number">62</span> requests per second</span><br></pre></td></tr></table></figure>
<p>与优化前相比，短连接性能能够提升 30+%，所以能够保证存在短连接的情况下，性能不至于太差。</p>
<h2 id="info-命令导致-CPU-高"><a href="#info-命令导致-CPU-高" class="headerlink" title="info 命令导致 CPU 高"></a>info 命令导致 CPU 高</h2><p>有用户通过定期执行 info 命令监视 redis 的状态，这会在一定程度上导致 CPU 占用偏高。频繁执行 info 时通过 perf 分析发现 getClientsMaxBuffers、getClientOutputBufferMemoryUsage 及 getMemoryOverheadData 这几个函数占用 CPU 比较高。</p>
<p>通过 Info 命令，可以拉取到 redis-server 端的如下一些状态信息（未列全）：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">client</span><br><span class="line">connected_clients:<span class="number">1</span></span><br><span class="line">client_longest_output_list:<span class="number">0</span> <span class="comment">// redis-server端最长的outputbuffer列表长度</span></span><br><span class="line">client_biggest_input_buf:<span class="number">0.</span> <span class="comment">// redis-server端最长的inputbuffer字节长度</span></span><br><span class="line">blocked_clients:<span class="number">0</span></span><br><span class="line">Memory</span><br><span class="line">used_memory:<span class="number">848392</span></span><br><span class="line">used_memory_human:<span class="number">828.51</span>K</span><br><span class="line">used_memory_rss:<span class="number">3620864</span></span><br><span class="line">used_memory_rss_human:<span class="number">3.45</span>M</span><br><span class="line">used_memory_peak:<span class="number">619108296</span></span><br><span class="line">used_memory_peak_human:<span class="number">590.43</span>M</span><br><span class="line">used_memory_peak_perc:<span class="number">0.14</span>%</span><br><span class="line">used_memory_overhead:<span class="number">836182</span> <span class="comment">// 除dataset外，redis-server为维护自身结构所额外占用的内存量</span></span><br><span class="line">used_memory_startup:<span class="number">786552</span></span><br><span class="line">used_memory_dataset:<span class="number">12210</span></span><br><span class="line">used_memory_dataset_perc:<span class="number">19.74</span>%</span><br><span class="line">为了得到client_longest_output_list、client_longest_output_list状态，需要遍历redis-server端所有的client, 如getClientsMaxBuffers所示，可能看到这里也是存在同样的O(N)运算。</span><br><span class="line"><span class="type">void</span> <span class="title function_">getClientsMaxBuffers</span><span class="params">(<span class="type">unsigned</span> <span class="type">long</span> *longest_output_list,</span></span><br><span class="line"><span class="params">                          <span class="type">unsigned</span> <span class="type">long</span> *biggest_input_buffer)</span> &#123;</span><br><span class="line">    client *c;</span><br><span class="line">    listNode *ln;</span><br><span class="line">    listIter li;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> lol = <span class="number">0</span>, bib = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">/* 遍历所有client, 复杂度O(N) */</span></span><br><span class="line">    listRewind(server.clients,&amp;li);</span><br><span class="line">    <span class="keyword">while</span> ((ln = listNext(&amp;li)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        c = listNodeValue(ln);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (listLength(c-&gt;reply) &gt; lol) lol = listLength(c-&gt;reply);</span><br><span class="line">        <span class="keyword">if</span> (sdslen(c-&gt;querybuf) &gt; bib) bib = sdslen(c-&gt;querybuf);</span><br><span class="line">    &#125;</span><br><span class="line">    *longest_output_list = lol;</span><br><span class="line">    *biggest_input_buffer = bib;</span><br><span class="line">&#125;</span><br><span class="line">为了得到used_memory_overhead状态，同样也需要遍历所有client计算所有client的outputBuffer所占用的内存总量，如getMemoryOverheadData所示：</span><br><span class="line"><span class="keyword">struct</span> redisMemOverhead *<span class="title function_">getMemoryOverheadData</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ......... */</span></span><br><span class="line">    mem = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (server.repl_backlog)</span><br><span class="line">        mem += zmalloc_size(server.repl_backlog);</span><br><span class="line">    mh-&gt;repl_backlog = mem;</span><br><span class="line">    mem_total += mem;</span><br><span class="line">   <span class="comment">/* ...............*/</span></span><br><span class="line">    mem = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (listLength(server.clients)) &#123;</span><br><span class="line">        listIter li;</span><br><span class="line">        listNode *ln;</span><br><span class="line">        <span class="comment">/*  遍历所有的client, 计算所有client outputBuffer占用的内存总和，复杂度为O(N)  */</span></span><br><span class="line">        listRewind(server.clients,&amp;li);</span><br><span class="line">        <span class="keyword">while</span>((ln = listNext(&amp;li))) &#123;</span><br><span class="line">            client *c = listNodeValue(ln);</span><br><span class="line">            <span class="keyword">if</span> (c-&gt;flags &amp; CLIENT_SLAVE)</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            mem += getClientOutputBufferMemoryUsage(c);</span><br><span class="line">            mem += sdsAllocSize(c-&gt;querybuf);</span><br><span class="line">            mem += <span class="keyword">sizeof</span>(client);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mh-&gt;clients_normal = mem;</span><br><span class="line">    mem_total+=mem;</span><br><span class="line"></span><br><span class="line">    mem = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (server.aof_state != AOF_OFF) &#123;</span><br><span class="line">        mem += sdslen(server.aof_buf);</span><br><span class="line">        mem += aofRewriteBufferSize();</span><br><span class="line">    &#125;</span><br><span class="line">    mh-&gt;aof_buffer = mem;</span><br><span class="line">    mem_total+=mem;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ......... */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mh;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>从上面的分析知道，当连接数较高时（O(N)的 N 大），如果频率执行 info 命令，会占用较多 CPU。</p>
<h4 id="建立一个连接，不断执行-info-命令"><a href="#建立一个连接，不断执行-info-命令" class="headerlink" title="建立一个连接，不断执行 info 命令"></a>建立一个连接，不断执行 info 命令</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">     c, err := redis.Dial(<span class="string">&quot;tcp&quot;</span>, addr)</span><br><span class="line">     <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">&quot;Connect to redis error:&quot;</span>, err)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">for</span> &#123;</span><br><span class="line">        c.Do(<span class="string">&quot;info&quot;</span>)</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实验结果表明，CPU 占用仅为 20%左右。</p>
<p><img src="/images/0003.png" alt="CPU 占用仅为 20%左右"></p>
<h4 id="建立-9999-个空闲连接，及一个连接不断执行-info"><a href="#建立-9999-个空闲连接，及一个连接不断执行-info" class="headerlink" title="建立 9999 个空闲连接，及一个连接不断执行 info"></a>建立 9999 个空闲连接，及一个连接不断执行 info</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">     clients := []redis.Conn&#123;&#125;</span><br><span class="line">     <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">9999</span>; i++ &#123;</span><br><span class="line">        c, err := redis.Dial(<span class="string">&quot;tcp&quot;</span>, addr)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">           fmt.Println(<span class="string">&quot;Connect to redis error:&quot;</span>, err)</span><br><span class="line">           <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">        clients = <span class="built_in">append</span>(clients, c)</span><br><span class="line">     &#125;</span><br><span class="line">     c, err := redis.Dial(<span class="string">&quot;tcp&quot;</span>, addr)</span><br><span class="line">     <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        fmt.Println(<span class="string">&quot;Connect to redis error:&quot;</span>, err)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">for</span> &#123;</span><br><span class="line">        _, err = c.Do(<span class="string">&quot;info&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">           <span class="built_in">panic</span>(err)</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>实验结果表明 CPU 能够达到 80%，所以在连接数较高时，尽量避免使用 info 命令。</p>
<p><img src="/images/0004.png" alt="CPU 能够达到 80%"></p>
<h2 id="pipeline-导致内存占用高"><a href="#pipeline-导致内存占用高" class="headerlink" title="pipeline 导致内存占用高"></a>pipeline 导致内存占用高</h2><p>有用户发现在使用 pipeline 做只读操作时，redis-server 的内存容量偶尔也会出现明显的上涨, 这是对 pipeline 的使不当造成的。下面先以一个简单的例子来说明 Redis 的 pipeline 逻辑是怎样的。</p>
<p>下面通过 golang 语言实现以 pipeline 的方式从 redis-server 端读取 key1、key2、key3。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">&quot;fmt&quot;</span></span><br><span class="line">    <span class="string">&quot;github.com/garyburd/redigo/redis&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    c, err := redis.Dial(<span class="string">&quot;tcp&quot;</span>, <span class="string">&quot;127.0.0.1:6379&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(err)</span><br><span class="line">    &#125;</span><br><span class="line">    c.Send(<span class="string">&quot;get&quot;</span>, <span class="string">&quot;key1&quot;</span>)       <span class="comment">//缓存到client端的buffer中</span></span><br><span class="line">    c.Send(<span class="string">&quot;get&quot;</span>, <span class="string">&quot;key2&quot;</span>)       <span class="comment">//缓存到client端的buffer中</span></span><br><span class="line">    c.Send(<span class="string">&quot;get&quot;</span>, <span class="string">&quot;key3&quot;</span>)       <span class="comment">//缓存到client端的buffer中</span></span><br><span class="line">    c.Flush()                   <span class="comment">//将buffer中的内容以一特定的协议格式发送到redis-server端</span></span><br><span class="line">    fmt.Println(redis.String(c.Receive()))</span><br><span class="line">    fmt.Println(redis.String(c.Receive()))</span><br><span class="line">    fmt.Println(redis.String(c.Receive()))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而此时 server 端收到的内容为：</p>
<figure class="highlight moonscript"><table><tr><td class="code"><pre><span class="line">*<span class="number">2</span>\r\n$<span class="number">3</span>\r\nget\r\n$<span class="number">4</span>\r\nkey1\r\n*<span class="number">2</span>\r\n$<span class="number">3</span>\r\nget\r\n$<span class="number">4</span>\r\nkey2\r\n*<span class="number">2</span>\r\n$<span class="number">3</span>\r\nget\r\n$<span class="number">4</span>\r\nkey3\r\n</span><br></pre></td></tr></table></figure>

<p>下面是一段 redis-server 端非正式的代码处理逻辑，redis-server 端从接收到的内容依次解析出命令、执行命令、将执行结果缓存到 replyBuffer 中，并将用户端标记为有内容需要写出。等到下次事件调度时再将 replyBuffer 中的内容通过 socket 发送到 client，所以并不是处理完一条命令就将结果返回用户端。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">readQueryFromClient(client* c) &#123;</span><br><span class="line">    read(c-&gt;querybuf) <span class="comment">// c-&gt;query=&quot;*2\r\n$3\r\nget\r\n$4\r\nkey1\r\n*2\r\n$3\r\nget\r\n$4\r\nkey2\r\n*2\r\n$3\r\nget\r\n$4\r\nkey3\r\n&quot;</span></span><br><span class="line">    cmdsNum = parseCmdNum(c-&gt;querybuf)  <span class="comment">// cmdNum = 3</span></span><br><span class="line">    <span class="keyword">while</span>(cmsNum--) &#123;</span><br><span class="line">        cmd = parseCmd(c-&gt;querybuf)    <span class="comment">// cmd:  get key1、get key2、get key3</span></span><br><span class="line">        reply = execCmd(cmd)</span><br><span class="line">        appendReplyBuffer(reply)</span><br><span class="line">        markClientPendingWrite(c)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>考虑这样一种情况：</p>
<p>如果用户端程序处理比较慢，未能及时通过 c.Receive()从 TCP 的接收 buffer 中读取内容或者因为某些 BUG 导致没有执行 c.Receive()，当接收 buffer 满了后，server 端的 TCP 滑动窗口为 0，导致 server 端无法发送 replyBuffer 中的内容，所以 replyBuffer 由于迟迟得不到释放而占用额外的内存。当 pipeline 一次打包的命令数太多，以及包含如 mget、hgetall、lrange 等操作多个对象的命令时，问题会更突出。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>上面几种情况，都是非常简单的问题，没有复杂的逻辑，在大部分场景下都不算问题，但是在一些极端场景下要把 Redis 用好，开发者还是需要关注这些细节。建议：</p>
<ul>
<li>尽量不要使用短连接；</li>
<li>尽量不要在连接数比较高的场景下频繁使用 info；</li>
<li>使用 pipeline 时，要及时接收请求处理结果，且 pipeline 不宜一次打包太多请求。</li>
</ul>
<hr>
<blockquote>
<p>Reference: <a href="https://www.infoq.cn/article/yqUuS2qNRybILGrQUliv">https://www.infoq.cn/article/yqUuS2qNRybILGrQUliv</a></p>
</blockquote>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/redis/redis-performance-issues-cpu.html" target="_blank">Redis常见的CPU和内存性能问题</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/redis/redis-performance-issues-cpu.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Redis Performance</tag>
      </tags>
  </entry>
  <entry>
    <title>做产品为什么要画这些图？</title>
    <url>/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/uml-for-product-manager.html</url>
    <content><![CDATA[<p>经常看到网上有人问，产品经理要画哪些图，怎么画流程图等关于画图的问题。</p>
<p>确实，画图是产品经理必备的硬核技能。然而，画图又不仅仅是画几个图而已。</p>
<p>做产品没有统一、标准的规范指导，容易让人为了画图而画图。</p>
<p>甚至，在很多外行看来，感觉产品经理就是个画图的。</p>
<p>还有人戏称，去大厂当产品经理，就是个画图仔。</p>
<p>幸好，我从最初做项目，就学着用 UML 进行需求分析。受益于此，我渐渐体会到，画图背后的逻辑和意义。</p>
<p>趁这段时间，从画图入手，用自己的理解，总结自己做产品的方法。</p>
<h2 id="当我们画图时，是在画什么"><a href="#当我们画图时，是在画什么" class="headerlink" title="当我们画图时，是在画什么"></a>当我们画图时，是在画什么</h2><h3 id="探寻本源"><a href="#探寻本源" class="headerlink" title="探寻本源"></a>探寻本源</h3><p>在需求分析领域，谈到画图，不能不提 UML 。</p>
<p>早在IT软件时代，UML 就是一套非常好用的需求分析、系统分析设计的工具和方法。</p>
<p><strong>那么，什么是 UML ？</strong></p>
<p>UML（Unified Modeling Language）统一建模语言，是一种用来对软件系统开发的产出进行可视化、规范定义、构造和文档化的面向对象的标准建模语言。这是比较官方的定义。</p>
<p>我理解，它是用一套规范的可视化图形，及建模方法，来描述软件系统的分析、设计等各个阶段，最终形成可视化、文档化的产出。</p>
<p>作为一门语言，UML 在建模过程使用的基本图形元素，就是它的 “ 词汇 ” ，如用例、参与者、类等；而这些元素间的使用规则，好比 “ 语法 ” ，如用例图、活动图便是在这种 “ 语法 ” 指导下绘制的视图。</p>
<p>学习一门语言，既要学习其 “ 词汇 ” ，也要掌握其 “ 语法 ” 的运用，将 “ 词汇 ” 合理组织起来，才能编写足以 “ 传情达意 ” 的 “ 文章 ” 。</p>
<p>UML 中，通过元素、视图建立起来的模型，正是这样一种可准确描述需求，又便于用开发思维去理解的 “ 文章 ” 。</p>
<p>UML 不仅提供了一套工具，还提供了一套思想和方法。</p>
<p>学工具，只能让我们知其然；掌握该工具背后的思想和方法，才能让我们知其所以然、活学活用。</p>
<p>UML 中，将可视化视图分为 “ 静态视图 ” 和 “ 动态视图 ” 。从“ 静 ”和“ 动 ”两个维度，来描述软件系统。</p>
<p>这也是人们描述现实事物的方法。从 “ 静 ” 的方面，描述事物的结构性特征；从 “ 动 ” 的方面，要描述事物的行为性特征。</p>
<p>一静一动相结合，便能把事物全面、准确地描述清楚。</p>
<p>这让我明白，做产品需求分析，也是对需求进行描述和表达。</p>
<p>使用这种方法，从静态、动态两个视角维度去分析和描述需求，就有了指导思想，能提高准确性和效率。</p>
<h3 id="画图的实质"><a href="#画图的实质" class="headerlink" title="画图的实质"></a>画图的实质</h3><p>这就不难理解，<strong>当我们画图时，一方面是在借助工具，对业务、需求、场景等进行梳理；一方面是在对需求、产品进行描述，并输出可视化的材料，供相关人员，阅读使用。</strong></p>
<p>因此，画图，是需求分析的重要组成部分，是用可视化的方式，对需求进行梳理和展示。</p>
<p>产出的可视化图形，是后续产品规划、研发、设计、测试，及优化迭代、问题排查等的重要依据。</p>
<h3 id="本文思路"><a href="#本文思路" class="headerlink" title="本文思路"></a>本文思路</h3><p>UML 中的图形、视图、建模方法等知识内容很多，要深入学习，推荐《 大象：Thinking in UML 》一书。</p>
<p>本文，结合在产品工作用到的内容，及自己的理解、体会，先从整体进行总结，建立一个整体的认知框架，后续再具体深入。</p>
<p>为了方便理解，我结合在资讯、充值等方面的经验，虚构了一个小型 APP 的前端需求，作为案例来分析。从静态、动态两个维度，总结在产品工作中常用的视图。</p>
<p><img src="/images/0007.jpeg"></p>
<h2 id="从静态视角看需求"><a href="#从静态视角看需求" class="headerlink" title="从静态视角看需求"></a>从静态视角看需求</h2><p><strong>从静态的视角去分析需求，是用静态视图，来描述产品的结构性特征，这些结构决定了产品是由什么组成、能做什么、长什么样的。</strong></p>
<p>在 UML 中，静态视图包括用例图、类图、包图。类图与包图，在产品层面较少使用，开发层面更为需要。</p>
<p>结合实际工作，总结产品的静态视图有：<strong>结构图、用例图、无交互的原型图</strong>。</p>
<h3 id="结构图"><a href="#结构图" class="headerlink" title="结构图"></a>结构图</h3><p>结构图，顾名思义就是描述、展示产品的基本结构、框架。它能清晰展示产品有哪些模块、功能或系统组成，它们之间的层级、从属等结构关系是怎样的。</p>
<p>这在需求分析的初始阶段，就要明确。</p>
<p>好比，建一栋楼，需要有建设蓝图，得先知道楼要建多高、地基要挖多深、面积多大、盖多少层等基本的框架信息。</p>
<p>结构图，像一栋楼的框架，那么一旦确立，就很难改，除非推倒重来。所以，一开始一定要搞清楚，避免挖坑。</p>
<p>当然，在基本框架下，随着对需求的不断深挖，各模块、功能、系统之间的结构、层级、从属关系，会更加清晰，结构图也要细化、完善。</p>
<p>根据使用情况，结构图大致可分为：<strong>功能结构图、信息结构图、产品结构图</strong>。</p>
<h4 id="功能结构图"><a href="#功能结构图" class="headerlink" title="功能结构图"></a>功能结构图</h4><p>功能结构图，就是描述产品都有哪些功能，层级和归属关系是怎样的。</p>
<p>这在产品工作中，经常用到。大部分人做产品，都知道在规划产品时，要画功能结构图。</p>
<p>现在用案例来看看这些图是怎么画的。</p>
<p>这个虚构 APP 的需求是：要做一个 APP ，给用户提供电商优惠活动信息、手机话费充值，后续会加更多功能，发展用户体系等。</p>
<p>一般经过需求调研和确认，脑海里就要有个大概的框架，这个 APP 给什么人用的、由哪些功能组成。</p>
<p>这个需求，我只能先脑补需求调研和确认的过程，然后得出这个产品大概要有：首页聚合展示、优惠活动、话费充值、个人中心，这四个大的功能模块。</p>
<p><img src="/images/0008.jpeg" alt="功能结构图"></p>
<h4 id="信息结构图"><a href="#信息结构图" class="headerlink" title="信息结构图"></a>信息结构图</h4><p>信息架构图，跟功能结构图，容易搞混。</p>
<p>其实，有所不同，<strong>信息结构图重点在 “ 信息 ”</strong>。也就是，从信息的维度，将整个产品的信息进行抽象、归类，说明产品包括哪些信息、字段数据。</p>
<p>这有点类似，UML 中的类图。在产品层面，更多是要把产品里面的信息进行整理、归类、描述清楚，特别是信息的类型、条件、规则。比如，标题字数上限、图片尺寸等。</p>
<p>案例中的需求进行抽象，可以得出如下简单的信息结构图。</p>
<p><img src="/images/0022.png" alt="信息结构图"></p>
<h4 id="产品结构图"><a href="#产品结构图" class="headerlink" title="产品结构图"></a>产品结构图</h4><p>产品结构图，网上说法不一，这本来就没什么标准，关键是看怎么理解、怎么用，能把需求准确、清晰地描述出来即可。</p>
<p>个人理解，产品结构图，就是「 功能结构图 」与「 信息结构图 」的结合。</p>
<p>就是在描述功能结构后，把对应功能模块有哪些信息，这些信息字段的定义、规则、条件、类型都列出来即可。</p>
<p>这种做法，更为常用。这个图画出来内容比较多，因为篇（太）幅（懒）关系，这里就不再画，可以自行脑补下。</p>
<h3 id="用例图"><a href="#用例图" class="headerlink" title="用例图"></a>用例图</h3><p>用例图，采用参与者和用例来展现产品的功能性需求，是 UML 中一种很重要的视图。</p>
<p>在 UML 中，将用例图，分为业务用例图和系统用例图。</p>
<p>除了画图，还要写用例规约，以描述说明用例，包括对用例的描述、参与者、前后置条件、基本流程等，一般用表格形式比较清晰。</p>
<h4 id="业务用例图"><a href="#业务用例图" class="headerlink" title="业务用例图"></a>业务用例图</h4><p>业务用例图，是<strong>从业务的视角，通过业务建模，对业务进行描述</strong>。</p>
<p>这里说的业务，是在还没有新系统或产品前，业务是如何进行的。</p>
<p>UML 使用业务用例图，进行业务建模，旨在把业务描述清楚，发现业务问题和难点，这样的新系统才能更好的融入业务去解决问题。</p>
<p>简单的需求，很少画业务用例图；如面对比较复杂、有规模的需求，建议最好用这个思路进行分析，可以更好地发现业务问题，以保证产品需求不跑偏。</p>
<p>案例需求中，就话费充值这个业务，可画成业务用例图如下。</p>
<p><img src="/images/0009.jpeg" alt="业务用例图"></p>
<h4 id="系统用例图"><a href="#系统用例图" class="headerlink" title="系统用例图"></a>系统用例图</h4><p>系统用例图，是对有新系统或产品后，业务又是如何进行的，进行建模描述。它是对业务用例进行分析得到的，是系统的开发范围。</p>
<p>简单看来，「 系统用例图」与「 功能结构图」很类似。</p>
<p>功能结构图，只是从产品或系统层面，描述都有哪些功能。</p>
<p><strong>系统用例图，则是从使用者的角度，描述对应用户能使用产品做什么</strong>。这样的好处，是让我们时刻以用户为中心，思考产品和功能。</p>
<p>好多人，在做产品时，经常做着做着就忘了用户是谁、产品或功能是给谁用的。使用系统用例图，可以帮我们避免这一点。</p>
<p>以下为案例需求的系统用例图。</p>
<p><img src="/images/0010.jpeg" alt="系统用例图"></p>
<h4 id="原型图（无交互）"><a href="#原型图（无交互）" class="headerlink" title="原型图（无交互）"></a>原型图（无交互）</h4><p>原型图，是产品经理最熟悉不过的，也是最常用的。甚至，有不少人，以为做产品就是画原型图，一接到需求，巴不得马上打开 Axure 画图。</p>
<p>众所周知，原型图，是产品表现层面的 Demo ，描绘产品的界面长什么样，功能如何设计、摆放，有哪些内容。</p>
<p>好比，建一栋大楼，需要设计每一层楼的布局，都有哪些房间、大小怎样，到具体每一间房的格局，什么地方设置门、在什么位置安窗户等。</p>
<p>一般来说，无交互的原型图，属于结构图的范畴。在工作中，为了提高效率，很少画交互型的原型，除非像大厂有专门的交互设计师。</p>
<p>画原型，除了要准确把握需求，还涉及一些人机交互、视觉设计的知识。这里不具体展开。案例中的话费充值功能，简单绘制原型参考如下。</p>
<p><img src="/images/0011.jpeg" alt="话费充值页面原型图"></p>
<h2 id="从动态视角看需求"><a href="#从动态视角看需求" class="headerlink" title="从动态视角看需求"></a>从动态视角看需求</h2><p><strong>从动态的视角去分析需求，则用动态视图，来描述产品的行为性特征，这些特征决定了产品是怎样运行的。</strong></p>
<p>在 UML 中，动态视图包括活动图、时序图、协作图、状态图。协作图，在产品层面较少使用。活动图，就是常用的流程图。</p>
<p>结合实际工作，总结产品的动态视图有：<strong>流程图、时序图、状态图</strong>。</p>
<h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><p>流程图，是描述为完成某个目标，需要以什么顺序做哪些动作；能直观描述实现目标过程的具体步骤。在很多领域，被广泛使用。</p>
<p>梳理、绘制流程图的过程，也是一种流程化的思考。</p>
<p>UML 中，流程图，也叫活动图；另外，还有泳道活动图。产品上，都经常使用。</p>
<h4 id="普通流程图"><a href="#普通流程图" class="headerlink" title="普通流程图"></a>普通流程图</h4><p>普通的流程图，就是在描述产品的具体功能，在具体场景下，是怎么一步步实现的运转过程。</p>
<p>普通流程图中，包括了多个不同对象执行的动作事件，<strong>只能大致描述过程；无法将整个过程中，参与的各个对象体现出来</strong>。</p>
<p>案例需求中，从用户感受到的充值过程，用一般的流程图来梳理，可绘制如下。</p>
<p><img src="/images/0012.jpeg" alt="话费充值流程图"></p>
<h4 id="泳道活动图"><a href="#泳道活动图" class="headerlink" title="泳道活动图"></a>泳道活动图</h4><p>泳道活动图，用来梳理、描述有多个对象参与的流程，对象可以是人，也可以是系统。</p>
<p>泳道活动图，在活动图的基础上，引入了泳道，像游泳比赛的运动员只能在其泳道中比赛一样，规定每个对象的动作只能画在其对应区域。</p>
<p>这样，可以很好地体现整个过程参与的多个对象所做的动作和顺序。</p>
<p>同样是用户充值话费的过程，在产品层面，至少有用户、APP、管理后台、话费供应商（这跟每个公司的业务和系统情况有关，但基本逻辑类似。）的参与才完成。</p>
<p>因此，用泳道活动图来描述，最合适不过。为了避免示例图过于复杂，此处仅画出正常流程，并未包括异常分支。</p>
<p><img src="/images/0023.png" alt="话费充值泳道活动图"></p>
<h4 id="时序图"><a href="#时序图" class="headerlink" title="时序图"></a>时序图</h4><p>时序图，<strong>用于描述产品为实现某一具体目标，多个参与对象之间按时间顺序交互的过程</strong>。</p>
<p>时序图，与泳道活动图类似，不同的是，<strong>时序图更强调对象在交互过程中消息事件的发生顺序</strong>00。</p>
<p>有时为了了解系统性能，或优化体验，要统计某些交互的时长，用时序图，就很方便定义和描述。</p>
<p>用时序图来梳理多个系统间的交互过程，特别好用，我最常使用。时序图画得好，泳道活动图不画都没关系。</p>
<p>同样用户充值话费过程，用时序图来梳理，可以对比下与泳道活动图的区别。</p>
<p><img src="/images/0024.png" alt="话费充值时序图"></p>
<h4 id="状态图"><a href="#状态图" class="headerlink" title="状态图"></a>状态图</h4><p>状态图，<strong>用于描述产品为完成某个目标，某个对象的状态变化和流转过程</strong>。状态，是对象执行或等待某个事件的条件。</p>
<p>常见的，有电商的订单状态、快递物流状态、支付状态等。</p>
<p>系统中对象的状态细化和明确，对监控系统的处理过程，和事后问题排查有很大帮助。</p>
<p>状态图非常重要，又很容易被忽略。以前填过很多坑，就是产品没定义好状态，结果开发按自己想象补上了，事后发现问题，处理起来很麻烦。</p>
<p>如案例中，如今的话费充值，虽然到账时间很快，但订单在系统的流转过程，也有各种状态的变化。</p>
<p>下面以此为例，看看一个比较完整的状态图，可以注意下其与流程图的区别。</p>
<p><img src="/images/0025.png" alt="话费充值订单状态图"></p>
<h2 id="原则与工具"><a href="#原则与工具" class="headerlink" title="原则与工具"></a>原则与工具</h2><h3 id="基本原则"><a href="#基本原则" class="headerlink" title="基本原则"></a>基本原则</h3><p>画图，虽说没有标准答案，但毕竟，产出的可视化图形是后续工作的重要依据，也要给各环节的人阅读使用。</p>
<p>所以，为了保证产出质量和工作效率，还是要满足以下基本原则：</p>
<ul>
<li>逻辑合理、清晰</li>
<li>没有疏漏</li>
<li>可读性强</li>
<li>美观</li>
</ul>
<h3 id="善用工具"><a href="#善用工具" class="headerlink" title="善用工具"></a>善用工具</h3><p>画图、分析过程，可用的工具很多，只要功能满足我们的需要，用起来顺手即可。</p>
<p>另外，一定要善于利用工具，让工具为我们所用，可找准一两个工具，用好它，能大大提高效率。</p>
<p>比如，Axure 就非常强大，不仅画原型图，大部分图都可用它完成。</p>
<p>甚至，还能用来写需求文档，这样输出的文档相对统一，便于管理和阅读。</p>
<p>其他常用的，有 Visio ，及专门画思维导图的 MindManager、XMind 等。</p>
<p>其实，只要掌握了方法，哪怕是用纸和笔，照样能描述清楚。</p>
<h2 id="回顾总结"><a href="#回顾总结" class="headerlink" title="回顾总结"></a>回顾总结</h2><p>总结一下，做产品为什么要画这些图？</p>
<p><strong>首先，得明白，为什么要画图？</strong></p>
<ul>
<li>因为，画图，是需求分析的重要环节，是用可视化的方式，对需求进行梳理和展示。</li>
<li>能帮助我们梳理、分析需求，更好地理解和分析清楚需求</li>
<li>能产出可视化的需求描述，便于阅读使用。</li>
</ul>
<p><strong>其次，得知道，为什么画这些图？</strong></p>
<ul>
<li>因为，画图，有一定的指导思想和方法，能提高准确性和效率。</li>
</ul>
<p>UML 提供了很好的思想和方法，可以从产品的静态和动态两个视角进行描述。</p>
<p>由此，有了静态和动态两种视图，每个视图有对应的图形，供不同情况使用。</p>
<p><strong>静态视图，描述产品的结构，决定产品是由什么组成、能做什么、长什么样的，包括：</strong></p>
<ul>
<li>结构图：功能结构图、信息结构图、产品结构图</li>
<li>用例图：业务用例图、系统用例图</li>
<li>原型图（无交互）</li>
</ul>
<p><strong>动态视图，描述产品的行为，决定了产品是怎样运行的，包括：</strong></p>
<ul>
<li>流程图：普通流程图、泳道活动图</li>
<li>时序图</li>
<li>状态图</li>
</ul>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/uml-for-product-manager.html" target="_blank">做产品为什么要画这些图？</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/uml-for-product-manager.html]]></content>
      <categories>
        <category>产品经理</category>
      </categories>
      <tags>
        <tag>产品经理</tag>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title>关于产品需求阶段的思维公式</title>
    <url>/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/user-demands-howto.html</url>
    <content><![CDATA[<blockquote>
<p>编辑导语：需求是一款产品在开发过程中始终需要面对的重要因素，那么需求从哪儿来？在对需求进行分析时又有哪些误区？本文作者对以上问题进行了解答，并且推导出了“需求”环节的思维公式。</p>
</blockquote>
<p>前段时间，我跟几位产品新同学讨论一个问题，产品经理的职责是什么？大家七嘴八舌说了很多，有的说项目管理、有的说功能设计、有的说用户调研，当然，这些都是，其中有个同学回答说：“做需求”，产品经理就是一个做需求的。</p>
<p>我就问他，为什么是做需求呢，他说每一个需求，都是以上这些内容的总和，每一个需求，都包含了用户调研、功能设计、项目管理、资源协调，所以说，产品经理就是做需求的，这没毛病。</p>
<p>可是，做需求只是表象，再往深了想，做需求，其实也是为了解决用户或者客户的实际问题。因此，我觉得说产品经理的职责是「解决问题」，更准确一点。“解决问题”是产品经理的职责，“做需求”是产品经理工作的主要内容。</p>
<p>那我们就说说“需求”。</p>
<p>需求这个话题聊的人太多了，不少前辈、大佬、专家，都深入阐述过，产品新人入门导师苏杰、刘飞、王诗沐、俞军几位老师，在他们的著作中，也用了大量的篇幅来讲需求。站在前人的肩膀上，结合自己的一些思考，我也想同读者分享一下，我对于“需求”的理解。</p>
<p>本文从需求的概念、需求的科学理论，到需求的来源，结合做需求过程中的常见误区，最后推导出“需求”环节的思维公式。全文万字，可能是非常完善的“需求”通识文章了，收藏转发再细看。</p>
<h2 id="一、需求是什么？"><a href="#一、需求是什么？" class="headerlink" title="一、需求是什么？"></a>一、需求是什么？</h2><p>生活中，我们经常会有一些行为，这些行为背后，是因为我们有相应的诉求。</p>
<ul>
<li>临近夏天，天气越来越热，走在街上，忍不住买一根雪糕；</li>
<li>买了一屋子盲盒；</li>
<li>认识到学习的价值，购买了很多付费课程。</li>
</ul>
<p>以上三个案例，都是最后表现出来的行为。这种行为，分别对应着各自的诉求：买雪糕是因为热，想要获得降温快感的诉求；买盲盒是满足收集欲和好奇心的诉求；买课程是为了满足提升能力、缓解焦虑，然后找到更好工作，或者升值加薪的诉求。</p>
<p>这个“行为背后的诉求”，其实就是需求。所以我们可以给需求下一个定义：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">需求是行为背后的诉求。</span><br></pre></td></tr></table></figure>

<p>基于这个定义，我们可以发现，任何行业，其实都有需求的概念，需求这件事，不仅仅存在于互联网产品上，其他的建筑行业、汽车行业、纺织行业等等，都同样通过挖掘用户背后的需求，来实现产品的创新和进步。</p>
<p>对应到产品经理的职业上，我们这个“做需求”，做的是什么“需求”？</p>
<p>产品经理成长过程中，一套思考的全流程，应该是：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">归纳现象-发现问题-拆解问题-分类问题-提出解决方案-回归分析-发现新问题。</span><br></pre></td></tr></table></figure>
<p>简化来讲，就是：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">发现问题——归纳核心痛点——解决方案。</span><br></pre></td></tr></table></figure>

<p>这其中的“解决方案”，就成了产品经理工作中所要完成的需求。这是产品经理接触最多的工作内容，也是产品工作的核心。只有通过优雅高效的解决方案，才能真正解决用户痛点，实现产品经理存在的价值。</p>
<h2 id="二、两个需求理论"><a href="#二、两个需求理论" class="headerlink" title="二、两个需求理论"></a>二、两个需求理论</h2><p>正因为“需求”是一个常悟常新的话题，在绵延的历史长河中，也有很多经典的、历久不衰的需求理论。对于产品经理，有两个非常经典的需求理论，就是<code>“马斯洛需求层次理论”</code>和<code>“KANO模型”</code>。</p>
<h3 id="马斯洛需求层次理论"><a href="#马斯洛需求层次理论" class="headerlink" title="马斯洛需求层次理论"></a>马斯洛需求层次理论</h3><p><img src="/images/0006.png" alt="马斯洛需求层次理论"></p>
<p>马斯洛需求层次理论就不用多说了，初高中的时候课本里就提到过。马斯洛把一个人的需求分为生理需求、安全需求、社交需求、尊重需求和自我实现的需求。</p>
<p>一般来说，这五个需求映射到产品上，则越是金字塔底部的需求，需求面越大，但ARPU可能越小，比如肚子不饿的生理需求，10块钱的炒粉就可以满足。</p>
<h3 id="KANO模型"><a href="#KANO模型" class="headerlink" title="KANO模型"></a>KANO模型</h3><p><img src="/images/0007.png" alt="KANO模型"></p>
<p>KANO模型，是东京理工大学教授狩野纪昭(Noriaki Kano)发明的对用户需求分类和优先排序的有用工具，以分析用户需求对用户满意的影响为基础，体现了产品性能和用户满意之间的非线性关系。</p>
<p>KANO模型把产品需求分成五类：</p>
<h4 id="1-基础型需求"><a href="#1-基础型需求" class="headerlink" title="1. 基础型需求"></a>1. 基础型需求</h4><p>基础性需求是一个产品最基础的功能，这个需求不能够被满足，则产品就不能正常使用，比如IM软件的打字聊天功能，美颜软件的拍摄功能等等。</p>
<h4 id="2-期望型需求"><a href="#2-期望型需求" class="headerlink" title="2. 期望型需求"></a>2. 期望型需求</h4><p>期望型需求的效果，是让用户满意度提升。比如微信聊天中的表情包，用户期望有一种俏皮的、不局限于文字的聊天方式，表情包恰好满足了用户这一点。</p>
<h4 id="3-兴奋（魅力）型需求"><a href="#3-兴奋（魅力）型需求" class="headerlink" title="3. 兴奋（魅力）型需求"></a>3. 兴奋（魅力）型需求</h4><p>兴奋型需求也称为魅力型需求，是超出用户预期的，让用户满意度大幅提升的需求。比如微信的“拍一拍”和动态表情，用户并没有这个功能的预期，但微信做出来之后，大家也玩儿得不亦乐乎。</p>
<p>还有当年的微信红包，用户突然发现微信中就可以直接发红包了，足不出户，就能完成拜年互动，于是，一个春节，借着红包的力量，微信支付一下子成为可以比肩支付宝的支付平台。</p>
<p>值得注意的是，<strong>这五种需求类型，并不是一成不变的，随着行业的进步，他们之间可能会发生转变</strong>。比如微信红包在刚推出时，属于魅力型需求，但随着红包成为趋势，用户也要求其他社交产品做红包功能，这就变成了期望型需求。</p>
<h4 id="4-无差异型需求"><a href="#4-无差异型需求" class="headerlink" title="4. 无差异型需求"></a>4. 无差异型需求</h4><p>无差异性需求则是用户并不在意的需求，无论有或没有，用户体验都并不会产生较大的影响，用户满意度也并不会提高或降低。</p>
<p>做无差异性需求看似是一个鸡肋的、无意义的行为，但在当下互联网产品大幅度内卷的情况下，几乎每个平台类APP都在疯狂堆砌这些功能，试图抢占用户时间——打车软件做团购、团购软件做打车、地图软件做购物、工具软件做内容，这大抵就是做产品的岐路罢（当然，实际上也有公司战略的考虑）。</p>
<h4 id="5-反向型需求"><a href="#5-反向型需求" class="headerlink" title="5. 反向型需求"></a>5. 反向型需求</h4><p>顾名思义，反向型需求就是做了之后，用户体验和用户满意度会下降的需求。在这里我忍不住要吐槽知乎，现在的知乎，充斥着各种小故事小短文，最关键的是，小故事读着正爽，来了一句“最低0.3元/天开通会员，查看完整内容”，掐死知乎的心思都有了。</p>
<p>值得一说的是，现在的互联网产品中，反向型需求一般是因为商业诉求同用户体验产生了矛盾，做产品是为了盈利，追求效益无可厚非，而<strong>产品经理，就要在商业诉求和用户体验中反复横跳，做放纵与克制间的守夜人</strong>。</p>
<h3 id="马斯洛-vs-KANO"><a href="#马斯洛-vs-KANO" class="headerlink" title="马斯洛 vs KANO"></a>马斯洛 vs KANO</h3><p><strong>马斯洛需求层次理论，说得是人性。KANO模型，对应着产品功能。</strong>这两个理论经过多年的发展，其内涵已经足够丰富，许多新的产品理论，也大多脱胎于类似的理念，异曲而同工。</p>
<p>这些“新产品理论”中，梁宁老师格外推崇的“痛点爽点痒点”理论，是非常热门的概念。</p>
<ul>
<li><strong>痛点是恐惧</strong>，上班马上就迟到，迟到就要被扣工资，这时候地铁口有一辆共享单车，非常及时地解决了即将迟到的恐惧，这就是痛点；</li>
<li><strong>爽点是即时满足</strong>，周六的早晨一觉醒来已经是中午，依然不想起床，躺在床上动动手指，外卖就送到家门口，暂时的快乐得以满足，这就是爽点；</li>
<li><strong>痒点是虚拟自我实现</strong>，看着直播里的小姐姐，甜甜地说giegie你好厉害，你立刻幻想到了迎娶白富美，马上一个火箭送出去，这就是因为满足了用户对于自己的虚拟想象，最近特别流行的“头上长摄像头”短视频，也是一样的道理。</li>
</ul>
<h2 id="三、需求从哪儿来？"><a href="#三、需求从哪儿来？" class="headerlink" title="三、需求从哪儿来？"></a>三、需求从哪儿来？</h2><p>了解了需求是什么，也学习了关于需求的理论，作为一名产品经理，归根结底还是要执行力。那落到操作层面，需求到底从哪儿来？</p>
<p>需求的来源有很多很多，我把它们先归为两类：一类是正经来源，另一类是不那么正经的来源。</p>
<p><img src="/images/0008.png"></p>
<h3 id="1-需求的正经来源"><a href="#1-需求的正经来源" class="headerlink" title="1. 需求的正经来源"></a>1. 需求的正经来源</h3><p>在我看来，需求的正经来源，只有两个：用户和数据。</p>
<h4 id="1）需求来源于用户"><a href="#1）需求来源于用户" class="headerlink" title="1）需求来源于用户"></a>1）需求来源于用户</h4><p>这是一句每个产品经理都信口拈来的话。产品的存在，就是为了解决用户的问题，用户所面临的这些问题，肯定都得从用户当中去发现。而对于产品来说，需求阶段是整个产品生命周期中的孕育期，需求能否准确命中，决定着一个功能乃至一个产品的生死。</p>
<h4 id="2）需求同样也来源于数据"><a href="#2）需求同样也来源于数据" class="headerlink" title="2）需求同样也来源于数据"></a>2）需求同样也来源于数据</h4><p>在数据时代的今天，每一个人都是数据大网下的一个节点，最关键的是，通过用户的数据，能够更好地发现用户的群体行为，从而找准大多数用户的真正需求。某种意义上来讲，数据中找到的用户需求，比直接和用户访谈、调研得到的数据更真实。</p>
<p>为什么需求要来源于数据？是因为，“用户”是会骗人的呀。业内有一个非常经典的栗子：</p>
<blockquote>
<p>索尼要为一款即将面市的游戏机做一个调研，请了很多目标用户来公司，收集用户对于样品的反馈，其中一项就是询问用户希望这款游戏机是什么颜色（有黄色及黑色），很多人在被问及这个问题时，都答了黄色，索尼就认为，黄色的游戏机更收欢迎。但最后，访谈结束时，索尼公司提出，用户可以从门口随意挑选一个颜色的游戏机带走，以感谢他们参加此次用户访谈，结果时候统计数据却发现，用户们在实际挑选时，纷纷选择了黑色的游戏机。</p>
</blockquote>
<p>用户调研的需求具体生动，但有可能因为样本太小并不真实；数据分析得到的用户行为，样本足够统计准确，却略显僵硬并不鲜活。其实，在做产品需求的过程中，用户和数据，都是为了更好地满足用户需要，应当两种来源结合使用、交叉验证。</p>
<p><strong>用户是微观，定性；数据是宏观，定量。</strong></p>
<h3 id="2-需求的不正经来源"><a href="#2-需求的不正经来源" class="headerlink" title="2. 需求的不正经来源"></a>2. 需求的不正经来源</h3><p>虽然严格来说，用户需求都来源于用户和数据，但其实在真正的产品工作中，也有很多需求是来源于其他渠道，毕竟生活和工作不可能时时刻刻都处在理想状态。</p>
<p>我之所以称它们为“不正经来源”，倒也不是说这些来源不好，而是表示，它们不像用户和数据这样“掉书袋”“科班理论”。</p>
<p><img src="/images/0009.png"></p>
<h4 id="1）竞争对手"><a href="#1）竞争对手" class="headerlink" title="1）竞争对手"></a>1）竞争对手</h4><p>实际工作中，确实很多需求，都来源于竞争对手。“我们为什么要做这个功能？是因为竞品这么做啦！这个功能为什么这样做？是因为竞品就是这么做哒！”这种想法当然不对，但也不是说，做需求不能看竞品。</p>
<p>相反，持续进行竞品的监控分析，能够获得很多需求灵感，而且，竞品的新功能也是在付出成本帮助我们去做验证，如果效果OK，那我们去借鉴参考，也不是什么坏事。所以，<strong>需求来源于竞争对手，核心在于思考竞品为什么这么做，我们可以从中学习什么优点，辩证批判地看待竞品的动作。</strong></p>
<h4 id="2）产品经理拍脑袋"><a href="#2）产品经理拍脑袋" class="headerlink" title="2）产品经理拍脑袋"></a>2）产品经理拍脑袋</h4><p>不得不说，挺多需求确实是拍脑袋拍出来的……<strong>原因挺多的，但也要尽量避免</strong>。</p>
<h4 id="3）协同部门"><a href="#3）协同部门" class="headerlink" title="3）协同部门"></a>3）协同部门</h4><p>尤其是体量比较大的产品，产品经理距离客户/用户的距离，其实没有那么近，一线的很多用户反馈，往往并不能直接传达给产品团队，大多数情况下，是销售、客服、市场等协同部门的同事去响应。所以，协同部门就会定期向产品团队反馈需求。</p>
<p>协同部门提出的需求，一般分为两类，一类是“用户希望怎样”，一类是“我们（协同部门）希望怎样”。</p>
<p>前者，是一线协同部门把用户反馈过来的问题，传递给产品团队；后者，则是一线部门为了自身的KPI或者工作量，而提出的需求，比如销售部门为了更好的售卖产品，就会不断反馈要求获得产品中更多的入口、更多的弹窗。</p>
<p><strong>针对协同部门的需求，产品经理要做的，首先是要分类整理，判断哪些需求是产品真实存在的问题，哪些是协同部门对于产品规则理解不深刻的问题。针对用户真实存在的问题，又要往深层次思考，用户的核心诉求是什么，进而根据优先级，提出产品方案。</strong></p>
<h4 id="4）客户直接提出的功能需求"><a href="#4）客户直接提出的功能需求" class="headerlink" title="4）客户直接提出的功能需求"></a>4）客户直接提出的功能需求</h4><p>有时候客户或者用户反馈问题时，会直接提出一些具体的功能建议：希望在XXX处做一个XXX功能。这个来源能够收到的需求非常多，毕竟“人人都是产品经理”嘛，每个人都能对产品提点功能建议。</p>
<p>针对这种来源的需求，产品经理要做的，不是照单全收，而是得认真归类分析，找到问题背后的真实来源，进而提出优雅的产品解决方案。用户很热，想买雪糕，但她正好在姨妈期，如果直接听用户的，就会导致她肚子疼，这个时候，产品经理可以带她去吹空调，解决“热”的问题。</p>
<p>“热”是核心问题，“吃雪糕”和“吹空调”都是解决方案，选择哪个解决方案，要结合具体的情况而定（风险提示：这里就是举个例子，谈恋爱不能太“产品思维”）。</p>
<p>你看，同样是用户提出的反馈，认真分析后找出需求，就叫用户访谈，就是正经的需求来源；不加分析直接采用，就是不正经的需求来源，容易踩雷，你说有不有趣。</p>
<p>话说回来，这些不正经来源，其实深溯一下，很多也还是来源于用户和数据。比如需求来源于竞争对手，其实只不过是竞争对手的产品经理完成了需求收集，这个需求，来源于竞争对手的用户；需求来源于客户的具体建议，那也是表达出客户对于当前功能的不满，这种不满背后是什么样的原因，这个原因就是真正的需求。</p>
<blockquote>
<p>无论是需求来源于老板还是竞争对手，产品经理都应该想一想，这个需求到底是从何而来。老板提出了这个需求，那老板是出于什么样的考量？看似降低了这一个小功能的体验，但有没有可能，是为了全公司战略的联动？竞争对手做了这个功能，有没有可能这就是竞争对手的产品经理拍脑袋拍出来的，我们到底要不要跟进？</p>
</blockquote>
<h2 id="四、需求的误区"><a href="#四、需求的误区" class="headerlink" title="四、需求的误区"></a>四、需求的误区</h2><p>既然明确了需求的来源，我们就可以推导出，一个需求的思维公式，从而快速准确地找到核心需求。但在归纳之前，我们不如先用一种逆向思维，来看看“需求”阶段中的错误示范，五个常见的需求误区，这能够帮助我们更好的理解需求，避免走上弯路。</p>
<h3 id="1-误区一：自己代表用户"><a href="#1-误区一：自己代表用户" class="headerlink" title="1. 误区一：自己代表用户"></a>1. 误区一：自己代表用户</h3><p>前段时间有一个问题讨论得特别火，“产品经理要不要变成自己产品的用户？”有正方认为产品经理只有是产品的核心用户，才能更好地找到目标用户的痛点；反方则认为，对于产品经理来说，冷峻理智地站在上帝视角，才是把产品做好的重要法门。</p>
<p>其实对于这个问题，往深层次思考其实是<strong>产品经理的同理心</strong>。</p>
<p>产品经理既需要客观全面的看待整个产品，也需要瞬间把自己切换到用户视角来提升体验和发现漏洞，对用户有同理心，能够站在用户的视角看待需求。产品经理本身就是这样一个反复跳转的角色，小白用户、资深用户、产品上帝、老板视角，等等等等，这些角色可能每天都要转变几十次。</p>
<p>用户视角看产品，是发现产品问题的一个妙招，但过于依赖这个办法，就会走火入魔。很多产品经理恰好是自己产品的受众，这是一件非常幸运和幸福的事情，但这种情况下，就要格外注意，<em>你要做的功能，是你自己的需求，还是用户的需求？</em></p>
<p>在产品经理自认为自己是目标用户后，往往会陷入“我自己就是用户，我能代表目标用户群体”这个死胡同当中。最后的结果当然是一场赌博，意外命中了群体需求，那就赚了；如果没赌中，可能就是一个鸡肋的功能，在后期做减法的时候痛不欲生。</p>
<p>这个误区归根结底还是需求调研不充分的问题，依赖主管臆断，陷入经验主义，导致需求偏向。</p>
<h3 id="2-误区二：确定了产品强行找用户"><a href="#2-误区二：确定了产品强行找用户" class="headerlink" title="2. 误区二：确定了产品强行找用户"></a>2. 误区二：确定了产品强行找用户</h3><p>有人可能会觉得，这是一个很低级的问题，但就是这样一个低级的问题，几乎每时每刻都在发生。</p>
<p>理想主义的产品经理会以为，一个需求一定要来源于用户痛点，但现实是，每天都有无数的产品或功能，是因为老板拍脑袋、公司要求强行创新、KPI压力负重、业务战略需要、圆之前融资画得大饼，而匆匆上马的。</p>
<p>我之前做过一个产品，是因为老板觉得小众音乐在未来很有市场，应该做一个产品提前占位，就立项了一个创新项目。先定了小众音乐这条赛道，才开始想满足什么需求，甚至才开始为了这个已经定好了方向的项目招聘产品经理。</p>
<p>但现实情况是，产品的痛点和需求并非源自实际的用户群体，只能根据竞品先做了一些功能，然后开始想，哪些用户可能喜欢这些功能，这样倒推回来，确实能够找到一个差不多的目标用户群体写在MRD、PRD里。但事实呢，这些“先有了功能后定下来的目标群体”本身没有任何的动力使用产品。结局自然是可预料的，公司砸钱砸出来几万用户，补贴一停用户就流失，产品就这么不了了之，后来业务调整裁撤了。</p>
<p>需求还是一定要来源于用户的，即使是来自老板的要求，也得在公司战略和用户痛点当中尽力周旋，<strong>先有需求后有产品，这个顺序不能乱</strong>。</p>
<h3 id="3-误区三：只抓住表象，不能深层次思考需求背后的动机"><a href="#3-误区三：只抓住表象，不能深层次思考需求背后的动机" class="headerlink" title="3. 误区三：只抓住表象，不能深层次思考需求背后的动机"></a>3. 误区三：只抓住表象，不能深层次思考需求背后的动机</h3><p>在拿到一个需求时，我们要思考，这个需求深层次的动机是什么。</p>
<p>我刚做产品的时候，经常会被用户提得反馈牵着走，用户经常会说，“这个功能有问题，应该这样做那样做”，我一听还觉得挺有道理，就被带跑了。但其实不应该这样，用户或者老板在提出一个需求的时候，我们要深层次地想一想，<strong>他们为什么提出这个需求，是有更多的期待没有被满足，还是这个功能的流程逻辑有漏洞</strong>。</p>
<p>用户的需求反馈往往带着主观的影响，一些有想法的用户在提反馈的时候，也会带上一个设想的解决方案，毕竟“人人都是产品经理”，但作为职业的产品经理，还是要理智地思考思考，把需求背后的动机挖掘出来，才能解决更核心的问题，才能提高更多用户的体验。</p>
<p>之前在写互联网销售的文章中，我引用过“卖钻讲孔”的故事，其实这个故事是从王诗沐老师的《幕后产品》中学到的。</p>
<p>客户要买一个钻头，我们应该看到他买钻头是想打一个孔，他的真正需求是打孔，我们如果能够给他提供一整套打孔的解决方案，是不是更加符合客户的心意？这样深挖需求动机的思考，是职业产品经理所不能绕开的。</p>
<h3 id="4-误区四：以偏概全，以孤例代表整体，陷入小众用户的自我束缚"><a href="#4-误区四：以偏概全，以孤例代表整体，陷入小众用户的自我束缚" class="headerlink" title="4. 误区四：以偏概全，以孤例代表整体，陷入小众用户的自我束缚"></a>4. 误区四：以偏概全，以孤例代表整体，陷入小众用户的自我束缚</h3><p>对于产品经理来说，因为产品要服务的用户很多，即便都是同一类目标用户，也会因为用户的圈层而产生需求的差异。产品经理不可能面面俱到每一个用户，因此就必然要在功能上予以取舍。</p>
<p>小众用户的需求是需求吗？当然是，即使是小众的需求，也应当纳入产品经理的需求池当中。</p>
<p>但是否要做、什么时候做、怎么做，这三个问题还是要想清楚。相对于“自己代表用户”这个误区，小众需求确实是命中了需求，但小众需求无法与大众市场相连接，从更宏观的视角来看，性价比并不高。</p>
<p>做一些小众需求，的确能够产生比较不错的口碑，但把过多的精力和资源放在小众需求上，某种程度也是在伤害主流用户的体验。<strong>需求的把握同样需要遵循二八法则，即优先满足80%用户的主流需求，优先考虑更大众化的痛点，保证大多数用户的体验。</strong></p>
<p>至于小众需求怎么处理，有两种思路。<strong>一种是先暂时延期，等到大众需求基本满足，产品主流用户增量见顶，开始寻找额外增量的时候，通过满足小众群体的需要，来寻求产品突破点；另外一种则是找到小众需求和大众需求的相通之处，深入挖掘深层次需要，既提高了主流用户的体验，同时也用一种更加优雅的方式解决了这些小众需求。</strong></p>
<h3 id="5-误区五：需求确实存在，但不符合产品整体目标"><a href="#5-误区五：需求确实存在，但不符合产品整体目标" class="headerlink" title="5. 误区五：需求确实存在，但不符合产品整体目标"></a>5. 误区五：需求确实存在，但不符合产品整体目标</h3><p>我们常说产品经理是CEO的预科班，做一家公司，必须要明确公司的目标、愿景，对于一个产品来说，思考它的整体目标是一件至关重要的事情。</p>
<p>正如前面所说，产品经理会面临各种各样的需求，有真需求、有伪需求，有大众需求、有小众需求，有商业需求、有性能需求，面对这么多需求，如何取舍如何排序就是一个关键的问题。</p>
<p>对于这些数不清的待办需求，产品经理要做到心中有数。需求池当中的这个需求，能否在产品长期目标的主线上发挥作用；如果需要开启一个支线的产品目标，那这个支线的投入和产出又是如何。产品经理不仅要为用户体验负责，也需要对产品良性发展负责。</p>
<p>可能会有同学说，思考产品长期目标是产品总监的事情，新手期产品经理做好自己的事情就可以了。但其实，即使初级产品经理没有权力做出产品目标的相关决策，至少也可以把自己放在更高的视野做做沙盘推演，学会用更大的视野思考整条业务线的宏观目标，对于一个产品经理的成长，会非常有帮助。</p>
<h2 id="五、需求的思维公式"><a href="#五、需求的思维公式" class="headerlink" title="五、需求的思维公式"></a>五、需求的思维公式</h2><p>我们根据需求的定义、来源、误区，可以抽象出需求的思维要素。我给出这样一个公式：</p>
<figure class="highlight fix"><table><tr><td class="code"><pre><span class="line"><span class="attr">需求</span>=<span class="string">目标人群+场景+痛点/问题+解决方案</span></span><br></pre></td></tr></table></figure>

<p><img src="/images/0010.png"></p>
<p>一个完整的需求，应当是有特定的目标人群，在特定的场景下，发现特定的问题，并提出针对这个问题的解决方案。</p>
<p>任何一个需求，都不能脱离这四个组成部分。</p>
<h3 id="1-目标人群"><a href="#1-目标人群" class="headerlink" title="1. 目标人群"></a>1. 目标人群</h3><p>目标人群代表着“什么人”的问题。任何一个产品，都一定是面向某一个群体，而不是面向所有人，因为人和人的诉求，不可能完全一致，会因为性别、年龄、学历、收入水平、从事行业等许多因素，产生差异。因此，一个需求面向的人群一定是有一个范围的，比如“找互联网工作的人”“骑行爱好者”等等。</p>
<h3 id="2-场景"><a href="#2-场景" class="headerlink" title="2. 场景"></a>2. 场景</h3><p>即使是圈定了目标人群，也并不能说，这个目标人群的用户群体在任何时刻都存在这个需求，场景就是“什么时候”有这个需求。就以打电话这个需求为例，打电话是“需要和他人远程沟通”这个场景下的诉求，其他时候，用户是不需要打电话这个功能的，我们不能苛求用户所有时刻都在打电话。</p>
<p>场景还有一个重要特性，就是用户具体怎么使用这个功能。比如用户在支付时进行扫码，就是在“支付”场景下，用了“扫一扫”的功能。</p>
<p>有时候，用户天然产生的场景不够多，那我们就可以创造场景，比如支付宝为了更多的使用场景，投资了哈罗单车，提供了支付宝直接扫码就可以骑车的功能，于是，就创造出了一个新的使用支付宝扫一扫的场景。</p>
<h3 id="3-痛点-问题"><a href="#3-痛点-问题" class="headerlink" title="3. 痛点/问题"></a>3. 痛点/问题</h3><p>明确了目标人群和场景，还要知道，这一些人在这个场景下，遇到了什么问题，只有把问题找准了，才不会马屁拍在马蹄子上。</p>
<p>比如：西二旗上班的白领（目标人群），出了地铁口距离公司还有一公里，马上就要迟到了（场景），走路来不及，打车打不到（遇到的问题）。这个时候，帮助用户快速到达公司不至于迟到，就是要解决的问题。</p>
<h3 id="4-解决方案"><a href="#4-解决方案" class="headerlink" title="4. 解决方案"></a>4. 解决方案</h3><p>找到了问题，那就要提出需求中最核心的“解决方案”，产品终归是要解决用户问题的，要不然，找到了一堆问题，一个都不解决，那依然没什么用。这一群人，在这个场景下，遇到了问题，你打算用什么方法解决。</p>
<p>值得注意的是，解决方案不一定有一个，而且大多数情况下，是有多个。产品经理就要在这多个解决方案中，找到最合适的那个。</p>
<p>还是白领迟到这个例子，最后一公里，走路来不及，打车打不到，我们可以给一个共享单车的解决方案，也可以给通勤摆渡车的解决方案。分析之后发现，上班高峰容易堵车，摆渡车依然有迟到风险，所以，最后给用户提供了共享单车的解决方案，帮助用户解决了问题。</p>
<p>一般情况下，大部分需求，都可以用这个思维公式进行提炼。但任何产品理论都是教科书式的知识，在实际工作中，还是要灵活应用，具体问题具体分析。</p>
<p>以上，就是关于“需求”模块下，我的总结、分析和思考，逐渐形成的一点小体系。但依然不够完善，我也会在后面的工作中，持续反思完善。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/user-demands-howto.html" target="_blank">关于产品需求阶段的思维公式</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/user-demands-howto.html]]></content>
      <categories>
        <category>产品经理</category>
      </categories>
      <tags>
        <tag>产品经理</tag>
        <tag>需求</tag>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>B端产品人为什么总说“我不关注用户体验”</title>
    <url>/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/user-experience-in-tob-products.html</url>
    <content><![CDATA[<blockquote>
<p>编辑导语：很多时候产品对于用户体验都是非常看重的，互联网人在设计产品时，需要考虑到各方面的体验；但有人会觉得B端产品不用在乎用户体验，为什么会有这样的想法呢？本文作者分享了关于B端对用户体验的看法，我们一起来了解一下。</p>
</blockquote>
<p>互联网行业的崛起，衍生出了很多专业术语，“用户体验”就是其中一个。</p>
<p>用户体验被当成“新时代的工匠精神”，并在以腾讯、字节、阿里为首的一线互联网大厂持续践行的过程中，逐渐成为互联网人所关注和接受的设计理念。</p>
<p>可近两年崛起的B端产品，却截然相反，不仅表现出不重视用户体验，甚至有人宣称“做B端产品，并不需要用户体验”。</p>
<p>而这个理由，居然吸引了不少在C端行业，排斥强化用户体验的年轻人，转向了B端产品的怀抱中。</p>
<p>可事实上，我们的B端产品真的不关注用户体验吗？</p>
<p>如果不是的话，那为什么B端产品经理总说“我不关注用户体验”呢？</p>
<p>我将从岗位职能、决策过程、关注内容这三个角度上，来谈谈下我对这句话的理解。</p>
<h2 id="一、做B端行业就可以不需要关注用户体验了？"><a href="#一、做B端行业就可以不需要关注用户体验了？" class="headerlink" title="一、做B端行业就可以不需要关注用户体验了？"></a>一、做B端行业就可以不需要关注用户体验了？</h2><p>随着互联网行业的发展，产品岗被逐步衍生并细化出来（如下图所示）</p>
<p><img src="/images/0005.png"></p>
<p>产品经理总的来说可分为B端和C端，这里划分的依据是看这款产品，主要是为谁而设计的。</p>
<p>如果是为每一个独立个体服务的产品，就属于C端产品，而为每个企业、公司、甚至有经营资格的小微商户服务的产品，就属于B端产品。</p>
<p>而对应的C端和B端之下，根据行业和岗位职能的不同，也可以划分出很多不同带有“前缀”的产品经理。</p>
<p>可在实际工作中，我们的划分，有时候并没有清晰可见的界限。</p>
<p>C端的产品，有可能也需要从B端客户角度去思考业务，同样，B端的业务，有可能也需要从C端用户的角度去思考方案。</p>
<p>如淘宝，在用户使用app的页面上，也可能需要考虑到商家使用后台的设计；</p>
<p>同样，钉钉的产品经理，在客户端的设计上，也可能需要考虑每一个公司下，每一个实际用户，如何使用产品更舒服。</p>
<p>所以，刚入行的新同学，如果认为做B端产品，可以不需要关注用户体验的话，其实是不太正确的观点。</p>
<p>我们所有的工作，都是以业务为导向的。即，我们在什么行业，为谁，做什么方案，能够提升产品价值，提高团队的收益。</p>
<p>除此之外，产品是否关注用户体验，也会随着产品的生命周期而不断变化。</p>
<p>不论是B端还是C端产品，发展到相对成熟的阶段，或者说拥有足够体量的用户/客户的时候，在产品的设计上，都是会关注产品使用者的使用体验。</p>
<p>所以，如果你认为做B端业务，就可以避免扣细节和抠体验，这类繁琐工作的话。我劝你，还是趁早打消这个念头吧。</p>
<p>想通过转行来偷懒，不仅是在互联网行业，而是任何行业，都行不通。</p>
<h2 id="二、为什么B端产品会说“我不关注用户体验”"><a href="#二、为什么B端产品会说“我不关注用户体验”" class="headerlink" title="二、为什么B端产品会说“我不关注用户体验”"></a>二、为什么B端产品会说“我不关注用户体验”</h2><p>在正式回答这个问题之前，我们得先了解下，为什么C端产品需要关注用户体验。</p>
<h3 id="1-C端产品：从无到有，从有到优的竞争模式"><a href="#1-C端产品：从无到有，从有到优的竞争模式" class="headerlink" title="1. C端产品：从无到有，从有到优的竞争模式"></a>1. C端产品：从无到有，从有到优的竞争模式</h3><p>从根本目的来说，C端产品本质是消费，即，通过免费或付费的方式，去解决我们生活过程中遇到的需求。</p>
<p>我们做产品的根本目的，就是创造一款尽可能让更多人来使用的产品，当用户足够多之后，产品才可以通过各种方式让用户付费，从而帮助企业实现盈利。</p>
<p>所以，为了让更多人来用，产品必须先解决用户的核心需求，如，淘宝的出现，一开始，就是为了让人们可以在家，就能买到想买的东西。</p>
<p>可很多人不知道的是，刚面世的淘宝，在使用上也是不太好用的。</p>
<p>因为这还是产品“从无到有”的阶段。</p>
<p>我得先保证你产品能用，解决你的根本需求之后，我才会考虑如何让你“更好用”这个问题。</p>
<p>而随着网络的发展和普及，我们每个人都可以根据自己的喜好和需求，来决定选择使用或不使用一款产品。</p>
<p>因为，当选择增多之后，用户在产品的忠诚度也会随之下降。</p>
<p>在面对同样能满足需求的竞品不断涌现时，如何让用户留下来，就成了产品的首要目标。</p>
<p>而如果一款产品能让用户感觉这款产品比其他产品“更好用”，用户就会持续选择使用这款产品，甚至让用户成为产品的忠实粉丝。</p>
<p>更好用的定义，个人认为主要包括两个层面：</p>
<ol>
<li>新功能，可以解决在使用过程中的问题；</li>
<li>旧功能，用起来比别的产品更顺畅；</li>
</ol>
<p>而使用起来更顺畅，就是用户体验。</p>
<p>俞军产品公式：</p>
<blockquote>
<p>用户价值 = (新体验-旧体验) – 替换成本</p>
</blockquote>
<p>C端产品的替换成本，在同类能够解决需求的C端产品面前，可以算是在一定区间内动态变化的，或者说是可控的。</p>
<p>所以，一款C端产品想要尽可能的获取用户，尽可能地获得市场份额，就需要不断优化你的新体验，拉开与竞品之间的体验差。</p>
<p>同理，你想要让你的用户留存下来，不被其他产品瓜分，也需要不断优化你的用户体验，避免与新产品之间产生体验差。</p>
<p>所以，从这个角度上来说，C端产品用户体验的好坏，就能够直接影响到你的用户留存情况，这也是为什么一线大厂愿意投入大量的资源去优化产品的用户体验。</p>
<h3 id="2-B端产品：解决客户问题为主导"><a href="#2-B端产品：解决客户问题为主导" class="headerlink" title="2. B端产品：解决客户问题为主导"></a>2. B端产品：解决客户问题为主导</h3><p>和C端产品不同的是，B端产品的根本目的是商业，即，开源和节流。</p>
<p>客户选择一款产品，往往是因为这款产品能帮他赚到更多的钱，或者能解决他在团队工作过程中遇到的问题，提升团队的工作效率。</p>
<p>也因此，客户决定是否使用一款产品时，不太可能根据个人的喜好去选择。</p>
<p>同理，客户选择不使用一款产品的时候，也会从更理性的角度去思考问题，包括资金成本、团队学习成本、历史数据无法迁移成本等等。</p>
<p>而其中，客户最大的阻碍，是数据，准确的说，应该是是在产品中留下的经营数据。</p>
<p>比如客户在使用了多年企业微信之后，要换成钉钉，几乎是不可能的。</p>
<p>因为客户在替换时，一旦考虑到整个团队在过去几年中，在产品里留下的工作资料，是无法迁移的，他就准备放弃了。</p>
<p>因为他知道，数据一旦无法迁移，意味着过去很多经营内容，将无法追溯，这其中包括内部沟通资料，对外的业务资料，甚至是财务账单截图等等，都将丢失。</p>
<p>俞军产品公式：</p>
<blockquote>
<p>用户价值 = (新体验-旧体验) – 替换成本</p>
</blockquote>
<p>而从俞军的产品替换公式来解释，随着时间的增加，产品的替换成本将持续增大，如果新产品无法提供更多能服务于团队的新功能，仅仅是因为“用户体验”更好的话，是无法推动客户替换产品的。</p>
<p>除非，当客户团队所有的成员都跟客户反馈说，这款产品太难用了，无法解决多个问题时，客户才会去考虑，是否可以尝试使用下其他的产品了。</p>
<p>所以，从这个角度上来说，用户体验，对B端的产品来说，并不是决定客户是否使用和放弃一款产品的决定因素。</p>
<h2 id="三、当我在说“我不关注产品体验时”，我在说什么"><a href="#三、当我在说“我不关注产品体验时”，我在说什么" class="headerlink" title="三、当我在说“我不关注产品体验时”，我在说什么"></a>三、当我在说“我不关注产品体验时”，我在说什么</h2><p>那回过头来，我们来回答下最开始的那个问题：为什么很多B端产品总说“我不关注用户体验”呢？是因为用户体验真的不重要吗？</p>
<p>在B端行业，如何更快地去帮助客户赚更多的钱， 更好地去帮客户节省更多资金成本，人力成本，才是更有价值的事情。</p>
<p>所以，当B端产品经理这句话时，并不是因为用户体验真的不重要，而是对B端的产品来说，只有关乎产品核心价值的用户体验，才重要的。</p>
<p>可很多初入B端得产品人提出的用户体验，其实和产品价值是无关的。</p>
<p>假如有10个用户体验的优化，可能其中只有2个体验和产品的核心价值有关，所以，公司都会倾向于把资源投入的这两个体验中，把这2个的使用体验做到极致。</p>
<p>比如，企业的支付流程，如何实现支付从T+1提升至时或秒到账的流程优化，提高企业节省支付到账时间这件事，不论多难，产品和开发都会想方设法去克服。</p>
<p>因为这个是产品的核心价值体验，是能够提升企业合作效率，为团队提高工作效率的重要工作。</p>
<p>而在支付流程中，支付的按钮放在左边还是右边，颜色用蓝色还是绿色，对企业来说，真的很重要吗？</p>
<p>我其实只要保证和大多数产品一样，颜色和软件的主色调一致，其实就可以了吧。</p>
<p>于是，你就会发现，市面上大部分的B端产品，在用户体验上，做的或许都不如C端产品。</p>
<p>那也有人会说，那是因为你没有工匠精神，只要增加人力其实也可以做到的。</p>
<p>这会导致投资回报率降低，管理成本增大。</p>
<p>前面也说过，所有的产品，都是为了留住人。影响客户决策是否愿意为产品买单的关键因素，并不是用户体验，而是数据。</p>
<p>而且，不论在什么公司，资源都是不够用的，资源一定是随着业务发展的必要性增加的，自然也就没有公司会愿意，为了不影响产品核心价值的去投入资源。</p>
<p>俗话说，好钢要用在刀刃上，也就是这个道理吧。</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/user-experience-in-tob-products.html" target="_blank">B端产品人为什么总说“我不关注用户体验”</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/user-experience-in-tob-products.html]]></content>
      <categories>
        <category>产品经理</category>
      </categories>
      <tags>
        <tag>产品经理</tag>
        <tag>用户体验</tag>
        <tag>UE</tag>
      </tags>
  </entry>
  <entry>
    <title>RPA是什么？解析AI和RPA结合方式和架构</title>
    <url>/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/whatis-rpa.html</url>
    <content><![CDATA[<p>2019年至今，国产RPA企业已经陆续拿到融资，其中有三起集中发生在6月份，其中一起追加融资发生在8月份，保守估计，5个国产RPA企业融资总金额在8亿人民币上下，但市场估值已高达54.2亿人民币。</p>
<p>资本如此青睐的RPA是何方神圣呢？本文将为读者介绍RPA的定义和概念，RPA的前世今生，实际应用场景，未来发展的趋势（RPA如何与人工智能结合）等方面。</p>
<h1 id="一、RPA的定义和工作原理"><a href="#一、RPA的定义和工作原理" class="headerlink" title="一、RPA的定义和工作原理"></a>一、RPA的定义和工作原理</h1><p>RPA是<code>Robotic Process Automation(机器人流程自动化）</code>的简称。</p>
<p>RPA的概念是由一家研发此类软件的IT创业公司和一家研究机构在2012年所提出的。当前还未有明确的定义概念，RPA的概念主要通过厂商和用户不断地实践总结、口耳相传而逐步推广开来。</p>
<p>我们可以把它理解为：<strong>“虚拟机器人”替代人工的一种方式。RPA不仅可以模拟人类，而且可以利用和融合现有各项技术，实现其流程自动化的目标。</strong></p>
<p>或者可以理解为：<strong>软件自动化=人工+电脑。</strong></p>
<p>由于它可在无需改造原有业务系统的条件下即可为企业实现业务流程自动化，所以这种<code>非侵入式技术</code>部署受到了许多企业的青睐。</p>
<p>为了更好地理解，我们可以举个例子来解释其运行原理。</p>
<p>比如说“按键精灵”——一款在游戏领域被广泛熟知的国产软件，它的一些简单功能能帮助我们完成一些自动化的工作。</p>
<p>“按键精灵”基本的工作原理为：</p>
<ol>
<li>通过录制操作者的鼠标和键盘的动作步骤形成操作脚本</li>
<li>通过手工编辑方式编写脚本</li>
<li>执行流程（或者成批）</li>
</ol>
<p>当执行脚本动作后，便会根据新的脚本运行产生新的动作，这样用户便可以借助这些脚本的改动完成一些简单的操作，形成自动化，理论上便可以解决很多重复性的工作。</p>
<p>以上就是基于RPA原理的示例，其与当前的RPA相比，逻辑并没有本质的差异。如今的RPA工具功能会更加丰富，场景更加多样实用，定制化程度高，针对性更强。</p>
<h1 id="二、RPA的前世今生"><a href="#二、RPA的前世今生" class="headerlink" title="二、RPA的前世今生"></a>二、RPA的前世今生</h1><p>本段落，我们将从时间线角度概述RPA的发展情况，分为：出现前、出现、出现后等时间段。</p>
<h2 id="（1）出现前"><a href="#（1）出现前" class="headerlink" title="（1）出现前"></a>（1）出现前</h2><p>1990年代早中期，计算机开始出现在日常办公中，此时出现的一些软件和工具身上已经具备RPA的雏形。大致可以分为几种：屏幕抓取类、流程自动化工具类等几种类别。</p>
<h3 id="屏幕抓取类："><a href="#屏幕抓取类：" class="headerlink" title="屏幕抓取类："></a>屏幕抓取类：</h3><p>屏幕抓取技术是第一种能在不兼容的两个系统之间建立桥梁的技术，可提取关键术语，扫描大量静态信息等数据。这种数据抓取、数据分类、数据分析的能力是目前RPA的核心功能。</p>
<h3 id="流程自动化工具类："><a href="#流程自动化工具类：" class="headerlink" title="流程自动化工具类："></a>流程自动化工具类：</h3><p>从20世纪90年代开始，各类工作流程自动化软件可以通过捕获某些特定字段的办法来帮助处理订单。</p>
<p>首先获取数据，如：客户联系信息、发票总额和订购的项目清单等；然后形成数据库；最后通知相应的员工。流程自动化存储数据替代手动数据录入的方式提高了订单处理的速度，效率和准确性。</p>
<h2 id="（2）出现"><a href="#（2）出现" class="headerlink" title="（2）出现"></a>（2）出现</h2><p>RPA一词出现在2000年。</p>
<p>此时的RPA已经比之前的“类RPA”有所不同，“取其精华，去其槽粕，推陈出新，革故鼎新”可以很好地总结这一阶段的发展情况。</p>
<p>它已经能将人工智能技术和自动化技术有效结合，其中应用最多的还是OCR技术，这让RPA软件不再依赖于代码进行屏幕抓取，而是允许用户以可视化的方式来使用拖放功能，建立流程管理工作流，并且将重复劳动自动化。这种方式降低了用户的使用门槛，无需专业编码知识即可迅速获取数据与搭建流程，也是RPA的价值所在。</p>
<h2 id="（3）出现后"><a href="#（3）出现后" class="headerlink" title="（3）出现后"></a>（3）出现后</h2><p>随着RPA开始通过简单的操作系统解决更复杂的任务，并且操作容易上手，越来越多的行业大规模投入使用。例如：BPO（Business process outsourcing ，业务流程外包）。</p>
<p>BPO将RPA视为提升效率和生产力的关键驱动因素。两者相辅相成，借助RPA，BPO以更低成本效益、更快响应能力的优势快速实现办公自动化。同时，RPA也得以在外包领域落地。</p>
<p>接着在2010年后，随着“互联网+”和“智能+”提上发展日程，RPA这项技术在各行各业实现了快速增长，特别是在保险、医疗保健、银行、新零售等行业。</p>
<p><strong>RPA的实施大幅降低了人力成本，提高了生产力，同时减少了错误。</strong></p>
<h1 id="三、发展趋势"><a href="#三、发展趋势" class="headerlink" title="三、发展趋势"></a>三、发展趋势</h1><p>RPA未来发展趋势是怎么样的？</p>
<p>RPA 的火热是社会发展的必然趋势，主要基于以下几点：</p>
<ul>
<li>我国人口红利逐渐消失，正加速步入老龄化社会，劳动力的不足情况正在出现；</li>
<li>人工成本增加为企业带来了巨大的财务负担；</li>
<li>互联网技术发展迅速，旧系统无法满足需求，急需扩展业务能力；</li>
<li>人工智能技术逐步从实验室走向市场。</li>
</ul>
<p>RPA会经历四个阶段的发展，前三代RPA不涉及到决策层，只是帮助人执行预先定义好的流程。需要人在初始化和运行的过程中参与监控，确保实施的准确性。</p>
<p>而随着人工智能技术的日益成熟，便产生了第四代RPA发展阶段，即：AI+RPA。人工智能与机器人流程自动化有效结合，进行复杂场景的智能决策，其功能更加完善，应用场景更加广泛，适用范围更广，RPA机器人更加智能，我们具体展开来看这4个发展阶段。</p>
<h2 id="第一个阶段-RPA1-0"><a href="#第一个阶段-RPA1-0" class="headerlink" title="第一个阶段 RPA1.0"></a>第一个阶段 RPA1.0</h2><p>RPA1.0可以理解为辅助人工，既简单的辅助人完成一些基础数据录入、文件打开类的标准化桌面工作，整个工作过程离不开人工干预，无法自动执行，效果往往是辅助单个员工提升较小幅度的工作效率。</p>
<h2 id="第二个阶段-RPA2-0"><a href="#第二个阶段-RPA2-0" class="headerlink" title="第二个阶段 RPA2.0"></a>第二个阶段 RPA2.0</h2><p>RPA2.0，这个阶段的RPA可以部分解放人工，可以自动完成整个业务流程中部分（某个环节）的工作流程，机器人永远不会对这些重复性工作感到无聊，他们会完全按照预定的指示和规则，以最高的效率来完成这些任务，无需人工干预。</p>
<h2 id="第三个阶段-RPA3-0"><a href="#第三个阶段-RPA3-0" class="headerlink" title="第三个阶段 RPA3.0"></a>第三个阶段 RPA3.0</h2><p>RPA3.0可以理解为增强智能RPA，3.0阶段的RPA可以简单融合感知技术，尝试部分获取相关的外部知识，自动化处理目标文档中的非结构化数据，例如发票信息（图像）和来自客户的邮件（文字）。但是本阶段的RPA每次执行的动作都是一致的，他们并不会从每次的重复执行中进行“学习”，也不会在每天的程序化工作中进行自我改进和寻求更优的解决策略。</p>
<h2 id="第四个阶段-RPA4-0"><a href="#第四个阶段-RPA4-0" class="headerlink" title="第四个阶段 RPA4.0"></a>第四个阶段 RPA4.0</h2><p>RPA4.0概念，即通过感知技术(语音、人机交互、视觉)、认知技术(智能决策)、RPA技术相结合， 打造出能够模拟人类进行业务决策和业务处理的智能助理机器人。</p>
<p>RPA和人工智能AI结合后的应用范围超级广泛，一方面可以处理登发邮件、Excel计算、整理文件这类简单重复性工作外；另外还能完成身份信息智能审核、文本OCR智能分析、客服场景辅助决策与自动推荐等复杂决策类工作。</p>
<p>智能助理机器人可以学习人的业务处理经验（数据）， 在复杂的业务场景下，达到接近人或超过人的决策准确率，打破传统RPA技术只能按照特定规则处理业务的局限，实现深度的业务场景覆盖。</p>
<p><strong>我们对RPA和AI的架构是这么设计的：</strong></p>
<ol>
<li>AI+RPA（智慧大脑）通过监控引擎、决策引擎、运筹引擎、控制引擎等方式与Robot“沟通”；</li>
<li>Robot通过AI（例如：OCR,NLP,语音交互）充当“耳眼鼻”更好地执行操作命令；</li>
<li>Robot工作数据反馈给AI+RPA（智慧大脑）,通过算法训练，自身学习，之后选择更优路线运行。</li>
</ol>
<blockquote>
<p>AI（Artificial Intelligence），人工智能：1956年于Dartmouth学会上提出，一种旨在以类似人类反应的方式对刺激做出反应并从中学习的技术，是对人的意识、思维的信息过程的模拟。</p>
</blockquote>
<p>简单说，AI与RPA的关系，就好比“大脑指挥”和“手脚操作”的关系。其特点如下：</p>
<ul>
<li>RPA倾向于重复地执行命令，AI更倾向于发出命令；</li>
<li>RPA机器人能够将简单的工作自动化，并为AI提供大数据；</li>
<li>AI能够根据RPA提供的数据进行模仿并改进流程；</li>
<li>RPA以流程为中心，AI以数据为中心。</li>
</ul>
<p>AI结合机器学习和深度学习，具有很强的自主学习能力，其OCR、NLP、语音识别等技术让RPA拥有认知能力，可以通过大数据不断矫正自己的行为，从而有智能决策和智能运筹能力。</p>
<p>未来，随着RPA技术的不断发展，以及AI的不断落地，双方的融合将会更加快速与深入，进而演变成这一行业的大趋势。</p>
<h1 id="四、一个RPA4-0机器人实际例子"><a href="#四、一个RPA4-0机器人实际例子" class="headerlink" title="四、一个RPA4.0机器人实际例子"></a>四、一个RPA4.0机器人实际例子</h1><p>在我们政策匹配场景的RPA实施过程中，我们成功的完成了一个RPA4.0的成功案例：<strong>政策计算器</strong>。</p>
<p>它是AI+RPA的典型应用，通过人工智能语义分析，构建政策要求与企业条件之间的匹配算法，实现企业与政策双向智能匹配。</p>
<p>我们激动的发现，政策计算器可以有效的解决政府与企业信息不对称、政策自动化录入、自动化解析、自动化校验、企业政策推送、申请信息及时自动提醒等问题。</p>
<p>最让人惊喜的是，政策计算器可以智能评估企业多维度发展指数，量化评估企业自身条件与激励政策之间的距离，并综合专业政策解读经验提供专属行动建议，达到了在政策发布与匹配场景下RPA4.0所具备的卓越效果。为各级政府和企业的政策相关工作带来显著的提质降本增效！</p>
<br><hr><b>转载请注明出处：</b><a href="https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/whatis-rpa.html" target="_blank">RPA是什么？解析AI和RPA结合方式和架构</a><br><b>原文地址：</b>https://www.xiaotanzhu.com/%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86/whatis-rpa.html]]></content>
      <categories>
        <category>产品经理</category>
      </categories>
      <tags>
        <tag>产品经理</tag>
        <tag>RPA</tag>
      </tags>
  </entry>
</search>
